best_valid_epoch:37.0
train loss:0.0026650084
valid loss:0.2210589
test loss list:tf.Tensor(0.19645998, shape=(), dtype=float32)
mean test loss:0.19645998
mean loss list:tf.Tensor(0.17702594, shape=(), dtype=float32)
mean mean loss:0.17702594
accuracy list:[<tf.Tensor: shape=(), dtype=float64, numpy=0.769890022788071>]
mean accuracy:0.769890022788071
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/test_locks_8.c-1_000.smt2
true label:[0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0]
true label rank:[1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 1 2 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 2 1
 2 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 2 1
 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1]
predicted label:tf.Tensor(
[0.42563772 0.43974438 0.44217938 0.4232688  0.4448203  0.41413543
 0.41788945 0.41587496 0.43165794 0.41705668 0.4272064  0.4166648
 0.43561316 0.4361439  0.4193678  0.38037708 0.42622152 0.38658905
 0.4017644  0.3817497  0.3916782  0.38775367 0.38954663 0.3957119
 0.39501435 0.4062386  0.40098774 0.39714855 0.39853498 0.4029828
 0.3888492  0.4362749  0.45901132 0.423163   0.42245018 0.41109118
 0.47033986 0.44111893 0.44181958 0.46899864 0.44900647 0.464254
 0.4696328  0.44363084 0.47581398 0.48269728 0.46652815 0.437992
 0.4189483  0.4324274  0.44756153 0.46722597 0.44606513 0.46314028
 0.44204354 0.46135804 0.42991927 0.4201534  0.44850034 0.447072
 0.4538021  0.4498645  0.4615183  0.43496624 0.45025036 0.46416003
 0.4692587  0.43916184 0.45436352 0.44351205 0.4667872  0.4474957
 0.4439556  0.42546457 0.43971696 0.4530015  0.4462574  0.47028765
 0.47487336 0.47235796 0.4546416  0.4648953  0.4634447  0.47046742
 0.45519498 0.4544384  0.46581292 0.4608411  0.47338012 0.43836278
 0.46135068 0.4764692  0.45672855 0.4945064  0.47957563 0.45547855
 0.39446208 0.43391582 0.44387665 0.41559842 0.42163354 0.42936397
 0.43647024 0.43578577 0.44393796 0.43181533 0.40983468 0.42999816
 0.43697625 0.4367395  0.42726016 0.415106   0.42877918 0.39686638
 0.44641864 0.39408538 0.4300784  0.41149053 0.4717205  0.48141047
 0.4621214  0.47630584 0.4478596  0.45611355 0.47502142 0.47512156
 0.47432652 0.4606479  0.4575104  0.46838072 0.4299329  0.47027484
 0.41381156 0.4349839  0.4432722  0.4758361  0.43054262 0.40841672
 0.42159468 0.44086182 0.42038935 0.45198706 0.39805725 0.41481724], shape=(144,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(144,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.23443545, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0031_000.smt2
true label:[1, 1, 1]
true label rank:[1 1 1]
predicted label:tf.Tensor([0.4751054  0.47900435 0.48258427], shape=(3,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)
predicted label rank:[1 1 1]
mse:tf.Tensor(0.27155662, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/bandec.smt2-0157_000.smt2
true label:[1, 1, 1, 1]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([0.4660918  0.46976864 0.47003043 0.47000492], shape=(4,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)
predicted label rank:[1 1 1 1]
mse:tf.Tensor(0.28199145, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0036_000.smt2
true label:[0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1]
predicted label:tf.Tensor([0.13470069 0.11975765 0.06580412 0.14420798 0.23276842 0.09834152], shape=(6,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0.], shape=(6,), dtype=float32)
predicted label rank:[1 1 1 1 1 1]
mse:tf.Tensor(0.020244082, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/s_multipl_11_000.smt2
true label:[0, 0, 1, 0, 0]
true label rank:[1 1 2 1 1]
predicted label:tf.Tensor([0.4759468  0.48007286 0.4734947  0.47295344 0.46158668], shape=(5,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.23419006, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/06.c_000.smt2
true label:[0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0]
true label rank:[1 2 2 1 1 2 2 1 1 2 2 1 1 2 2 1 1 2 2 1]
predicted label:tf.Tensor(
[0.46505958 0.46269116 0.46912685 0.44157517 0.46954733 0.47819003
 0.4610545  0.47624016 0.4743401  0.4645724  0.47264516 0.46547654
 0.47476006 0.46812266 0.463876   0.46841332 0.4706466  0.4654343
 0.47241387 0.4565602 ], shape=(20,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.25037348, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/xy10.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.05418152 0.08737999 0.03929824 0.09138066 0.21398658 0.01762047
 0.01784509], shape=(7,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0.], shape=(7,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1]
mse:tf.Tensor(0.009554979, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0102_000.smt2
true label:[1, 1]
true label rank:[1 1]
predicted label:tf.Tensor([0.48315248 0.47489017], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 0.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.27143583, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/bandec.smt2-0148_000.smt2
true label:[0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1]
true label rank:[1 2 2 2 1 1 1 1 1 2 2 1 2 1 2 2 2 1 1 1 1 1 2]
predicted label:tf.Tensor(
[0.43811464 0.42706537 0.42642692 0.41363025 0.42116868 0.42598522
 0.44013882 0.43011996 0.43462485 0.44066522 0.43516114 0.43033165
 0.4278126  0.46063527 0.44827113 0.4451682  0.44583377 0.44180375
 0.43228704 0.44306168 0.45199347 0.44585946 0.43567526], shape=(23,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(23,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.24762662, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0016_000.smt2
true label:[0, 0, 0, 1]
true label rank:[1 1 1 2]
predicted label:tf.Tensor([0.28385472 0.32953063 0.35819367 0.31953186], shape=(4,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)
predicted label rank:[1 1 1 1]
mse:tf.Tensor(0.19512588, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/s3_srvr_8.cil.c-1_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1
 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 2 2 1 1 1 1
 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 1 2 2 2 2 2 1 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 2 2 1 2 2 2 1 1 1 1 1 1
 1 1 2 2 1 1 1 2 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2
 2 2 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 2 2 1
 1 2 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 2 2 2 2 2 2 1 1
 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1
 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 2 2]
predicted label:tf.Tensor(
[3.8361990e-01 3.8921446e-01 4.1654259e-01 3.9532444e-01 3.9605090e-01
 3.8802367e-01 3.7710100e-01 3.9689079e-01 3.8326254e-01 3.9658824e-01
 3.9451405e-01 3.8657638e-01 4.2460954e-01 3.9466697e-01 3.8518101e-01
 3.8210344e-01 4.2237079e-01 4.0289110e-01 4.0284351e-01 3.7511045e-01
 3.8694328e-01 3.8714162e-01 3.7164766e-01 1.0062439e-04 5.6649148e-03
 4.4813187e-05 5.1584975e-05 7.0059382e-06 9.3464414e-06 4.8592091e-03
 2.7332306e-03 2.8452277e-04 1.4945269e-03 1.6042590e-04 8.9210398e-06
 7.9267025e-03 2.2122890e-02 8.0777781e-06 8.3062053e-04 1.0797942e-01
 1.6438313e-05 4.6190619e-04 3.3947408e-02 4.9546361e-04 3.2832026e-03
 5.9562624e-02 4.1948551e-01 4.1569269e-01 3.7958777e-01 4.2286551e-01
 4.0473267e-01 4.3846774e-01 4.2295873e-01 4.2806414e-01 4.0986714e-01
 4.3394005e-01 4.1097188e-01 4.2038518e-01 4.1886985e-01 3.9084980e-01
 4.2036521e-01 4.0409815e-01 3.9001408e-01 4.0699795e-01 3.9708599e-01
 4.5099065e-01 4.2736569e-01 3.8542503e-01 4.0030584e-01 4.0414089e-01
 4.1716227e-01 3.8350785e-01 3.9441732e-01 3.6895716e-01 3.8525558e-01
 3.8585711e-01 3.8828146e-01 4.0334326e-01 3.9273620e-01 4.2277148e-01
 3.9378446e-01 3.7935257e-01 4.0943113e-01 4.0903383e-01 4.0146792e-01
 4.0587255e-01 4.2921746e-01 3.8760293e-01 4.1605589e-01 3.8855764e-01
 3.9364490e-01 4.2079633e-01 4.1197079e-01 3.8996404e-01 4.3548188e-01
 4.5680979e-01 4.3458256e-01 4.3028697e-01 4.4227320e-01 4.3551713e-01
 4.4315726e-01 4.2096439e-01 4.2639428e-01 4.3092242e-01 4.2532277e-01
 4.2404976e-01 4.1527829e-01 4.4674101e-01 4.3482193e-01 4.3869486e-01
 4.4609383e-01 4.3519676e-01 4.4115180e-01 4.1578734e-01 4.3688574e-01
 4.2546350e-01 4.3974590e-01 4.2895561e-01 4.3313107e-01 4.6038306e-01
 4.2935482e-01 4.4445348e-01 4.2273813e-01 4.3568775e-01 4.3152392e-01
 4.4167209e-01 4.3962607e-01 4.2774123e-01 4.4570103e-01 4.3424085e-01
 4.3638745e-01 4.5500252e-01 4.5078605e-01 4.3819836e-01 4.4277906e-01
 4.2696267e-01 4.5300362e-01 4.3213964e-01 4.4696856e-01 4.4580036e-01
 4.4762510e-01 4.5092312e-01 4.7331011e-01 4.6827653e-01 4.7211832e-01
 4.5861393e-01 4.6133429e-01 4.6861300e-01 4.6532005e-01 4.6729454e-01
 4.6714324e-01 4.7292006e-01 4.7118717e-01 4.6827832e-01 4.6485367e-01
 4.6915311e-01 4.6403071e-01 4.5713782e-01 4.6944165e-01 4.5787412e-01
 4.7080424e-01 4.6420175e-01 4.6297076e-01 4.6859255e-01 4.6485308e-01
 3.9904273e-01 4.5080209e-01 4.1909033e-01 4.2825645e-01 4.4194272e-01
 4.2698592e-01 3.9545304e-01 4.1730249e-01 4.1300800e-01 4.4273499e-01
 3.8976112e-01 4.4314176e-01 4.2455566e-01 3.9441556e-01 3.6788148e-01
 4.4468865e-01 4.2278528e-01 4.3672222e-01 4.1627580e-01 3.6240393e-01
 3.9647174e-01 4.3826422e-01 4.2136297e-01 4.4548392e-01 4.4110599e-01
 4.0714276e-01 4.1228423e-01 4.1247129e-01 4.2015553e-01 4.2924821e-01
 4.1579211e-01 4.0356705e-01 3.8590705e-01 4.2571661e-01 4.1776383e-01
 4.3891272e-01 3.8996691e-01 4.1122365e-01 4.5013091e-01 4.2673853e-01
 4.0349001e-01 4.0227586e-01 4.2442340e-01 4.1030547e-01 4.1991276e-01
 4.5502958e-01 4.4827801e-01 4.4834960e-01 4.4735375e-01 4.5095655e-01
 4.4372523e-01 4.4056159e-01 4.3479568e-01 4.5049870e-01 4.4755211e-01
 4.6110627e-01 4.5587373e-01 4.4227132e-01 4.4791564e-01 4.4136915e-01
 4.5267391e-01 4.4873676e-01 4.4194672e-01 4.5320177e-01 4.4752401e-01
 4.4884887e-01 4.5399228e-01 4.4633454e-01 4.5050049e-01 4.6639615e-01
 4.5934239e-01 4.4819206e-01 4.7577736e-01 4.5913067e-01 4.5749220e-01
 4.6498013e-01 4.4596359e-01 4.7235402e-01 4.4752249e-01 4.5078132e-01
 4.5607123e-01 4.6547136e-01 4.6331200e-01 4.4799140e-01 4.6230882e-01
 4.7710499e-01 4.5782712e-01 4.7145072e-01 4.6260419e-01 4.5596021e-01
 4.6447629e-01 4.3967468e-01 4.6959323e-01 4.7536656e-01 4.6562815e-01
 4.6917427e-01 4.6624765e-01 4.7043347e-01 4.6506944e-01 4.5425037e-01
 4.5764732e-01 4.5465806e-01 4.7360340e-01 4.5527381e-01 4.6874866e-01
 4.5858762e-01 4.5668709e-01 4.6945280e-01 4.6973562e-01 4.5970970e-01
 4.6300000e-01 4.7031280e-01 4.5329115e-01 4.7626865e-01 4.6728158e-01
 4.5646548e-01 3.9658999e-01 4.3551588e-01 3.9573240e-01 4.0930152e-01
 3.7155169e-01 4.4152912e-01 4.1470063e-01 4.1767347e-01 4.0625456e-01
 4.1593561e-01 4.1357127e-01 4.1854763e-01 4.0867010e-01 4.0719470e-01
 4.0656090e-01 4.2452255e-01 4.2660722e-01 4.0868211e-01 4.0786028e-01
 4.0158251e-01 4.2300937e-01 4.3273395e-01 3.9793724e-01 4.0059751e-01
 4.1730428e-01 3.9065790e-01 4.1127372e-01 3.9694393e-01 3.8988817e-01
 4.3321085e-01 4.0153193e-01 4.3088040e-01 3.9754772e-01 3.9208353e-01
 4.0328705e-01 4.1559151e-01 4.1942745e-01 4.4371903e-01 4.1567370e-01
 3.9132184e-01 4.1288620e-01 4.0159431e-01 4.3048000e-01 4.4474477e-01
 4.2541620e-01 4.1981444e-01], shape=(327,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(327,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.24463049, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/heapsort_true-unreach-call.c.flat_000.smt2
true label:[0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0]
true label rank:[1 1 1 1 1 1 2 1 1 2 1 1 2 1]
predicted label:tf.Tensor(
[0.46828443 0.4750536  0.48587304 0.4763426  0.468855   0.4717102
 0.00508636 0.03423873 0.01588207 0.26361758 0.07946822 0.01983747
 0.03529224 0.15425703], shape=(14,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(14,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.2746413, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/metros_1_e2_1102_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1
 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1
 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1
 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2
 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1
 1 1 1 1 1 2 2 1 1 1 2 1 2 1 2 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 2 2 1
 1 1 1 1 1 1 2 2 2 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 2 2 1 1 2 1 1 2 1 1 1 1 1
 1 2 2 2 2 1 1 1 1 2 1 1 1 1 2 1 1 2 2 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1 2 2 2
 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 2 1 2 2 1 1 2 2 1 1 1 1 1 1 1 1 1 2 2 1 2
 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1
 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 2 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 2 1 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 1 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[4.88269329e-03 6.86880946e-02 6.83102012e-03 6.88970089e-03
 8.55948627e-02 4.32235003e-03 4.78497148e-03 1.85190141e-02
 2.78156996e-03 1.62434340e-01 1.86348766e-01 9.54565406e-03
 6.29061162e-02 2.04771191e-01 1.41852081e-01 5.67832589e-03
 1.14917070e-01 2.13793814e-02 5.20719051e-01 4.27007675e-04
 1.76805258e-03 2.42531300e-03 2.00664997e-03 8.97884369e-03
 1.07048512e-01 6.18550181e-03 4.56503034e-03 1.85009837e-03
 3.10143828e-03 6.22121990e-02 4.46496308e-02 6.17936254e-03
 3.90454233e-02 4.70939279e-03 1.11165643e-03 5.11334538e-02
 6.51314259e-02 8.11487436e-03 2.19943523e-02 2.18630731e-01
 3.82447243e-03 7.56327808e-02 2.95652032e-01 1.43800378e-02
 5.93536496e-02 4.53827381e-01 3.31404448e-01 4.35394555e-01
 4.16139334e-01 3.68089259e-01 3.28141212e-01 3.44769120e-01
 2.70378411e-01 3.26312333e-01 3.04145247e-01 2.91416466e-01
 3.41947913e-01 2.88128793e-01 2.56465077e-01 2.61096150e-01
 3.08929145e-01 3.22547615e-01 2.35485733e-01 2.95352519e-01
 3.79324287e-01 3.83451700e-01 3.70120615e-01 3.33095312e-01
 2.78717875e-01 3.58244270e-01 3.74764740e-01 2.62734711e-01
 3.51715267e-01 3.19016039e-01 2.61752665e-01 3.17671418e-01
 3.22822809e-01 3.43158275e-01 3.84801179e-01 3.52206558e-01
 3.49538624e-01 3.89187217e-01 3.32819462e-01 3.65049064e-01
 2.66145766e-01 2.55607247e-01 3.27427328e-01 3.65256846e-01
 3.84401262e-01 3.50572199e-01 3.12426537e-01 4.23670799e-01
 3.55515271e-01 2.54669070e-01 3.80814463e-01 3.62217844e-01
 3.18513930e-01 3.94219875e-01 4.13690120e-01 3.29218388e-01
 2.67899394e-01 4.25561219e-01 3.77204031e-01 3.44734192e-01
 2.85764664e-01 4.06142771e-01 2.99180329e-01 3.64517838e-01
 3.59343946e-01 3.36360365e-01 3.61174196e-01 3.36774051e-01
 3.64318430e-01 2.88063139e-01 4.10176903e-01 2.96835184e-01
 2.23430187e-01 3.06587160e-01 3.43733221e-01 4.05860364e-01
 3.41923177e-01 3.93459022e-01 2.53500015e-01 3.06412995e-01
 3.61579478e-01 3.78602207e-01 3.56552780e-01 3.15705001e-01
 2.98129886e-01 4.00762111e-01 3.54984879e-01 4.66750145e-01
 3.52609158e-01 4.18079227e-01 3.51901948e-01 3.20791960e-01
 3.86185884e-01 3.65380228e-01 3.31597954e-01 2.96712101e-01
 3.75972986e-01 3.67122233e-01 3.98329675e-01 3.77924889e-01
 2.94047385e-01 4.57965493e-01 4.36423093e-01 4.43557203e-01
 4.33177710e-01 4.40769702e-01 4.20602500e-01 4.43639785e-01
 4.22989607e-01 4.38086987e-01 4.30255294e-01 4.28647846e-01
 4.16987032e-01 4.17878896e-01 4.35276479e-01 3.94611716e-01
 4.14760888e-01 4.25171107e-01 4.43598509e-01 4.02185142e-01
 4.60263014e-01 4.39332694e-01 4.65394437e-01 4.43711668e-01
 4.41583097e-01 4.48361516e-01 4.60099488e-01 4.38749015e-01
 4.39131767e-01 4.16514158e-01 4.48454618e-01 4.37776208e-01
 4.33256567e-01 4.35693920e-01 4.30735826e-01 4.20932829e-01
 4.71050292e-01 4.35933352e-01 4.61160600e-01 4.62487161e-01
 4.02366132e-01 4.34505165e-01 4.46540773e-01 4.10078168e-01
 4.45528626e-01 4.18402612e-01 4.08044994e-01 4.37459052e-01
 4.40639228e-01 4.07741755e-01 4.16216552e-01 4.12883282e-01
 3.99267137e-01 4.13627744e-01 4.33648348e-01 4.18201983e-01
 4.57786232e-01 4.35355067e-01 4.20343846e-01 4.52542543e-01
 4.31687623e-01 4.23101127e-01 4.37405348e-01 4.47949082e-01
 4.20370519e-01 4.26196784e-01 4.41825122e-01 3.99624586e-01
 4.08239782e-01 4.51136053e-01 4.34937418e-01 4.29025084e-01
 4.39585745e-01 4.23173845e-01 4.14767206e-01 4.36014444e-01
 4.58167255e-01 4.55247760e-01 4.09067392e-01 4.34396714e-01
 4.36728328e-01 4.54206377e-01 4.10975456e-01 4.43437248e-01
 4.65512693e-01 4.20324773e-01 4.45606768e-01 4.17382538e-01
 4.30911511e-01 4.11463946e-01 4.40075606e-01 4.38971847e-01
 4.36228693e-01 4.55128670e-01 4.43321288e-01 4.07106280e-01
 4.45444733e-01 4.37125444e-01 4.36740518e-01 4.35276955e-01
 4.23902214e-01 4.22275782e-01 4.42626536e-01 4.44887996e-01
 4.23923582e-01 4.78555888e-01 4.55157816e-01 4.66721147e-01
 4.61509049e-01 4.46464002e-01 4.37201500e-01 4.40431476e-01
 3.93105865e-01 4.10505623e-01 4.33304608e-01 4.08009231e-01
 4.54853654e-01 4.41265285e-01 4.44239765e-01 4.17421460e-01
 4.38689202e-01 4.48768914e-01 4.57883209e-01 4.26523209e-01
 4.16910648e-01 4.63202745e-01 4.32581306e-01 4.45472062e-01
 4.27731514e-01 4.43056703e-01 4.66192007e-01 4.39762712e-01
 4.36782807e-01 4.55497682e-01 4.56842989e-01 4.52021390e-01
 4.44146067e-01 4.46684062e-01 4.49972034e-01 4.31543231e-01
 4.02058542e-01 3.84549886e-01 4.31060940e-01 4.01538849e-01
 3.87085140e-01 4.14142728e-01 3.93988609e-01 4.24445480e-01
 3.96651894e-01 4.12429363e-01 3.90528262e-01 3.80658388e-01
 4.44775730e-01 4.09293354e-01 4.04641777e-01 4.02157426e-01
 3.85922134e-01 4.17520881e-01 4.40470636e-01 3.98310602e-01
 4.49392378e-01 1.17450655e-02 4.64606285e-03 2.52720714e-03
 3.23957205e-03 6.41752183e-02 2.26196855e-01 6.81132078e-04
 8.63617659e-03 7.62982965e-02 1.07312202e-03 2.61576297e-05
 8.60446692e-03 7.32958317e-03 1.38378143e-03 1.25887930e-01
 7.72830248e-02 1.19918585e-03 8.99404287e-04 2.31927335e-02
 5.27426600e-03 5.38855791e-04 8.32438469e-04 1.70350075e-04
 4.45913464e-01 4.44663018e-01 4.63812411e-01 4.54099476e-01
 4.40562427e-01 4.46117848e-01 4.64093447e-01 4.57271069e-01
 4.22129214e-01 4.40438867e-01 4.56020594e-01 4.42134023e-01
 4.43238497e-01 4.43795055e-01 4.43675816e-01 4.45462316e-01
 4.31697845e-01 4.29923534e-01 4.33847696e-01 4.51532573e-01
 4.30065930e-01 4.44417119e-01 4.09107655e-01 4.57223207e-01
 4.43534195e-01 4.15377319e-01 4.40685987e-01 4.20391500e-01
 3.92226279e-01 4.29659605e-01 4.29689199e-01 4.27339137e-01
 4.51889396e-01 4.16867346e-01 4.42046762e-01 4.21056151e-01
 4.45585161e-01 4.69362259e-01 4.11554694e-01 4.33297873e-01
 4.30055916e-01 4.18747276e-01 4.50795084e-01 4.45866138e-01
 4.44171995e-01 4.22751158e-01 4.34916735e-01 4.32215154e-01
 4.44372445e-01 2.70650387e-01 3.52985680e-01 4.34312433e-01
 2.97215700e-01 4.17627066e-01 3.23324949e-01 3.28326881e-01
 3.63931715e-01 3.05944055e-01 3.91139448e-01 3.84400696e-01
 3.59167010e-01 4.38857853e-01 4.13881868e-01 2.75071591e-01
 3.23116690e-01 3.00729692e-01 3.38025331e-01 3.77289116e-01
 3.73431444e-01 2.61167735e-01 3.59519660e-01 2.91513145e-01
 3.05575252e-01 3.71756971e-01 3.53196323e-01 2.46928006e-01
 3.30730081e-01 2.25517988e-01 3.15102011e-01 3.24331760e-01
 3.19563925e-01 3.49400461e-01 3.40941399e-01 4.48340476e-01
 3.77968967e-01 4.20969039e-01 4.37030196e-01 4.31713372e-01
 3.71115148e-01 4.56981510e-01 4.25386637e-01 3.94960672e-01
 4.25381482e-01 4.18912262e-01 4.52756464e-01 4.45423156e-01
 4.36431140e-01 4.18365359e-01 4.12765801e-01 4.20414656e-01
 4.12978381e-01 4.12226826e-01 4.03770894e-01 3.75133932e-01
 3.94995689e-01 4.04703408e-01 3.86567891e-01 3.79253507e-01
 3.93758833e-01 3.48649621e-01 3.91846597e-01 4.33008015e-01
 3.95011514e-01 3.68180931e-01 4.12990838e-01 3.84421289e-01
 3.90659571e-01 3.91038358e-01 3.60725343e-01 4.16912943e-01
 4.04358119e-01 4.19801116e-01 4.21181083e-01 4.26164627e-01
 4.25075382e-01 4.15209711e-01 4.14851725e-01 4.29340631e-01
 4.10924017e-01 4.66089904e-01 4.25621778e-01 4.19112623e-01
 3.73239517e-01 4.12779957e-01 4.22216654e-01 4.28621888e-01
 4.30300713e-01 4.31844354e-01 4.31354493e-01 4.09162819e-01
 4.28804487e-01 4.32657510e-01 4.49471116e-01 4.23283637e-01
 4.43730712e-01 4.30887043e-01 4.51769710e-01 4.48242098e-01
 4.54248309e-01 4.17548656e-01 4.57511663e-01 4.39011812e-01
 4.40286756e-01 4.32927638e-01 4.40370619e-01 4.42623317e-01
 4.29867566e-01 4.39650416e-01 4.38310325e-01 4.66998816e-01
 1.16655827e-02 5.61193228e-02 3.69310677e-02 4.58142161e-03
 1.11136138e-02 1.98670059e-01 2.76796222e-02 1.14701122e-01
 1.98317170e-02 8.85406137e-03 2.30761141e-01 1.69281960e-02
 5.50422072e-02 1.32766366e-03 1.06613606e-01 8.31202269e-02
 1.00348264e-01 2.02762604e-01 4.56946492e-02 3.69310379e-04
 2.14126557e-01 6.71948195e-02 5.18803000e-02 1.40788257e-02
 8.37047994e-02 1.56396210e-01 1.40897423e-01 2.05265641e-01
 3.78896713e-01 1.70088470e-01 1.19386137e-01 2.28280991e-01
 1.87226295e-01 1.33598864e-01 8.49087238e-02 1.99476391e-01
 1.02660060e-01 1.66437656e-01 1.66892081e-01 8.84944201e-02
 8.82565975e-02 1.35966927e-01 5.30874133e-02 1.40841752e-01
 9.14103687e-02 1.76263779e-01 1.27648473e-01 4.11490500e-01
 4.01710570e-01 3.95071477e-01 4.12955284e-01 4.01923835e-01
 4.01812315e-01 4.03277576e-01 4.10791010e-01 4.06290233e-01
 3.99422437e-01 3.94236386e-01 4.08615828e-01 4.04359430e-01
 4.04584408e-01 4.04404134e-01 4.06006575e-01 3.95941436e-01
 4.00550812e-01 3.93822581e-01 4.01922792e-01 3.98620427e-01
 4.02123302e-01 4.04774249e-01 4.09423143e-01 3.87503654e-01
 3.71226132e-01 4.04163033e-01 4.14628923e-01 4.08123434e-01
 4.25672233e-01 3.91231239e-01 3.93467903e-01 3.63466859e-01
 4.14795250e-01 4.02273923e-01 4.13414747e-01 4.01147991e-01
 4.04139251e-01 4.15584713e-01 4.02834415e-01 4.17873532e-01
 3.78872931e-01 4.15109903e-01 4.02343810e-01 4.00749564e-01
 4.05079961e-01 4.18300748e-01 4.63471800e-01 4.54588801e-01
 4.56162483e-01 4.46908891e-01 4.59520012e-01 4.24168587e-01
 4.41103935e-01 4.53169793e-01 4.60798442e-01 4.44607168e-01
 4.55732971e-01 4.58099663e-01 4.16051030e-01 4.53671396e-01
 4.53261912e-01 4.63380396e-01 4.71031755e-01 4.43260729e-01
 4.66576308e-01 4.29497480e-01 4.68822598e-01 4.48608994e-01
 4.52515095e-01 4.46979284e-01 4.15360242e-01 4.51357991e-01
 4.60754693e-01 4.32357252e-01 4.29383725e-01 3.89085591e-01
 4.31466073e-01 4.54980940e-01 4.54523981e-01 4.02367383e-01
 4.03749257e-01 4.37334955e-01 4.18592930e-01 4.35285807e-01
 4.26804870e-01 4.38206136e-01 4.55031723e-01 4.31638241e-01
 4.48751450e-01 4.45137471e-01 4.15942073e-01 4.14277196e-01
 4.21438068e-01 4.33414340e-01 4.12761956e-01 4.21087801e-01
 4.32242870e-01 4.37905490e-01 4.05788571e-01 4.38178062e-01
 3.95956397e-01 4.58652645e-01 4.44472790e-01 4.06043917e-01
 4.52361584e-01 3.99527639e-01 4.16891724e-01 4.14484829e-01
 4.24927354e-01 4.45804179e-01 4.41683620e-01 4.51400518e-01
 4.28045183e-01 4.25852835e-01 4.08865392e-01 4.29730594e-01
 4.37425852e-01 4.08529669e-01 4.41733450e-01 4.45006013e-01
 4.36589420e-01 4.54377502e-01 4.27536428e-01 4.36650097e-01
 4.47169662e-01 4.13493574e-01 4.31619406e-01 4.25294727e-01
 4.29581314e-01 3.95905316e-01 4.20887530e-01 4.22332078e-01
 4.37550873e-01 4.34896767e-01 4.29022014e-01 4.25391614e-01
 3.90560389e-01 3.84660661e-01 3.88856590e-01 3.78957808e-01
 3.81069839e-01 3.85528266e-01 3.86093438e-01 3.80313635e-01
 3.86339396e-01 3.85375947e-01 3.76618266e-01 3.84701014e-01
 3.86980474e-01 3.86845857e-01 3.91327709e-01 3.86473268e-01
 3.78573239e-01 3.81154925e-01 3.90783489e-01 3.90230209e-01
 3.80213648e-01 3.90119284e-01 3.83393198e-01 3.85801315e-01
 3.95667493e-01 3.82159323e-01 3.86600822e-01 3.81158769e-01
 3.87686163e-01 3.91926646e-01 3.90579641e-01], shape=(703,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0.], shape=(703,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.19598338, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/jm2006_true-unreach-call.c.flat_000.smt2
true label:[0, 0, 0, 0]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([0.4646317  0.46498048 0.4768194  0.46648005], shape=(4,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)
predicted label rank:[1 1 1 1]
mse:tf.Tensor(0.21926247, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/gulwani_fig1a.c_000.smt2
true label:[0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1]
predicted label:tf.Tensor([0.11708322 0.10186392 0.04560775 0.09816253 0.19383797 0.07918835], shape=(6,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0.], shape=(6,), dtype=float32)
predicted label rank:[1 1 1 1 1 1]
mse:tf.Tensor(0.013274107, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/minepump_spec2_product64_true-unreach-call.cil.c.flat_000.smt2
true label:[1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1]
predicted label:tf.Tensor([1.7683952e-22 1.4008655e-21 3.0412468e-28 0.0000000e+00 3.4740921e-14], shape=(5,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(1.0, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/diamond_1-1.c-1_000.smt2
true label:[1, 1]
true label rank:[1 1]
predicted label:tf.Tensor([0.45960435 0.4806468 ], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 0.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.2808776, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/break_single_merged_safe.c-1_000.smt2
true label:[0, 1, 0, 1, 1]
true label rank:[1 2 1 2 2]
predicted label:tf.Tensor([0.45660874 0.4792055  0.4434265  0.46487874 0.4617628 ], shape=(5,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.2504799, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/while_after_while_if_merged_safe.c-1_000.smt2
true label:[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0]
true label rank:[2 1 1 1 1 2 1 1 2 1 2 2 1 1 1 2 2 1]
predicted label:tf.Tensor(
[0.4544631  0.46251765 0.47289962 0.4616518  0.4643671  0.46558887
 0.46433282 0.46718308 0.4693783  0.4707831  0.46616867 0.4716511
 0.4633187  0.47479603 0.47695464 0.48424742 0.48746687 0.48451087], shape=(18,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(18,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.24342966, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/nested-while_merged_safe.c-1_000.smt2
true label:[1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 2 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.44845822 0.4693847  0.46364912 0.45826936 0.46206838 0.47064817
 0.45120156 0.46366638 0.47035336 0.47332355 0.47252795 0.45110077
 0.4680345  0.4755656  0.47038668 0.4684047  0.42990085 0.46478787
 0.48073962 0.3903157  0.4324205  0.42286667 0.46232125 0.437325
 0.44645256], shape=(25,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0.], shape=(25,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.23376983, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/cyclic.smt2-0007_000.smt2
true label:[1, 0]
true label rank:[2 1]
predicted label:tf.Tensor([0.48592559 0.4747351 ], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 0.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.24482298, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0000_000.smt2
true label:[1, 1]
true label rank:[1 1]
predicted label:tf.Tensor([0.47559965 0.48481998], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 0.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.27020308, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0270_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[1.0909447e-37 4.0735831e-28 0.0000000e+00 0.0000000e+00 9.5349301e-17
 2.2727129e-34 0.0000000e+00 4.7593504e-01 4.7910923e-01 3.6571068e-01
 3.6447251e-01 3.6632088e-01 3.8894060e-01 3.7380385e-01 3.7183201e-01
 3.9370543e-01 3.7166685e-01 4.6723109e-01 4.5517451e-01 4.6686661e-01
 4.6156642e-01 4.5475391e-01 4.6349856e-01 4.6352559e-01 4.5746285e-01
 4.5578319e-01 4.6832016e-01 4.6151263e-01 4.6054018e-01 4.6513164e-01
 4.6863139e-01 4.7655350e-01 4.7450081e-01 4.5322821e-01 4.7089002e-01
 4.7296819e-01 4.6197721e-01 4.6818772e-01 4.7031057e-01 4.7511566e-01
 4.7417864e-01 4.6912298e-01 4.7563568e-01 4.8041421e-01 4.8425007e-01
 4.4242439e-01 4.4514021e-01 4.4428146e-01 4.4214913e-01 4.4852823e-01
 4.5302555e-01 4.4766253e-01 4.7315213e-01 4.6754295e-01 4.7002685e-01
 4.7582239e-01 4.6043101e-01 4.7683203e-01 4.6792388e-01 4.7244412e-01
 4.7918844e-01 4.7928852e-01 4.5739812e-01 4.6627846e-01 4.6729487e-01
 4.7047728e-01 4.8733920e-01 4.7531828e-01 4.7328669e-01 4.7934496e-01
 4.8783275e-01 4.8482174e-01 4.8171854e-01 4.4333306e-01 4.3362081e-01
 4.6236280e-01 4.5816880e-01 4.5560730e-01 4.4087905e-01 4.4889462e-01
 4.6610710e-01 4.4918552e-01 4.7456676e-01 4.5639241e-01 4.6963271e-01
 4.6664801e-01 4.6938208e-01 3.8707691e-01 4.3357420e-01 3.7700820e-01
 3.4614328e-01 4.6831048e-01 3.3414459e-01 3.0269113e-01 4.8047122e-01
 3.5260326e-01 3.2669008e-01 3.7717247e-01 4.2517203e-01 3.2404280e-01
 3.2109100e-01 4.0936732e-01 4.0128207e-01 4.0002674e-01 3.5894608e-01
 4.1556877e-01 3.2954377e-01 3.7433255e-01 4.6388894e-01 4.0548643e-01
 3.8772985e-01 4.0445274e-01 3.9413986e-01 3.4479797e-01 4.4677469e-01
 3.2616782e-01 3.9176238e-01 3.5941070e-01 3.3508387e-01 4.1702062e-01
 3.2609582e-01 3.2943934e-01 2.6991051e-01 3.4412631e-01 3.6222807e-01
 3.7822258e-01 3.0199802e-01 2.9018140e-01 3.7968040e-01 4.4014522e-01
 3.6510563e-01 4.3141943e-01 4.3012542e-01 3.6417413e-01 3.7580729e-01
 4.1538388e-01 4.3642405e-01 4.0072295e-01 3.6741602e-01 4.0259224e-01
 4.1524205e-01 3.6772144e-01 4.5024496e-01 3.5174665e-01 3.8796717e-01
 4.5112190e-01 4.0424445e-01 3.3446908e-01 4.3016365e-01 3.7154311e-01
 3.3839393e-01 4.0387094e-01 3.6246365e-01 4.4804353e-01 4.2819256e-01
 3.3333689e-01 4.2522192e-01 2.7800137e-01 3.5990304e-01 2.9747427e-01
 3.6984816e-01 3.8613534e-01 3.8204384e-01 3.3613572e-01 4.1203752e-01
 3.3762497e-01 4.2190623e-01 3.6182028e-01 4.1293728e-01 3.5547590e-01
 4.5549998e-01 3.6880726e-01 3.4996086e-01 3.3265072e-01 4.6399105e-01
 2.8825301e-01 3.2270744e-01 3.4758610e-01 3.5901421e-01 4.1739780e-01
 4.5116192e-01 3.6268115e-01 3.8178802e-01 4.5756844e-01 2.9156706e-01
 4.0098676e-01 4.5075962e-01 3.7494564e-01 3.7489641e-01 4.4356459e-01
 4.3213943e-01 4.4361877e-01 4.7075215e-01 3.6500472e-01 4.6660307e-01
 4.8125583e-01 3.8249505e-01 3.8924691e-01 4.1284394e-01 3.6014295e-01
 3.9522785e-01 3.7806672e-01 3.3819035e-01 4.0145296e-01 4.1473100e-01
 3.7196121e-01 3.9375210e-01 3.9342785e-01 4.1591331e-01 4.1363254e-01
 4.2862943e-01 3.4954435e-01 4.1305822e-01 4.1527760e-01 4.0000647e-01
 4.0429699e-01 4.1207340e-01 3.3414322e-01 4.1820067e-01 4.6869612e-01
 4.2655709e-01 3.6853921e-01 2.5476113e-01 3.1115171e-01 3.9763129e-01
 3.7822217e-01 3.8532048e-01 3.7203667e-01 4.1883412e-01 3.7371072e-01
 4.1763070e-01 3.3565724e-01 3.4467691e-01 3.4571463e-01 3.9981109e-01
 3.2550794e-01 4.0384641e-01 4.0249509e-01 4.2603266e-01 3.6036736e-01
 3.7321100e-01 4.4592679e-01 3.8687554e-01 3.3116898e-01 4.2419916e-01
 3.4904355e-01 3.1686145e-01 3.4784999e-01 3.0073479e-01 3.6706358e-01
 4.1175008e-01 4.1039068e-01 4.7068822e-01 4.2402950e-01 4.0472627e-01
 3.8644558e-01 3.1793910e-01 3.7585074e-01 3.9348656e-01 3.4578091e-01
 4.2455286e-01 3.8826859e-01 3.8606673e-01 3.8165340e-01 4.0129727e-01
 4.0084705e-01 3.3633643e-01 4.2616728e-01 4.4110322e-01 4.4293800e-01
 3.5079330e-01 3.6402994e-01 4.1649455e-01 3.9623612e-01 4.0030694e-01
 3.6084628e-01 4.2286390e-01 4.5982653e-01 4.7294351e-01 4.2009240e-01
 3.0904776e-01 3.9138415e-01 3.4400427e-01 3.7879765e-01 3.4217429e-01
 4.0267700e-01 4.1398972e-01 3.6004308e-01 3.8224664e-01 4.0493351e-01
 3.8798684e-01 3.8961783e-01 3.2653630e-01 3.2873821e-01 3.8871774e-01
 4.0111616e-01 4.5148498e-01 3.5900187e-01 3.8653845e-01 5.0330710e-01
 2.5136691e-01 3.4513718e-01 3.6262566e-01 4.5782065e-01 3.7629369e-01
 4.2035553e-01 4.6049267e-01 3.9757001e-01 4.0868425e-01 4.2836475e-01
 4.0541217e-01 3.6012036e-01 4.0235987e-01 4.1061258e-01 4.3975177e-01
 3.4360918e-01 3.5385287e-01 3.6834651e-01 3.6857176e-01 4.1385037e-01
 4.4063640e-01 3.4398392e-01 3.6102921e-01 3.7515578e-01 3.8143450e-01
 3.8022608e-01 4.0310395e-01 3.3729041e-01 3.3835071e-01 3.7207896e-01
 4.3692011e-01 4.1731653e-01 3.6851865e-01 3.9843559e-01 3.8924021e-01
 4.3981335e-01 3.1507784e-01 3.1621906e-01 4.1601259e-01 2.8225338e-01
 4.3541563e-01 3.0713826e-01 4.0146929e-01 4.2082721e-01 3.9886218e-01
 3.5796100e-01 3.3720940e-01 3.6341015e-01 4.2717940e-01 2.9916912e-01
 4.1228232e-01 3.4250411e-01 4.3787280e-01 4.5013088e-01 4.3360269e-01
 3.6928600e-01 3.3792877e-01 3.9609176e-01 3.7791944e-01 3.8896930e-01
 4.2764187e-01 4.2710885e-01 3.5423708e-01 3.8797316e-01 4.0343291e-01
 4.3217468e-01 4.1205156e-01 3.5364377e-01 3.5397050e-01 4.2106992e-01
 3.8365963e-01 3.5534704e-01 3.5836530e-01 3.3462173e-01 3.5043225e-01
 3.2914972e-01 4.4315469e-01 2.6475933e-01 4.2518759e-01 4.4142303e-01
 3.2543093e-01 3.9507109e-01 3.5428417e-01 4.0764385e-01 4.0165538e-01
 3.0466175e-01 4.5802242e-01 3.9762813e-01 4.1284716e-01 4.3980718e-01
 4.2162913e-01 3.6017102e-01 3.1791252e-01 3.6405537e-01 3.5263544e-01
 4.4337052e-01 4.3158853e-01 3.3346456e-01 4.1677833e-01 4.2927405e-01
 3.2258433e-01 4.5365992e-01 3.4769863e-01 3.8320565e-01 4.0172046e-01
 3.1630200e-01 3.3642542e-01 3.5736138e-01 4.0829325e-01 4.2137712e-01
 3.8340586e-01 4.2207411e-01 2.5908706e-01 3.7819400e-01 2.9980496e-01
 3.8935030e-01 3.4550399e-01 4.9547976e-01 3.6904740e-01 3.8521868e-01
 3.5548526e-01 3.0549029e-01 3.5125458e-01 4.7432250e-01 4.1876861e-01
 3.9123473e-01 2.9682058e-01 3.4039342e-01 4.3685097e-01 3.9268541e-01
 4.1478190e-01 4.3831360e-01 4.1915873e-01 3.9810017e-01 4.0675718e-01
 4.0221426e-01 4.7199827e-01 3.2542631e-01 4.2398959e-01 3.4958619e-01
 3.3772260e-01 3.9738292e-01 3.7457070e-01 3.5993671e-01 4.6140164e-01
 2.9135421e-01 3.5653406e-01 3.8914448e-01 4.0656114e-01 3.2152700e-01
 4.0185511e-01 4.2916945e-01 3.5052353e-01 3.1695399e-01 4.2968625e-01
 3.5582882e-01 4.0037769e-01 4.3644896e-01 3.9772192e-01 3.8905543e-01
 3.8651127e-01 4.3677315e-01 4.1775459e-01 3.8704181e-01 4.2333233e-01
 3.9052948e-01 3.6585638e-01 3.1514397e-01 3.5974753e-01 3.3022743e-01
 3.9497304e-01 4.3119264e-01 4.0848783e-01 3.8035429e-01 3.1642300e-01
 4.3576732e-01 4.3226731e-01 3.1393352e-01 4.6217221e-01 3.5412130e-01
 3.9147100e-01 4.0475863e-01 3.8768989e-01 3.8435477e-01 4.1464061e-01
 4.0042305e-01 3.0781522e-01 2.9417622e-01 2.9212856e-01 3.9082322e-01
 2.7663594e-01 3.0815381e-01 3.9850703e-01 3.8692057e-01 4.0094483e-01
 4.0975043e-01 3.5958886e-01 3.6010331e-01 4.4675797e-01 3.5300893e-01
 3.9044607e-01 3.5845822e-01 4.2495817e-01 3.6894333e-01 3.9173332e-01
 3.6836499e-01 3.9914158e-01 4.7298455e-01 4.7279155e-01 4.7878227e-01
 4.8754257e-01 4.7372559e-01 4.7903854e-01 4.7211766e-01], shape=(514,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(514,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.15771687, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/counter.correct.nts_000.smt2
true label:[1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1]
predicted label:tf.Tensor([0.4746328  0.46789575 0.46812135 0.48183408 0.45432273 0.43255252], shape=(6,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0.], shape=(6,), dtype=float32)
predicted label rank:[1 1 1 1 1 1]
mse:tf.Tensor(0.2883828, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/nested4.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.00872174 0.0185352  0.0292024  0.01020205 0.09512392 0.01303989
 0.00992846 0.01871046], shape=(8,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0.], shape=(8,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.0013804673, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/loop__loop_000.smt2
true label:[1, 1, 0, 0, 1]
true label rank:[2 2 1 1 2]
predicted label:tf.Tensor([0.45255905 0.4565212  0.44595584 0.43476063 0.4499262 ], shape=(5,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.25710708, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/minepump_spec2_product60_true-unreach-call.cil.c.flat_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[2.15830805e-05 5.06401062e-04 1.10998553e-06 5.97408580e-05
 1.07619166e-03 3.95253241e-01 3.52184296e-01 4.00759876e-01
 3.86261195e-01 3.71434271e-01 4.38479006e-01 4.01340634e-01
 4.19826418e-01 4.43118542e-01 4.23325866e-01 4.57623690e-01
 4.28183466e-01 4.39056844e-01 4.20375079e-01 3.86164784e-01
 4.27811027e-01 3.94875616e-01 4.19574142e-01 4.25008237e-01
 4.18647200e-01 1.32240385e-01 1.20188773e-01 6.18690252e-02
 1.05557829e-01 3.21443081e-01 2.25998640e-01 1.62946850e-01
 2.33100653e-01 1.70254230e-01 6.00642860e-02 1.93313688e-01
 2.60976672e-01 1.21474236e-01 1.56263441e-01 1.69477493e-01
 7.33272731e-02 7.67454505e-02 1.45797938e-01 1.58332348e-01
 1.58889979e-01 3.49320799e-01 4.34815884e-02 1.51807427e-01
 9.62118208e-02 1.08965993e-01 6.12558126e-02 3.78592014e-02
 2.95771629e-01 3.35410446e-01 3.13179910e-01 4.16126072e-01
 3.36006105e-01 3.04072469e-01 3.24597657e-01 3.46745580e-01
 3.19331288e-01 3.65691006e-01 2.97610521e-01 2.62365103e-01
 3.71404648e-01 4.09169257e-01 3.47355872e-01 3.67108226e-01
 3.57733071e-01 3.38802993e-01 3.35519910e-01 3.54245335e-01
 3.50332737e-01 3.62726569e-01 2.65731633e-01 3.47773433e-01
 3.10806632e-01 3.15129995e-01 4.57665324e-01 3.37625146e-01
 3.95252287e-01 4.52710718e-01 4.24537539e-01 4.02619421e-01
 3.91901135e-01 3.96764636e-01 4.27825898e-01 4.43512172e-01
 4.31849092e-01 4.35280800e-01 4.07470405e-01 4.51389849e-01
 4.07719553e-01 4.05957490e-01 4.82350141e-01 4.36992466e-01
 4.01919782e-01 4.43565845e-01 3.43370914e-01 8.68964195e-02
 8.79192650e-02 3.33489358e-01 1.94132805e-01 2.20630884e-01
 8.19378793e-02 2.79792964e-01 6.02174401e-02 3.16010863e-01
 2.34149933e-01 1.55390829e-01 2.73945898e-01 1.37904257e-01
 2.63028383e-01 7.61749446e-02 3.53757620e-01 8.22906196e-02
 1.08161956e-01 3.94331425e-01 3.84287357e-01 4.02219176e-01
 3.86867106e-01 3.71498346e-01 3.34828138e-01 4.05285239e-01
 4.16215003e-01 4.04110193e-01 3.83647174e-01 3.31380218e-01
 4.16990995e-01 4.08226430e-01 3.75100940e-01 4.31366593e-01
 4.16916460e-01 4.27925110e-01 3.85575682e-01 3.74879181e-01
 3.85044515e-01 4.05817091e-01 3.87474179e-01 3.63954365e-01
 6.76363707e-04 8.35196988e-06 1.03768706e-03 3.30318908e-05
 3.78564000e-03 2.16186047e-03 1.70111656e-04 3.26395035e-04
 4.50760126e-03 9.59588870e-05 1.17765812e-05 1.64830685e-03
 9.05254627e-09 1.79794431e-03 6.95019960e-04 2.43905106e-06
 3.60246599e-02 5.30592921e-08 7.80545008e-07 2.69945502e-07
 9.15804994e-05 2.57313251e-04 7.62134790e-04 4.50812250e-01
 4.38920170e-01 4.24249202e-01 4.25811142e-01 4.34374392e-01
 4.19231564e-01 4.40780550e-01 4.30059850e-01 4.26203310e-01
 4.27188128e-01 4.30884182e-01 4.43897814e-01 4.38526869e-01
 4.35139894e-01 4.38007742e-01 4.15108025e-01 4.27852660e-01
 1.55222505e-01 4.19074297e-03 5.51212728e-02 5.99319339e-02
 7.53462315e-04 1.21006966e-02 2.47859657e-02 1.77890062e-04
 9.48071480e-03 1.22969151e-02 8.98578763e-03 2.23231077e-01
 1.00898564e-01 3.95479798e-03 8.29756260e-04 2.47969538e-01
 4.82717752e-02 8.92951190e-02 5.24345636e-02 7.47457147e-02
 8.61606896e-02 1.99870765e-02 1.35680139e-02 6.16925061e-02
 1.25388443e-01 8.12449455e-02 6.04443550e-02 1.32521063e-01
 1.61165148e-01 2.96639502e-02 3.66175175e-02 2.03078985e-03
 5.88119030e-04 3.55569720e-02 8.43176246e-03 7.62223899e-02
 7.77602196e-04 1.71518326e-03 1.60081774e-01 4.26434904e-01
 4.28720176e-01 3.71344030e-01 1.49135351e-01 1.98100924e-01
 2.84633100e-01 3.69751155e-01 1.91687495e-01 3.06225628e-01
 3.67368996e-01 3.17594528e-01 3.85577470e-01], shape=(231,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(231,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.08623906, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/bandec.smt2-0178_000.smt2
true label:[1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1]
true label rank:[2 2 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 2 1 2 2 2 1 1 1 1 1 2 2]
predicted label:tf.Tensor(
[0.46563524 0.47311258 0.46485326 0.46988952 0.47474837 0.4329877
 0.42982095 0.41981348 0.43706337 0.4287215  0.42159045 0.42138556
 0.43760335 0.43024004 0.41856065 0.43139282 0.43850437 0.4265184
 0.43650234 0.44478154 0.4449174  0.44195855 0.44087777 0.45704433
 0.44894078 0.43393394 0.44715524 0.4479169  0.44137633 0.44152352], shape=(30,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.], shape=(30,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.25725356, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/underapprox_2-2.c-1_000.smt2
true label:[1, 0]
true label rank:[2 1]
predicted label:tf.Tensor([0.47773147 0.4766496 ], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 0.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.24997963, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/SYNAPSE_2_e8_1118_e7_1043_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.23578307 0.39215508 0.34447318 0.31958234 0.35955212 0.26649448
 0.18130073 0.34120768 0.21289605 0.43798396 0.45243576 0.24291885
 0.32597864 0.3403176  0.40226024 0.32954103 0.3020491  0.3363461
 0.4440754  0.18888974 0.24712017 0.21319053 0.24079153 0.28841135
 0.27009255 0.30103087 0.30825984 0.2282128  0.26060426 0.36764643
 0.25061893 0.41284797 0.41971704 0.40731803 0.40676093 0.40715262
 0.4159094  0.4078388  0.42080364 0.42184582 0.41943735 0.42777786
 0.43201634 0.43346462 0.41469568 0.42223766 0.4166283  0.4344315
 0.42558756 0.4243217  0.41885704 0.4522177  0.43533692 0.43521133
 0.43434528 0.44517463 0.41827232 0.41299206 0.4356094  0.4313381
 0.4315653  0.42054757 0.4701262  0.46596265 0.47740605 0.4777256
 0.47100276 0.46678224 0.4676345  0.47271565 0.4636963  0.47551715
 0.47955558 0.4710754  0.48081627 0.48066705 0.4754888  0.4796714
 0.4888427  0.48562622 0.48808083 0.48526928 0.47428358 0.4655752
 0.46867946 0.46947303 0.46894765 0.47466993 0.47372326 0.45958725
 0.4532887  0.4680338  0.20380351 0.13087368 0.42220855 0.21816707
 0.16618368 0.25768065 0.43657553 0.18749827 0.2390508  0.40689945
 0.31505316 0.28857425 0.17984146 0.44162866 0.40418118 0.3823379
 0.44926664 0.42072386 0.3933492  0.41590413 0.38359317 0.3487237
 0.4450205  0.34596092 0.40149528 0.39604566 0.40741628 0.43832552
 0.29200733 0.22108018 0.19877526 0.33074653 0.35051662 0.4211424
 0.35107794 0.29942596 0.37376    0.37409052 0.34597743 0.40569854
 0.38979316 0.30785614 0.37131393 0.35610312 0.38968453 0.40754914
 0.46421143 0.44586357 0.45714176 0.42618722 0.43848607 0.4303905
 0.46445245 0.45915273 0.44844714 0.4295593  0.46087283 0.4547202
 0.42975277 0.45557258 0.40809935 0.46873778 0.44765654 0.4371095
 0.4426893  0.4472573  0.43444908 0.42862356], shape=(160,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(160,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.1589307, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/002-horn_000.smt2
true label:[1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0]
true label rank:[2 1 1 2 1 1 2 1 1 2 1 1]
predicted label:tf.Tensor(
[0.4503905  0.46157104 0.4669439  0.47199008 0.45967472 0.45662415
 0.462256   0.46718124 0.46573278 0.4766456  0.47675896 0.45745957], shape=(12,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(12,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.23887984, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0091_000.smt2
true label:[0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0]
true label rank:[1 2 2 1 1 1 2 2 1 1 1 2 2 1 1 1 2 2 1 1 2 2 1]
predicted label:tf.Tensor(
[0.4661452  0.45886406 0.460574   0.4462475  0.45076138 0.42872575
 0.38155952 0.42730004 0.40119004 0.446001   0.47451794 0.4760974
 0.4799666  0.47439745 0.47925103 0.47211885 0.47170088 0.4762678
 0.47611213 0.4610067  0.46774995 0.44590524 0.46810868], shape=(23,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(23,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.24814352, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/bandec.smt2-0181_000.smt2
true label:[1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1]
true label rank:[2 2 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 2 1 2 2 2 1 1 1 1 1 2 2]
predicted label:tf.Tensor(
[0.46563524 0.47271338 0.46485326 0.47150728 0.47407645 0.4329877
 0.42982095 0.41981348 0.43706337 0.4287215  0.42159045 0.42138556
 0.43760335 0.43024004 0.41856065 0.43139282 0.43850437 0.4265184
 0.43650234 0.44478154 0.4449174  0.44195855 0.44087777 0.45704433
 0.44894078 0.43393394 0.44715524 0.4479169  0.44137633 0.44152352], shape=(30,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.], shape=(30,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.25723404, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/car_4_e3_57_e4_1047_000.smt2
true label:[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1
 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1
 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1
 2 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1
 2 1 1 2 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1
 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[2.4145991e-01 3.0585286e-01 2.0609763e-01 1.7302412e-01 2.9221171e-01
 1.7896605e-01 1.5609598e-01 1.7326373e-01 1.4106500e-01 4.0626130e-01
 4.3894818e-01 2.5206095e-01 3.6764652e-01 3.3997071e-01 3.4662002e-01
 2.2162011e-01 2.8000772e-01 3.2167721e-01 4.0209427e-01 9.7486734e-02
 1.6278940e-01 2.2332433e-01 2.2440213e-01 1.5121156e-01 2.1639758e-01
 1.9057110e-01 2.6399761e-01 9.5776200e-02 1.3888693e-01 3.6508387e-01
 2.8279227e-01 1.9212332e-01 3.2093436e-02 1.2058586e-02 2.0358562e-03
 6.5111071e-02 7.5359851e-02 1.6846359e-02 3.5658896e-02 2.5788152e-01
 8.8501275e-03 1.5698165e-02 2.4245301e-01 1.3288975e-02 3.6913753e-02
 1.9133562e-01 7.9578161e-03 1.2380719e-01 3.5883456e-02 9.8907679e-02
 7.4678928e-02 2.5595903e-02 5.7333708e-03 1.0706574e-02 1.1568964e-03
 8.7983310e-03 3.3274323e-02 1.2245566e-02 1.0598928e-02 1.4415920e-02
 1.3178527e-02 4.3003589e-02 1.6210675e-03 1.6268790e-03 3.6508918e-02
 4.1173130e-02 9.8327816e-02 4.5575619e-02 1.2107998e-02 4.4727594e-02
 2.0167023e-02 2.3561716e-03 4.4734478e-03 8.4684491e-03 1.0030866e-03
 5.4966003e-02 2.5820404e-02 2.9759377e-02 3.5881644e-01 3.0481482e-01
 2.6113927e-01 3.0676341e-01 2.9072598e-01 2.8676006e-01 2.1040589e-01
 1.7468822e-01 2.4595180e-01 3.0394888e-01 2.8371751e-01 2.6673275e-01
 2.4955687e-01 4.1063339e-01 2.6099968e-01 1.4579207e-01 4.0250084e-01
 2.9231369e-01 6.8412721e-03 1.5382946e-02 1.6820982e-01 1.9616783e-03
 8.8572502e-04 9.5536053e-02 1.5378684e-01 2.8012067e-02 6.6859722e-03
 1.0464361e-01 1.4982790e-02 5.9791714e-02 1.6318733e-01 3.7273288e-02
 1.4286581e-01 5.7737827e-03 1.7119753e-01 1.9610345e-02 2.3033163e-01
 1.1772215e-03 3.4028292e-03 4.5546591e-03 6.5125823e-03 4.5418948e-02
 4.8919618e-03 4.8086941e-03 4.6578050e-04 1.8506229e-02 4.0351748e-03
 9.9556237e-02 5.4464817e-02 2.0817518e-03 3.0200779e-02 1.3472974e-02
 8.0644190e-03 1.4129919e-01 1.2319267e-02 9.6046627e-03 9.2501342e-03
 6.8614185e-03 8.9186788e-02 9.5546216e-02 4.2938888e-03 9.7976625e-03
 8.8859826e-02 2.7404726e-02 4.6283308e-01 4.6734309e-01 4.4829622e-01
 4.6063575e-01 4.5973772e-01 4.4570816e-01 4.5608872e-01 4.5616946e-01
 4.5852736e-01 4.4761693e-01 4.5453566e-01 4.6275032e-01 4.5352823e-01
 4.4434863e-01 4.3571949e-01 4.4628137e-01 4.4882026e-01 4.4358975e-01
 4.5066565e-01 4.3582577e-01 4.4135776e-01 4.5156687e-01 4.5168406e-01
 4.5020843e-01 4.3967026e-01 4.5100451e-01 4.4548741e-01 4.4497105e-01
 4.2819831e-01 4.4836989e-01 4.4415903e-01 4.3158889e-01 4.4238102e-01
 4.2748901e-01 4.2721620e-01 4.3396270e-01 4.3773001e-01 4.2796776e-01
 4.3066424e-01 4.2604613e-01 4.5352027e-01 4.6091613e-01 4.3254384e-01
 4.5684654e-01 4.5683518e-01 4.4827190e-01 4.5350441e-01 4.6525544e-01
 4.5505476e-01 4.6196103e-01 4.4747266e-01 4.3542227e-01 4.6204638e-01
 4.5586047e-01 4.6148717e-01 4.5786729e-01 4.6599579e-01 4.6738750e-01
 4.6096179e-01 4.5577112e-01 4.6577752e-01 4.4562384e-01 4.5672798e-01
 4.5208222e-01 4.6243185e-01 4.5683566e-01 4.6859312e-01 4.5581871e-01
 4.5557314e-01 4.5874518e-01 4.5730159e-01 4.6410307e-01 4.4779420e-01
 4.4593117e-01 4.5903981e-01 4.5258424e-01 4.5591223e-01 4.4752109e-01
 4.5791358e-01 4.6828997e-01 4.5251110e-01 4.0928906e-01 4.0375307e-01
 4.2568821e-01 4.1260540e-01 4.3104762e-01 4.0908194e-01 4.1604009e-01
 4.2089230e-01 4.1434965e-01 4.0481579e-01 4.1263604e-01 4.2284578e-01
 4.2513904e-01 4.0731594e-01 4.3182707e-01 4.1235876e-01 4.1000861e-01
 4.2737928e-01 4.1863310e-01 4.1441625e-01 4.2638206e-01 4.1248453e-01
 4.0978944e-01 4.0614581e-01 4.3389371e-01 4.0429962e-01 4.2157531e-01
 7.3152453e-02 4.7445932e-01 3.4347820e-01 1.7493641e-01 2.7380288e-02
 2.4521428e-01 1.3861418e-02 1.8411934e-02 2.0883510e-01 3.7724435e-02
 4.4909245e-01 4.0866208e-01 4.2589769e-01 4.2808807e-01 4.1838908e-01
 4.3502516e-01 4.4531801e-01 4.3038443e-01 4.2612433e-01 4.1170582e-01
 3.2145518e-01 3.3392885e-01 4.2523623e-01 3.0869079e-01 3.9089864e-01
 3.7622324e-01 3.6866575e-01 4.2934975e-01 3.9790702e-01 4.2946365e-01
 2.2452071e-01 3.5780299e-01 3.2071096e-01 4.2612100e-01 4.3462631e-01
 4.5170113e-01 4.2225295e-01 4.5969510e-01 4.3908498e-01 4.4795743e-01
 4.4356662e-01 4.5120516e-01 4.5519459e-01 4.5410332e-01 4.6020779e-01
 4.5406586e-01 4.6057704e-01 4.0891802e-01 4.2384484e-01 4.4532454e-01
 3.9835295e-01 4.1767794e-01 4.3947008e-01 4.4800541e-01 4.1780576e-01
 4.1338935e-01 4.5209378e-01 4.5115349e-01 4.2240256e-01 4.3169475e-01
 4.4504845e-01 3.8218093e-01 4.2099646e-01 4.2959923e-01 4.3294674e-01
 3.8527015e-01 3.9044064e-01 4.1018820e-01 4.0329832e-01 4.0514994e-01
 4.3054500e-01 3.8987923e-01 4.0869084e-01 3.8107136e-01 4.1184983e-01
 4.0456554e-01 3.7818527e-01 3.8880110e-01 3.4913945e-01 3.8261476e-01], shape=(330,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(330,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.17117776, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/id_build.i.p+sep-reducer.c-1_000.smt2
true label:[1, 1, 1]
true label rank:[1 1 1]
predicted label:tf.Tensor([0.45286754 0.46898857 0.45841208], shape=(3,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)
predicted label rank:[1 1 1]
mse:tf.Tensor(0.29154822, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/nested6.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[1.95407592e-05 1.88213587e-03 2.13304611e-06 1.41926075e-05
 1.78632140e-03 1.08648946e-05 1.24527378e-06 1.02859995e-05
 1.29109608e-07], shape=(9,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(9,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(7.482436e-07, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/traverse3_unsafe.c_000.smt2
true label:[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 2 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 2 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 2 1 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.34370854 0.34766114 0.34939316 0.34440982 0.348626   0.3417467
 0.3549809  0.34542662 0.35262454 0.33951497 0.34629947 0.34614193
 0.3542983  0.34740126 0.34671092 0.3545757  0.35868403 0.34099287
 0.3395146  0.35013145 0.3428685  0.3412438  0.33489388 0.347241
 0.3545739  0.33815312 0.3489994  0.34391445 0.3513003  0.34855607
 0.34649655 0.3442783  0.34155476 0.338469   0.33097178 0.34759766
 0.33226436 0.33870524 0.3451371  0.35798147 0.33516705 0.34508005
 0.34868217 0.35102922 0.34508327 0.34914166 0.34611177 0.35150844
 0.33330625 0.3405452  0.3404919  0.3612281  0.35312796 0.3496338
 0.33935165 0.35699236 0.3443491  0.34731922 0.3552552  0.35348675
 0.34051058 0.34915495 0.3461485  0.3417443  0.34526128 0.33391505
 0.32135049 0.33113924 0.32874644 0.33609173 0.3294619  0.32036224
 0.34460503 0.32760262 0.32650468 0.32242543 0.33303034 0.34748584
 0.3233046  0.33792526 0.33153278 0.33911592 0.32197    0.31843787
 0.3396748  0.32786906 0.34271228 0.31544536 0.33561146 0.3224799
 0.31960368 0.34005415 0.3176313  0.34448275 0.3332682  0.33681452
 0.31947684 0.3201192  0.32380494 0.32592586 0.32133496 0.33262366
 0.336464   0.3315667  0.34768197 0.3106169  0.31252685 0.33544403
 0.32273245 0.339535   0.32852244 0.3355716  0.34502205 0.33068937
 0.33287185 0.32871443 0.32668054 0.32012898 0.33002988 0.3207217
 0.31626493 0.3334905  0.33171052 0.3230629  0.321262   0.34052616
 0.33003485 0.32471836 0.32991508 0.3307587  0.32633832 0.3353234
 0.34249794 0.33049366 0.3121066  0.32988602 0.32542363 0.33279812
 0.32789508 0.32746518 0.32511288 0.32469022 0.33462584 0.3210873
 0.3376413  0.3339711  0.32819876 0.31944537 0.34202874 0.31139964
 0.3260247  0.3434859  0.34912542 0.33558795 0.3293398  0.32369038
 0.32211703 0.32015958 0.3230375  0.31756043 0.33667287 0.3189339
 0.3178104  0.3195346  0.34037054 0.3596262  0.3430968  0.3602353
 0.34698063 0.36249894 0.3438244  0.35181865 0.3548958  0.34888965
 0.36403376 0.35524803 0.34944975 0.36356568 0.35030493 0.33458525
 0.36095726 0.37022048 0.36057645 0.34519434 0.34965456 0.3603549
 0.34220818 0.34947515 0.34615245 0.36471835 0.3501578  0.3544284
 0.351926   0.34219474 0.36106646 0.34555745 0.35889775 0.36266762
 0.35294688 0.3587489  0.35636294 0.3605956  0.36423507 0.36300406
 0.35513133 0.34102917 0.36477023 0.356275   0.3618696  0.34753978
 0.35637915 0.36649954 0.35938495 0.36569005 0.35206807 0.3551463
 0.37042224 0.35252213 0.34904528 0.33683854 0.35371214 0.37141305
 0.36068648 0.36158514 0.3469863  0.36160457 0.3533629  0.36045325
 0.3665918  0.3497616  0.36768755 0.35094792 0.35033476 0.34012854
 0.36236602 0.35597542 0.33865696 0.36404154 0.36249992 0.34588602
 0.36347544 0.37092167 0.33948636 0.35461932 0.3403145  0.34676874
 0.34864038 0.36750165 0.34413412 0.35297096 0.3629675  0.3565305
 0.35822433 0.35305196 0.3587426  0.3401129  0.3525432  0.36557198
 0.33904833 0.34308332 0.3505749  0.35717046 0.35336018 0.36285612
 0.3670519  0.3447108  0.35768613 0.35761085 0.3627376  0.3459322
 0.3533005  0.34666705 0.348096   0.34611642 0.35182193 0.3733666
 0.36001366 0.33915168 0.35713434 0.357467   0.3534538  0.35571927
 0.35338396 0.35411382 0.3490459  0.33915803 0.345173   0.33641666
 0.34337652 0.35291386 0.33701855 0.3287424  0.33478355 0.34286672
 0.3295368  0.32511485 0.35398293 0.33828682 0.3339451  0.32244787
 0.3145858  0.33322492 0.33416244 0.33316508 0.32377547 0.3335654
 0.3375676  0.3435976  0.34034765 0.33619514 0.32818016 0.34538648
 0.3224188  0.33726573 0.3367465  0.34033453 0.33431515 0.32671678
 0.3248623  0.33967245 0.32322028 0.34774768 0.33982652 0.32853627
 0.33973446 0.33034074 0.32805085 0.3187485  0.32934356 0.33345383
 0.33908868 0.32102442 0.33267358 0.35025    0.3348675  0.3401342
 0.33684665 0.3170389  0.33579898 0.33194602 0.3342054  0.32664907
 0.33557084 0.33661488 0.33657962 0.3336702  0.325764   0.3433808
 0.3273319  0.33321124 0.3257795  0.31824756 0.3396272  0.3360516
 0.34169775 0.3321819  0.33555532 0.33760744 0.3193071  0.34427595
 0.32677296 0.3408087  0.34109414 0.3180886  0.3291499  0.3414489
 0.33921364 0.33630294 0.32714266 0.33993834 0.34671235 0.33413643
 0.33928412 0.32720566 0.34124428 0.3267752  0.3502071  0.32765973
 0.3384745  0.33704758 0.3423385  0.34176463 0.3285148  0.35396323
 0.3426777  0.3360855  0.33640772 0.33911395 0.32708076 0.33099207
 0.34924698 0.33409762 0.33171076 0.3450112  0.33874944 0.3419155
 0.33212787 0.34409776 0.33081847 0.32840812 0.3315913  0.34329182
 0.33562168 0.33756506 0.33155817 0.33150274 0.33328384 0.32739133
 0.3458174  0.3345377  0.32756916 0.3371294  0.3356163  0.32947046
 0.3299982  0.32573256 0.337546   0.33716932 0.3245328  0.3278681
 0.3342957  0.3365301  0.34324133 0.34249058 0.34214538 0.34651434
 0.3254004  0.33257258 0.34321952 0.33193916 0.3359952  0.32216522
 0.33045018 0.33531195 0.37239814 0.39681175 0.38505128 0.37556115
 0.38895264 0.4023861  0.3838572  0.39430404 0.41119522 0.3714769
 0.40184563 0.39693102 0.41036934 0.38475555 0.40810326 0.38451892
 0.3937059  0.4125773  0.36998877 0.36984617 0.4000175  0.378358
 0.38690382 0.3969782  0.38824826 0.39817932 0.39710787 0.3976696
 0.3959593  0.40444136 0.38717836 0.3978676  0.3795119  0.3935603
 0.3884353  0.3918338  0.3957382  0.38793528 0.39035985 0.3887124
 0.3957541  0.40072435 0.39153916 0.39652455 0.3943798  0.3809774
 0.3876947  0.38950983 0.39426094 0.3788892  0.38806444 0.38178974
 0.39756367 0.36842775 0.3976245  0.4009946  0.3922271  0.3806394
 0.39983794 0.39857638 0.37199384 0.3909051  0.3854705  0.38043964
 0.38247716 0.39958775 0.3810268  0.38272166 0.3959462  0.3958868
 0.39353302 0.39529192 0.39932865 0.39698178 0.37317455 0.39490625
 0.38941887 0.401171   0.4099537  0.39031363 0.3789698  0.37172455
 0.40689477 0.39124253 0.38204378 0.40628755 0.39588058 0.38624123
 0.42273453 0.3821956  0.3898438  0.39976513 0.39961955 0.39275438
 0.37850094 0.4101908  0.40263617 0.42766774 0.3884021  0.40027714
 0.3894112  0.37953016 0.38853657 0.37568784 0.40011352 0.41027725
 0.39384213 0.38668072 0.41468745 0.38698587 0.39989856 0.40383655
 0.4017972  0.3894059  0.3763618  0.38996848 0.38520736 0.3844614
 0.38725924 0.37863255 0.39763823 0.38325372 0.3707937  0.38629222
 0.38887218 0.40620637 0.3750254  0.4049489  0.39449254 0.38141495
 0.37909052 0.39810348 0.3935501  0.38976383 0.39020634 0.39430568
 0.39214957 0.3792458  0.39101437 0.40258044 0.37975016 0.40184566
 0.39035723 0.36694726 0.3948544  0.3710811  0.37728179 0.3997545
 0.38593554 0.39539844 0.40428844 0.38722754 0.38543072 0.40233332
 0.4042173  0.38850224 0.3869904  0.40420255 0.3794946  0.40065262
 0.393753   0.38395053 0.39803946 0.4047684  0.3899112  0.38381922
 0.39946288 0.4059037  0.3851436  0.38204783 0.37261188 0.42254683
 0.4292786  0.42150083 0.4247135  0.42003912 0.41885242 0.41401058
 0.40534705 0.42219108 0.42378026 0.42853513 0.42093238 0.42014185
 0.424209   0.4217053  0.42600787 0.41994026 0.41972658 0.4203541
 0.4086768  0.42536345 0.4202222  0.4176787  0.4147592  0.42521405
 0.41613027 0.42398176 0.41810068 0.4143308  0.41507363 0.42255083
 0.42814508 0.42077956 0.41977426 0.4255659  0.42657778 0.42343277
 0.41829488 0.4162447  0.42788824 0.42238623 0.4228963  0.42063475
 0.4186533  0.41523996 0.41944546 0.42647982 0.42538768 0.4227845
 0.42102534 0.42157018 0.42135373 0.4234418  0.42350188 0.43034554
 0.41967162 0.42217088 0.41486502 0.4225161  0.42192855 0.42044017
 0.42461428 0.42228645 0.4274311  0.4288525  0.4170779  0.47450945
 0.4792495  0.4748819  0.47592452 0.46983778 0.48142466 0.46602914
 0.47669956 0.4768354  0.4821706  0.4710434  0.47888222 0.4791851
 0.47479782 0.49259627 0.44154793 0.438587   0.42855147 0.43368804
 0.4411204  0.43979785 0.43971854 0.43406692 0.4362305  0.4449398
 0.4353037  0.43278575 0.4478086  0.44037208 0.4361492  0.43488792
 0.436222   0.4380552  0.43536383 0.4363801  0.43285778 0.4445052
 0.431805   0.42354274 0.4172628  0.41418976 0.41364866 0.41543967
 0.41672003 0.41327855 0.41708922 0.417277   0.4140616  0.42257828
 0.4194472  0.41110006 0.4154673  0.4194746  0.40855616 0.41141248
 0.41156757 0.41401815 0.4198965  0.4112316  0.41587907 0.40917325
 0.4097277  0.4142437  0.41771388 0.4165069  0.41331476 0.40313923
 0.41311246 0.40855938 0.4469179  0.4525614  0.4387864  0.45328152
 0.4489585  0.44686913 0.43941915 0.44619656 0.4401377  0.44977024
 0.44114116 0.45056894 0.44877398 0.44967723 0.44293255 0.44174668
 0.44424742 0.43524212 0.45102087 0.44306177 0.44558996 0.4515235
 0.4508341  0.4462603  0.44171402 0.44810307 0.44058043 0.45205367
 0.43898672 0.44916326 0.442494   0.45125967 0.45404813 0.45391443
 0.44896638 0.4484881  0.43856314 0.44801554 0.4407359  0.44862133
 0.4515674  0.46063352 0.45506686 0.4430719  0.45123693 0.445987
 0.44647872 0.44272214 0.4446463  0.45210826 0.44214094 0.44522598
 0.45266658 0.4506142  0.44624674 0.446618   0.4560684  0.44110012
 0.4445205  0.44844654 0.45176542 0.44957447 0.45688224 0.4383856
 0.44733733 0.44824368 0.44625968 0.45290512 0.44993755 0.45289284
 0.45228612 0.44275975 0.44274092 0.44181037 0.44432637 0.4415765
 0.44864616 0.4367396  0.44894138 0.44994807 0.44344664 0.44984278
 0.4504845  0.4420474  0.45072457 0.44613448], shape=(826,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(826,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.17004354, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/NetBSD_glob3_iny.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[6.2412601e-12 2.7957747e-10 1.4402692e-15 2.3855848e-18 4.0194879e-09
 5.6175890e-15 1.0390049e-11 5.4554402e-15 2.9293619e-20 6.3314645e-11], shape=(10,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(10,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(1.6238603e-18, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/minepump_spec5_product56_true-unreach-call.cil.c.flat_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[2.77191401e-04 1.23045444e-02 2.14338303e-04 3.02076340e-04
 3.32229376e-01 2.49144852e-01 2.33391941e-01 2.64854342e-01
 2.11361170e-01 3.98762584e-01 4.51163888e-01 1.46242112e-01
 2.75016785e-01 3.72207254e-01 1.62942588e-01 1.52120143e-01
 2.33275115e-01 2.88799524e-01 3.06274027e-01 4.84546721e-02
 7.84822404e-02 1.10238940e-01 3.93230617e-01 4.13591981e-01
 3.93203765e-01 4.05243516e-01 3.92793417e-01 4.08272445e-01
 4.15626585e-01 4.12867248e-01 4.13442403e-01 3.97163123e-01
 4.18469727e-01 4.13772941e-01 4.03698862e-01 3.97814572e-01
 4.08862203e-01 3.98639292e-01 3.39798421e-01 4.21053350e-01
 3.75967801e-01 4.24002469e-01 4.46830153e-01 4.03312027e-01
 4.48215514e-01 4.66756225e-01 4.16179210e-01 3.93791616e-01
 3.77841711e-01 3.85966301e-01 3.84046167e-01 3.92089039e-01
 3.18940848e-01 3.87689829e-01 4.47094917e-01 4.52696323e-01
 4.48090255e-01 4.38439250e-01 4.49638844e-01 4.55584764e-01
 4.69094247e-01 4.45754588e-01 4.32115376e-01 4.34318721e-01
 4.49707597e-01 4.67438132e-01 4.40624297e-01 4.43685114e-01
 4.41728413e-01 4.34214354e-01 4.71596986e-01 4.49628353e-01
 3.94578874e-02 3.32874060e-02 1.09707415e-02 1.26160890e-01
 5.71743250e-02 1.37950182e-01 1.73730463e-01 5.02533317e-02
 8.05818439e-02 8.77133012e-02 5.03444374e-02 4.18991446e-02
 3.45189273e-02 2.84303427e-02 5.93776703e-02 1.15187377e-01
 1.33751601e-01 3.05374861e-02 4.74168658e-02 9.27686989e-02
 1.14828472e-04 4.62238461e-07 5.05381346e-01 5.33014536e-04
 1.43378973e-04 2.02596188e-04 1.34453923e-01 8.41140427e-05
 2.95661562e-06 5.85328341e-02 1.51996315e-02 6.68892264e-03
 3.19361687e-04 8.00603628e-03 1.58995390e-04 5.39511442e-04
 2.56353915e-02 1.04692578e-03 4.99206781e-03 1.49548054e-04
 5.49665987e-02 4.05751675e-01 4.10636276e-01 3.91780794e-01
 4.15298820e-01 4.39175040e-01 4.11491662e-01 4.37616467e-01
 4.02698815e-01 4.11881626e-01 3.78671169e-01 4.02454436e-01
 4.16916221e-01 4.14043188e-01 3.85387629e-01 4.08885151e-01
 4.08521891e-01 4.26929116e-01 3.86458278e-01 4.24526989e-01
 4.34263200e-01 3.98447782e-01 4.04544652e-01 4.41033274e-01
 3.97957504e-01 4.36881393e-01 3.95682812e-01 3.93712997e-01
 4.32894707e-01 4.10348356e-01 3.98763657e-01 4.25868392e-01
 4.34312522e-01 3.89587015e-01 4.43540841e-01 4.15849090e-01
 4.13552940e-01 4.37612712e-01 4.30906981e-01 4.07991707e-01
 3.90471846e-01 4.42575753e-01 4.46486145e-01 3.57202649e-01
 4.16381657e-01 3.79662067e-01 9.98310767e-10 1.34916883e-10
 6.96629968e-07 4.21279128e-06 9.72510315e-06 2.67879108e-10
 2.53746824e-09 4.08360706e-11 4.31668758e-03 4.35177242e-07
 1.99309079e-06 6.75444880e-07 4.62734699e-03 3.02500553e-07
 1.82346263e-10 7.30802725e-08 1.58843398e-03 3.25202942e-04
 5.33794449e-08 2.30737683e-07 1.64039740e-10 1.83403492e-04
 6.67750835e-04 4.22641903e-01 4.24263924e-01 4.19564426e-01
 4.23834980e-01 4.07684624e-01 4.21344519e-01 4.23465490e-01
 4.33932692e-01 4.44197118e-01 4.36721206e-01 4.23492223e-01
 4.38559920e-01 4.23257619e-01 4.42840934e-01 4.07983929e-01
 4.41571981e-01 4.25255299e-01 4.85387444e-03 7.46902823e-03
 2.74772942e-02 7.73876905e-04 1.09535456e-03 4.74739075e-03
 1.39581203e-01 1.84117854e-02 5.80221415e-03 7.65105784e-02
 2.44621038e-02 6.57844841e-02 1.22897923e-01 3.28049064e-03
 6.64950013e-02 1.54034466e-01 3.70198786e-02 2.13650197e-01
 1.86414421e-02 3.60673070e-02 4.77303565e-02 2.63757706e-01
 2.14256048e-01 7.70474076e-02 6.52581453e-03 1.82002783e-04
 8.57678056e-03 9.49797034e-03 2.28852034e-04 2.17490196e-02
 2.68760920e-02 1.72835886e-02 1.24134123e-02 3.05588543e-01
 2.76433170e-01 2.47287512e-01 3.22049767e-01 2.56245673e-01
 2.66145468e-01 3.46866548e-01 3.69549334e-01 2.83394963e-01
 2.73746669e-01], shape=(241,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0.], shape=(241,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.09290253, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/durationThm_2_e1_118_000.smt2
true label:[1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0]
true label rank:[2 2 1 1 2 2 2 2 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1]
predicted label:tf.Tensor(
[9.3740155e-06 3.8656592e-04 2.6742987e-06 7.6352975e-05 2.7091205e-03
 5.5792216e-06 4.3421983e-06 8.8203742e-05 1.3419599e-06 1.0712773e-02
 1.9167691e-02 1.3363361e-04 9.4088912e-04 1.3496250e-02 2.8014690e-02
 7.1626902e-04 2.2945315e-02 2.1471977e-03 2.7685139e-01 1.2959979e-06
 3.0851952e-05 3.6459071e-05 6.5295397e-05], shape=(23,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(23,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.4526469, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/metros_4_e3_1091_e3_522_000.smt2
true label:[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]
true label rank:[1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1
 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1
 2 1 1 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 2 1 1 2 2 1 1 1 1 2 2 1 1 1 1
 1 1 1 2 1 2 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1
 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1
 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1
 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1
 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1
 1 2 1 1]
predicted label:tf.Tensor(
[0.22602168 0.24277449 0.14537674 0.19126621 0.27743956 0.13125521
 0.12571073 0.20430353 0.1790719  0.30801797 0.3792855  0.16899675
 0.2948286  0.3962049  0.3470518  0.23206982 0.259334   0.2262567
 0.41495854 0.09473234 0.11353642 0.18043143 0.11320835 0.1718542
 0.25672662 0.16796282 0.15898827 0.06939098 0.13710964 0.28910702
 0.27498698 0.17142111 0.21669891 0.1190297  0.07532132 0.26754552
 0.24710903 0.18559662 0.20658019 0.45124292 0.1223594  0.23588836
 0.4530649  0.2597428  0.19162482 0.44739044 0.10729674 0.37945023
 0.37190962 0.3535799  0.3843007  0.37445676 0.35243493 0.36519867
 0.34150276 0.35493615 0.383381   0.35368747 0.37533545 0.35385826
 0.38751608 0.3735969  0.3389982  0.32258838 0.36024785 0.37674454
 0.3524867  0.36126316 0.3635751  0.39143378 0.37665498 0.36327112
 0.3907897  0.33538866 0.373555   0.41513795 0.38413024 0.39195943
 0.40258065 0.40164453 0.3885455  0.40674707 0.41384843 0.40979815
 0.40986952 0.4001458  0.42550665 0.42774785 0.41629633 0.40380877
 0.4021903  0.43213612 0.4123311  0.42382288 0.40340883 0.4310646
 0.39112535 0.4057934  0.4444019  0.41919369 0.4131747  0.4129402
 0.42478633 0.37643456 0.33535498 0.35907418 0.25430086 0.3620386
 0.3797085  0.2721008  0.3422279  0.37744144 0.35427725 0.32679313
 0.40542936 0.27123725 0.29629606 0.30004317 0.35200077 0.36814332
 0.30422962 0.2976429  0.1870918  0.3544286  0.32162055 0.3756446
 0.29264525 0.28405273 0.36019766 0.30528885 0.34913844 0.44212747
 0.38297224 0.34099725 0.36087292 0.36283785 0.38410765 0.37744915
 0.30251276 0.30892628 0.3643549  0.39376253 0.42027837 0.39071015
 0.40986702 0.45281166 0.3388723  0.29897672 0.38606945 0.33253458
 0.30333382 0.30010495 0.29993135 0.35626745 0.3767677  0.2708093
 0.4103576  0.25107476 0.33124706 0.24441609 0.283775   0.37539783
 0.31834954 0.323513   0.3570363  0.28220183 0.43702298 0.31405312
 0.39415562 0.34903476 0.4222596  0.3298831  0.37457192 0.36546487
 0.37778947 0.30401027 0.31268537 0.3374924  0.2813893  0.39964592
 0.4603673  0.3047588  0.35702705 0.43045348 0.22186595 0.35160536
 0.4136068  0.28113282 0.35829353 0.3763419  0.34995222 0.36049417
 0.40988058 0.29257116 0.348109   0.41644654 0.325899   0.35110915
 0.36035085 0.32331538 0.38367006 0.28855821 0.31843764 0.3866465
 0.3891778  0.31774753 0.20664698 0.30126262 0.3210109  0.30940247
 0.38168493 0.1679577  0.17505854 0.29583818 0.22204944 0.30520278
 0.22014573 0.18640706 0.353054   0.48818216 0.3240855  0.39700168
 0.3349388  0.3115859  0.39706957 0.41563383 0.32547972 0.394884
 0.44397518 0.4397382  0.4230125  0.41020033 0.4250827  0.36310214
 0.43851447 0.37738588 0.4279215  0.42761976 0.45339844 0.40190327
 0.450778   0.4280915  0.45182818 0.4443645  0.45988294 0.4470112
 0.41206393 0.45634288 0.42959198 0.4699433  0.43107694 0.44726872
 0.4757536  0.45913634 0.43771118 0.4212946  0.39089316 0.4205937
 0.40886018 0.39387348 0.44699728 0.4459261  0.38535398 0.3721508
 0.3943025  0.39428395 0.3540652  0.3866296  0.38319468 0.4186665
 0.43202117 0.38654858 0.40233222 0.4024978  0.4459267  0.3791015
 0.40867448 0.44482908 0.42870432 0.398178   0.3902157  0.40822393
 0.43728518 0.40673336 0.41581482 0.3972889  0.43211704 0.4183668
 0.38233572 0.4192234  0.40303206 0.4115582  0.4070943  0.40217158
 0.4185269  0.4159861  0.41990745 0.4097094  0.4253162  0.47794738
 0.1221092  0.23656893 0.2253542  0.45939797 0.25984803 0.3235071
 0.32232988 0.2903648  0.29327646 0.29249924 0.31531546 0.22832394
 0.3373077  0.3289929  0.2552991  0.15662712 0.21284544 0.2982967
 0.27378258 0.45310014 0.4429832  0.46420586 0.45865658 0.45114398
 0.48796725 0.45552474 0.44868585 0.43970263 0.45135787 0.42406222
 0.46702155 0.46971935 0.46869734 0.4799252  0.45018816 0.47155046
 0.4067523  0.4202945  0.45999944 0.42087877 0.42835504 0.43477648
 0.42058158 0.4257403  0.43014985 0.41807592 0.42705327 0.4300494
 0.42946386 0.42573217 0.4223093  0.42412812 0.43196598 0.43761754
 0.42295194 0.43055573 0.42623654 0.4227105  0.43051583 0.43033302
 0.43305522 0.43276745 0.4302783  0.4571267  0.45704612 0.44554842
 0.4588378  0.45383823 0.44906807 0.43129042 0.43811736 0.3949104
 0.4226357  0.4445552  0.43213475 0.471375   0.45295647 0.41220635
 0.4668906  0.4221319  0.44739723 0.4221177  0.45380783 0.4390418
 0.44203883 0.43415153 0.41297325 0.40150607 0.39882743 0.40253276
 0.43638033 0.4063753  0.42280486 0.3852411  0.45737737 0.40653214
 0.36525697 0.40053287 0.40246576 0.39749095 0.44984013 0.44801673
 0.39912948 0.40195757 0.4154166  0.41134512 0.41996557 0.3979234
 0.42203215 0.41170013 0.42635378 0.40291876 0.35108942 0.40318772
 0.3927331  0.4236556  0.42277697 0.37726432 0.44968084 0.40557224
 0.42496797 0.45112568 0.3957876  0.43660718 0.42694676 0.4094427
 0.36715236 0.4009741  0.44737473 0.36750764 0.3883332  0.43790975
 0.40448755 0.39859933 0.43257442 0.39894873 0.36135167 0.3913999
 0.3646314  0.36937955 0.334166   0.3785924  0.35261124 0.32684076
 0.32392824 0.3739561  0.3153534  0.35983407 0.38685924 0.4019227
 0.37868443 0.3644516  0.39103884 0.3613628  0.34036535 0.34543252
 0.35865963 0.37125766 0.324691   0.42315173 0.34097272 0.3931055
 0.35196662 0.40426844 0.41092175 0.4145537  0.4255409  0.42566985
 0.43348426 0.4501407  0.4428823  0.4169541  0.43493047 0.44978252
 0.4108708  0.4486541  0.4246901  0.4330413  0.41154402 0.4173155
 0.41134852 0.42185366 0.41948658 0.42807233 0.4391464  0.42582437
 0.43599853 0.43125743 0.4222711  0.44209468 0.36926422 0.44182146
 0.43357927 0.43320107 0.42778173 0.4025955  0.4480439  0.4074954
 0.40684518 0.390528   0.40798306 0.42366087 0.46831092 0.4189908
 0.4149637  0.42566568 0.4470269  0.40775296 0.43885002 0.44762176
 0.4101397  0.412378   0.4587008  0.44007888 0.45833382 0.397119
 0.38137963 0.4138899  0.45156443 0.40786773 0.42912242 0.46944565], shape=(522,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(522,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1]
mse:tf.Tensor(0.18206842, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/svd-some-loop.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[4.01424030e-20 4.88462198e-19 1.34326873e-28 0.00000000e+00
 3.99705122e-08 2.96018161e-23 3.91107291e-22 2.59646168e-33
 0.00000000e+00 1.41953357e-19 1.06541286e-07 0.00000000e+00], shape=(12,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(12,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(1.0790573e-15, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/s3_srvr_1a.cil.c-1_000.smt2
true label:[1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1]
true label rank:[2 2 1 1 1 1 2 1 1 1 2 2]
predicted label:tf.Tensor(
[0.49098453 0.04492211 0.00081944 0.01294535 0.02945542 0.004345
 0.00302151 0.4780708  0.47799793 0.464858   0.47578058 0.4698707 ], shape=(12,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(12,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.28293845, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0115_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[2.0180632e-05 4.1657686e-04 1.0959648e-05 2.3218243e-05 2.8410554e-04
 4.8432295e-05 9.3517374e-06 9.5454147e-05 3.4837478e-06 3.6200881e-03
 1.7910689e-02 3.9001374e-05], shape=(12,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(12,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(2.7847183e-05, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/loop__loop2_000.smt2
true label:[1, 1, 0, 1, 1]
true label rank:[2 2 1 2 2]
predicted label:tf.Tensor([0.45353216 0.45755658 0.44949162 0.43351626 0.45219707], shape=(5,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.2831813, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/12.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0]
true label rank:[1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1
 1 2 1 1 2 2 1]
predicted label:tf.Tensor(
[0.4138303  0.454896   0.43667743 0.41440225 0.43953228 0.4127912
 0.38283396 0.41474846 0.42158324 0.46492884 0.42525136 0.42282856
 0.45167455 0.44065785 0.44903558 0.42082375 0.43014485 0.43570465
 0.4224137  0.39809233 0.45193726 0.4473107  0.45480868 0.46081132
 0.45774767 0.46137443 0.4595266  0.45440117 0.45819333 0.4610056
 0.4912457  0.48291782 0.47971675 0.4679513  0.47497958 0.4786827
 0.4637115  0.4584347  0.44896507 0.46284053 0.48508623 0.4891333
 0.49058715 0.48587012], shape=(44,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(44,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1]
mse:tf.Tensor(0.2422081, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/listcounter.correct.nts_000.smt2
true label:[1, 1, 1, 1, 1, 0, 1, 0, 1, 0]
true label rank:[2 2 2 2 2 1 2 1 2 1]
predicted label:tf.Tensor(
[0.47761735 0.48898008 0.4685616  0.47343656 0.47301793 0.47304997
 0.46291316 0.46568257 0.47613207 0.48458427], shape=(10,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(10,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.26097894, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/spline-fixed.smt2-0008_000.smt2
true label:[0, 1]
true label rank:[1 2]
predicted label:tf.Tensor([0.4779178  0.48033762], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 0.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.2492272, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0260_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.0000000e+00 7.9832700e-35 0.0000000e+00 0.0000000e+00 2.2093523e-27
 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.5929095e-01 4.7518885e-01
 3.7541494e-01 3.6612886e-01 3.9804098e-01 3.7945110e-01 3.7379584e-01
 3.7618181e-01 3.6761391e-01 3.7507442e-01 3.6707431e-01 3.4292436e-01
 4.5028773e-01 3.8221344e-01 4.1023839e-01 4.1377872e-01 3.5327357e-01
 3.8729775e-01 3.6692542e-01 2.2148028e-01 2.8067601e-01 4.0073848e-01
 3.7528822e-01 3.0894935e-01 3.7136969e-01 2.6793295e-01 2.5878635e-01
 3.2985276e-01 3.9044601e-01 3.9347133e-01 3.6469522e-01 4.4189593e-01
 3.1377596e-01 4.2935327e-01 4.5010537e-01 3.7266311e-01 4.0823275e-01
 4.7559035e-01 3.2724547e-01 4.3276921e-01 3.8147044e-01 4.1758019e-01
 3.7196943e-01 3.9471900e-01 3.2531518e-01 3.8281375e-01 3.7659019e-01
 3.8337880e-01 4.4259241e-01 3.7238920e-01 3.3194983e-01 3.2681555e-01
 2.9473728e-01 3.5991070e-01 3.2662830e-01 2.7331927e-01 3.8967294e-01
 4.0064785e-01 3.5787287e-01 3.8217586e-01 3.4471399e-01 3.7448585e-01
 3.6636901e-01 3.2414407e-01 3.6596841e-01 3.0665267e-01 2.8645176e-01
 3.0942222e-01 3.2173425e-01 3.7310809e-01 4.0427589e-01 4.0412927e-01
 3.3024806e-01 3.8408011e-01 2.9038376e-01 3.8653606e-01 3.7765035e-01
 2.8406847e-01 3.4785837e-01 3.3970714e-01 3.6223328e-01 3.5378635e-01
 2.9681921e-01 4.6100315e-01 3.5063225e-01 2.6415876e-01 4.2754096e-01
 2.9878688e-01 2.4991813e-01 3.4030485e-01 4.3071857e-01 3.3874124e-01
 3.2889038e-01 4.3896550e-01 4.3431395e-01 4.2800659e-01 3.1540415e-01
 4.0082407e-01 3.2618564e-01 4.0450639e-01 3.4712633e-01 3.1663677e-01
 4.3874159e-01 3.5043433e-01 3.3809155e-01 2.8649116e-01 4.2279941e-01
 2.7911302e-01 3.0388594e-01 3.3639547e-01 3.4257424e-01 3.5499007e-01
 3.5591367e-01 3.3257946e-01 1.9922462e-01 3.1358635e-01 3.9007413e-01
 3.9164630e-01 2.9612088e-01 3.2382554e-01 3.9881876e-01 3.4606051e-01
 3.8977870e-01 4.2273909e-01 3.3727986e-01 3.2314724e-01 3.1748110e-01
 3.4819287e-01 3.5453236e-01 3.9182425e-01 2.3941907e-01 3.1343234e-01
 4.5349801e-01 3.5167783e-01 4.2501113e-01 3.2560238e-01 3.4489813e-01
 3.9497718e-01 3.1754577e-01 3.7619081e-01 3.7126023e-01 3.6531866e-01
 3.6326364e-01 4.4498473e-01 2.4208748e-01 4.2855421e-01 3.7772995e-01
 3.7817961e-01 4.2189378e-01 2.7705282e-01 3.1993443e-01 3.2364702e-01
 4.3197459e-01 4.3292367e-01 3.9325294e-01 2.5685057e-01 3.4616330e-01
 3.7821355e-01 4.4655856e-01 3.0694363e-01 3.6433303e-01 3.0398798e-01
 4.5673430e-01 3.4440011e-01 3.4400940e-01 2.7284363e-01 4.2425165e-01
 2.7562380e-01 3.1863272e-01 3.0981651e-01 3.5348839e-01 3.3721185e-01
 4.3750736e-01 3.6020637e-01 3.0680019e-01 4.5380780e-01 1.9300416e-01
 3.2396439e-01 3.6167467e-01 1.4871353e-01 2.9478592e-01 2.5970858e-01
 2.6228750e-01 3.6810929e-01 4.0621510e-01 2.1920711e-01 2.5716776e-01
 4.3261430e-01 3.1632584e-01 2.8795564e-01 3.2411343e-01 3.3200455e-01
 4.0049970e-01 2.7270758e-01 3.1644893e-01 4.3139577e-01 4.0913612e-01
 3.1977493e-01 3.8774723e-01 3.5967702e-01 3.5961258e-01 4.1722694e-01
 4.3004721e-01 3.8700011e-01 3.0886507e-01 4.0044001e-01 3.5644275e-01
 4.4799945e-01 3.9821839e-01 3.4055132e-01 3.9139041e-01 4.7963879e-01
 4.7265303e-01 4.2320472e-01 2.7337527e-01 3.1679139e-01 4.3570715e-01
 4.1454077e-01 2.7577835e-01 3.6149305e-01 4.0900725e-01 3.1510860e-01
 4.1361722e-01 3.8630208e-01 4.2561010e-01 2.8233808e-01 3.5088789e-01
 3.1783718e-01 3.4003264e-01 4.3173304e-01 3.7482911e-01 3.5128933e-01
 3.5592774e-01 4.4914228e-01 4.3647993e-01 3.2253826e-01 3.9293739e-01
 2.9168671e-01 2.6395294e-01 3.3189553e-01 3.0241513e-01 3.9165324e-01
 3.8767806e-01 4.3520725e-01 4.1841447e-01 4.0062746e-01 3.7661964e-01
 3.5270649e-01 2.7521002e-01 2.9007015e-01 3.6762449e-01 2.5103348e-01
 3.8964799e-01 3.4236747e-01 3.0422646e-01 3.5923725e-01 3.7444639e-01
 3.7184411e-01 3.2963330e-01 3.2825774e-01 3.3633763e-01 3.5977224e-01
 2.2330430e-01 3.1446505e-01 4.0979588e-01 3.2835013e-01 4.0962732e-01
 3.9381891e-01 3.3670199e-01 4.0055037e-01 4.5119771e-01 3.8399875e-01
 2.2377518e-01 3.1507629e-01 4.1202047e-01 3.0844277e-01 2.7999461e-01
 3.3827129e-01 3.2855010e-01 3.2690638e-01 2.8338909e-01 3.5554826e-01
 3.3594793e-01 3.5996997e-01 4.1312993e-01 2.8556848e-01 3.7347865e-01
 3.8483864e-01 4.5659214e-01 2.8644735e-01 3.2721633e-01 4.8801833e-01
 2.7798635e-01 3.6745957e-01 3.3891690e-01 4.7210082e-01 3.5542485e-01
 3.8056925e-01 4.0707046e-01 3.2018930e-01 4.0509433e-01 3.9688450e-01
 4.7671181e-01 3.4736907e-01 4.2504668e-01 4.5199040e-01 4.5631242e-01
 2.8824788e-01 3.8473246e-01 4.4493774e-01 3.4907511e-01 3.6623544e-01
 4.3002599e-01 3.3677205e-01 3.9493805e-01 4.2592123e-01 4.1891092e-01
 3.4079731e-01 3.1944430e-01 3.0187854e-01 2.4695182e-01 3.7893194e-01
 4.4484285e-01 4.4342360e-01 4.0455788e-01 3.6148447e-01 3.6833364e-01
 4.1620648e-01 2.4842036e-01 3.2654357e-01 3.8172939e-01 3.3896387e-01
 3.8643697e-01 2.7447784e-01 2.5379455e-01 4.0014201e-01 3.6361769e-01
 2.4235684e-01 2.9027969e-01 3.1470105e-01 4.3996757e-01 3.0908906e-01
 4.4817135e-01 3.4058625e-01 4.5754808e-01 4.4107911e-01 4.2107439e-01
 3.0755031e-01 2.5811893e-01 3.5680026e-01 3.4435081e-01 3.8341683e-01
 2.9762471e-01 3.8699985e-01 3.9580387e-01 3.4711611e-01 3.4679002e-01
 4.1614100e-01 2.8715611e-01 2.9067427e-01 3.4956402e-01 4.1781718e-01
 3.8052326e-01 3.2540426e-01 4.2964482e-01 2.6381528e-01 3.3326903e-01
 2.4352837e-01 4.5663172e-01 2.8590906e-01 3.7854993e-01 4.1483852e-01
 3.1087863e-01 3.1381321e-01 3.7019718e-01 3.2508481e-01 3.5151693e-01
 3.0851817e-01 4.0581796e-01 2.9754016e-01 4.3291974e-01 3.9791101e-01
 4.4040468e-01 3.3372638e-01 2.7519834e-01 3.8360444e-01 3.5720277e-01
 4.2248738e-01 3.8442826e-01 2.7461112e-01 3.9081725e-01 3.4979856e-01
 3.5819006e-01 3.9661658e-01 3.2371545e-01 3.0679810e-01 4.0192264e-01
 2.7613896e-01 3.7310410e-01 3.1462580e-01 4.0723446e-01 3.8708055e-01
 3.2816666e-01 3.9873272e-01 2.3068267e-01 3.4604079e-01 3.3703053e-01
 4.2353851e-01 2.5176498e-01 5.0585788e-01 4.2957371e-01 3.7120879e-01
 3.2266068e-01 2.8539738e-01 2.9887033e-01 4.4056356e-01 4.0645820e-01
 3.1761280e-01 3.3322361e-01 3.2876134e-01 3.5856092e-01 3.6955097e-01
 3.6765033e-01 3.5817075e-01 3.9947993e-01 3.5048485e-01 3.8850993e-01
 2.9748687e-01 4.1456747e-01 3.3845711e-01 3.9780632e-01 2.7279305e-01
 3.0165917e-01 4.2728394e-01 2.9111820e-01 3.3983272e-01 4.1738701e-01
 2.8817052e-01 3.5861951e-01 3.8221973e-01 4.2387587e-01 3.0425388e-01
 4.0488917e-01 4.1509938e-01 2.8434289e-01 2.9264629e-01 4.0923262e-01
 3.1761038e-01 4.0390098e-01 3.7922868e-01 3.5810679e-01 3.8401625e-01
 3.2254285e-01 4.6307322e-01 3.6752707e-01 4.0952495e-01 3.9593422e-01
 4.8807177e-01 3.7245387e-01 2.8945899e-01 3.7882090e-01 2.6469433e-01
 3.7090912e-01 2.8730357e-01 3.3157697e-01 3.2862934e-01 2.6674408e-01
 3.7675864e-01 3.0229911e-01 2.1338156e-01 4.3309370e-01 3.4601295e-01
 3.9314279e-01 3.4242111e-01 3.4120929e-01 4.2730319e-01 4.0004924e-01
 3.5971689e-01 3.6206943e-01 3.6853868e-01 3.8697463e-01 3.4800261e-01
 3.6182725e-01 3.1923378e-01 3.6356845e-01 4.8266581e-01 3.8809204e-01
 3.8716519e-01 3.2560104e-01 3.1565723e-01 4.1418535e-01 4.2204189e-01
 4.4972020e-01 4.1453195e-01 4.2434847e-01 4.3359774e-01 4.4803667e-01
 4.2408830e-01 4.3723735e-01], shape=(507,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0.], shape=(507,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.13062474, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/MOESI_1_e3_1884_e7_1875_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[7.91162252e-04 1.23870969e-02 1.74537301e-03 1.91569328e-04
 3.66837978e-02 3.60488892e-04 5.35458326e-04 4.11468744e-03
 1.36381388e-03 1.02028847e-01 9.34270322e-02 3.36199999e-04
 9.55447555e-03 1.83917463e-01 4.51095104e-02 1.44708157e-03
 5.28910160e-02 2.55533159e-02 3.70653003e-01 5.59949585e-05
 2.79217958e-04 4.46438789e-04 7.56502151e-04 2.42310762e-03
 1.18563473e-02 3.72406840e-03 9.68748864e-05 1.59174204e-04
 6.82085752e-04 1.64125264e-02 1.14950538e-03 9.11861658e-04
 1.11055672e-02 2.21610069e-03 4.06682491e-04 3.77330184e-02
 3.19923460e-02 1.44079328e-03 4.59721684e-03 1.67541265e-01
 1.72632933e-03 1.23346150e-02 1.26896143e-01 1.09779835e-03
 4.88678813e-02 2.07436383e-01 6.15000725e-04 1.33530468e-01
 2.78547406e-03 3.94769311e-02 1.96314156e-02 1.90323591e-03
 3.63722384e-01 3.61374140e-01 3.59411597e-01 3.66810590e-01
 3.49368542e-01 3.53907079e-01 3.65211189e-01 3.62374425e-01
 3.63420665e-01 3.64894986e-01 3.48972380e-01 3.33975434e-01
 3.53913665e-01 3.71039867e-01 3.56137246e-01 3.66796970e-01
 3.65991652e-01 3.54871154e-01 3.72591227e-01 3.73790622e-01
 3.68452400e-01 3.55876505e-01 3.65315497e-01 3.55379343e-01
 3.31757009e-01 3.70234251e-01 3.60801488e-01 3.56428415e-01
 3.61276805e-01 3.48715603e-01 3.63437772e-01 2.51558542e-01
 2.26586848e-01 1.57194197e-01 2.03771621e-01 2.81928986e-01
 2.99962878e-01 2.40738064e-01 2.47636050e-01 4.30190980e-01
 2.26606965e-01 1.44468218e-01 4.69040573e-01 2.19403654e-01
 2.69054383e-01 2.06388950e-01 3.44781756e-01 2.17771977e-01
 2.90983468e-01 3.96162242e-01 2.69462794e-01 2.65977800e-01
 1.70030177e-01 3.63770306e-01 1.20920181e-01 3.45789909e-01
 2.97266006e-01 2.81071544e-01 2.50462294e-01 1.83460295e-01
 2.58462906e-01 1.78275257e-01 3.24642986e-01 1.38168603e-01
 3.26012343e-01 2.01870441e-01 2.84016728e-01 4.03887868e-01
 3.72253120e-01 3.87259066e-01 3.80002916e-01 3.79985780e-01
 3.94871235e-01 3.79119307e-01 3.90128314e-01 3.85910422e-01
 3.81140113e-01 3.87147069e-01 3.93244922e-01 3.85277033e-01
 3.80961478e-01 3.91233325e-01 3.73355925e-01 3.90511096e-01
 3.92633110e-01 3.76257032e-01 3.85478318e-01 3.75274211e-01
 3.85803461e-01 3.93473953e-01 3.87291461e-01 3.89190763e-01
 3.80904168e-01 3.83492827e-01 3.89735878e-01 3.73695910e-01
 3.87260020e-01 3.84108990e-01 3.75783771e-01 4.55346942e-01
 4.43648040e-01 4.45928335e-01 4.49629128e-01 4.48351115e-01
 4.36914712e-01 4.34279144e-01 4.48643625e-01 4.38278437e-01
 4.47316468e-01 4.26789224e-01 4.37832952e-01 4.27510977e-01
 4.56947088e-01 4.47612882e-01 4.65163529e-01 4.52415764e-01
 4.59928036e-01 4.63935167e-01 4.64148372e-01 4.54598784e-01
 4.71202761e-01 4.56282198e-01 4.73441601e-01 4.57188845e-01
 4.47134316e-01 4.55680370e-01 4.50648606e-01 4.56701636e-01
 4.62276042e-01 4.48405892e-01 4.60753441e-01 4.55743879e-01
 4.40380573e-01 3.41150820e-01 3.64100844e-01 2.89621294e-01
 3.86362374e-01 3.37272346e-01 3.68389040e-01 4.07150745e-01
 4.51242596e-01 3.26069534e-01 3.37888539e-01 4.56575036e-01
 2.58444428e-01 3.58469844e-01 3.30709130e-01 3.45029891e-01
 3.82815033e-01 4.63168681e-01 4.61059511e-01 4.72937077e-01
 4.71018970e-01 4.73705322e-01 4.68989700e-01 4.63839620e-01
 4.67438042e-01 4.68604863e-01 4.70385164e-01 4.76270318e-01
 4.78236973e-01 4.62710589e-01 4.71229494e-01 4.70069140e-01
 4.73812252e-01 4.72825319e-01 4.78778303e-01 4.88400608e-01
 4.83363003e-01 4.81995136e-01 4.77449745e-01 4.76353467e-01
 4.78359610e-01 4.86370027e-01 4.83766586e-01 4.82223988e-01
 4.84402657e-01 4.84499633e-01 4.80646491e-01 4.80347574e-01
 4.77166772e-01 4.54531431e-01 4.60517019e-01 4.47397441e-01
 4.44341540e-01 4.57082182e-01 4.37431723e-01 4.55530047e-01
 4.60633129e-01 4.70424265e-01 4.61161077e-01 4.59890783e-01
 4.48561281e-01 4.43691343e-01 4.59129095e-01 4.60909128e-01
 4.55523700e-01 4.74429458e-01 4.74133372e-01 4.57472801e-01
 4.79080051e-01 4.70436811e-01 4.72487748e-01 4.45167452e-01
 4.10952032e-01 4.48213398e-01 4.62700695e-01 4.21842247e-01
 4.65153724e-01 4.40272778e-01 4.57071126e-01 4.59772468e-01
 4.60687399e-01 4.41108733e-01 4.45808947e-01 4.27911162e-01
 4.33346868e-01 4.27766860e-01 4.34069216e-01 4.39765960e-01
 4.22230393e-01 4.35486913e-01 4.41854060e-01 4.36745942e-01
 4.31240022e-01 4.32905763e-01 4.44604933e-01 4.40772295e-01
 4.41084445e-01 4.44140941e-01 4.45292413e-01 4.39253002e-01
 4.38831866e-01 4.28633422e-01 4.31339324e-01 4.38224703e-01
 4.26273465e-01 4.49784636e-01 4.36659038e-01 4.30989802e-01
 4.37217057e-01 4.28181648e-01 4.34265226e-01 4.33992535e-01
 4.40610915e-01 4.35534209e-01 4.40095931e-01 4.27327454e-01
 4.32666987e-01 4.32297260e-01 4.31874007e-01 4.37869728e-01
 4.29000258e-01 4.32265848e-01 4.29351211e-01 3.48642230e-01
 3.51742327e-01 4.21945393e-01 4.88405108e-01 3.68182719e-01
 3.77877533e-01 4.28445160e-01 3.46962214e-01 3.03633332e-01
 3.44566554e-01 3.85878205e-01 3.87308061e-01 3.69380355e-01
 3.70879233e-01 2.78077781e-01 3.30197424e-01 3.64447892e-01
 3.72684538e-01 3.61280739e-01 3.14357042e-01 3.64552438e-01
 2.74701983e-01 4.06833410e-01 4.11189914e-01 4.12779093e-01
 4.07448113e-01 4.07599419e-01 4.13541377e-01 4.06823695e-01
 4.02485967e-01 4.02930140e-01 4.06615168e-01 4.10041600e-01
 4.02290761e-01 4.08475250e-01 3.99167120e-01 4.11275119e-01
 4.04907584e-01 4.11173731e-01 4.07210410e-01 4.10417706e-01
 4.01775509e-01 4.01466966e-01 3.99328738e-01 3.97819102e-01
 4.06403422e-01 4.05785054e-01 4.05989945e-01 4.01177406e-01
 4.07439709e-01 4.00836229e-01 4.03646231e-01 4.06113774e-01
 4.05361176e-01 4.02493238e-01 4.12676752e-01 3.89375657e-01
 4.01953578e-01 3.99131685e-01 4.01092052e-01 4.01662827e-01
 4.02311236e-01 4.04770195e-01 4.17824149e-01 4.10228789e-01
 4.05180037e-01 4.12608206e-01 3.97256047e-01 4.11166668e-01
 4.06999052e-01 4.06764328e-01 4.07025546e-01 3.95696849e-01
 4.04331803e-01 4.03722703e-01 4.01506186e-01 3.98980975e-01
 3.87932241e-01 3.90686989e-01 3.89672548e-01 3.90098304e-01
 3.92505288e-01 3.90138835e-01 3.86661857e-01 3.92106652e-01
 3.84883046e-01 3.80518913e-01 3.86423945e-01 3.89002770e-01
 3.98482502e-01 3.87518257e-01 3.79300714e-01 3.85785222e-01
 3.87532145e-01 3.96394223e-01 3.86524856e-01 3.82581592e-01
 3.90672117e-01 3.86950433e-01 3.89632702e-01 3.88605565e-01
 3.80814523e-01 3.79834116e-01 4.31899428e-01 4.23766732e-01
 4.19917405e-01 4.18466330e-01 4.21615899e-01 4.24612522e-01
 4.31517065e-01 4.12564158e-01 4.19595689e-01 4.23055202e-01
 4.36372697e-01 4.22229171e-01 4.26153183e-01 4.22998846e-01
 4.24760193e-01 4.15534705e-01 4.19494271e-01 4.16424751e-01
 4.16764855e-01 4.17485505e-01 4.16378915e-01 4.15719569e-01
 4.20866400e-01 4.24933970e-01 4.20377374e-01 4.18957502e-01
 4.17103052e-01 4.16177124e-01 4.68408287e-01 3.82623464e-01
 4.48079467e-01 4.49033976e-01 4.49391484e-01 4.40485686e-01
 4.41201657e-01 3.95927072e-01 4.45315629e-01 4.76038605e-01
 4.52579230e-01 4.31905538e-01 4.24888045e-01 4.67749000e-01
 4.30484772e-01 4.13673609e-01 3.82936299e-01 4.38765824e-01
 4.47113335e-01 4.64362413e-01 4.46615577e-01 4.42879856e-01
 4.15179819e-01 4.45719570e-01 4.49579388e-01 4.62920219e-01
 4.20919478e-01 4.56286848e-01 4.25069034e-01 4.30406332e-01
 4.05706406e-01 4.08471406e-01 4.47211266e-01 3.99994671e-01
 3.95521343e-01 4.18229997e-01 1.54219151e-01 3.04392278e-01
 2.71974146e-01 1.32481009e-01 3.77937168e-01 1.53192669e-01
 3.82386774e-01 2.75413007e-01 2.38809884e-01 2.99636602e-01
 3.47757280e-01 2.52829760e-01 3.13076138e-01 2.73164392e-01
 2.17675894e-01 4.01931971e-01 2.41538525e-01 2.19947904e-01
 3.30588937e-01 3.43775451e-01 2.31152326e-01 3.40833604e-01
 2.15694368e-01 2.54849970e-01 3.42785150e-01 2.87982613e-01
 3.04387152e-01 2.03876913e-01 2.78352916e-01 2.88559496e-01
 4.12427753e-01 3.76751721e-01 3.83683503e-01 1.48088038e-01
 4.22086179e-01 2.78512478e-01 2.85311759e-01 2.76475042e-01
 3.77379239e-01 3.05659831e-01 1.80349946e-01 4.38383430e-01
 4.49929714e-01 4.52565283e-01 4.40761566e-01 4.43220794e-01
 4.45467085e-01 4.26600486e-01 4.28762347e-01 4.52484369e-01
 4.33469236e-01 4.41952169e-01 4.17313069e-01 4.39729959e-01
 4.27654833e-01 4.44513261e-01 4.25382823e-01 4.42634404e-01
 4.45574820e-01 4.33565974e-01 4.64401484e-01 4.50406194e-01
 4.26467061e-01 4.20184880e-01 4.26816523e-01 4.47065532e-01
 4.39737529e-01 4.53685164e-01 4.38193828e-01 4.27642941e-01
 4.42088753e-01 4.42081034e-01 4.41873759e-01 4.46277767e-01
 4.41057980e-01 4.27332848e-01 4.33296263e-01 4.30448264e-01
 3.96527648e-01 4.09921497e-01 4.06414986e-01 3.95145953e-01
 3.98071051e-01 3.96811247e-01 3.93418849e-01 4.00009900e-01
 3.84494126e-01 4.04537350e-01 4.03527498e-01 4.10193354e-01
 3.92132133e-01 4.09872532e-01 3.97606403e-01 4.05469745e-01
 3.95101190e-01 3.92308533e-01 4.04270023e-01 3.91032219e-01
 4.06712353e-01 4.20912653e-01 3.99154931e-01 4.03350145e-01
 4.22593236e-01 4.02063608e-01 4.02771771e-01 3.93019587e-01
 3.91790152e-01 4.03878331e-01 3.92791480e-01 4.04219061e-01
 4.07262802e-01 4.00296926e-01 3.94226640e-01 3.96269262e-01
 4.12973762e-01 4.11890417e-01 3.62255812e-01 2.15536475e-01
 2.60172486e-01 3.73163998e-01 1.57743484e-01 1.73564047e-01
 1.60102278e-01 3.43878746e-01 2.54584581e-01 2.20055550e-01
 3.47698092e-01 2.71424115e-01 2.06600696e-01 1.53610289e-01
 3.39885712e-01 1.93249434e-01 1.95396364e-01 1.40670210e-01
 2.50511885e-01 1.50706470e-01 1.08084857e-01 2.89796531e-01
 2.61729240e-01 2.55522311e-01 3.32331002e-01 3.33300650e-01
 2.06216037e-01 3.17347407e-01 1.62410706e-01 3.94765139e-01
 2.58292198e-01 2.28429109e-01 2.86849380e-01 1.60568267e-01
 2.45690495e-01 1.92735225e-01 1.73351288e-01 2.47101367e-01
 3.43377203e-01 1.99808776e-01 4.06138957e-01 3.79564762e-01
 2.04686463e-01 2.74880975e-01 2.15949357e-01 2.36961454e-01
 1.23678625e-01 2.18785644e-01 2.44523287e-01 2.29702026e-01
 2.35909849e-01 7.04463720e-02 2.12588131e-01 1.86441123e-01
 2.73939431e-01 2.64641047e-01 1.80588126e-01 1.97187334e-01
 3.25255334e-01 1.60266578e-01 1.62158757e-01 3.47449243e-01
 2.13756919e-01 2.50396788e-01 2.83147693e-01 4.08853292e-01
 2.28705704e-01 3.50025624e-01 3.20768237e-01 2.36203939e-01
 2.49385208e-01 1.78290099e-01 2.75279343e-01 1.90049440e-01], shape=(664,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(664,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.13874452, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/destroy_test_dangling_unsafe.c_000.smt2
true label:[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 2 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 2 1 2 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2
 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.3568443  0.35123396 0.339912   0.3493272  0.34646228 0.35341403
 0.34669057 0.33625942 0.35430783 0.34876058 0.32805333 0.3440671
 0.35278094 0.341536   0.3507855  0.35531056 0.35223305 0.34258312
 0.34364238 0.3494151  0.3385464  0.32975885 0.34264135 0.3437342
 0.34844238 0.3432223  0.34903002 0.3419817  0.34971845 0.3470651
 0.3346022  0.33754238 0.3390746  0.34011993 0.33836454 0.35056302
 0.3383276  0.34053314 0.34039867 0.35405946 0.32767352 0.35009044
 0.33039278 0.3479501  0.34368733 0.34047103 0.3450545  0.349465
 0.33807164 0.34022158 0.3457209  0.3568222  0.36109233 0.3532398
 0.34149802 0.35212582 0.32942706 0.33195236 0.35120997 0.34306902
 0.34057784 0.3336952  0.33753863 0.3474909  0.34273738 0.35203585
 0.3385332  0.34291792 0.34549075 0.34950322 0.34115458 0.34344172
 0.3488989  0.3393449  0.35782698 0.3409164  0.33112612 0.35210854
 0.33793995 0.36099482 0.33009866 0.3362717  0.33569628 0.33167344
 0.34396487 0.3273489  0.33773068 0.3357057  0.32740763 0.31158334
 0.33140373 0.35434753 0.34013984 0.3457982  0.33719972 0.341572
 0.33082968 0.33107132 0.33068204 0.3337314  0.32829523 0.3313356
 0.3450486  0.33627626 0.34227192 0.3251465  0.31887734 0.3353179
 0.3319153  0.33783686 0.34919065 0.32989702 0.34419036 0.3194066
 0.3313895  0.34280318 0.34135157 0.34156692 0.33392054 0.34001106
 0.3193972  0.32979602 0.32053673 0.32248032 0.32671776 0.33330977
 0.32266986 0.3258492  0.32127088 0.3311987  0.32424724 0.32921413
 0.33682245 0.32737908 0.33966756 0.34750336 0.327774   0.32841027
 0.3385284  0.33199292 0.3239033  0.3282176  0.34529114 0.34099233
 0.35066462 0.3380318  0.33437735 0.32841045 0.33435088 0.33539677
 0.33140787 0.35342658 0.3453881  0.3426433  0.3400994  0.3444929
 0.32882857 0.3333847  0.34461802 0.3284105  0.33976007 0.33006492
 0.32760525 0.3235088  0.34339988 0.3322571  0.3202364  0.33714384
 0.3241498  0.33637166 0.33261827 0.33781892 0.34401745 0.32946768
 0.35078418 0.3271634  0.3312258  0.33328342 0.32108885 0.323679
 0.3294788  0.33539116 0.34218085 0.3237626  0.31825244 0.33551252
 0.34317505 0.33344406 0.33807278 0.349519   0.34097695 0.33271372
 0.334805   0.3417074  0.33210093 0.3367253  0.318444   0.32273826
 0.3228112  0.3532513  0.34050447 0.33209208 0.33195123 0.34444615
 0.32856423 0.3295368  0.33701825 0.3319857  0.36072168 0.34902543
 0.36184865 0.3658895  0.3448547  0.37721473 0.34013024 0.3425764
 0.36179838 0.35477442 0.3355717  0.3395557  0.35145628 0.35826576
 0.35018826 0.36836112 0.3480112  0.37072653 0.35103163 0.34125942
 0.36452562 0.36346543 0.35242963 0.3639402  0.35626054 0.36113116
 0.36670545 0.36124998 0.35352457 0.36027807 0.36045325 0.35943496
 0.3565621  0.35997832 0.3604732  0.36115253 0.34574604 0.35781813
 0.36134413 0.3590837  0.35391647 0.3502936  0.36962682 0.34144592
 0.35869378 0.35824066 0.36230886 0.35490113 0.3538043  0.35663182
 0.3503357  0.3564399  0.356094   0.35996968 0.35803497 0.36359987
 0.3740254  0.36195272 0.37375915 0.3518956  0.3697064  0.35809964
 0.3534243  0.35285282 0.34487304 0.3540876  0.3512175  0.36028257
 0.35521463 0.34899467 0.3629785  0.3554839  0.35987985 0.35433516
 0.37179777 0.36449772 0.3793881  0.34444875 0.33964187 0.35147676
 0.36245784 0.3603528  0.36535528 0.35972667 0.35910767 0.35929662
 0.3592612  0.3468117  0.36583644 0.36830264 0.36304522 0.37003854
 0.34352022 0.36799788 0.35066277 0.3475386  0.3566236  0.36006057
 0.35407102 0.3773569  0.35325125 0.36123607 0.3571517  0.37037453
 0.34882987 0.36178762 0.35758507 0.36505258 0.35969633 0.36099195
 0.35753798 0.35150462 0.35307455 0.35944527 0.34992367 0.36014995
 0.3515826  0.36002445 0.35233873 0.35174865 0.37137887 0.360324
 0.3669837  0.37818718 0.35177723 0.3609256  0.36675602 0.34572583
 0.3705626  0.3664257  0.36672163 0.35907635 0.35536665 0.35158837
 0.35468304 0.36489868 0.36126328 0.3560319  0.3484491  0.34903848
 0.34947982 0.3568698  0.36306542 0.34997773 0.36467224 0.34996372
 0.3641317  0.330908   0.34661064 0.34332865 0.3106761  0.34719542
 0.3316673  0.3457973  0.35106605 0.32640195 0.32955468 0.34412545
 0.34589243 0.33377337 0.32813153 0.34445363 0.3392225  0.3353899
 0.3434042  0.3296572  0.33480048 0.33418274 0.3370927  0.32526782
 0.33702588 0.34427378 0.33749312 0.33487266 0.32632726 0.34907135
 0.32847726 0.34554145 0.33712077 0.3435718  0.3357845  0.3445347
 0.3453191  0.3398716  0.33642298 0.33836257 0.33774614 0.33486488
 0.34178096 0.33785942 0.33373272 0.3313922  0.3316408  0.34474444
 0.3291605  0.33789253 0.34222555 0.33046553 0.3236069  0.3234833
 0.35114285 0.32923424 0.32316032 0.34818214 0.32630092 0.3430075
 0.33382913 0.33490634 0.33973122 0.32731238 0.3314671  0.32508022
 0.3400237  0.33045256 0.34182566 0.34116867 0.34357986 0.3561821
 0.34143838 0.33706215 0.34233645 0.33845973 0.3388121  0.33211872
 0.33853555 0.34945747 0.34396657 0.32179612 0.3265959  0.3245081
 0.34858313 0.3385532  0.34168455 0.35151517 0.34679186 0.33882615
 0.3433339  0.34494784 0.33285582 0.32746607 0.3402232  0.33168882
 0.3466879  0.34839922 0.3399092  0.32675076 0.34430924 0.33520657
 0.33474502 0.34586138 0.33819547 0.33193725 0.32973915 0.33954424
 0.33096206 0.33646318 0.34367996 0.3382882  0.34298503 0.33352676
 0.3324322  0.33782643 0.3375606  0.33234078 0.33885056 0.32781097
 0.34122288 0.34799403 0.34330225 0.33836305 0.34481955 0.34719098
 0.3282249  0.32947895 0.3460067  0.3420051  0.34198976 0.3468133
 0.3200044  0.3219474  0.34185624 0.34086227 0.33316183 0.3562682
 0.34932974 0.34451845 0.3241643  0.3331058  0.3332237  0.33563346
 0.33638605 0.34086716 0.33268273 0.3323915  0.33799303 0.34205127
 0.34673327 0.33048633 0.34466797 0.3579275  0.33787888 0.33489624
 0.34396365 0.34081    0.34326446 0.34819186 0.33549434 0.34369588
 0.33037904 0.3406633  0.33845186 0.35876805 0.3422054  0.31787968
 0.3318371  0.33885318 0.3302193  0.34576574 0.40530396 0.41291556
 0.40440267 0.4171139  0.4117428  0.42259493 0.40788335 0.4098166
 0.4005323  0.4078464  0.4011898  0.40644515 0.4066703  0.41014215
 0.41958782 0.41550523 0.41597813 0.40688655 0.40880132 0.40286708
 0.400108   0.407858   0.41117096 0.4182719  0.40842518 0.39717406
 0.40705776 0.40636125 0.41376546 0.40706038 0.40935078 0.4127283
 0.40757772 0.41213915 0.40137208 0.40302128 0.41528517 0.40843293
 0.39948064 0.4099729  0.40995312 0.40247047 0.40838373 0.40756643
 0.40470734 0.40371463 0.4055566  0.40423304 0.39266175 0.41874042
 0.40124252 0.40197617 0.39851552 0.40728316 0.39582443 0.40473357
 0.4084072  0.41663492 0.40658987 0.40542907 0.41176072 0.4100588
 0.4094758  0.4054451  0.40623203 0.4158282  0.40910345 0.40723726
 0.40753165 0.41696262 0.4158442  0.40744087 0.41069824 0.4059878
 0.40961584 0.40222737 0.41057074 0.4085927  0.39453945 0.40398395
 0.40894073 0.4115556  0.40639699 0.40903336 0.41165525 0.407664
 0.40063116 0.4090723  0.39990735 0.4079014  0.40775144 0.4061321
 0.42016587 0.40326345 0.4038198  0.40774432 0.4088612  0.41592026
 0.40180302 0.4091789  0.39637256 0.4049838  0.4048485  0.41736528
 0.4081939  0.4097037  0.40704763 0.41075727 0.4122694  0.40990278
 0.41825962 0.41079256 0.41025785 0.41106302 0.41003382 0.40524793
 0.415225   0.4078925  0.41319913 0.40770274 0.41343102 0.4050222
 0.4107932  0.41098046 0.39806125 0.4107711  0.40879965 0.40517658
 0.40851673 0.4092846  0.41357154 0.41206494 0.4052651  0.41519552
 0.4006764  0.40101802 0.408636   0.39675283 0.408118   0.413736
 0.4123361  0.40517938 0.40767503 0.41482973 0.41051334 0.4213775
 0.41884345 0.40893677 0.40706885 0.41028887 0.41246828 0.4053518
 0.40606982 0.41079143 0.39840934 0.40589043 0.4046523  0.4102846
 0.4095353  0.41111505 0.41852653 0.40624794 0.4115138  0.40580654
 0.41651854 0.41524214 0.41122553 0.41453186 0.41324174 0.40447217
 0.40586105 0.39626968 0.41469824 0.41428524 0.40192944 0.41249573
 0.4121698  0.40568417 0.39806223 0.406371   0.40747702 0.40809935
 0.4042808  0.4169997  0.4155716  0.4080136  0.41161373 0.40189278
 0.4039645  0.39939976 0.41199344 0.40844858 0.4017531  0.41437155
 0.4402647  0.4319118  0.43892685 0.4379501  0.42432395 0.45068607
 0.44304729 0.43266243 0.4384296  0.42787966 0.43938422 0.4391999
 0.43433076 0.44219995 0.43836462 0.43305328 0.43441465 0.43215197
 0.4342089  0.43413883 0.43943498 0.43639663 0.4338938  0.4472052
 0.44616416 0.44860828 0.4451096  0.44795033 0.44119957 0.44742092
 0.44631588 0.44308817 0.45066845 0.44589573 0.44982722 0.44526452
 0.44825104 0.444974   0.4488008  0.44699058 0.4473023  0.44880703
 0.45111436 0.4468106  0.45135614 0.4478958  0.44515854 0.44712013
 0.4403566  0.44650814 0.44305384 0.4402778  0.4452877  0.44716728
 0.41239837 0.41419554 0.4115314  0.40784425 0.40372226 0.41291842
 0.41517362 0.4043411  0.4109205  0.41940403 0.40873206 0.41216275
 0.40860462 0.41455474 0.40473494 0.40657377 0.41093382 0.42123425
 0.4078225  0.40208435 0.41300237 0.4146387  0.4058615  0.40742335
 0.41032434 0.41606966 0.41469985 0.4075921  0.41178948 0.4183613
 0.41198722 0.41971868 0.40653402 0.40568763 0.4150294  0.4060148
 0.41806108 0.41628182 0.40900934 0.40889177 0.40539962 0.4106937
 0.40605092 0.40596366 0.4061581  0.40595198 0.40564775 0.40449557
 0.4039964  0.40046006 0.40019238 0.40607774 0.4074157  0.4015214
 0.3973366  0.4017226  0.39872488 0.40101606 0.40091416 0.40229416
 0.40124235 0.40759438 0.40293026 0.4054948  0.39858603 0.40400922
 0.40398866 0.40340444 0.39932513 0.40185797 0.40502146 0.39780173
 0.4091836  0.41502345 0.4052712  0.40253937 0.40657502 0.40119538
 0.4079868  0.4044391  0.41243824 0.41350996 0.402968   0.40388423
 0.40368453 0.40158433], shape=(860,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(860,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.16733822, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/04.c_000.smt2
true label:[0, 0]
true label rank:[1 1]
predicted label:tf.Tensor([0.47725236 0.47860157], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 0.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.22841465, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/013b-horn_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.45860785 0.46680894 0.47202712 0.4617333  0.45090437 0.4199208
 0.4532063  0.47598353], shape=(8,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0.], shape=(8,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.20948043, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/bound.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[8.4975362e-04 4.6670139e-03 4.5082983e-05 5.0300360e-04 2.1873116e-03
 1.8409422e-05 2.7366699e-05 1.7699599e-04 4.4194894e-05 6.7516565e-03], shape=(10,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(10,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(7.316172e-06, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/metros_1_e8_725_e3_556_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1
 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1
 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1
 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1
 1 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 2 2 1 1 1 1 1 1
 1 2 2 2 2 1 1 2 2 1 1 2 1 2 1 1 1 1 1 1 1 2 2 2 2 1 1 1 2 1 2 1 2 1 1 1 2
 1 1 1 1 2 2 2 2 1 1 2 1 1 2 1 1 1 2 1 2 1 1 1 1 2 2 2 2 1 1 2 1 1 1 1 2 1
 2 1 1 1 1 1 1 2 2 2 2 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 1 2 2
 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 2 1 1 2
 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1
 1 2 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 2 1 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 2
 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 1 1 1 1 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[8.2490444e-03 6.9492847e-02 1.5233159e-03 1.0187298e-02 8.4952474e-02
 7.1542561e-03 2.7701557e-03 9.4310641e-03 3.8783550e-03 1.3688651e-01
 1.2494221e-01 5.6168139e-03 7.2457403e-02 2.3049083e-01 3.9347708e-02
 1.3940781e-02 8.0558032e-02 2.8224736e-02 3.2323003e-01 2.1010637e-04
 4.5011640e-03 3.3901334e-03 5.6651533e-03 9.9117458e-03 3.9679438e-02
 2.4916828e-03 1.6095072e-02 1.0696948e-03 1.1703074e-03 7.0576221e-02
 4.9381822e-02 5.9864521e-03 4.1581154e-02 5.4295361e-03 2.3347139e-03
 8.1152201e-02 8.5892618e-02 1.0570198e-02 1.3512492e-02 2.3586547e-01
 4.8850179e-03 2.5851727e-02 2.3708704e-01 2.7606457e-02 4.2949021e-02
 2.6173189e-01 1.3955534e-03 2.5037897e-01 4.6544731e-02 3.3556360e-01
 3.2580310e-01 3.3401430e-01 2.8022721e-01 3.1388533e-01 2.7098131e-01
 3.0822349e-01 2.9996520e-01 3.3265334e-01 2.7123439e-01 2.8754425e-01
 3.2731411e-01 4.1208631e-01 2.5301898e-01 3.0037516e-01 3.7146923e-01
 3.5311449e-01 3.6382073e-01 3.4709945e-01 3.0378217e-01 3.7039530e-01
 2.6568115e-01 2.6671267e-01 2.8597975e-01 3.3733410e-01 2.8992340e-01
 3.1456345e-01 3.0218902e-01 3.7256405e-01 3.8318604e-01 3.6979496e-01
 3.3270052e-01 3.8869131e-01 4.0135109e-01 3.3429354e-01 2.5588596e-01
 3.1248170e-01 2.8273776e-01 3.3059990e-01 3.6434376e-01 2.5734192e-01
 3.0055881e-01 4.3626016e-01 3.3439350e-01 2.9349443e-01 3.9050454e-01
 2.8901851e-01 3.2396674e-01 3.1187585e-01 4.1095039e-01 3.3312112e-01
 3.6266166e-01 3.8359246e-01 4.1333953e-01 3.6055359e-01 2.8262076e-01
 4.0540954e-01 2.6249397e-01 3.4866458e-01 3.6643386e-01 3.1981182e-01
 2.9409450e-01 2.9866165e-01 3.2259929e-01 2.9986247e-01 4.0086845e-01
 3.3323190e-01 2.8793412e-01 2.9596624e-01 3.0485106e-01 3.6818641e-01
 3.1781983e-01 3.1779319e-01 2.2155982e-01 3.0845392e-01 2.5199831e-01
 3.8818201e-01 3.3685672e-01 2.8559425e-01 3.0443811e-01 3.3710051e-01
 2.8804043e-01 4.2927858e-01 3.9744958e-01 3.9469266e-01 3.4610626e-01
 3.7064266e-01 3.5578716e-01 3.4514678e-01 2.9812038e-01 3.5959673e-01
 3.6137557e-01 3.7492204e-01 3.6530513e-01 4.1262186e-01 3.7113005e-01
 4.4041854e-01 3.3646476e-01 3.2125878e-01 3.5041225e-01 3.8711143e-01
 3.1095642e-01 4.1029486e-01 2.4686468e-01 3.7071449e-01 4.2459404e-01
 3.6036000e-01 4.4403028e-01 4.2655873e-01 4.0625548e-01 4.0343797e-01
 4.0488619e-01 4.3779948e-01 4.3680692e-01 4.1030172e-01 4.4553444e-01
 4.2077214e-01 4.5661461e-01 4.2372331e-01 4.3232000e-01 4.1894397e-01
 4.5342621e-01 3.9776850e-01 4.4521663e-01 4.1278204e-01 4.5564392e-01
 4.0371966e-01 4.0372431e-01 4.2365423e-01 4.0290534e-01 4.5550773e-01
 4.5409527e-01 4.2833045e-01 4.4323915e-01 4.5288327e-01 3.8771319e-01
 4.4775695e-01 4.5663828e-01 4.3062308e-01 4.5682016e-01 4.4872165e-01
 4.6987343e-01 4.7219953e-01 4.7615063e-01 4.3736485e-01 4.4550291e-01
 4.3791282e-01 4.5862395e-01 3.9510205e-01 4.2693496e-01 4.5897552e-01
 4.6481201e-01 4.2789850e-01 4.1907215e-01 4.4815254e-01 4.2746884e-01
 3.7814730e-01 4.2434415e-01 4.0705362e-01 4.1730547e-01 4.2266619e-01
 4.2974275e-01 4.2404860e-01 4.1582054e-01 4.4631657e-01 4.4267231e-01
 4.1169310e-01 4.1600296e-01 3.9751592e-01 4.1171345e-01 4.2580384e-01
 4.2786339e-01 4.2677835e-01 4.3476012e-01 4.0632454e-01 4.2329741e-01
 4.3108100e-01 4.1220152e-01 4.1367280e-01 4.0533730e-01 4.2776749e-01
 4.2056957e-01 4.2720816e-01 4.0295956e-01 3.9580107e-01 4.1662180e-01
 4.1552910e-01 4.3406865e-01 4.1275859e-01 4.2084903e-01 4.0622777e-01
 4.2693651e-01 3.9402142e-01 4.0721643e-01 4.4345409e-01 3.9085340e-01
 4.0255243e-01 3.7450570e-01 3.7900001e-01 4.4598061e-01 4.3465391e-01
 4.2112103e-01 4.5141062e-01 4.7328046e-01 4.4982430e-01 4.6643358e-01
 4.3390742e-01 4.0759113e-01 4.0818024e-01 4.4230339e-01 4.1582653e-01
 4.3845424e-01 4.4376406e-01 4.0880397e-01 4.1552088e-01 4.5396191e-01
 4.4792914e-01 4.2643371e-01 4.7580427e-01 4.3926838e-01 4.4755965e-01
 4.3101680e-01 4.3073425e-01 4.7399455e-01 4.4989631e-01 4.7077709e-01
 3.9902782e-01 4.3190250e-01 4.3373322e-01 4.7337365e-01 4.5701799e-01
 4.1606569e-01 4.3906030e-01 4.4480705e-01 4.3460995e-01 4.2031676e-01
 4.5136487e-01 4.1610587e-01 4.0645784e-01 3.9435160e-01 4.5395818e-01
 4.6487415e-01 4.6067452e-01 4.3353775e-01 4.2285147e-01 4.5430019e-01
 4.4169998e-01 4.6838421e-01 4.3920201e-01 4.4556886e-01 4.6016526e-01
 4.4571894e-01 4.2300954e-01 4.5505267e-01 4.7500020e-01 4.3566799e-01
 4.6474963e-01 4.6822056e-01 4.5641321e-01 4.6041241e-01 4.5223218e-01
 4.6997073e-01 3.7747762e-01 4.0414175e-01 3.6086571e-01 3.5814747e-01
 3.6934489e-01 4.3243441e-01 4.3231994e-01 4.0662229e-01 3.6033601e-01
 3.8727653e-01 4.0413755e-01 4.3934834e-01 4.0281147e-01 4.2419550e-01
 3.9304090e-01 4.0653798e-01 3.7947100e-01 3.9882556e-01 4.0570936e-01
 4.0931422e-01 3.8386250e-01 4.2364186e-01 1.7672241e-02 6.5171719e-04
 6.6842914e-02 8.2510710e-04 5.4846406e-03 1.7351747e-02 7.4478216e-05
 1.0010123e-02 4.3541098e-05 1.2219202e-05 4.4043064e-03 4.4596195e-04
 1.6111135e-04 9.1087818e-04 2.2752285e-03 1.4023036e-02 2.8621418e-05
 2.0188838e-02 2.6595592e-04 8.3556682e-02 1.7855191e-01 1.5603575e-01
 8.0420403e-05 2.1590575e-05 1.4704764e-03 2.8925979e-01 2.8413859e-01
 1.4971623e-01 2.5346661e-01 3.1043899e-01 1.8676484e-01 2.0388106e-01
 2.8523189e-01 1.7639515e-01 2.0273337e-01 2.4217451e-01 2.6777613e-01
 3.3470017e-01 1.5797776e-01 2.5549397e-01 1.5243378e-01 2.3155633e-01
 8.7682068e-02 4.4253436e-01 3.8666102e-01 4.2623878e-01 4.4972521e-01
 3.5261950e-01 4.4725564e-01 4.3443769e-01 4.4041437e-01 4.2670876e-01
 4.2896467e-01 4.2771709e-01 4.2570522e-01 4.2408425e-01 4.2383635e-01
 4.4113088e-01 4.2843169e-01 4.3579301e-01 4.5580581e-01 4.1451409e-01
 4.0801495e-01 4.3914664e-01 3.8193330e-01 4.3528759e-01 4.1320592e-01
 4.0381056e-01 4.1624790e-01 4.0403235e-01 4.0270114e-01 4.3023282e-01
 3.9797467e-01 4.2227578e-01 4.0007937e-01 4.0609533e-01 4.0979651e-01
 4.1266870e-01 4.1811413e-01 3.6784220e-01 4.4764683e-01 4.1834679e-01
 4.5113257e-01 2.3715332e-01 4.3239883e-01 3.1267852e-01 3.7478301e-01
 3.6583233e-01 3.0617401e-01 2.9721302e-01 4.0186816e-01 3.9411414e-01
 3.3800948e-01 2.8872979e-01 3.5468575e-01 3.7678280e-01 3.8219649e-01
 3.7626371e-01 3.0890650e-01 3.9830294e-01 3.6645389e-01 3.9139092e-01
 2.5198299e-01 4.2946023e-01 3.2391825e-01 4.2032331e-01 3.2374018e-01
 2.5832391e-01 3.8165292e-01 3.2266790e-01 3.5340130e-01 3.2643721e-01
 2.7887031e-01 3.2230705e-01 3.8436761e-01 3.9871198e-01 3.3678526e-01
 3.6552393e-01 4.3069869e-01 2.3853037e-01 3.2930052e-01 3.7377679e-01
 2.6377779e-01 3.6993974e-01 3.6625069e-01 3.7501669e-01 4.1917500e-01
 3.7198377e-01 4.1476530e-01 3.9933106e-01 3.7623593e-01 3.8844737e-01
 3.7996486e-01 3.7546474e-01 3.4934616e-01 3.9318058e-01 3.9906418e-01
 4.2539054e-01 4.4132489e-01 4.1232380e-01 4.2912108e-01 3.6487681e-01
 3.8598204e-01 3.7514058e-01 3.5473588e-01 4.4866210e-01 3.8599476e-01
 3.8164747e-01 3.6872786e-01 4.2558321e-01 3.8251284e-01 4.0404603e-01
 3.6765671e-01 3.8913292e-01 4.2863673e-01 4.0475368e-01 3.5386392e-01
 3.8506693e-01 3.8013902e-01 4.0347037e-01 3.7287080e-01 3.9947736e-01
 3.8133892e-01 3.8515416e-01 3.8962859e-01 4.1334990e-01 3.6213535e-01
 4.2959228e-01 4.2743778e-01 4.2552936e-01 4.2545003e-01 4.4052976e-01
 4.1011482e-01 4.3138358e-01 4.0405551e-01 4.2269546e-01 4.2477390e-01
 4.3335742e-01 4.2914215e-01 4.4082740e-01 4.1100687e-01 4.1040653e-01
 4.1894567e-01 4.6765560e-01 4.1215152e-01 4.0854621e-01 4.3673992e-01
 4.2624098e-01 4.0479147e-01 4.1411221e-01 4.3513575e-01 4.4758549e-01
 4.4288844e-01 4.4754282e-01 4.5922598e-01 4.5345253e-01 4.5477107e-01
 4.5529464e-01 4.4138831e-01 4.4791228e-01 4.4643298e-01 4.4085222e-01
 4.5175418e-01 4.4917682e-01 4.4205210e-01 4.4108450e-01 4.3841565e-01
 4.5181179e-01 4.5079783e-01 4.4948047e-01 4.3811655e-01 4.4926307e-01
 4.4427213e-01 2.3027125e-01 1.4657468e-02 1.1520207e-02 1.1516242e-04
 5.0848365e-02 4.2044669e-02 4.8857927e-03 3.5018390e-01 1.5923947e-02
 1.6073585e-02 2.5977939e-02 3.4917891e-03 1.1367661e-01 3.9259911e-02
 9.4780326e-04 1.0511279e-03 3.2321692e-02 1.0202253e-01 1.0397351e-01
 1.0743022e-02 1.3430724e-01 7.4433088e-03 2.9172003e-03 1.1031717e-01
 1.9636750e-03 1.3067424e-03 3.6816508e-02 1.4135385e-01 1.1968359e-01
 2.4852851e-01 2.4081162e-01 4.6377569e-02 5.4702371e-02 1.5578756e-01
 5.7203412e-02 1.5029499e-01 4.1175088e-01 1.2655127e-01 1.8632004e-01
 8.3591074e-02 1.2176365e-01 1.2230623e-01 2.6009440e-01 2.5218517e-01
 2.8092289e-01 1.9436404e-01 2.3990172e-01 2.9205844e-01 1.2665436e-01
 8.1768930e-02 8.0373764e-02 2.3890269e-01 4.0225500e-01 4.0312669e-01
 4.0674222e-01 3.9696702e-01 4.0933925e-01 4.0436155e-01 4.0800226e-01
 4.0582949e-01 3.9939073e-01 4.0200198e-01 4.0219128e-01 4.1150615e-01
 4.1189730e-01 4.0979126e-01 4.0248832e-01 4.0628678e-01 4.0837032e-01
 4.0520722e-01 4.0306368e-01 4.1047490e-01 4.0565848e-01 4.0451103e-01
 4.0806419e-01 3.7023193e-01 4.1103131e-01 4.1775867e-01 4.0725380e-01
 3.9915198e-01 4.3343222e-01 4.1665861e-01 4.0313953e-01 4.0277261e-01
 4.2249250e-01 4.0516931e-01 4.0617663e-01 4.1757354e-01 4.1626847e-01
 3.9343378e-01 4.1548571e-01 3.9123154e-01 4.1830298e-01 4.3024904e-01
 4.2856190e-01 3.9670265e-01 4.0822846e-01 3.6293051e-01 3.9902186e-01
 4.2947665e-01 3.8546202e-01 4.1834956e-01 4.1605183e-01 4.5518184e-01
 4.4821000e-01 4.5422891e-01 4.5544848e-01 4.5957893e-01 4.4246477e-01
 4.6630061e-01 4.6093351e-01 4.5722938e-01 4.6487123e-01 4.5184445e-01
 4.3908483e-01 4.4381621e-01 4.6109080e-01 4.4066200e-01 4.3208367e-01
 4.2226252e-01 4.4691557e-01 4.5031857e-01 4.5455635e-01 4.7547537e-01
 4.5221952e-01 4.0383196e-01 4.7132343e-01 4.6029186e-01 4.6852773e-01
 4.2917776e-01 4.6899718e-01 4.4545373e-01 4.6222505e-01 4.4037375e-01
 3.9645201e-01 3.9525354e-01 4.1866517e-01 3.7419635e-01 4.2195487e-01
 4.2960292e-01 4.2549405e-01 4.1463673e-01 4.3313655e-01 4.1944826e-01
 4.3577296e-01 4.4020435e-01 4.3752351e-01 4.4691998e-01 4.2444915e-01
 4.3333828e-01 4.2765662e-01 3.8970912e-01 4.3844053e-01 3.9621478e-01
 4.1825876e-01 4.6490008e-01 4.5386988e-01 4.4107652e-01 4.2392242e-01
 4.6417132e-01 4.3505359e-01 4.0630460e-01 3.9165509e-01 4.3607566e-01
 4.3043691e-01 4.4242522e-01 3.9067444e-01 4.1634607e-01 4.1712260e-01
 3.9466971e-01 4.1065887e-01 4.1309425e-01 4.5189604e-01 4.0283054e-01
 4.2630234e-01 3.9176422e-01 4.6255401e-01 4.2622274e-01 4.2921743e-01
 4.0812436e-01 4.0066600e-01 3.9922684e-01 4.3279788e-01 4.4427004e-01
 4.2007470e-01 4.1366756e-01 3.9100403e-01 4.0939718e-01 4.1428012e-01
 4.0087724e-01 4.1440096e-01 3.8146359e-01 4.0017247e-01 4.2577153e-01
 4.3621686e-01 3.9018244e-01 4.2064488e-01 3.9853117e-01 4.2613474e-01
 3.7966082e-01 3.8291773e-01 3.7645847e-01 3.6655295e-01 3.7342662e-01
 3.7536916e-01 3.7113702e-01 3.7237287e-01 3.7529123e-01 3.7777457e-01
 3.8138860e-01 3.7696585e-01 3.6780927e-01 3.7547234e-01 3.8905743e-01
 3.6722201e-01 3.7982795e-01 3.7539679e-01 3.7057838e-01 3.7573269e-01
 3.8451236e-01 3.7675068e-01 3.7941527e-01 3.6738703e-01 3.7681606e-01
 3.6813897e-01 3.7991953e-01 3.6513042e-01 3.7189686e-01 3.8391283e-01
 3.6759597e-01 3.7699926e-01], shape=(777,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(777,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.19544345, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/16.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.45789748 0.47651199 0.4447612  0.44487152 0.44870326 0.4648004
 0.46858844 0.46503532 0.4655132  0.4750489 ], shape=(10,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(10,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.2128038, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/durationThm_3_e2_63_e7_21_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.00349456 0.03878939 0.00220093 0.00174084 0.02326813 0.00339222
 0.00152749], shape=(7,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0.], shape=(7,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1]
mse:tf.Tensor(0.0002971357, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/amebsa.smt2-0078_000.smt2
true label:[1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]
true label rank:[2 1 1 2 2 2 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2
 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 2 1 1 2]
predicted label:tf.Tensor(
[0.44064716 0.4449827  0.4528662  0.4436721  0.4484335  0.44312125
 0.44963548 0.4469201  0.44811234 0.45326644 0.3785601  0.34972614
 0.39474237 0.36701423 0.36888546 0.34729344 0.39726967 0.3673343
 0.3719133  0.35044777 0.35747725 0.33905068 0.35212675 0.35622877
 0.35311502 0.36638623 0.3782715  0.37357038 0.35904774 0.38481408
 0.34517977 0.37398392 0.36687896 0.33916056 0.34847072 0.36022392
 0.37443402 0.35909617 0.38197255 0.37505734 0.34186333 0.38426483
 0.40588638 0.41953745 0.42055702 0.4020086  0.4001176  0.40899485
 0.3771503  0.41921854 0.39982098 0.44652268 0.4071302  0.41068947
 0.3956427  0.43966907 0.41152087 0.38387415 0.4160521  0.3878938
 0.43686163 0.40451324 0.38422006 0.40532157 0.4193741  0.44193828
 0.41171658 0.39444834 0.42413133 0.40345192 0.39652076 0.40144908
 0.39568505 0.37938726 0.383204   0.3806354  0.3857581  0.39739883
 0.3849289  0.39686954 0.38471025 0.40281868 0.40480137 0.40134132
 0.400501   0.39224795 0.40078306 0.39141542 0.38702613 0.3830338
 0.40149176 0.40030417 0.39193672 0.4015479  0.39277834 0.39608893
 0.38730806 0.39268658 0.3851902  0.42250764 0.43936816 0.41536546
 0.4146623  0.42651182 0.4321658  0.4336597  0.4049152  0.423363
 0.42513198 0.438686   0.42763203 0.42901126 0.4323146  0.39413851
 0.4456389  0.4338622  0.43623903 0.43428832 0.4312716  0.44985977
 0.38514835 0.4177731  0.42694688 0.4289791  0.4368184  0.4306658
 0.44345835 0.4055532  0.40536085 0.4209809  0.43582502 0.4483735
 0.4387175  0.4292657  0.4253123  0.40884528 0.43905059 0.4533496
 0.44007653 0.41866446 0.44300386 0.4368189  0.41053545 0.43906727
 0.43321508 0.45263523 0.43602055 0.4288474  0.4495855  0.4386661
 0.42158133 0.4307211  0.43930036 0.4403243  0.4324773  0.4399379
 0.41683066 0.42358196 0.44375244], shape=(159,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(159,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.19504714, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/bandec.smt2-0188_000.smt2
true label:[1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1]
true label rank:[2 1 1 2 2 2 2 2 1 1 2 2]
predicted label:tf.Tensor(
[0.46096963 0.4646011  0.46158847 0.45995227 0.440066   0.45906204
 0.4760776  0.46336544 0.46266696 0.4711874  0.4735899  0.4745883 ], shape=(12,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(12,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.2640815, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/s3_clnt_1.cil-1.c-1_000.smt2
true label:[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]
true label rank:[1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1
 1 1 2 2 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1
 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 1
 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1
 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1
 1 2 2 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 1 2 2 2]
predicted label:tf.Tensor(
[3.87327820e-01 3.85448277e-01 3.85567278e-01 3.80506277e-01
 3.67809236e-01 3.63524020e-01 3.63916188e-01 3.75558943e-01
 3.45275760e-01 3.59157562e-01 3.64283860e-01 3.58772993e-01
 3.86367500e-01 3.67489904e-01 3.53426337e-01 3.37800205e-01
 3.82055461e-01 3.80868584e-01 3.22631955e-01 3.58980000e-01
 3.52572173e-01 3.40599716e-01 3.67406726e-01 3.77752721e-01
 3.60640258e-01 3.73876929e-01 3.59350562e-01 3.77789736e-01
 3.99314433e-01 3.90672743e-01 3.54064673e-01 1.17890477e-06
 6.58243895e-04 8.46493822e-06 8.41500167e-08 8.27461481e-04
 2.20277905e-03 1.01687954e-06 5.12495490e-06 1.65606678e-01
 7.48702405e-07 7.31247201e-05 6.54092431e-03 2.12538780e-05
 9.18630758e-06 2.22898126e-02 1.62319779e-07 5.47375381e-02
 5.57899475e-04 2.24655867e-03 6.10282825e-07 6.23546327e-07
 1.36428966e-07 1.16625181e-08 3.10471049e-09 4.29193321e-08
 8.03115228e-08 1.11790904e-07 2.31965419e-06 1.54450379e-06
 4.24993157e-01 4.03628856e-01 3.94154370e-01 4.23515081e-01
 4.15798336e-01 4.35194641e-01 4.26953465e-01 3.98231626e-01
 4.05448794e-01 4.13163871e-01 4.17594910e-01 4.24018145e-01
 4.11935866e-01 4.06610072e-01 4.13834423e-01 4.06460047e-01
 3.94529074e-01 4.18232054e-01 4.08493400e-01 4.12478477e-01
 4.02750671e-01 4.31223363e-01 4.07453954e-01 4.18140739e-01
 4.17712599e-01 4.16226625e-01 4.22856927e-01 4.09057915e-01
 4.25881028e-01 3.86335075e-01 3.82685184e-01 3.97388369e-01
 3.89696419e-01 3.76585543e-01 3.86384040e-01 3.92271072e-01
 3.79703611e-01 3.91174436e-01 3.76774788e-01 3.79194081e-01
 3.93074214e-01 3.79431605e-01 3.84455562e-01 3.94379765e-01
 3.84796858e-01 3.95371854e-01 3.67478490e-01 3.89253378e-01
 3.91834021e-01 3.89273494e-01 3.95064682e-01 3.85289431e-01
 3.86501491e-01 3.83537263e-01 4.05379236e-01 3.91642779e-01
 3.76943767e-01 3.85411859e-01 3.96843463e-01 4.03734088e-01
 4.18225557e-01 4.27724063e-01 4.16238755e-01 4.27896947e-01
 4.33316678e-01 4.52010065e-01 4.12591517e-01 4.14365530e-01
 4.20304358e-01 4.15794671e-01 4.17483449e-01 4.44608986e-01
 4.36342239e-01 4.29986805e-01 4.27702159e-01 4.24789578e-01
 4.29171026e-01 4.40147698e-01 4.32847917e-01 4.17940229e-01
 4.37999815e-01 4.30621415e-01 4.28813815e-01 4.19504344e-01
 4.32526708e-01 4.43082601e-01 4.19159204e-01 4.19678658e-01
 4.36058551e-01 4.42812711e-01 4.51821536e-01 4.45129871e-01
 4.35993165e-01 4.39522892e-01 4.37190652e-01 4.35744882e-01
 4.37696785e-01 4.40458864e-01 4.37632293e-01 4.33611512e-01
 4.48713213e-01 4.47164118e-01 4.40668046e-01 4.48300630e-01
 4.49916899e-01 4.45612073e-01 4.37082559e-01 4.38749969e-01
 4.51623917e-01 4.53246355e-01 4.55172479e-01 4.36596632e-01
 4.52019691e-01 4.41792101e-01 4.63797212e-01 4.36234355e-01
 4.31809813e-01 4.47130710e-01 4.31350827e-01 4.71200407e-01
 4.41099107e-01 4.48281050e-01 4.50756818e-01 4.65491384e-01
 4.27569717e-01 4.61728990e-01 4.57196444e-01 4.53038156e-01
 4.57779408e-01 4.51613069e-01 4.73970890e-01 4.72391427e-01
 4.69645619e-01 4.55421448e-01 4.61028993e-01 4.61597025e-01
 4.64019090e-01 4.45205152e-01 4.56536263e-01 4.62725967e-01
 4.62817311e-01 4.50143814e-01 4.44912285e-01 4.52124000e-01
 4.70797092e-01 4.46470976e-01 4.63978589e-01 4.14900750e-01
 3.95933360e-01 4.04866099e-01 4.10130739e-01 4.02146041e-01
 3.83207947e-01 4.27837789e-01 4.16508853e-01 4.06310111e-01
 3.95466834e-01 3.93069148e-01 4.04179960e-01 4.34876770e-01
 4.03825253e-01 4.28404599e-01 4.05881643e-01 4.00264919e-01
 3.81021440e-01 4.15145040e-01 3.94094110e-01 4.23488975e-01
 4.44079667e-01 3.77931118e-01 4.39365387e-01 4.17389065e-01
 4.29165184e-01 3.70930403e-01 4.42598701e-01 4.25811917e-01
 4.19033438e-01 4.08049911e-01 4.17676806e-01 3.86011928e-01
 4.15167481e-01 3.99265379e-01 3.98683220e-01 4.20982003e-01
 3.92493904e-01 4.12322342e-01 4.12741095e-01 4.49325770e-01
 4.18940783e-01 4.30265874e-01 4.16517675e-01 3.92913580e-01
 4.05639231e-01 4.15322304e-01 4.25070375e-01 4.36763555e-01
 4.15026367e-01 4.23388004e-01 4.05969858e-01 4.09744084e-01
 4.10677552e-01 4.36134219e-01 4.05142754e-01 4.26503032e-01
 4.14258718e-01 4.22873974e-01 4.20757890e-01 4.30708021e-01
 4.43652153e-01 4.38059241e-01 4.25425351e-01 4.34550732e-01
 4.21296805e-01 4.16716933e-01 4.35033202e-01 4.33710098e-01
 4.05979693e-01 4.38913018e-01 4.45880473e-01 4.53735411e-01
 4.08142596e-01 4.24117893e-01 4.48128462e-01 4.30104762e-01
 4.19202060e-01 4.14611638e-01 4.16655958e-01 4.30241436e-01
 4.08431232e-01 4.34575737e-01 4.35402125e-01 4.08826172e-01
 4.30525064e-01 4.21188742e-01 4.85754550e-01 4.90545988e-01], shape=(296,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.], shape=(296,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.19419332, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0259_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]
predicted label:tf.Tensor(
[0.4828855  0.4785436  0.46558896 0.48037952 0.48220694 0.47876874
 0.4478215  0.45373058 0.4695565  0.48261482 0.4733045  0.45993418
 0.46103227 0.4739345  0.45344338 0.45069918 0.47091663 0.4763682
 0.46873352 0.47776428 0.4772748  0.47782418 0.48621458 0.4626969
 0.4499573  0.4467675  0.4694946  0.46223605 0.4686999  0.47599298
 0.47026977 0.47132808 0.46925765 0.45612797 0.46401358 0.46898016
 0.48808086 0.49140835 0.4880784  0.48338664 0.48489705 0.4853762
 0.48043773 0.48532286 0.48342863 0.47205955 0.4669169  0.46809042
 0.40858597 0.42310852 0.41823083 0.4255339  0.42728925 0.42632237
 0.39243695 0.45483834 0.4202869  0.39792645 0.39596114 0.40508986
 0.43743584 0.3998281  0.39040464 0.40325475 0.48908883 0.3702674
 0.39384925 0.36630452 0.31686813 0.3526735  0.31494945 0.2916179
 0.36135638 0.29073215 0.2722316  0.30675602 0.31519657 0.38769388
 0.41965115 0.36505944 0.32442805 0.34496614 0.28434986 0.3917259
 0.37873185 0.35437647 0.4138605  0.38274992 0.4168799  0.38326445
 0.3842514  0.44122195 0.36048192 0.31185395 0.47695512 0.40596196
 0.33069175 0.3905997  0.45883587 0.48755932 0.41652238 0.44310883
 0.45006984 0.41749966 0.4137668  0.40248474 0.39243448 0.43014097
 0.4303633  0.4224522  0.42723233 0.4281266  0.42807746 0.38741532
 0.41739923 0.40972066 0.04563394 0.08867869 0.0800474  0.16433555
 0.05092886 0.03510436 0.00929415 0.10888934 0.06177756 0.16226023
 0.06368944 0.03032482 0.32146445 0.10004017 0.22369486 0.31780362
 0.13209859 0.16062158 0.08171478 0.39651605 0.3570149  0.41453066
 0.40838742 0.4078425  0.3810363  0.40161532 0.40065554 0.39147833
 0.40793014 0.40785435 0.382033   0.36180925 0.39971906 0.41215777
 0.4508663  0.44271135 0.44355068 0.45825776 0.44733188 0.45078856
 0.43864316 0.43538862 0.44977674 0.43740287 0.43626937 0.43430513
 0.44505462 0.45383826 0.4398064  0.43316934 0.45172596 0.4410239
 0.43398458 0.42496413 0.46486634 0.42021593 0.42508674 0.46529907
 0.47102812 0.42232156 0.4209723  0.4547923  0.3989771  0.4244049
 0.46097448 0.33504555 0.4258096  0.43521547 0.33393097 0.40436196
 0.43007576 0.35946077 0.38249475 0.44089815 0.4079602  0.43546993
 0.42580462 0.37464893 0.3841123  0.45760807 0.37193096 0.14426455
 0.10011405 0.12705198 0.16198474 0.03457263 0.10710821 0.20113525
 0.13829607 0.09600863 0.0988884  0.17931446 0.19170871 0.29241812
 0.33033967 0.10001221 0.07714906 0.23483649 0.10183054 0.42807743
 0.39607784 0.36007482 0.39494962 0.49277997 0.46304822 0.39893043
 0.33292562 0.39000058 0.41534245 0.3851791  0.37926614 0.38579497
 0.45126012 0.39658162 0.45076492 0.40143746 0.42858183 0.4115276
 0.44235703 0.41773546 0.432517   0.43849155 0.43901837 0.3888858
 0.41732907 0.3827324  0.40994817 0.4447352  0.40384525 0.43717176
 0.40206105 0.43327272 0.46244523 0.46942177 0.45590237 0.46379903
 0.4539353  0.45935193 0.4646008  0.45894477 0.45944887 0.47119176
 0.46790004 0.4578213  0.4567991  0.46006337 0.45467627 0.46762407
 0.4362298  0.44756147 0.44551018 0.4258441  0.42188823 0.43657768
 0.40747517 0.3970229  0.4415387  0.4164357  0.44651306 0.40606034
 0.43774453 0.43733883 0.4336726  0.41249487 0.37793452 0.42622444
 0.48087314 0.45189202 0.45435688 0.43136826 0.42514342 0.41740733
 0.4181217  0.44280457 0.45030877 0.42637265 0.41362536 0.4569491
 0.41973796 0.42158598 0.4736866  0.44024214 0.4475795  0.47919613
 0.3999041  0.42943734 0.4106812  0.41832328 0.42625862 0.41104168
 0.4177118  0.41119576 0.39958113 0.4318061  0.40269879 0.41126117
 0.41711256 0.41490686 0.42837352 0.37652808 0.4260468  0.39739937
 0.434004   0.46084034 0.40600798 0.4215579  0.42213336 0.44893774
 0.43542737 0.42027363 0.4435802  0.37494624 0.34204334 0.40709254
 0.46060184 0.41788855 0.39134753 0.39927757 0.39861995 0.47092575
 0.3570972  0.39904964 0.44464573 0.34553975 0.39447996 0.3860863
 0.34803098 0.43155625 0.42637587 0.3603594  0.37175602 0.4593467
 0.45156085 0.44458133 0.43682337 0.43518773 0.4566871  0.44162858
 0.44240552 0.43346274 0.45434937 0.4265057  0.44039637 0.45523915
 0.44491166 0.41288197 0.45160535 0.43256527 0.44351748 0.46024182
 0.43636638 0.45170552 0.44868237 0.46346036 0.45919442 0.4522613
 0.4500374  0.43484762 0.45192176 0.44195282 0.45598364 0.4423427
 0.4449463  0.45551357 0.42424464 0.4407594  0.41571426 0.38441688
 0.40406376 0.39889127 0.41711655 0.40106678 0.41207734 0.40883106
 0.40851462 0.42076457 0.4280617  0.40549767 0.40227845 0.39204502
 0.4521898  0.42487827 0.42497596 0.43550265 0.43156478 0.41380352
 0.43754095 0.4099254  0.46356207 0.4299796  0.44639742 0.436356
 0.44554007 0.43844795 0.46532568 0.44155616 0.34270543 0.37946275
 0.38097367 0.41353002 0.31068182 0.4432401  0.39438003 0.38144565
 0.3026604  0.35706055 0.3998593  0.4707604  0.37240386 0.40769824
 0.3777264  0.40975827 0.37428278 0.42434275 0.4445349  0.38965276
 0.44589615 0.40600884 0.46120885 0.32466373 0.4242627  0.3720709
 0.44626123 0.3752594  0.40676075 0.42190814 0.44385543 0.41935784
 0.4523766  0.3396755  0.39189485 0.41870964 0.43186575 0.3324405
 0.41775718 0.44184184 0.36873037 0.33821875 0.42797112 0.4030748
 0.4252391  0.42645463 0.4005373  0.40448013 0.36754262 0.40904722
 0.3678779  0.44899684 0.4071091  0.4078554  0.37914878 0.3555711
 0.40138054 0.3707464  0.39587373 0.41096207 0.39657944 0.41140595
 0.34953335 0.41330814 0.37456018 0.43868414 0.46174818 0.44412678
 0.46363226 0.43372208 0.47001153 0.4476055  0.4638355  0.43816003
 0.43046382 0.45309338 0.44914263 0.42612457 0.41458666 0.4383434
 0.4259376  0.4737801  0.41109827 0.4264233  0.39528656 0.38145313
 0.4503442  0.3959239  0.4291501  0.39027914 0.43243903 0.4362107
 0.45746914 0.41115114 0.43914413 0.35299477 0.43856114 0.43609753
 0.46042264 0.44524875 0.4317744  0.4256327  0.42759323 0.4271743
 0.45513338 0.4289984  0.4485355  0.4502276  0.43123743 0.4224961
 0.41859975 0.467885   0.45302808 0.46071923 0.4273194  0.40100056
 0.40913144 0.42254102 0.43144962 0.42665684 0.41015273 0.41144696
 0.41908652 0.41180325 0.3983497  0.4067703  0.40613526 0.4174156
 0.42281657 0.41727608 0.41090307 0.45285812 0.4762555  0.4455491
 0.46643612 0.45754147 0.44085267 0.45565838 0.4438501  0.41312507
 0.4486187  0.45143864 0.45925927 0.41677392 0.45178437 0.43598685
 0.45198262 0.46740213 0.32699323 0.32125074 0.3710471  0.39766434
 0.43635726 0.36192727 0.42245126 0.36928588 0.33867687 0.41067207
 0.36076325 0.4043178  0.42582473 0.3709612  0.3619545  0.41427943
 0.3842305  0.31033626 0.35151473 0.3656953  0.40601358 0.39144608
 0.39883065 0.4211751  0.410362   0.4124039  0.4094424  0.3619216
 0.37196922 0.37597075 0.41879782 0.37785077 0.4578312  0.42583027
 0.43610588 0.43934423 0.40828687 0.46331823 0.42929214 0.42278308
 0.46848378 0.42136234 0.4504602  0.45271146 0.45730847 0.41527545
 0.42325318 0.38694912 0.45998713 0.44850206 0.4552485  0.46462572
 0.4550759  0.47264025 0.46651158 0.46924824 0.4575448  0.47396848
 0.45992514 0.4509409  0.45937997 0.467036   0.45524576 0.45845175
 0.46097818 0.44110283 0.42761064 0.44111457 0.4685768  0.4461856
 0.43293947 0.42806086 0.44826615 0.44991973 0.45132715 0.44952005
 0.42731908 0.44529712 0.43329227 0.43837228 0.44951195 0.4154597
 0.42521998 0.41637158 0.44519952 0.45800242 0.4165507  0.48206547
 0.45453382 0.43122047 0.42993113 0.46591854 0.40330315 0.42157778
 0.43980485 0.445528   0.4449221 ], shape=(657,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(657,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.35081884, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/minepump_spec5_product55_true-unreach-call.cil.c.flat_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[1.6818047e-03 1.1896670e-02 1.6350448e-03 7.1551204e-03 3.3438540e-01
 2.2321853e-01 3.0059379e-01 2.9444778e-01 3.1210729e-01 3.3236423e-01
 4.0803087e-01 4.1395971e-01 4.1850692e-01 4.5354885e-01 4.2438471e-01
 4.3755385e-01 4.3407649e-01 4.6752086e-01 4.6749094e-01 3.3333653e-01
 4.2531824e-01 3.5433739e-01 3.0274040e-01 3.3839935e-01 2.6219827e-01
 3.5790789e-01 3.3025080e-01 1.9096395e-01 1.5783066e-01 3.8981292e-01
 3.4176701e-01 3.2001483e-01 3.2882988e-01 4.2739478e-01 4.1246995e-01
 4.4169596e-01 4.5290411e-01 4.3707010e-01 4.3457282e-01 4.2209977e-01
 4.4473499e-01 4.4400886e-01 4.5748633e-01 4.4948065e-01 4.6004587e-01
 4.4653547e-01 4.4137940e-01 4.4382000e-01 7.2679192e-02 2.5888947e-01
 6.4598590e-02 1.3798407e-01 7.5197011e-02 1.6368303e-01 8.4140897e-02
 2.2682923e-01 1.1407772e-01 1.0280484e-01 7.7787459e-02 6.1468512e-02
 1.2311110e-01 3.3249938e-01 7.1272552e-02 3.3379078e-02 4.4351205e-01
 4.5663819e-01 4.3206525e-01 4.3205109e-01 4.3417877e-01 4.5799929e-01
 4.3646714e-01 4.4964680e-01 4.3220952e-01 4.3763244e-01 4.3860474e-01
 4.5182237e-01 4.2656213e-01 4.3894002e-01 4.5407528e-01 4.2523655e-01
 4.3743876e-01 4.4934011e-01 4.5535752e-01 4.5272771e-01 4.5250553e-01
 4.4868097e-01 4.5963609e-01 4.4942182e-01 4.5233023e-01 4.3513763e-01
 4.4486278e-01 4.5072481e-01 4.5259762e-01 4.5917386e-01 4.3780792e-01
 4.4686955e-01 4.3980309e-01 4.5751095e-01 4.0269738e-01 3.0050650e-01
 3.5636312e-01 4.3839976e-01 3.8484770e-01 3.2525560e-01 3.2342029e-01
 3.3675215e-01 2.8392684e-01 4.2379892e-01 3.9101067e-01 3.2598454e-01
 3.7497556e-01 3.6648369e-01 4.3339273e-01 3.1580183e-01 4.6093175e-01
 2.7803183e-01 3.5731393e-01 3.4923345e-01 3.7524506e-01 3.9696881e-01
 3.2499713e-01 3.3626407e-01 3.0408055e-01 3.4625494e-01 3.6473462e-01
 3.9411491e-01 3.1568825e-01 3.1188750e-01 3.9989045e-01 3.7068594e-01
 3.1798118e-01 4.5875892e-01 3.9803272e-01 3.6012036e-01 3.2568777e-01
 3.3050823e-01 4.4639996e-01 4.5470151e-01 4.4477266e-01 4.6710673e-01
 4.5065045e-01 4.4872200e-01 4.5569608e-01 4.5913154e-01 4.5625442e-01
 4.5076337e-01 4.6032894e-01 4.4529676e-01 4.5972434e-01 4.4246098e-01
 4.4315687e-01 4.6959507e-01 4.2094967e-01 4.6078783e-01 2.6305726e-05
 6.4342697e-07 1.0272384e-02 1.5859125e-07 5.0818068e-07 2.1072715e-07
 1.0370366e-06 2.1213293e-04 4.0736794e-04 5.2723557e-08 2.6036982e-06
 6.0793252e-07 4.3712765e-02 5.6646932e-06 6.8817724e-05 1.4075637e-04
 6.9756806e-03 7.8656194e-05 3.7912327e-01 3.6372510e-01 4.0084618e-01
 3.9081547e-01 3.7707871e-01 3.5132536e-01 3.6617994e-01 3.7789392e-01
 3.6642548e-01 3.5475695e-01 3.7946019e-01 3.8320491e-01 4.5078993e-04
 3.8803309e-02 2.0792693e-02 6.3332915e-04 2.9774427e-02 1.4366537e-02
 2.2041619e-02 7.3015958e-02 1.3667649e-01 1.0538846e-02 6.8810284e-03
 2.6378351e-01 2.2385716e-03 2.4884403e-02 8.8791847e-03 7.1387589e-03
 3.5545826e-02 7.1474910e-04 4.2853355e-03 3.4351766e-01 2.8508443e-01
 3.1331015e-01 2.9448253e-01 3.2897031e-01 3.5754105e-01 3.5244274e-01
 3.8967043e-01], shape=(211,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(211,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.11892428, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/bandec.smt2-0260_000.smt2
true label:[1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1]
true label rank:[2 2 2 2 2 2 1 1 2 2 1 2 2 2 1 1 2 2]
predicted label:tf.Tensor(
[0.471572   0.47055358 0.47559193 0.47601315 0.4595836  0.46059486
 0.44756275 0.4451099  0.44820115 0.452213   0.45047578 0.44744644
 0.46461317 0.4614044  0.46530032 0.46555546 0.4649456  0.46442008], shape=(18,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(18,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.26591414, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/loop__barthe2_000.smt2
true label:[1, 0, 1, 1, 1]
true label rank:[2 1 2 2 2]
predicted label:tf.Tensor([0.45663044 0.45194146 0.4449026  0.43128216 0.4556331 ], shape=(5,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.285482, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/minepump_spec2_product58_true-unreach-call.cil.c.flat_000.smt2
true label:[1, 1, 1, 1]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([2.3507790e-17 1.6178731e-17 6.2947188e-21 1.1583854e-28], shape=(4,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)
predicted label rank:[1 1 1 1]
mse:tf.Tensor(1.0, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/sum3_000.smt2
true label:[1, 0]
true label rank:[2 1]
predicted label:tf.Tensor([0.47493297 0.4836747 ], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 0.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.25481832, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/minepump_spec5_product59_true-unreach-call.cil.c.flat_000.smt2
true label:[1, 1, 1, 1]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([6.4838606e-30 7.4679641e-33 0.0000000e+00 0.0000000e+00], shape=(4,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)
predicted label rank:[1 1 1 1]
mse:tf.Tensor(1.0, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/02.c_000.smt2
true label:[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1]
true label rank:[1 1 2 2 2 2 1 1 2 2 2 2 1 1 2 2 2 2]
predicted label:tf.Tensor(
[0.4582667  0.46250048 0.45727682 0.45778403 0.46292666 0.44071332
 0.45708945 0.4518452  0.45207664 0.45453992 0.46470064 0.45007268
 0.46680775 0.46315473 0.463809   0.47133642 0.46740124 0.461449  ], shape=(18,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(18,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.2659236, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/21.c_000.smt2
true label:[0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1]
true label rank:[1 2 1 1 2 2 1 2 1 1 2 2 1 2 1 1 2 2 2 1 2 1 1 2 2]
predicted label:tf.Tensor(
[0.44548598 0.4645937  0.453866   0.43078706 0.46328214 0.44571376
 0.45408934 0.46480563 0.4721607  0.468741   0.4594704  0.46318877
 0.46356896 0.46687305 0.45485184 0.47081605 0.4571501  0.4641835
 0.47063348 0.46060088 0.4680343  0.4615101  0.4656229  0.46725464
 0.45671868], shape=(25,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0.], shape=(25,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.25124854, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/25.c_000.smt2
true label:[0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0]
true label rank:[1 2 2 2 2 1 1 2 2 2 2 1 1 2 2 2 2 1 1 2 2 2 2 1 1 2 2 2 2 1]
predicted label:tf.Tensor(
[0.44239482 0.46040747 0.46339172 0.4559052  0.4603364  0.45793578
 0.4682702  0.47097614 0.4707002  0.46573517 0.46614972 0.46354535
 0.45303717 0.46480414 0.45391044 0.4435122  0.45622265 0.4602857
 0.45711654 0.44229448 0.4509957  0.45888838 0.45566306 0.46355203
 0.48037532 0.4748307  0.468602   0.46945676 0.4689035  0.47244287], shape=(30,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.], shape=(30,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.26482037, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0018_000.smt2
true label:[1, 0]
true label rank:[2 1]
predicted label:tf.Tensor([0.47411823 0.47192502], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 0.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.24963243, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/MOESI_2_e8_926_e8_2138_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1
 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1]
predicted label:tf.Tensor(
[6.36434697e-06 2.03132629e-04 4.25015514e-06 5.89138581e-05
 2.74407864e-03 1.56070000e-05 6.07045286e-06 1.35183334e-04
 3.21021457e-06 2.52151191e-02 1.02032423e-02 1.23274061e-04
 3.29911709e-04 4.25039232e-02 1.83194280e-02 8.25007446e-05
 2.29007006e-03 4.75525856e-04 3.66959333e-01 3.20377929e-08
 2.48880951e-07 3.71887450e-06 1.24561175e-05 6.25255416e-05
 2.66337395e-03 2.64252867e-05 9.21446826e-07 1.25210681e-06
 1.25762608e-06 1.25887990e-03 6.30110502e-04 2.27183104e-04
 1.25020742e-03 9.82880592e-04 1.79525262e-06 8.30611587e-03
 1.46430433e-02 4.03937447e-05 4.44835314e-05 8.38963091e-02
 1.88964600e-06 2.40743160e-04 7.59875774e-03 5.12740153e-05
 1.65492296e-04 2.90586948e-02 2.82050951e-06 5.36257625e-02
 4.65273857e-04 7.18268752e-03 3.23146269e-05 2.31268405e-05
 2.51488882e-06 4.55232976e-06 3.49237297e-08 3.26474369e-01
 3.48461360e-01 3.27923208e-01 3.80797327e-01 3.36515188e-01
 3.53967279e-01 3.60524952e-01 3.23875815e-01 3.14331830e-01
 3.27669203e-01 3.36923480e-01 3.33908081e-01 3.54881316e-01
 3.22711408e-01 3.69629920e-01 3.31245482e-01 3.36406261e-01
 3.43913257e-01 3.34056973e-01 3.40692222e-01 3.18415940e-01
 3.20755720e-01 3.76244664e-01 3.48682880e-01 3.73231471e-01
 3.67729425e-01 3.26230347e-01 3.08043242e-01 3.40008497e-01
 3.48503172e-01 3.23407352e-01 3.62537950e-01 3.19490671e-01
 3.24919552e-01 2.77746439e-01 3.42094779e-01 3.70248377e-01
 3.44815433e-01 4.34957564e-01 4.20256197e-01 4.43004996e-01
 4.32158917e-01 4.30324197e-01 4.26186264e-01 4.22590554e-01
 4.23944950e-01 4.27490801e-01 4.38305944e-01 4.38196570e-01
 4.23225641e-01 4.26556706e-01 4.15387809e-01 4.30810928e-01
 4.14378881e-01 4.36385155e-01 4.16746169e-01 4.20639634e-01
 4.10833865e-01 4.17882323e-01 4.26614642e-01 4.36173558e-01
 4.15463924e-01 4.21337366e-01 4.32281852e-01 4.44133878e-01
 4.08094615e-01 4.24447685e-01 4.12173569e-01 4.13322926e-01
 4.16640460e-01 4.21479881e-01 4.27815378e-01 4.16881830e-01
 4.26280767e-01 4.13066745e-01 3.84867132e-01 4.77333039e-01
 4.32073891e-01 3.68730187e-01 3.70626807e-01 3.49724621e-01
 4.12770838e-01 3.43893588e-01 2.15944141e-01 3.90614390e-01
 3.84902686e-01 4.74527478e-01 4.66604859e-01 4.60302591e-01
 4.77931559e-01 4.80429441e-01 4.70116884e-01 4.75496173e-01
 4.84896123e-01 4.89350110e-01 4.80906248e-01 4.83970761e-01
 4.80597526e-01 4.86773610e-01 4.74464864e-01 4.81201380e-01
 4.71943110e-01 4.87687439e-01 4.77467299e-01 4.75434154e-01
 4.77107912e-01 4.78603333e-01 4.77429271e-01 4.75706011e-01
 4.71856147e-01 4.72508639e-01 4.70496923e-01 4.70907569e-01
 4.68938947e-01 4.68332648e-01 4.68846321e-01 4.62045252e-01
 4.76274759e-01 4.48411584e-01 4.88158762e-01 4.51880932e-01
 4.65058714e-01 4.69159722e-01 4.54390794e-01 4.78262603e-01
 4.84882563e-01 4.74356771e-01 4.69169170e-01 4.80069011e-01
 4.63471889e-01 4.73470747e-01 4.77720946e-01 4.28708643e-01
 4.61045146e-01 4.39755589e-01 4.61790562e-01 4.45079267e-01
 4.62240636e-01 4.21287835e-01 4.60644066e-01 4.68155235e-01
 4.45027173e-01 4.33380216e-01 4.63989198e-01 4.51742083e-01
 4.40730751e-01 4.48779076e-01 4.22024310e-01 4.38354492e-01
 4.33511555e-01 4.26626474e-01 4.29512918e-01 4.25871611e-01
 4.35490817e-01 4.14758235e-01 4.31432933e-01 4.29295331e-01
 4.38272119e-01 4.33695018e-01 4.20513958e-01 4.32965517e-01
 4.28584635e-01 4.32475448e-01 4.42142874e-01 4.26065356e-01
 4.22618836e-01 4.19330895e-01 4.14949477e-01 4.27603900e-01
 4.08385485e-01 4.36596304e-01 4.28681999e-01 4.26543444e-01
 4.24007684e-01 4.22623336e-01 4.26005542e-01 4.34159994e-01
 4.15342242e-01 4.25398260e-01 4.22089338e-01 4.16525215e-01
 4.26986098e-01 4.19029802e-01 4.21249539e-01 4.09569263e-01
 4.62874800e-01 4.37641054e-01 4.81098980e-01 4.35737759e-01
 4.49117333e-01 4.23707664e-01 4.51751053e-01 4.37322199e-01
 4.57900912e-01 4.62185442e-01 4.56152081e-01 4.72054780e-01
 4.84556049e-01 4.68709975e-01 4.23491269e-01 4.41089690e-01
 4.42606091e-01 4.22575623e-01 4.49975193e-01 4.21469718e-01
 4.61623490e-01 4.40589786e-01 4.32853371e-01 4.07088012e-01
 4.24622208e-01 4.11455035e-01 4.18235689e-01 4.01619643e-01
 3.93791765e-01 3.96909624e-01 4.17449534e-01 3.92221183e-01
 4.07667875e-01 4.03498292e-01 4.24576014e-01 3.78686070e-01
 3.92889112e-01 3.93045992e-01 4.27045405e-01 3.93472105e-01
 3.88751566e-01 3.94485772e-01 3.97080183e-01 3.76542270e-01
 3.56450915e-01 3.93487543e-01 3.85680377e-01 4.12683874e-01
 4.05596614e-01 4.25612599e-01 3.99901509e-01 4.10103738e-01
 4.06084239e-01 3.98744434e-01 4.20832425e-01 4.08710867e-01
 4.29622859e-01 4.12440538e-01 4.11737502e-01 4.19276625e-01
 4.14240122e-01 4.19721782e-01 4.16193813e-01 4.19957668e-01
 4.13651377e-01 4.18505311e-01 4.23407316e-01 4.29249644e-01
 4.09538597e-01 4.12301123e-01 4.11305487e-01 4.25511211e-01
 4.17228073e-01 4.06753063e-01 4.06837404e-01 4.53742683e-01
 4.43849087e-01 4.50995654e-01 4.49688464e-01 4.59873796e-01
 4.58351940e-01 4.64717001e-01 4.66056436e-01 4.55111265e-01
 4.65469778e-01 4.54434216e-01 4.55388188e-01 4.51531440e-01
 4.60630208e-01 4.51735109e-01 4.61530596e-01 4.69130754e-01
 4.64610934e-01 4.69612896e-01 4.64296490e-01 4.51252431e-01
 4.48466510e-01 4.60072935e-01 4.58941638e-01 4.58192021e-01
 4.53858674e-01 4.49514449e-01 4.08303261e-01 4.08067167e-01
 3.97148490e-01 4.25373763e-01 3.99122208e-01 4.14819777e-01
 4.11318809e-01 4.09754574e-01 4.03047740e-01 4.15625155e-01
 4.17180568e-01 4.07570988e-01 4.19987470e-01 3.95230144e-01
 4.07066315e-01 4.07886177e-01 4.18613613e-01 4.05889481e-01
 3.97932470e-01 4.12675679e-01 4.08114940e-01 4.09008414e-01
 4.13676143e-01 4.28779364e-01 3.94412816e-01 4.16127324e-01
 4.11292106e-01 4.16456878e-01 4.38368738e-01 4.03673708e-01
 4.31266546e-01 3.95974874e-01 4.11028862e-01 4.03954118e-01
 4.15486455e-01 4.07481015e-01 4.11471367e-01 4.04152036e-01
 4.09275264e-01 4.27459925e-01 4.26523000e-01 4.09136415e-01
 4.14381444e-01 3.97331178e-01 4.05733883e-01 4.23518479e-01
 4.11208570e-01 4.06002522e-01 4.26296145e-01 4.24634576e-01
 4.20679897e-01 4.21296716e-01 4.02236402e-01 4.03744221e-01
 4.06765223e-01 3.42962444e-01 3.67593646e-01 3.48862648e-01
 3.70265305e-01 3.67374688e-01 3.46661687e-01 3.85356784e-01
 3.66466463e-01 3.50758672e-01 3.73102963e-01 3.62164438e-01
 3.70689988e-01 3.80831063e-01 3.78436565e-01 3.53869617e-01
 3.63462925e-01 3.79360139e-01 3.80924702e-01 3.62463593e-01
 3.50300252e-01 3.53322864e-01 3.70693326e-01 3.57516825e-01
 3.41647029e-01 3.85332823e-01 4.08684015e-01 4.00753766e-01
 3.65695536e-01 3.15819919e-01 3.65964830e-01 3.68379772e-01
 3.84023160e-01 3.67576420e-01 3.84515643e-01 3.66749644e-01
 3.86231482e-01 3.75244796e-01 3.70098263e-01 5.36919832e-02
 2.71767437e-01 2.06877023e-01 3.52991164e-01 5.80720007e-02
 1.38556242e-01 3.08597445e-01 1.69788510e-01 1.14654750e-01
 2.66987890e-01 7.97948837e-02 1.82211488e-01 3.35260510e-01
 4.32060838e-01 1.55259281e-01 3.06924641e-01 2.06443787e-01
 8.86398256e-02 1.19192421e-01 2.36074388e-01 1.31708652e-01
 1.41747087e-01 2.66089618e-01 9.67603326e-02 2.53317654e-01
 8.82952511e-02 3.98856550e-01 2.20972627e-01 2.65255094e-01
 1.72268957e-01 3.05322587e-01 2.05068260e-01 1.31083608e-01
 2.52097934e-01 1.21123284e-01 1.08524621e-01 2.05865741e-01
 1.86777413e-01 2.83781826e-01 8.22659731e-02 3.05581868e-01
 9.63421762e-02 4.06605005e-01 4.13304657e-01 3.83865416e-01
 4.06434834e-01 4.09888864e-01 4.37930316e-01 4.34040844e-01
 4.47359771e-01 4.16038930e-01 4.27779943e-01 4.55738455e-01
 4.17630672e-01 4.56722617e-01 4.50396538e-01 3.97573799e-01
 4.76886868e-01 4.43225443e-01 4.37383354e-01 4.17837143e-01
 4.54295427e-01 4.32690740e-01 4.34955209e-01 4.33874696e-01
 4.41004336e-01 3.91499072e-01 4.55707431e-01 4.14758921e-01
 4.29861993e-01 4.50766325e-01 4.44247335e-01 3.75213236e-01
 4.17926192e-01 4.35873508e-01 4.38302845e-01 3.88192147e-01
 4.33418155e-01 4.07548934e-01 3.98161829e-01 4.03281659e-01
 4.28951651e-01 4.09309626e-01 4.14403170e-01 4.11628753e-01
 4.09958541e-01 4.07069713e-01 4.13230985e-01 3.96368235e-01
 4.04683888e-01 4.07787979e-01 3.87159795e-01 4.25132781e-01
 3.93223286e-01 4.15810406e-01 4.10244852e-01 4.13217604e-01
 3.99214149e-01 4.07279909e-01 4.15977240e-01 4.00004566e-01
 4.08881217e-01 3.95863235e-01 4.07135099e-01 3.99208426e-01
 4.10499960e-01 4.05723751e-01 4.08922017e-01 3.93134177e-01
 4.09208119e-01 4.16586936e-01 4.05885935e-01 4.07484055e-01
 4.05818105e-01 3.89288843e-01 4.44271505e-01 4.48987663e-01
 4.41991568e-01 4.53865737e-01 4.47466075e-01 4.45538461e-01
 4.37084138e-01 4.43855345e-01 4.51307714e-01 4.48982954e-01
 4.36651587e-01 4.48698580e-01 4.40991282e-01 4.51030076e-01
 4.51561689e-01 4.49583799e-01 4.40986544e-01 4.47591513e-01
 4.47031796e-01 4.30995584e-01 4.38860238e-01 4.27463889e-01
 4.45630163e-01 4.62008983e-01 4.39850241e-01 4.54898238e-01
 4.38116699e-01 4.25625443e-01 4.41108555e-01 4.33742434e-01
 4.43289131e-01 4.61538613e-01 4.46584344e-01 4.45223063e-01
 4.37162817e-01 4.35912728e-01 4.48303044e-01 4.07589018e-01
 4.11290199e-01 3.95174891e-01 4.01590556e-01 3.99650156e-01
 4.00424242e-01 4.03662413e-01 3.94737333e-01 3.97662491e-01
 4.08252656e-01 4.06757474e-01 4.07806158e-01 3.96070540e-01
 3.88303876e-01 4.02630985e-01 3.98549527e-01 3.91780615e-01
 3.94101888e-01 3.94326985e-01 3.92346144e-01 4.03460741e-01
 3.95114064e-01 4.02513355e-01 4.04016048e-01 3.99460495e-01
 4.01340455e-01 4.09562141e-01 4.07673955e-01 3.98817033e-01
 3.88677210e-01 4.08360839e-01 3.93396616e-01 4.10054326e-01
 3.91119510e-01 3.95911932e-01 3.95355701e-01 4.07363951e-01
 3.98004770e-01 3.98533702e-01 4.07564342e-01 3.98634136e-01
 3.99424523e-01 4.03053313e-01 3.93032610e-01 4.05317843e-01
 3.99298817e-01 3.78513753e-01 3.93097520e-01 3.79353046e-01
 4.05553281e-01 3.77514064e-01 3.75845879e-01 3.99262607e-01
 3.90565455e-01 3.91563892e-01 4.12267566e-01 3.81191969e-01
 3.79840344e-01 3.94956589e-01 3.87931705e-01 3.87491107e-01
 4.07813549e-01 3.84258777e-01 3.86743009e-01 3.85132551e-01
 3.68957937e-01 3.97623450e-01 3.98308456e-01 4.08354640e-01
 3.87942493e-01 4.02146757e-01 3.99938494e-01 3.94018739e-01
 3.98639858e-01 3.82766962e-01 3.96247566e-01 3.84966940e-01
 4.01256323e-01 3.84878963e-01 3.76646757e-01 3.77760112e-01
 3.97055387e-01], shape=(669,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(669,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1]
mse:tf.Tensor(0.15325734, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/bouncy_one_counter_000.smt2
true label:[1, 1, 0, 0, 0, 0]
true label rank:[2 2 1 1 1 1]
predicted label:tf.Tensor([0.46979573 0.47313234 0.4750631  0.47305143 0.4494204  0.4542263 ], shape=(6,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0.], shape=(6,), dtype=float32)
predicted label rank:[1 1 1 1 1 1]
mse:tf.Tensor(0.23607814, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/jm2006_variant_true-unreach-call.c.flat_000.smt2
true label:[1, 1, 1, 0, 1]
true label rank:[2 2 2 1 2]
predicted label:tf.Tensor([0.45047456 0.46261117 0.4671221  0.46407825 0.46056572], shape=(5,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.27621636, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/minepump_spec1_product58_true-unreach-call.cil.c.flat_000.smt2
true label:[1, 1, 1]
true label rank:[1 1 1]
predicted label:tf.Tensor([3.0744955e-14 1.9239364e-11 4.6731923e-17], shape=(3,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)
predicted label rank:[1 1 1]
mse:tf.Tensor(1.0, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/SpamAssassin-loop.i.v+cfa-reducer.c-1_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.32659763 0.34400427 0.25808513 0.23231757 0.378777   0.4185451
 0.36852264 0.40367287 0.39693227 0.45144266], shape=(10,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(10,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.41665584, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/durationThm_1_e3_173_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[2.5870353e-10 2.4075554e-05 1.7419776e-08 2.5622851e-10 4.2410713e-05
 1.2331050e-08 1.9288436e-07 6.1344053e-08 2.0827843e-11 3.7813187e-04
 3.1602383e-04 9.7464467e-12 5.8956543e-06 1.7659664e-03], shape=(14,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(14,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(2.4027892e-07, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/large_const_true-unreach-call.c.flat_000.smt2
true label:[1, 1, 1, 0, 1, 1, 1]
true label rank:[2 2 2 1 2 2 2]
predicted label:tf.Tensor(
[0.4030763  0.36059654 0.298467   0.3500058  0.47923595 0.47589037
 0.4568823 ], shape=(7,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0.], shape=(7,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1]
mse:tf.Tensor(0.3172386, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/bandec.smt2-0210_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1]
true label rank:[2 2 2 2 2 2 2 2 2 1 1 2 2 1 2 2 2 1 1 2 2]
predicted label:tf.Tensor(
[0.4826209  0.4885692  0.46059668 0.47251186 0.46301806 0.4520608
 0.45151854 0.46630722 0.46258736 0.45758948 0.4548213  0.45007885
 0.47515345 0.45985118 0.45876056 0.4795063  0.47587115 0.46444818
 0.46220523 0.4594248  0.46332264], shape=(21,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(21,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.2673927, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/minepump_spec5_product47_true-unreach-call.cil.c.flat_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.0600059  0.10999417 0.01751646 0.05298063 0.40575418 0.33546025
 0.29644433 0.3670938  0.34564543 0.42943686 0.46212864 0.37871376
 0.42787272 0.45741108 0.4221217  0.44406572 0.4305749  0.3904104
 0.43164518 0.3557025  0.29073763 0.27831548 0.27291965 0.32796758
 0.25826776 0.32834828 0.32907936 0.25955766 0.28848225 0.38546216
 0.36356527 0.2490144  0.44000512 0.35190946 0.40729612 0.39421067
 0.4640879  0.41297618 0.43454587 0.39633083 0.43131262 0.44149637
 0.47289976 0.4574558  0.47872856 0.4380918  0.23197037 0.4282023
 0.2997648  0.29113293 0.362968   0.3110646  0.23574415 0.25386584
 0.21727541 0.35422158 0.37377214 0.29014623 0.2527061  0.23490036
 0.22277895 0.34588093 0.44768426 0.4583252  0.4519863  0.45900846
 0.45815283 0.45512986 0.46007708 0.45685288 0.45808536 0.45574635
 0.4515476  0.4563334  0.46022958 0.46088803 0.45172876 0.46129578
 0.4524997  0.4147745  0.35502347 0.4119859  0.38743848 0.32375354
 0.3226799  0.25843394 0.29686183 0.40538618 0.4259686  0.36855692
 0.31741405 0.42376572 0.28545868 0.24604493 0.43041408 0.3360614
 0.38705945 0.4056947  0.4392252  0.40793785 0.42305586 0.38376066
 0.44070795 0.38923788 0.42385647 0.41230747 0.3889528  0.40806314
 0.40123925 0.41014928 0.4504558  0.40219212 0.45808005 0.43217373
 0.4482248  0.42062968 0.45549074 0.43911254 0.43759295 0.45512784
 0.42666453 0.4411379  0.38925618 0.4488953  0.4242832  0.45274025
 0.44988948 0.41966054 0.4281091  0.44147795 0.28838363 0.45133364
 0.3709849  0.26751447 0.27472693 0.2887045  0.3873145  0.3953889
 0.27414408 0.2732372  0.39173096 0.3746252  0.39201024 0.33133948
 0.37191576 0.40768266 0.38696706 0.06648663 0.07390425 0.08880627
 0.02484223 0.1276666  0.0140667  0.12584016 0.04889482 0.02669975
 0.39707828 0.01082617 0.05420223 0.0087671  0.05347207 0.13107455
 0.09356502 0.40974304 0.41241035 0.4273953  0.4543829  0.41054457
 0.43772665 0.39610854 0.40807116 0.4241965  0.41899616 0.2631714
 0.44243848 0.27342927 0.33226764 0.29119706 0.28422308 0.3547551
 0.48268485 0.0119265  0.15585187 0.23560855 0.00907564 0.09150112
 0.13068092 0.0066928  0.4243846  0.38751233 0.41135594 0.4264971
 0.420695   0.34965384 0.36078012 0.43100598], shape=(196,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0.], shape=(196,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.13342714, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/bandec.smt2-0238_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1]
true label rank:[2 2 2 2 2 2 2 2 1 1 2 2 1 2 2 2 1 1 2 2]
predicted label:tf.Tensor(
[0.47990268 0.48676264 0.4866492  0.4761286  0.4712322  0.46195212
 0.4575807  0.45905465 0.471551   0.44671446 0.45846605 0.44881383
 0.47232786 0.46069974 0.47079185 0.47516575 0.4685594  0.46855423
 0.46773452 0.46881822], shape=(20,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.2660399, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/nest-if1.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[3.4248829e-04 1.1845410e-02 3.6722286e-05 2.2700429e-04 1.0038525e-02
 3.1864643e-04 4.6461180e-05 8.1270933e-04 3.0350819e-05], shape=(9,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(9,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(2.6891219e-05, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/SYNAPSE_5_e2_1525_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.0363034  0.10416931 0.05548313 0.05593908 0.18477333 0.03173855
 0.03825098 0.05715749 0.03918543 0.31475985 0.33599305 0.02106073
 0.18842116 0.2943064  0.25302786 0.06255442 0.11881408 0.09044316
 0.32211205 0.00663039 0.05112618 0.0276432  0.03703722 0.0639118
 0.12886822 0.06841519 0.0543029  0.01161167 0.01971439 0.20629478
 0.07712039 0.41717327 0.4173653  0.3977465  0.40295595 0.41213995
 0.41337287 0.41140157 0.4121552  0.4302486  0.41638666 0.4206771
 0.41444832 0.41544193 0.41796452 0.41857013 0.416784   0.43296954
 0.40774068 0.42710716 0.4223628  0.44385657 0.44054276 0.4277488
 0.42773628 0.43812147 0.4216347  0.42574278 0.44218194 0.41684985
 0.42621362 0.42343622 0.41298488 0.4226318  0.46729046 0.46907008
 0.4778876  0.4653473  0.4684583  0.46634898 0.4390001  0.4478131
 0.46207428 0.4452054  0.4622184  0.45518652 0.47161886 0.4785082
 0.47231635 0.48357671 0.47154155 0.47460675 0.48126924 0.4875282
 0.48436707 0.49159414 0.48125014 0.48362565 0.4689764  0.4515702
 0.4620329  0.46426213 0.45062852 0.47321567 0.4538294  0.4700241
 0.45687956 0.46534976 0.4611104  0.38816375 0.38832283 0.40810797
 0.40695634 0.36592367 0.40193206 0.40155    0.3542123  0.41686967
 0.44713363 0.40797848 0.4155721  0.40333602 0.47381532 0.28619748
 0.41948777 0.31197697 0.34304097 0.36834472 0.30970967 0.41782254
 0.29851186 0.29525962 0.2607814  0.32560682 0.3348133  0.35566375
 0.33738354 0.25366092 0.3874805  0.3460987  0.365695   0.46794367
 0.37395775 0.36616558 0.30556613 0.3090017  0.33617198 0.3430564
 0.25566658 0.23672944 0.36168242 0.38530493 0.36401403 0.25255144
 0.3718601  0.45292926 0.30430788 0.31093454 0.3513378  0.36190584
 0.24555004 0.33324355 0.13406274 0.3185454  0.36933178 0.2651291
 0.35588366 0.17788216 0.24739277 0.17139545 0.43144283 0.4194033
 0.43302938 0.38118666 0.4331403  0.42681178 0.4525624  0.4172184
 0.44198212 0.4282506  0.45667455 0.44346148 0.45996356 0.39525965
 0.45193666 0.41126496 0.4629656  0.42349553 0.4237855  0.41129208
 0.46269283 0.449842   0.4474795 ], shape=(183,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(183,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.1419338, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/const_1-1.c-1_000.smt2
true label:[1, 1]
true label rank:[1 1]
predicted label:tf.Tensor([0.48027018 0.47968876], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 0.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.27042145, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/apache-get-tag.i.v+lhb-reducer.c-1_000.smt2
true label:[1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1]
predicted label:tf.Tensor([0.3855192  0.36222142 0.45043778 0.47123945 0.45134678 0.35667425], shape=(6,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0.], shape=(6,), dtype=float32)
predicted label rank:[1 1 1 1 1 1]
mse:tf.Tensor(0.34680715, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/nest-if.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.0002422  0.00292084 0.00064144 0.00019643 0.01019204 0.0009191
 0.00221986 0.00200385], shape=(8,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0.], shape=(8,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1]
mse:tf.Tensor(1.5338188e-05, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/test_locks_12.c-1_000.smt2
true label:[0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2
 1 2 1 2 1 2 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 2
 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1
 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1
 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1
 1 1 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 2 1
 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 1 2
 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.4097553  0.40258276 0.39706492 0.39393944 0.41556782 0.384374
 0.40344006 0.38046077 0.41279453 0.398928   0.40134615 0.39828265
 0.40434596 0.3944613  0.39294168 0.38326314 0.41083032 0.39771104
 0.39307553 0.3991202  0.38270494 0.39319202 0.4004412  0.38865402
 0.37665948 0.3882788  0.37676644 0.39438182 0.38274038 0.38783133
 0.3696816  0.39100832 0.3804165  0.3677947  0.37222314 0.37808844
 0.37704536 0.38468307 0.38767898 0.38591582 0.36546585 0.38467443
 0.38456005 0.39563847 0.38395277 0.3827925  0.38509393 0.4044673
 0.38775408 0.41240466 0.40181473 0.3967269  0.38895297 0.3861555
 0.400375   0.39068472 0.38746533 0.3911208  0.4010632  0.40135327
 0.37652025 0.4051267  0.39663398 0.38608667 0.4140264  0.39313805
 0.40390807 0.3938304  0.39934447 0.43424135 0.4412455  0.44285467
 0.4577284  0.4133394  0.45052615 0.44376546 0.42920077 0.44985458
 0.42957884 0.44615698 0.44189018 0.45096034 0.43691525 0.44560945
 0.42505667 0.434704   0.43914706 0.45386758 0.44722545 0.3984834
 0.45592916 0.47325388 0.4396115  0.45644447 0.4610166  0.45151603
 0.40197688 0.444744   0.4651408  0.42936385 0.43452635 0.43034908
 0.44321    0.44736677 0.45698068 0.42943722 0.3974976  0.4576162
 0.43397084 0.43679518 0.47089633 0.4455539  0.45494974 0.44954133
 0.45511442 0.45973128 0.4720827  0.45113757 0.47491395 0.4857424
 0.44509003 0.46600693 0.4415483  0.452482   0.45848984 0.4525713
 0.45996895 0.44413358 0.4742248  0.42056632 0.40789652 0.4452437
 0.42263448 0.41206098 0.4042328  0.4526415  0.44320077 0.42431527
 0.4289925  0.42372382 0.4132702  0.44473025 0.44511223 0.43231553
 0.43769073 0.4401344  0.44871265 0.43564975 0.43570238 0.43552974
 0.45434874 0.4395137  0.4537974  0.43751064 0.44660863 0.4566591
 0.42871428 0.45895752 0.44950208 0.42943344 0.45048127 0.4318612
 0.431471   0.44491172 0.46141294 0.4581589  0.45403704 0.44073248
 0.4629995  0.46039432 0.46258727 0.45034453 0.4577331  0.43905124
 0.46360692 0.44299784 0.446412   0.43861562 0.4234129  0.4439785
 0.46824735 0.46689987 0.43961418 0.48186287 0.43577805 0.46215957
 0.46426335 0.44503927 0.4715954  0.47977594 0.4639809  0.47131088
 0.48088408 0.4421268  0.453815   0.47591385 0.4657465  0.4560581
 0.46605644 0.47694314 0.45948088 0.46639818 0.45714986 0.46751785
 0.45656034 0.46560323 0.47716054 0.44410253 0.46554175 0.4027924
 0.4449221  0.41777155 0.43698722 0.4517211  0.42376286 0.42200142
 0.41602236 0.43252224 0.43354887 0.42513224 0.43470702 0.44645387
 0.40688676 0.44004276 0.4217357  0.44147107 0.4274383  0.46108842
 0.4247252  0.43021938 0.4605021  0.42158103 0.44620708 0.44433346
 0.4228075  0.42998877 0.42840448 0.4558491  0.45758444 0.4253484
 0.44697988 0.43650636 0.472639   0.42951456 0.43352228 0.3967929
 0.43592626 0.41667727 0.45707196 0.45814273 0.43560615 0.4644488
 0.47276387 0.4480933  0.4548347  0.42475653 0.39160806 0.43149102
 0.4258582  0.39476955 0.4368732  0.43312666 0.42276192 0.43625504
 0.42271218 0.42312557 0.437948   0.42124462 0.4230934  0.4057365
 0.40721178 0.37401164 0.416202   0.4038072  0.43243164 0.42152476
 0.42268455 0.4277749  0.43859577 0.4499912  0.37311625 0.43265432
 0.42412478 0.40729743 0.3837974  0.4350972  0.43548673 0.4242471
 0.38720292 0.427351   0.43030673 0.44723383 0.44169676 0.44399232
 0.42972708 0.4500066  0.46906438 0.4304084  0.46561718 0.44637552
 0.4082648  0.44382656 0.41833296 0.45021448 0.4479305  0.45126492
 0.45363614 0.47717914 0.45739618 0.44412726 0.444225   0.4469047
 0.43208578 0.42805016 0.43493095 0.41677344 0.4127848  0.4505786
 0.45245045 0.43781382 0.41775417 0.43854624 0.42320904 0.42436603], shape=(324,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(324,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.23483382, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/reverse_ret_unsafe.c_000.smt2
true label:[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2
 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2
 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.35901242 0.34303525 0.35376948 0.3559625  0.3443098  0.34573197
 0.34862888 0.34840634 0.34959656 0.3498182  0.3371386  0.34851182
 0.36367714 0.34077892 0.34899935 0.34603745 0.35744914 0.34033865
 0.36130202 0.3412909  0.35567588 0.34648103 0.32917637 0.3437811
 0.3489672  0.34123707 0.3416552  0.34871715 0.36033788 0.34931585
 0.35863885 0.34623098 0.34457603 0.3347988  0.33944932 0.35149926
 0.34002498 0.33094293 0.34398767 0.35869664 0.33263528 0.342161
 0.3414495  0.34336138 0.34749377 0.35583878 0.34481156 0.35763
 0.33739716 0.34413588 0.35393322 0.35496932 0.35792845 0.34459198
 0.34174755 0.35337475 0.34635562 0.34409142 0.35489202 0.35378522
 0.3473245  0.34266442 0.34305248 0.35020489 0.3419149  0.3310275
 0.32382107 0.3284197  0.32872975 0.32868093 0.34034377 0.3246965
 0.33728528 0.32299113 0.34090498 0.3204376  0.31233132 0.3523491
 0.33013675 0.32498115 0.33573365 0.3177628  0.33644196 0.31830573
 0.34144562 0.34534746 0.33134472 0.31665868 0.3498224  0.33073547
 0.32423127 0.34130213 0.33121556 0.3400768  0.32604915 0.33067164
 0.3189729  0.32959414 0.33555624 0.3267415  0.33566788 0.3189631
 0.33013147 0.32868546 0.34778246 0.31150937 0.31910294 0.3366732
 0.3219663  0.33746374 0.3466679  0.33358768 0.33043978 0.3198495
 0.32402933 0.310795   0.34000853 0.32173467 0.33529788 0.33935553
 0.31198037 0.32749552 0.304474   0.3279538  0.3353943  0.3276294
 0.31803048 0.30765188 0.31740844 0.33144343 0.3152139  0.31551242
 0.33683145 0.329023   0.31412876 0.3252163  0.33339494 0.3378902
 0.32500958 0.3254187  0.32403135 0.3316031  0.32328868 0.33383143
 0.3407286  0.33598888 0.3667243  0.367083   0.37373322 0.38471588
 0.37362123 0.37759265 0.3844165  0.3676678  0.36115542 0.37270182
 0.35962504 0.37295732 0.38446292 0.35082576 0.37918344 0.37128466
 0.35984498 0.3630969  0.36749125 0.37672094 0.3622979  0.36723524
 0.35761273 0.37463546 0.35593265 0.3840888  0.37133282 0.3714309
 0.3732478  0.3696715  0.3731994  0.3640778  0.35411865 0.3478852
 0.3674867  0.37293065 0.3669458  0.3534743  0.36379474 0.35930753
 0.36609435 0.3636975  0.36847386 0.38483685 0.34714645 0.39223444
 0.38564676 0.35328162 0.37098554 0.37056565 0.36876246 0.35669887
 0.38770622 0.37158144 0.38943055 0.369067   0.3766021  0.39279154
 0.3758374  0.35398835 0.37422723 0.36195982 0.35617298 0.36651158
 0.36671296 0.37686452 0.37219483 0.37650394 0.37380937 0.37600702
 0.37517685 0.36072344 0.35774302 0.33984178 0.37260386 0.36483684
 0.3790328  0.37493324 0.3542655  0.36555326 0.3693927  0.3687341
 0.36745766 0.36977476 0.37828544 0.36411935 0.37440252 0.35531163
 0.38047948 0.37165004 0.37252793 0.38136363 0.36696523 0.3608082
 0.3850668  0.3606465  0.36375234 0.35800093 0.3305036  0.33556402
 0.3443982  0.34184778 0.36204642 0.35742238 0.3490799  0.35534632
 0.35788256 0.33436775 0.3511144  0.32911032 0.31698745 0.33271027
 0.3262766  0.3377437  0.32523006 0.3438052  0.3338489  0.34260768
 0.3595727  0.33975428 0.3285728  0.3455851  0.34998775 0.35789245
 0.34288508 0.3566777  0.3550757  0.33906662 0.338019   0.3273224
 0.34564155 0.34978825 0.34604472 0.34058225 0.3257228  0.35373604
 0.34875944 0.33126438 0.32773075 0.33936805 0.3546551  0.348378
 0.33318722 0.3439963  0.34579703 0.33088544 0.3460993  0.34668761
 0.3343566  0.3392883  0.3407578  0.34256434 0.32851058 0.33602434
 0.336264   0.34023732 0.34158593 0.34119785 0.3381943  0.33515537
 0.32883793 0.3471343  0.33929443 0.3437817  0.33885598 0.33855242
 0.33365905 0.33511844 0.35244948 0.35140082 0.3324508  0.34185392
 0.34340292 0.3577019  0.340452   0.3517767  0.3416844  0.35681054
 0.35662895 0.33724433 0.346159   0.3392415  0.34240586 0.33166528
 0.35631445 0.33776334 0.35061038 0.3446647  0.35683143 0.34315762
 0.34077948 0.32388985 0.3507821  0.33329228 0.3429677  0.33909225
 0.33730412 0.3470884  0.35144258 0.34094942 0.3385151  0.359249
 0.33824742 0.3453372  0.32920808 0.33058095 0.34651595 0.3474191
 0.33363795 0.34588647 0.3870689  0.3784152  0.3778438  0.38387638
 0.3612844  0.37690663 0.3796263  0.37906307 0.36756963 0.38428015
 0.389745   0.3748092  0.3618365  0.37111253 0.38368416 0.36397678
 0.37931275 0.38307038 0.37814194 0.37569112 0.39042628 0.35903433
 0.37819192 0.37117556 0.38642937 0.388715   0.37926054 0.35882527
 0.37746087 0.3834504  0.37490657 0.3742609  0.37004417 0.373174
 0.39251322 0.37282658 0.3821307  0.37970424 0.36011338 0.35826272
 0.37051737 0.3619394  0.39139697 0.3657869  0.35483044 0.38388556
 0.35874304 0.3881701  0.38287583 0.37473613 0.36459428 0.36812055
 0.37635794 0.38512984 0.37264678 0.37629533 0.38007423 0.36903664
 0.3876247  0.3633796  0.39564303 0.3896532  0.37450978 0.3648091
 0.37979728 0.386512   0.37621242 0.38716042 0.36384717 0.38308123
 0.3778504  0.37700224 0.39031377 0.3709615  0.37184206 0.36723036
 0.36860168 0.3825196  0.3777524  0.3746664  0.3596086  0.35891056
 0.38487524 0.37746665 0.36809325 0.36453065 0.38298875 0.36901292
 0.37247425 0.3844237  0.3788727  0.3762649  0.37132585 0.36896622
 0.37446782 0.3987429  0.37623477 0.37664407 0.38198718 0.37726068
 0.36739036 0.3841254  0.37875322 0.3712175  0.37375507 0.3661404
 0.38673496 0.38994992 0.35848403 0.37893146 0.37479883 0.36397105
 0.37489307 0.37560868 0.37784547 0.3755766  0.38302857 0.37647107
 0.38555446 0.3808464  0.36670333 0.3727002  0.37675703 0.3837929
 0.37684095 0.36968672 0.381405   0.37841272 0.36860424 0.44517228
 0.44992447 0.44718987 0.44831657 0.45268112 0.4507571  0.44562572
 0.45300138 0.43899027 0.4452442  0.43600148 0.45134437 0.4459952
 0.45190495 0.45077032 0.44680613 0.4495366  0.44780764 0.4497391
 0.45617777 0.4528885  0.4475173  0.43933007 0.45313042 0.450987
 0.44935903 0.45311642 0.45395342 0.4512175  0.44828156 0.45687667
 0.45380986 0.45964524 0.4560679  0.45616794 0.45526075 0.45169824
 0.44777775 0.45251888 0.46193364 0.45038438 0.45123228 0.45406118
 0.44824877 0.44753528 0.45963985 0.45094758 0.4486935  0.44872752
 0.4471975  0.4535987  0.4518252  0.45905036 0.44545916 0.4101066
 0.40937978 0.40841815 0.41156936 0.40748182 0.4082858  0.42161903
 0.4089297  0.42156342 0.410586   0.40557298 0.40787828 0.40774283
 0.41263205 0.40686733 0.41041824 0.4100272  0.40818074 0.41103756
 0.41254613 0.41047418 0.40523225 0.4117195  0.4071472  0.40342325
 0.4089103  0.4080498  0.4081924  0.40079266 0.41161466 0.40978795
 0.405711   0.40522763 0.41607383 0.4123977  0.41124326 0.41343114
 0.41394946 0.41189885 0.40505326 0.40652916 0.41513154 0.40572292
 0.4045416  0.40985066 0.40745595 0.4024731  0.4051695  0.4061761
 0.40982157 0.40619346 0.4045923  0.40741482 0.40509734 0.40537912
 0.4103564  0.40673453 0.40766883 0.41262853 0.41001007 0.41507056
 0.40466183 0.41068214 0.4068446  0.4027288  0.39953277 0.4082095
 0.4068814  0.4105663  0.4087408  0.40848172 0.41428527 0.410982
 0.41212732 0.40637448 0.40719515 0.4034687  0.41492248 0.4068642
 0.4057336  0.4068968  0.41085568 0.39962596 0.40903592 0.40253562
 0.40170455], shape=(625,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0.], shape=(625,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.16678324, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/barthe2_merged_safe.c-1_000.smt2
true label:[0, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 2 2 2 2 2 2 2 2 2]
predicted label:tf.Tensor(
[0.43568423 0.46530592 0.45618334 0.42630118 0.46776658 0.46778193
 0.44866666 0.456367   0.45931116 0.45084774], shape=(10,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(10,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.28605318, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/metros_3_e3_1275_e2_454_000.smt2
true label:[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]
true label rank:[1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 2 1 1 1 2 2
 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 2 2 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 2 1
 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1
 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1
 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1
 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1
 1 1 2 1 1 1 1 1 2 1 1 1 1 1 2 1 1]
predicted label:tf.Tensor(
[0.14792252 0.17956379 0.11988598 0.16454509 0.22902727 0.13037255
 0.122008   0.2675294  0.14130253 0.37454516 0.37835935 0.12333232
 0.29117513 0.34106156 0.31672317 0.20027253 0.23809004 0.361341
 0.5094723  0.08106172 0.09039733 0.19028178 0.12359688 0.10393259
 0.26470378 0.09781966 0.216153   0.06852463 0.13805315 0.23866552
 0.22038543 0.17376027 0.16406754 0.1712965  0.08931348 0.20270538
 0.28471363 0.15823302 0.17308378 0.4374605  0.16393948 0.19587034
 0.40916935 0.15321818 0.3816424  0.397981   0.39692727 0.39413768
 0.36843318 0.37287214 0.37878126 0.37987962 0.36102986 0.37801376
 0.35688502 0.35987568 0.3685684  0.35081667 0.38527873 0.37617928
 0.35509455 0.3801767  0.34761423 0.3085697  0.33897406 0.37308243
 0.3719319  0.37569827 0.38599908 0.38745192 0.37801176 0.4117377
 0.40986052 0.41599604 0.40995294 0.39947903 0.39801407 0.41800117
 0.38389352 0.4002017  0.41635543 0.39125866 0.4090017  0.421777
 0.3851149  0.40238178 0.40643287 0.42013952 0.4347436  0.3885758
 0.38516614 0.4127803  0.42215416 0.4233419  0.40888643 0.42891812
 0.3972128  0.41246378 0.39529067 0.33760136 0.26834804 0.4532174
 0.38679487 0.37329817 0.35437799 0.3670983  0.25782186 0.34116954
 0.41216022 0.32391512 0.35157877 0.31441528 0.33760887 0.31985193
 0.41719744 0.27477646 0.27984196 0.30543575 0.31448722 0.3648498
 0.33257347 0.35712045 0.29596084 0.28906527 0.38945422 0.3897211
 0.33159682 0.33793443 0.3120258  0.41795984 0.36679137 0.4138179
 0.34371346 0.37227154 0.34576458 0.3437972  0.35337007 0.3250587
 0.30617943 0.3388999  0.39249104 0.4074954  0.43281046 0.36701506
 0.4146992  0.4139509  0.42266676 0.3418677  0.38075596 0.33044374
 0.30915707 0.31451252 0.2614687  0.37699965 0.36544293 0.3231038
 0.36568958 0.29524547 0.28022236 0.24980599 0.26774368 0.3914209
 0.37661383 0.26006752 0.28087407 0.31103164 0.40514922 0.35648456
 0.3637855  0.3487628  0.3941374  0.3639186  0.34786463 0.30948597
 0.42656487 0.28623807 0.31167108 0.32724902 0.2964366  0.39523137
 0.4366459  0.39414856 0.3859262  0.40713742 0.22946465 0.3077992
 0.41650334 0.28818393 0.36698776 0.33774304 0.3133769  0.41868198
 0.42313161 0.31419444 0.3143975  0.40465394 0.13270539 0.20921919
 0.20545945 0.24894479 0.34620738 0.18933156 0.20733526 0.3508622
 0.08451474 0.2050694  0.16335052 0.37286055 0.26467645 0.25054848
 0.38200384 0.38731536 0.37785512 0.40661827 0.39785516 0.41840163
 0.33814728 0.35689175 0.44295293 0.45739755 0.4272551  0.39721316
 0.34117424 0.3189965  0.3643793  0.42065093 0.3158338  0.39838076
 0.4479409  0.45751646 0.44480437 0.41529894 0.4537065  0.39750272
 0.4531439  0.44431674 0.40165794 0.4678384  0.4699619  0.43483505
 0.4600031  0.43985695 0.45808735 0.40534544 0.427837   0.42306614
 0.41161656 0.45782092 0.4212584  0.4691312  0.44773018 0.4543073
 0.47019917 0.4431376  0.4163421  0.39824304 0.3667112  0.38283306
 0.40989327 0.39240715 0.46599138 0.43222046 0.3763982  0.41571337
 0.41778332 0.41093338 0.389444   0.40378642 0.39422372 0.41428244
 0.39916548 0.41248822 0.39791223 0.40891066 0.4293918  0.40241468
 0.44826233 0.4154598  0.4406267  0.3972077  0.39690226 0.39796034
 0.43238407 0.41563988 0.16839352 0.30476326 0.30446395 0.24432781
 0.33353734 0.31202176 0.2391021  0.39730513 0.19778529 0.19573852
 0.27443647 0.20989105 0.42266893 0.19349495 0.19120577 0.4952284
 0.11922672 0.17568868 0.28929693 0.48146445 0.43754598 0.4389977
 0.47833523 0.45808625 0.45564193 0.44412935 0.47009966 0.44163907
 0.46534985 0.44437975 0.44041756 0.4226194  0.42479786 0.45610255
 0.4231203  0.46104127 0.44784302 0.45944518 0.43345493 0.42710114
 0.42845997 0.4335723  0.42536378 0.4306933  0.42051858 0.42987472
 0.42740136 0.43257362 0.43057734 0.42020902 0.421311   0.42146692
 0.4249029  0.42059165 0.4175306  0.42559087 0.41679403 0.4292129
 0.44961315 0.4438344  0.39804998 0.45357114 0.42595762 0.45324695
 0.42320198 0.4469874  0.43967852 0.4138568  0.43554813 0.44634104
 0.46309352 0.38802707 0.45009995 0.45057005 0.41063094 0.4609048
 0.44945756 0.4213215  0.45402157 0.44543302 0.45969412 0.45427394
 0.45385918 0.4068225  0.41398472 0.39886627 0.4247374  0.4354344
 0.4137203  0.3857334  0.40840068 0.39131042 0.4173404  0.40649337
 0.38436797 0.40534878 0.40979546 0.38303137 0.42674407 0.38939556
 0.40120405 0.41816723 0.4271585  0.4053983  0.37504104 0.39977407
 0.38416848 0.42350823 0.39788967 0.4331236  0.37948623 0.4468485
 0.43328014 0.3717978  0.44449952 0.38627824 0.39871693 0.44917676
 0.44126028 0.40164533 0.4233431  0.412995   0.42354968 0.4188664
 0.40483046 0.413113   0.41232154 0.408597   0.40796226 0.36440572
 0.4137727  0.2724372  0.38479406 0.37683707 0.35311747 0.36884838
 0.40577155 0.36521888 0.40525967 0.39365524 0.3494519  0.3949809
 0.39160842 0.3274603  0.37331337 0.39372814 0.30873337 0.4230559
 0.37575442 0.33951712 0.36904442 0.41996175 0.3295625  0.3455302
 0.3798221  0.34959036 0.32084724 0.3800264  0.41803074 0.4301551
 0.42905262 0.42528245 0.41327307 0.41194522 0.42812687 0.41639248
 0.43498534 0.40989658 0.43667448 0.4401616  0.43914625 0.40094763
 0.40803054 0.41798413 0.43519408 0.4104582  0.41906667 0.43630424
 0.42493674 0.43546942 0.40599433 0.42042738 0.40948552 0.47114366
 0.43910348 0.42014307 0.47292605 0.45856422 0.44374162 0.46699077
 0.46449164 0.42809343 0.44740006 0.42195886 0.4664596  0.39552
 0.4490915  0.41309217 0.43890318 0.4264326  0.46404862 0.36347967
 0.4189621  0.4197463  0.45093152 0.41067868 0.43459734 0.3693471
 0.43791243 0.42066902 0.43879417 0.4093017  0.41940027 0.44361368], shape=(498,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(498,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.1822987, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/nest-if3_true-unreach-call.c.flat_000.smt2
true label:[1, 1, 0, 1, 1, 1, 1]
true label rank:[2 2 1 2 2 2 2]
predicted label:tf.Tensor(
[0.46520957 0.462865   0.46715492 0.45456314 0.4524866  0.44486463
 0.4208683 ], shape=(7,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0.], shape=(7,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1]
mse:tf.Tensor(0.29051277, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/four1.smt2-0027_000.smt2
true label:[1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]
true label rank:[2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2]
predicted label:tf.Tensor(
[0.47843343 0.47904524 0.41371152 0.4384242  0.40957177 0.41827914
 0.41744035 0.41117638 0.41919896 0.43149048 0.41914055 0.41058236
 0.42269123 0.42891133 0.429096   0.4130245  0.4218536 ], shape=(17,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(17,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.21457043, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/minepump_spec3_product49_true-unreach-call.cil.c.flat_000.smt2
true label:[1, 1, 0, 1, 1]
true label rank:[2 2 1 2 2]
predicted label:tf.Tensor([5.5444241e-04 7.5276494e-03 4.4915916e-05 2.0171440e-12 2.4079229e-05], shape=(5,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.79676896, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/inf6.correct.nts.horn-0001_000.smt2
true label:[1, 1, 0, 0, 1, 0, 0, 0, 0, 1]
true label rank:[2 2 1 1 2 1 1 1 1 2]
predicted label:tf.Tensor(
[0.4779229  0.48845392 0.45377338 0.47625828 0.47454485 0.4746894
 0.4728544  0.48573345 0.4825925  0.4899124 ], shape=(10,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(10,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.24210222, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/tridag.smt2-0014_000.smt2
true label:[1]
true label rank:[1]
predicted label:tf.Tensor([0.48149478], shape=(1,), dtype=float32)
rounded label:tf.Tensor([0.], shape=(1,), dtype=float32)
predicted label rank:[1]
mse:tf.Tensor(0.26884764, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/loop__while_after_while_if_000.smt2
true label:[0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1]
true label rank:[1 1 1 2 1 1 2 1 2 2 1 2 1 2]
predicted label:tf.Tensor(
[0.4614402  0.46153992 0.47762254 0.4613486  0.45635885 0.39745462
 0.36161673 0.41495842 0.35964674 0.44778395 0.47234762 0.40205476
 0.4672549  0.47739738], shape=(14,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(14,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.2626613, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/inductive5_000.smt2
true label:[0, 1]
true label rank:[1 2]
predicted label:tf.Tensor([0.46683827 0.47973895], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 0.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.24430476, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/SYNAPSE_6_e3_1666_e5_1558_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.0363034  0.10416931 0.05548313 0.05593908 0.18477333 0.03173855
 0.03825098 0.05651945 0.04004502 0.31324714 0.32898355 0.02179807
 0.18842116 0.2943064  0.25302786 0.06255442 0.11881408 0.09044316
 0.32211205 0.00663039 0.05112618 0.0276432  0.03703722 0.0639118
 0.12886822 0.06841519 0.0543029  0.01161167 0.01960167 0.20359355
 0.07712039 0.41717327 0.4173653  0.3977465  0.40295595 0.41213995
 0.41337287 0.41140157 0.4121552  0.4302486  0.41638666 0.4206771
 0.41444832 0.41544193 0.41796452 0.41857013 0.416784   0.43296954
 0.40774068 0.42710716 0.4223628  0.44385657 0.44054276 0.4277488
 0.42773628 0.43812147 0.4216347  0.42574278 0.44218194 0.41684985
 0.42621362 0.42343622 0.41298488 0.4226318  0.46729046 0.46907008
 0.4778876  0.4653473  0.4684583  0.46634898 0.4390001  0.4478131
 0.46207428 0.4452054  0.4622184  0.45518652 0.47161886 0.4785082
 0.47231635 0.48357671 0.47154155 0.47460675 0.48126924 0.4875282
 0.48436707 0.49159414 0.48125014 0.48362565 0.4689764  0.4515702
 0.4620329  0.46426213 0.45062852 0.47321567 0.4538294  0.4700241
 0.45594335 0.4634318  0.4611104  0.38816375 0.39092082 0.40750542
 0.40695634 0.36592367 0.40193206 0.40155    0.3542123  0.41686967
 0.44713363 0.40797848 0.4155721  0.40333602 0.47381532 0.28619748
 0.41948777 0.31197697 0.34304097 0.36834472 0.30970967 0.41782254
 0.29851186 0.29525962 0.2607814  0.32560682 0.3348133  0.35566375
 0.33738354 0.25366092 0.3874805  0.3460987  0.365695   0.46794367
 0.37395775 0.36616558 0.30556613 0.3090017  0.33617198 0.3430564
 0.25566658 0.23672944 0.36168242 0.38530493 0.36401403 0.25255144
 0.3718601  0.45292926 0.30430788 0.31093454 0.3513378  0.36190584
 0.24555004 0.33324355 0.13406274 0.3185454  0.36933178 0.2651291
 0.35588366 0.17788216 0.24739277 0.17139545 0.43144283 0.4194033
 0.43302938 0.38118666 0.4331403  0.42681178 0.4525624  0.4172184
 0.44198212 0.4282506  0.45667455 0.44346148 0.45996356 0.39525965
 0.45193666 0.41126496 0.4629656  0.42349553 0.4237855  0.41129208
 0.46269283 0.449842   0.4474795 ], shape=(183,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(183,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.1418912, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0028_000.smt2
true label:[0, 0, 1, 0, 1]
true label rank:[1 1 2 1 2]
predicted label:tf.Tensor([0.4593858  0.46737    0.46437576 0.4438992  0.45018578], shape=(5,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.24314113, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0265_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.0000000e+00 7.9832700e-35 0.0000000e+00 0.0000000e+00 2.2093523e-27
 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.5929095e-01 4.7896695e-01
 3.7541494e-01 3.6612886e-01 3.9804098e-01 3.7945110e-01 3.7379584e-01
 3.7618181e-01 3.6761391e-01 3.7507442e-01 3.6707431e-01 3.4292436e-01
 4.5028773e-01 3.8221344e-01 4.1023839e-01 4.1377872e-01 3.5327357e-01
 3.8729775e-01 3.6692542e-01 2.2148028e-01 2.8067601e-01 4.0073848e-01
 3.7528822e-01 3.0894935e-01 3.7136969e-01 2.6793295e-01 2.5878635e-01
 3.2985276e-01 3.9044601e-01 3.9347133e-01 3.6469522e-01 4.4189593e-01
 3.1377596e-01 4.2935327e-01 4.5010537e-01 3.7266311e-01 4.0823275e-01
 4.7559035e-01 3.2724547e-01 4.3276921e-01 3.8147044e-01 4.1758019e-01
 3.7196943e-01 3.9471900e-01 3.2531518e-01 3.8281375e-01 3.7659019e-01
 3.8337880e-01 4.4259241e-01 3.7238920e-01 3.3194983e-01 3.2681555e-01
 2.9473728e-01 3.5991070e-01 3.2662830e-01 2.7331927e-01 3.8967294e-01
 4.0064785e-01 3.5787287e-01 3.8217586e-01 3.4471399e-01 3.7448585e-01
 3.6636901e-01 3.2414407e-01 3.6596841e-01 3.0665267e-01 2.8645176e-01
 3.0942222e-01 3.2173425e-01 3.7310809e-01 4.0427589e-01 4.0412927e-01
 3.3024806e-01 3.8408011e-01 2.9038376e-01 3.8653606e-01 3.7765035e-01
 2.8406847e-01 3.4785837e-01 3.3970714e-01 3.6223328e-01 3.5378635e-01
 2.9681921e-01 4.6100315e-01 3.5063225e-01 2.6415876e-01 4.2754096e-01
 2.9878688e-01 2.4991813e-01 3.4030485e-01 4.3071857e-01 3.3874124e-01
 3.2889038e-01 4.3896550e-01 4.3431395e-01 4.2800659e-01 3.1540415e-01
 4.0082407e-01 3.2618564e-01 4.0450639e-01 3.4712633e-01 3.1663677e-01
 4.3874159e-01 3.5043433e-01 3.3809155e-01 2.8649116e-01 4.2279941e-01
 2.7911302e-01 3.0388594e-01 3.3639547e-01 3.4257424e-01 3.5499007e-01
 3.5591367e-01 3.3257946e-01 1.9922462e-01 3.1358635e-01 3.9007413e-01
 3.9164630e-01 2.9612088e-01 3.2382554e-01 3.9881876e-01 3.4606051e-01
 3.8977870e-01 4.2273909e-01 3.3727986e-01 3.2314724e-01 3.1748110e-01
 3.4819287e-01 3.5453236e-01 3.9182425e-01 2.3941907e-01 3.1343234e-01
 4.5349801e-01 3.5167783e-01 4.2501113e-01 3.2560238e-01 3.4489813e-01
 3.9497718e-01 3.1754577e-01 3.7619081e-01 3.7126023e-01 3.6531866e-01
 3.6326364e-01 4.4498473e-01 2.4208748e-01 4.2855421e-01 3.7772995e-01
 3.7817961e-01 4.2189378e-01 2.7705282e-01 3.1993443e-01 3.2364702e-01
 4.3197459e-01 4.3292367e-01 3.9325294e-01 2.5685057e-01 3.4616330e-01
 3.7821355e-01 4.4655856e-01 3.0694363e-01 3.6433303e-01 3.0398798e-01
 4.5673430e-01 3.4440011e-01 3.4400940e-01 2.7284363e-01 4.2425165e-01
 2.7562380e-01 3.1863272e-01 3.0981651e-01 3.5348839e-01 3.3721185e-01
 4.3750736e-01 3.6020637e-01 3.0680019e-01 4.5380780e-01 1.9300416e-01
 3.2396439e-01 3.6167467e-01 2.4299932e-01 3.5723293e-01 3.4590530e-01
 3.6518431e-01 4.1658744e-01 4.2224377e-01 2.7261046e-01 3.5097146e-01
 4.3561602e-01 3.1776929e-01 3.2169467e-01 3.3487040e-01 3.2611698e-01
 3.8390034e-01 2.6231611e-01 3.2373166e-01 4.4513476e-01 4.1635793e-01
 3.8108057e-01 3.5562426e-01 3.3039665e-01 4.0067166e-01 4.1961876e-01
 4.1119727e-01 3.2492155e-01 2.9506886e-01 4.2799664e-01 3.6994505e-01
 4.2591891e-01 2.7694097e-01 3.6708027e-01 4.3220210e-01 4.9396810e-01
 4.3852273e-01 3.3980602e-01 2.8808850e-01 2.3470438e-01 3.5211143e-01
 4.2901152e-01 2.9893008e-01 3.7161359e-01 4.2496979e-01 3.3070576e-01
 4.4006771e-01 3.9299440e-01 3.9924893e-01 3.0524367e-01 3.9589405e-01
 2.6587260e-01 3.4046316e-01 4.1000846e-01 4.1316012e-01 3.6171147e-01
 3.7228161e-01 4.2700642e-01 4.1825944e-01 2.7322650e-01 3.7858856e-01
 2.7364382e-01 2.9044920e-01 3.2027727e-01 2.9212493e-01 4.2956385e-01
 4.0600976e-01 4.4963956e-01 4.7647142e-01 3.6393535e-01 3.8403234e-01
 3.6909682e-01 2.5594509e-01 2.9769558e-01 3.7775108e-01 2.7781484e-01
 3.8631129e-01 3.6236325e-01 2.8586283e-01 2.8869438e-01 4.0840632e-01
 3.8141948e-01 2.4612215e-01 3.7627971e-01 3.5793096e-01 3.7971368e-01
 3.1669217e-01 3.3230072e-01 3.9756885e-01 3.3456397e-01 4.1790307e-01
 3.9291459e-01 3.9275333e-01 4.1388583e-01 3.7814930e-01 4.0369937e-01
 2.2212645e-01 2.9361159e-01 4.0444398e-01 3.0348071e-01 3.0162060e-01
 3.8528779e-01 2.6524395e-01 3.6253196e-01 3.4320837e-01 3.8775745e-01
 2.6327357e-01 4.2814928e-01 3.8548636e-01 3.9738271e-01 4.1234717e-01
 3.4538651e-01 4.4997057e-01 3.4667999e-01 3.4401196e-01 4.9192837e-01
 1.9088271e-01 3.3603019e-01 3.3446798e-01 4.1264343e-01 3.0909044e-01
 3.4880143e-01 3.7678492e-01 3.2447207e-01 4.0867671e-01 4.0034789e-01
 4.7193825e-01 3.5777348e-01 4.2580700e-01 4.4477403e-01 4.5488235e-01
 2.9087591e-01 3.9010528e-01 4.4119537e-01 3.4829575e-01 3.6315435e-01
 4.2338330e-01 3.4645972e-01 3.9563140e-01 4.1836619e-01 4.2321262e-01
 3.4329408e-01 3.2619393e-01 3.0549571e-01 2.4133661e-01 3.8392773e-01
 4.3913513e-01 4.4355580e-01 4.0588915e-01 3.7487596e-01 3.6373955e-01
 4.2162061e-01 2.4771139e-01 3.2609627e-01 3.7876779e-01 3.3847398e-01
 3.9226341e-01 2.7729067e-01 2.4735448e-01 3.9900738e-01 3.6881787e-01
 2.4772221e-01 3.0590865e-01 3.0961016e-01 4.3328357e-01 3.0362016e-01
 4.4395706e-01 3.4454554e-01 4.5135158e-01 4.3443042e-01 4.1059428e-01
 3.1307763e-01 2.5829726e-01 3.4560394e-01 3.5206231e-01 3.7892079e-01
 2.8840619e-01 3.8294101e-01 4.0534368e-01 3.3960524e-01 3.5129571e-01
 4.1996670e-01 2.9072613e-01 2.8847694e-01 3.5429528e-01 4.1558394e-01
 3.8073766e-01 3.1914079e-01 4.2772913e-01 2.6561999e-01 3.3851209e-01
 2.4837497e-01 4.5840672e-01 2.8334904e-01 3.8514307e-01 4.1812938e-01
 3.1407014e-01 3.2084942e-01 3.6368001e-01 3.1723827e-01 3.5439008e-01
 3.1255433e-01 4.0569863e-01 2.9877543e-01 4.3235302e-01 3.9014813e-01
 4.4279712e-01 3.3132616e-01 2.7664000e-01 3.6891061e-01 3.5257503e-01
 4.2889762e-01 3.8806182e-01 2.7544850e-01 3.8897869e-01 3.4844160e-01
 3.5897437e-01 3.9471850e-01 3.1496286e-01 3.0469039e-01 4.0525356e-01
 2.7616894e-01 3.7485242e-01 3.1396317e-01 4.0492988e-01 3.8800308e-01
 3.2790658e-01 3.9223698e-01 2.2805470e-01 3.5382685e-01 3.4097412e-01
 4.1826725e-01 2.5486726e-01 5.0522912e-01 4.2132354e-01 3.6562616e-01
 3.1824088e-01 2.8290617e-01 2.9500729e-01 4.3789235e-01 4.1158682e-01
 3.1758201e-01 3.4272081e-01 3.3050740e-01 3.5358211e-01 3.7187028e-01
 3.6520272e-01 3.5793287e-01 3.9363781e-01 3.5011697e-01 3.8824430e-01
 2.8564996e-01 4.1717651e-01 3.5386968e-01 3.9597273e-01 2.7665079e-01
 2.9612318e-01 4.2289975e-01 2.9575342e-01 3.4180892e-01 4.1892049e-01
 2.7806139e-01 3.6280435e-01 3.8787612e-01 4.2947352e-01 3.0698198e-01
 3.9709407e-01 4.1850084e-01 2.8440118e-01 2.8993481e-01 4.1100243e-01
 3.2322544e-01 4.0537870e-01 3.7452465e-01 3.5311794e-01 3.8509017e-01
 3.1867450e-01 4.5821440e-01 3.7558100e-01 4.1134632e-01 3.7946147e-01
 4.8276731e-01 3.6483559e-01 2.9030246e-01 3.7105766e-01 2.6622707e-01
 3.7506852e-01 2.9929191e-01 3.3114165e-01 3.2639912e-01 2.7419406e-01
 3.7952673e-01 3.0732626e-01 2.1844333e-01 4.3234432e-01 3.4193787e-01
 3.6900309e-01 3.4290987e-01 3.3969977e-01 4.2564699e-01 4.0136224e-01
 3.7204796e-01 3.6668447e-01 3.6769342e-01 3.8816044e-01 3.4918910e-01
 3.5928094e-01 3.2055736e-01 3.6541051e-01 4.8399448e-01 3.8686889e-01
 3.8930160e-01 3.2594255e-01 3.1245488e-01 4.1011462e-01 4.2785498e-01
 4.5184433e-01 4.1305992e-01 4.2694366e-01 4.3465024e-01 4.4846225e-01
 4.2720178e-01 4.3815497e-01], shape=(507,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0.], shape=(507,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.13122882, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/car_all_e2_108_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 2 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1
 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2
 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[2.4883177e-13 1.7915275e-08 4.6548381e-14 1.1984627e-19 1.0836185e-06
 6.4710987e-11 1.9351410e-13 1.7997908e-13 7.5944985e-22 3.0567879e-08
 2.0352006e-04 1.9463372e-18 5.7921064e-12 7.0326434e-09 6.4578053e-06
 9.8763131e-13 1.5363080e-08 3.7765985e-10 1.6085276e-01 2.8759000e-23
 1.3576846e-18 2.8396104e-15 3.9098895e-17 5.1994253e-15 5.6513427e-12
 1.1973258e-10 1.2737936e-17 3.0766437e-17 4.0890413e-10 1.5522241e-09
 2.1628461e-08 4.5019384e-13 1.0545918e-08 2.3236689e-01 2.1365580e-01
 2.8376895e-01 4.0309334e-01 2.7811980e-01 3.3066291e-01 3.6603838e-01
 2.6467663e-01 2.9236346e-01 4.4322398e-01 2.8443950e-01 3.4297237e-01
 4.4916475e-01 2.9566514e-01 4.2664576e-01 3.1819746e-01 3.2984397e-01
 2.8531170e-01 3.0792686e-01 2.2381273e-01 2.6356462e-01 2.9264522e-01
 3.9534125e-01 4.1804731e-01 3.4529603e-01 3.2982484e-01 2.8627324e-01
 3.3099461e-01 3.7854883e-01 3.0965209e-01 3.2153296e-01 3.6830789e-01
 3.9672208e-01 4.0917778e-01 3.4592366e-01 3.4536701e-01 4.0379399e-01
 3.9626351e-01 3.2135653e-01 3.0527568e-01 4.0320793e-01 2.6512510e-01
 3.7624604e-01 3.4735593e-01 3.1022260e-01 3.5283461e-01 3.5907042e-01
 3.0082405e-01 3.7066567e-01 3.5625058e-01 3.3056822e-01 3.5428864e-01
 2.5598297e-01 2.9556686e-01 3.8239664e-01 3.7100351e-01 3.0185723e-01
 3.2443041e-01 4.0721524e-01 3.2975826e-01 2.6886100e-01 4.2110229e-01
 2.9575348e-01 3.4716165e-01 3.7209874e-01 4.1862172e-01 3.6879379e-01
 3.2344931e-01 4.8437494e-01 3.9560717e-01 3.9697742e-01 3.2390416e-01
 3.8185513e-01 3.0014044e-01 3.9802200e-01 3.9924651e-01 3.6897177e-01
 3.9922822e-01 3.3391625e-01 3.3887094e-01 3.2973969e-01 4.1621810e-01
 2.6175159e-01 3.1788132e-01 3.7193453e-01 3.8896239e-01 4.0426907e-01
 3.1431323e-01 3.3990753e-01 2.3225573e-01 3.1432199e-01 4.0576124e-01
 4.2145577e-01 2.5245574e-01 2.9558802e-01 3.3790517e-01 3.5428083e-01
 1.2512946e-01 2.9623491e-01 1.5110022e-01 8.0554396e-02 8.8904172e-02
 1.0536435e-01 2.1127105e-01 1.6261560e-01 5.6073576e-02 4.4474584e-01
 4.4103920e-01 4.5634860e-01 4.5516834e-01 4.5599666e-01 4.3155715e-01
 4.4531250e-01 4.5733693e-01 4.0853828e-01 4.3953928e-01 4.4515774e-01
 4.4100505e-01 4.2963600e-01 4.2138830e-01 4.3384439e-01 4.6471936e-01
 4.5280564e-01 4.6237150e-01 4.4672084e-01 4.4775137e-01 4.2597300e-01
 4.5633963e-01 4.5285457e-01 4.6893239e-01 4.4458830e-01 4.4376135e-01
 4.2756438e-01 4.7281170e-01 4.3933535e-01 4.5786089e-01 8.1957877e-03
 9.3512565e-02 1.5480250e-02 4.5955479e-03 3.5309196e-03 8.7232113e-02
 4.4421256e-03 4.7418773e-03 8.2430542e-03 1.9466281e-03 6.1165035e-02
 1.5525219e-01 1.2952298e-02 6.7373008e-02 1.2027690e-01 9.5289946e-04
 3.5499960e-02 1.7957747e-02 3.4868717e-04 3.5423341e-01 3.1835818e-01
 3.8358131e-01 4.0361121e-01 4.0090144e-01 3.0683371e-01 3.7960258e-01
 4.3171990e-01 2.8912830e-01 2.7703142e-01 3.5310343e-01 3.5612103e-01
 3.9885616e-01 3.0927670e-01 3.5319766e-01 3.5888675e-01 3.7088090e-01
 3.0946892e-01 3.0723578e-01 3.8242468e-01 3.2595021e-01 3.9920133e-01], shape=(210,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(210,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.16704275, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/bandec.smt2-0159_000.smt2
true label:[1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1]
true label rank:[2 1 1 2 2 1 2 2 2 1 1 2 2]
predicted label:tf.Tensor(
[0.4486875  0.47382715 0.45293003 0.45167288 0.4691792  0.46168676
 0.45556077 0.47212237 0.45294315 0.46589896 0.46858534 0.4692178
 0.4547702 ], shape=(13,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(13,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.26301312, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0276_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[1.0909447e-37 4.0735831e-28 0.0000000e+00 0.0000000e+00 9.5349301e-17
 2.2727129e-34 0.0000000e+00 4.7593504e-01 4.8175335e-01 3.6571068e-01
 3.6447251e-01 3.6632088e-01 3.8894060e-01 3.7380385e-01 3.7183201e-01
 3.9370543e-01 3.7166685e-01 4.6723109e-01 4.5517451e-01 4.6686661e-01
 4.6156642e-01 4.5475391e-01 4.6349856e-01 4.6352559e-01 4.5746285e-01
 4.5578319e-01 4.6832016e-01 4.6151263e-01 4.6054018e-01 4.6513164e-01
 4.6863139e-01 4.7655350e-01 4.7450081e-01 4.5322821e-01 4.7089002e-01
 4.7296819e-01 4.6197721e-01 4.6818772e-01 4.7031057e-01 4.7511566e-01
 4.7417864e-01 4.6912298e-01 4.7563568e-01 4.8041421e-01 4.8425007e-01
 4.4242439e-01 4.4514021e-01 4.4428146e-01 4.4214913e-01 4.4852823e-01
 4.5302555e-01 4.4766253e-01 4.7315213e-01 4.6754295e-01 4.7002685e-01
 4.7582239e-01 4.6043101e-01 4.7683203e-01 4.6792388e-01 4.7244412e-01
 4.7918844e-01 4.7928852e-01 4.5739812e-01 4.6627846e-01 4.6729487e-01
 4.7047728e-01 4.8733920e-01 4.7531828e-01 4.7328669e-01 4.7934496e-01
 4.8783275e-01 4.8482174e-01 4.8171854e-01 4.4333306e-01 4.3362081e-01
 4.6236280e-01 4.5816880e-01 4.5560730e-01 4.4087905e-01 4.4889462e-01
 4.6610710e-01 4.4918552e-01 4.7456676e-01 4.5639241e-01 4.6963271e-01
 4.6664801e-01 4.6938208e-01 3.8707691e-01 4.3357420e-01 3.7700820e-01
 3.4614328e-01 4.6831048e-01 3.3414459e-01 3.0269113e-01 4.8047122e-01
 3.5260326e-01 3.2669008e-01 3.7717247e-01 4.2517203e-01 3.2404280e-01
 3.2109100e-01 4.0936732e-01 4.0128207e-01 4.0002674e-01 3.5894608e-01
 4.1556877e-01 3.2954377e-01 3.7433255e-01 4.6388894e-01 4.0548643e-01
 3.8772985e-01 4.0445274e-01 3.9413986e-01 3.4479797e-01 4.4677469e-01
 3.2616782e-01 3.9176238e-01 3.5941070e-01 3.3508387e-01 4.1702062e-01
 3.2609582e-01 3.2943934e-01 2.6991051e-01 3.4412631e-01 3.6222807e-01
 3.7822258e-01 3.0199802e-01 2.9018140e-01 3.7968040e-01 4.4014522e-01
 3.6510563e-01 4.3141943e-01 4.3012542e-01 3.6417413e-01 3.7580729e-01
 4.1538388e-01 4.3642405e-01 4.0072295e-01 3.6741602e-01 4.0259224e-01
 4.1524205e-01 3.6772144e-01 4.5024496e-01 3.5174665e-01 3.8796717e-01
 4.5112190e-01 4.0424445e-01 3.3446908e-01 4.3016365e-01 3.7154311e-01
 3.3839393e-01 4.0387094e-01 3.6246365e-01 4.4804353e-01 4.2819256e-01
 3.3333689e-01 4.2522192e-01 2.7800137e-01 3.5990304e-01 2.9747427e-01
 3.6984816e-01 3.8613534e-01 3.8204384e-01 3.3613572e-01 4.1203752e-01
 3.3762497e-01 4.2190623e-01 3.6182028e-01 4.1293728e-01 3.5547590e-01
 4.5549998e-01 3.6880726e-01 3.4996086e-01 3.3265072e-01 4.6399105e-01
 2.8825301e-01 3.2270744e-01 3.4758610e-01 3.5901421e-01 4.1739780e-01
 4.5116192e-01 3.6268115e-01 3.8178802e-01 4.5756844e-01 2.9156706e-01
 4.0098676e-01 4.5075962e-01 3.7494564e-01 3.7489641e-01 4.4356459e-01
 4.3213943e-01 4.4361877e-01 4.7075215e-01 3.6500472e-01 4.6660307e-01
 4.8125583e-01 3.8249505e-01 3.8924691e-01 4.1284394e-01 3.6014295e-01
 3.9522785e-01 3.7806672e-01 3.3819035e-01 4.0145296e-01 4.1473100e-01
 3.7196121e-01 3.9375210e-01 3.9342785e-01 4.1591331e-01 4.1363254e-01
 4.2862943e-01 3.4954435e-01 4.1305822e-01 4.1527760e-01 4.0000647e-01
 4.0429699e-01 4.1207340e-01 3.3414322e-01 4.1820067e-01 4.6869612e-01
 4.2655709e-01 3.6853921e-01 2.5476113e-01 3.1115171e-01 3.9763129e-01
 3.7822217e-01 3.8532048e-01 3.7203667e-01 4.1883412e-01 3.7371072e-01
 4.1763070e-01 3.3565724e-01 3.4467691e-01 3.4571463e-01 3.9981109e-01
 3.2550794e-01 4.0384641e-01 4.0249509e-01 4.2603266e-01 3.6036736e-01
 3.7321100e-01 4.4592679e-01 3.8687554e-01 3.3116898e-01 4.2419916e-01
 3.4904355e-01 3.1686145e-01 3.4784999e-01 3.0073479e-01 3.6706358e-01
 4.1175008e-01 4.1039068e-01 4.7068822e-01 4.2402950e-01 4.0472627e-01
 3.8644558e-01 3.1793910e-01 3.7585074e-01 3.9348656e-01 3.4578091e-01
 4.2455286e-01 3.8826859e-01 3.8606673e-01 3.8165340e-01 4.0129727e-01
 4.0084705e-01 3.3633643e-01 4.2616728e-01 4.4110322e-01 4.4293800e-01
 3.5079330e-01 3.6402994e-01 4.1649455e-01 3.9623612e-01 4.0030694e-01
 3.6084628e-01 4.2286390e-01 4.5982653e-01 4.7294351e-01 4.2009240e-01
 3.0904776e-01 3.9138415e-01 3.4400427e-01 3.7879765e-01 3.4217429e-01
 4.0267700e-01 4.1398972e-01 3.6004308e-01 3.8224664e-01 4.0493351e-01
 3.8798684e-01 3.8961783e-01 3.2653630e-01 3.2873821e-01 3.8871774e-01
 4.0111616e-01 4.5148498e-01 3.5900187e-01 3.8653845e-01 5.0330710e-01
 2.5136691e-01 3.4513718e-01 3.6262566e-01 4.5782065e-01 3.2222164e-01
 3.7406385e-01 4.5119777e-01 3.2218087e-01 3.7490764e-01 4.0002123e-01
 4.0306550e-01 3.7132704e-01 3.9188662e-01 4.0087557e-01 4.7652480e-01
 3.2743588e-01 3.6716339e-01 3.9960840e-01 4.0898532e-01 3.8636512e-01
 3.8408995e-01 3.5927558e-01 3.6551633e-01 3.7742159e-01 4.1559243e-01
 3.6234730e-01 3.8882947e-01 3.3296704e-01 3.0839521e-01 3.9011493e-01
 4.4384986e-01 4.0698102e-01 4.1018897e-01 3.8599446e-01 3.6867547e-01
 4.6750471e-01 2.9780924e-01 3.1769246e-01 4.1418147e-01 2.9545316e-01
 3.9424637e-01 3.4089941e-01 3.6253369e-01 4.2695132e-01 3.8217276e-01
 3.6846653e-01 4.1420963e-01 3.3561510e-01 4.0049466e-01 3.2507440e-01
 4.3393439e-01 4.0651846e-01 4.5303813e-01 4.2584452e-01 4.2312413e-01
 3.6574769e-01 2.9013032e-01 3.9015269e-01 3.7550098e-01 3.9862892e-01
 3.8655397e-01 4.0217933e-01 4.3216309e-01 4.1210318e-01 4.0219924e-01
 4.2234588e-01 3.7170917e-01 3.1909239e-01 3.4210789e-01 4.2055097e-01
 3.8222772e-01 3.4155977e-01 4.2306268e-01 3.1898236e-01 3.7235987e-01
 3.0090487e-01 4.4525018e-01 2.5862271e-01 3.8338840e-01 4.1861308e-01
 3.3262011e-01 3.9161831e-01 3.7863064e-01 3.8447693e-01 3.9317840e-01
 3.2945937e-01 4.3585336e-01 3.7290373e-01 4.4729549e-01 4.7746590e-01
 4.2063165e-01 4.0108612e-01 3.4764102e-01 3.9527902e-01 3.7357241e-01
 4.1204870e-01 4.3134153e-01 2.9927748e-01 3.9285070e-01 3.4807587e-01
 3.8582513e-01 4.5530179e-01 3.2503325e-01 3.9113528e-01 3.8621733e-01
 3.2548440e-01 4.2125204e-01 3.3130720e-01 4.2327711e-01 3.7479055e-01
 4.0019646e-01 4.1731822e-01 3.3144331e-01 4.1241944e-01 2.8999817e-01
 4.1276532e-01 3.5842237e-01 4.3055218e-01 3.7120467e-01 3.8786775e-01
 4.1020373e-01 3.6783305e-01 3.5246676e-01 4.1989255e-01 4.1127202e-01
 4.0279576e-01 3.2738805e-01 4.2291704e-01 4.0049210e-01 3.9276385e-01
 4.4189274e-01 4.1355842e-01 4.5477360e-01 4.1422051e-01 4.5273006e-01
 3.3876249e-01 4.5146659e-01 3.4215832e-01 3.7495047e-01 3.1131333e-01
 3.3362034e-01 3.9683667e-01 3.6385021e-01 3.8758379e-01 3.9155748e-01
 3.1115857e-01 3.5260516e-01 4.0264261e-01 4.1567713e-01 3.8281655e-01
 3.5028362e-01 3.7278342e-01 3.1028983e-01 3.5880274e-01 4.2239428e-01
 3.5186240e-01 3.9178753e-01 4.2627826e-01 3.3984932e-01 3.8983265e-01
 3.8901174e-01 3.9217949e-01 3.3414450e-01 4.3873134e-01 3.9749563e-01
 4.0246332e-01 3.8182312e-01 2.9129732e-01 3.8477537e-01 3.6362165e-01
 3.7520117e-01 3.6967149e-01 3.8139144e-01 3.9800498e-01 3.5392460e-01
 4.3933779e-01 4.0197954e-01 2.7094638e-01 4.2728758e-01 3.1426102e-01
 3.9091641e-01 4.1300631e-01 3.8111663e-01 4.1450894e-01 4.2716244e-01
 4.2933455e-01 3.9480871e-01 3.3371723e-01 3.7086695e-01 3.9635193e-01
 3.6916107e-01 3.6478621e-01 4.0991783e-01 3.8317657e-01 3.9667434e-01
 4.1131413e-01 3.6160177e-01 3.5927454e-01 4.4755873e-01 3.5320282e-01
 3.9044607e-01 3.5845822e-01 4.2495817e-01 3.6894333e-01 3.9173332e-01
 3.6836499e-01 3.9914158e-01 4.7298455e-01 4.7279155e-01 4.7878227e-01
 4.8754257e-01 4.7372559e-01 4.7903854e-01 4.7211766e-01], shape=(514,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(514,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.15760322, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/hysteresis_2_000.smt2
true label:[0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]
true label rank:[1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 1 1 2]
predicted label:tf.Tensor(
[1.0397959e-11 1.0804928e-06 2.3484110e-11 1.0303718e-13 6.3546372e-06
 7.9905839e-12 1.2089056e-09 1.4466168e-09 4.6495071e-17 2.8628447e-06
 9.9945068e-04 4.3656391e-11 1.1572460e-09 6.1830310e-06 7.8174699e-06
 1.5046924e-02 1.9117853e-01 4.9951315e-02 2.9124087e-01 1.0001063e-03
 6.5897107e-03 1.2163401e-02 7.2400868e-03 2.2479028e-02 4.5953131e-01
 4.4639033e-01 4.5951182e-01 4.5001096e-01 2.9279298e-01 4.5766100e-01
 3.4424543e-01 3.3402020e-01 3.8067251e-01 3.3693534e-01 2.6809800e-01
 3.7140483e-01 3.8714874e-01 3.3654362e-01 3.5562035e-01 4.2080331e-01], shape=(40,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(40,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1]
mse:tf.Tensor(0.16950357, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/rotation_vc.correct.1.nts_000.smt2
true label:[0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1]
true label rank:[1 2 2 1 2 2 2 1 2 2 2 1 2 2 1 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2
 1 2 2 1 2 2 1 2 2 1 2 2 2 1 2 2 1 2 1 2 2 1 2 1 2 2 1 1 2 2 1 2 2 1 2 2 1
 2 2 1 2 2]
predicted label:tf.Tensor(
[0.19997406 0.33828524 0.1546565  0.20463067 0.28236687 0.13267097
 0.16056925 0.4478328  0.4566235  0.45375556 0.45144805 0.45343757
 0.460803   0.4651793  0.45280537 0.46770716 0.4687211  0.4572912
 0.45156842 0.44032705 0.4246076  0.4036065  0.40218925 0.43448144
 0.40613985 0.44380364 0.44650257 0.388359   0.4118941  0.44775262
 0.44859317 0.3915055  0.40204778 0.41619617 0.3692075  0.3868882
 0.42153472 0.4504924  0.4513185  0.46130365 0.42451963 0.45647958
 0.4667152  0.4177231  0.44207418 0.47172368 0.38762134 0.45637548
 0.3904822  0.40433055 0.45690817 0.4722406  0.4556465  0.47691834
 0.46220013 0.4495337  0.44416422 0.45113498 0.44740883 0.44387218
 0.4305844  0.45538816 0.40249938 0.41512674 0.45575634 0.45247424
 0.44802368 0.3970555  0.40196723 0.44652957 0.39544958 0.36643332
 0.39027512 0.4632482  0.46671844 0.46277767 0.43892702 0.4715069
 0.4720167 ], shape=(79,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0.], shape=(79,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1]
mse:tf.Tensor(0.2719306, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/nest-len.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[6.1886107e-10 1.9945939e-05 2.4483504e-11 1.4352962e-09 6.2387799e-06
 2.8554183e-09 8.7689211e-10 1.5992108e-09 1.1617220e-13], shape=(9,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(9,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(4.8529205e-11, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0303_000.smt2
true label:[0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1]
true label rank:[1 2 1 ... 2 2 2]
predicted label:tf.Tensor([0.36805958 0.34380078 0.354821   ... 0.40964547 0.48636976 0.48165086], shape=(1640,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(1640,), dtype=float32)
predicted label rank:[1 1 1 ... 1 1 1]
mse:tf.Tensor(0.28682405, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/MOESI_2_e3_1523_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1
 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[4.77271627e-08 2.88467527e-05 4.21141699e-08 9.86277904e-09
 2.01255083e-04 5.37838432e-08 9.70651914e-09 3.09511599e-08
 5.50763289e-11 4.78744507e-04 1.03425980e-03 1.84343936e-08
 4.19895912e-07 1.53261423e-03 1.34262443e-03 1.06864064e-07
 3.18083257e-05 8.36717300e-06 3.82126600e-01 5.62093883e-13
 4.83471874e-11 8.48181803e-10 3.20257421e-09 1.56070961e-08
 2.26640041e-05 1.34872323e-07 4.85164200e-11 3.06728559e-10
 4.51171045e-10 4.09795075e-06 2.51172860e-05 2.70845590e-06
 2.35143016e-05 1.37067746e-05 3.04504910e-09 6.94703340e-05
 1.74534321e-03 2.94633598e-08 5.53751704e-07 7.06876218e-02
 8.99445463e-10 6.86662815e-07 1.86264515e-04 1.72053817e-07
 1.70635616e-07 3.14646959e-03 1.32436184e-09 3.79174948e-04
 3.70436028e-05 1.86145306e-04 7.96240496e-09 1.44557144e-09
 1.16098509e-08 8.46032480e-11 1.53497413e-13 3.68374676e-01
 3.43948364e-01 3.21783662e-01 3.58141661e-01 3.28369111e-01
 3.34239215e-01 3.34648758e-01 3.25107515e-01 2.98452973e-01
 3.05715859e-01 3.52737546e-01 3.17298889e-01 3.60067427e-01
 3.16914111e-01 3.56600910e-01 3.02120149e-01 3.12984556e-01
 3.25264037e-01 3.25891376e-01 3.30202788e-01 3.15725625e-01
 3.03456128e-01 3.64056408e-01 3.21351647e-01 3.07397604e-01
 3.54679942e-01 3.17358792e-01 3.23614299e-01 3.39034617e-01
 3.40985626e-01 3.21571469e-01 3.46857786e-01 3.09870005e-01
 3.53313565e-01 2.96528578e-01 3.29482317e-01 3.68819773e-01
 3.13060671e-01 4.45239276e-01 4.36114818e-01 4.44938123e-01
 4.36467469e-01 4.22015458e-01 4.42926407e-01 4.40279126e-01
 4.33410108e-01 4.32455122e-01 4.36869085e-01 4.43976581e-01
 4.34714645e-01 4.29626793e-01 4.32221860e-01 4.32825834e-01
 4.30627584e-01 4.49127376e-01 4.37267065e-01 4.27926183e-01
 4.21845824e-01 4.25037146e-01 4.40140635e-01 4.36435044e-01
 4.21143591e-01 4.14346874e-01 4.22420114e-01 4.30736542e-01
 4.18871522e-01 4.20121014e-01 4.17010486e-01 4.02343929e-01
 4.11726177e-01 4.12768066e-01 4.22450364e-01 4.14519757e-01
 4.22785252e-01 1.73164785e-01 2.05859900e-01 3.40756118e-01
 1.87080681e-01 1.32242709e-01 8.92710686e-02 1.09249771e-01
 1.84196621e-01 1.89290702e-01 6.73435330e-02 7.14026690e-02
 3.40350211e-01 4.68322009e-01 4.73366499e-01 4.57710296e-01
 4.71030921e-01 4.67673272e-01 4.69045758e-01 4.66023505e-01
 4.62670654e-01 4.76260692e-01 4.74815339e-01 4.82570499e-01
 4.74334568e-01 4.75007206e-01 4.71678466e-01 4.72777724e-01
 4.76444691e-01 4.79590565e-01 4.72009778e-01 4.66352344e-01
 4.73290712e-01 4.81150955e-01 4.79383290e-01 4.80270565e-01
 4.71373141e-01 4.67339545e-01 4.61224347e-01 4.69401151e-01
 4.68522251e-01 4.61656064e-01 4.61270183e-01 4.70213920e-01
 4.75809693e-01 4.69479263e-01 4.68141019e-01 4.74543810e-01
 4.59406525e-01 4.63142872e-01 4.53757405e-01 4.64175642e-01
 4.65907693e-01 4.62846935e-01 4.68346477e-01 4.74269301e-01
 4.52526540e-01 4.61236149e-01 4.78496403e-01 4.87886727e-01
 4.77628440e-01 4.75135803e-01 4.80505019e-01 4.86507118e-01
 4.73616093e-01 4.25249606e-01 4.51772004e-01 4.66697335e-01
 4.43647742e-01 4.33288544e-01 4.64920551e-01 4.46766734e-01
 4.47116256e-01 4.42925721e-01 4.40940261e-01 4.59359407e-01
 4.58018839e-01 4.46317732e-01 4.56876993e-01 4.16368723e-01
 4.13846344e-01 4.10279155e-01 4.21372950e-01 4.34514284e-01
 4.23538685e-01 4.30925906e-01 4.10642117e-01 4.14159924e-01
 4.14443552e-01 4.23362315e-01 4.22428668e-01 4.15099084e-01
 4.27002907e-01 4.26784158e-01 4.21296597e-01 4.28170919e-01
 4.09421593e-01 4.20713782e-01 4.22572613e-01 4.16805148e-01
 4.21498150e-01 4.23763037e-01 4.22031939e-01 4.18328434e-01
 4.22354639e-01 4.12833810e-01 4.28121924e-01 4.25324380e-01
 4.06135529e-01 4.16847646e-01 4.24311191e-01 4.20985699e-01
 4.23654884e-01 4.20007467e-01 4.21016693e-01 4.12668288e-01
 4.19184595e-01 4.31201488e-01 4.33575809e-01 4.31658328e-01
 4.31333750e-01 4.74265575e-01 4.38022852e-01 4.46604908e-01
 4.50748116e-01 4.43305671e-01 4.56128687e-01 4.43817794e-01
 4.24860239e-01 4.41094398e-01 4.31869656e-01 4.34808552e-01
 4.63958025e-01 4.47007924e-01 4.39289510e-01 4.52201366e-01
 4.43985373e-01 4.55775052e-01 4.45287317e-01 4.52495366e-01
 4.26365912e-01 3.93949628e-01 3.88626277e-01 3.60297203e-01
 4.07191664e-01 4.06289935e-01 4.02336836e-01 3.32074791e-01
 3.99635017e-01 3.87395978e-01 4.36619490e-01 3.84675026e-01
 3.78669500e-01 4.03226823e-01 3.90668303e-01 3.61921728e-01
 3.54446709e-01 4.04443413e-01 3.73752832e-01 3.84856820e-01
 3.90297502e-01 4.00048196e-01 4.01042044e-01 4.27381277e-01
 4.01499540e-01 4.01857048e-01 4.18164045e-01 4.13375705e-01
 4.24429387e-01 4.11000878e-01 4.09703851e-01 4.05708849e-01
 4.04686660e-01 4.17918265e-01 4.22613382e-01 4.08321351e-01
 4.20423925e-01 4.19128001e-01 4.15144265e-01 4.12211508e-01
 4.22513127e-01 4.07020748e-01 4.12640452e-01 4.26075399e-01
 4.05921459e-01 4.05827582e-01 4.12791818e-01 4.07476962e-01
 4.16977555e-01 4.11080480e-01 4.20413256e-01 4.19587791e-01
 4.09214646e-01 4.58670825e-01 4.64927793e-01 4.48951602e-01
 4.71832007e-01 4.59753394e-01 4.51288104e-01 4.53184545e-01
 4.59685922e-01 4.54610467e-01 4.58486497e-01 4.56601292e-01
 4.60056126e-01 4.61970747e-01 4.67109203e-01 4.47426647e-01
 4.59017038e-01 4.56027687e-01 4.61589962e-01 4.44249630e-01
 4.49906260e-01 4.32119906e-01 4.65949297e-01 4.50628817e-01
 4.63582844e-01 4.63005215e-01 4.63749886e-01 4.60684270e-01
 4.15001035e-01 3.93148690e-01 4.03994024e-01 4.11655396e-01
 4.23972428e-01 4.12582964e-01 4.13211316e-01 4.06917751e-01
 4.00661558e-01 4.12044853e-01 4.37589735e-01 4.13809299e-01
 3.93045843e-01 4.11005616e-01 4.08156723e-01 4.18853164e-01
 4.09140855e-01 4.29090530e-01 4.02702272e-01 4.21618134e-01
 4.09198165e-01 4.20798659e-01 4.13239270e-01 4.16104585e-01
 4.31481898e-01 4.17590827e-01 3.99479032e-01 4.12091136e-01
 4.09439147e-01 4.17502582e-01 4.15810525e-01 4.08208311e-01
 4.12712812e-01 4.22302961e-01 4.36607122e-01 4.13839519e-01
 4.11771238e-01 4.21184719e-01 4.19630736e-01 4.26346362e-01
 4.19628561e-01 4.02437389e-01 4.29083347e-01 4.32488978e-01
 4.27780777e-01 4.08480644e-01 4.02250707e-01 4.15481329e-01
 4.21789378e-01 4.20351803e-01 4.17135596e-01 4.25511390e-01
 4.14350033e-01 4.09926593e-01 4.04271841e-01 3.95194709e-01
 3.54501426e-01 3.32187712e-01 3.84195805e-01 3.72551560e-01
 3.45057189e-01 3.80030483e-01 3.71170461e-01 3.42254549e-01
 3.62749577e-01 3.83220464e-01 3.58324766e-01 3.72733891e-01
 3.25138509e-01 3.81122410e-01 3.51656646e-01 3.42383921e-01
 3.60416532e-01 3.64784539e-01 4.07547057e-01 3.89055669e-01
 3.67949218e-01 3.33460182e-01 3.84986699e-01 3.68063748e-01
 3.44806463e-01 3.76576483e-01 3.77563298e-01 3.72780800e-01
 3.54442060e-01 3.90419275e-01 3.68824244e-01 3.41196775e-01
 3.45636904e-01 3.20890009e-01 3.77520710e-01 4.15058464e-01
 3.69179726e-01 1.76502019e-01 6.01775944e-02 9.86167490e-02
 1.96514964e-01 7.49331713e-03 9.04181600e-02 2.16408521e-01
 2.77755171e-01 4.61702645e-02 2.08774954e-01 1.49286151e-01
 8.20499659e-03 7.21201301e-03 1.44959003e-01 2.65443921e-02
 5.61984777e-02 7.42765069e-02 4.87838387e-02 7.64714479e-02
 2.61759758e-02 3.30393344e-01 8.28880072e-02 1.84421182e-01
 1.19113117e-01 2.45878756e-01 1.10377491e-01 4.64535356e-02
 4.57321405e-02 1.88761652e-02 3.46002877e-02 4.54156101e-02
 1.16287172e-01 6.77717626e-02 2.75075734e-02 1.31515890e-01
 5.47332764e-02 4.86189127e-03 1.63972199e-01 3.18538845e-02
 2.73759067e-02 1.48578137e-01 6.48911595e-02 4.51685578e-01
 4.55852777e-01 4.25530255e-01 4.28218544e-01 4.50858086e-01
 4.47460622e-01 4.45938826e-01 4.50609297e-01 4.10107940e-01
 4.54726130e-01 4.74821478e-01 4.48408663e-01 4.52387452e-01
 4.61191595e-01 4.36690390e-01 4.30830538e-01 4.03218001e-01
 4.59053546e-01 3.87882560e-01 4.58235711e-01 4.33884382e-01
 4.27694678e-01 4.36771095e-01 4.46393132e-01 3.67815077e-01
 3.94138336e-01 4.38570857e-01 4.68115628e-01 4.08664674e-01
 4.50460196e-01 3.78246963e-01 4.61573124e-01 4.09486473e-01
 4.30731177e-01 3.99030983e-01 4.21004355e-01 3.97395670e-01
 3.94242913e-01 4.05585915e-01 3.97505015e-01 4.06469733e-01
 4.14073467e-01 3.93552452e-01 3.91175389e-01 4.08185422e-01
 3.82394612e-01 4.09547240e-01 4.08977628e-01 4.14355338e-01
 4.04389232e-01 3.91144156e-01 4.02188957e-01 3.88968885e-01
 3.92713308e-01 3.89483660e-01 3.92726302e-01 3.86545986e-01
 4.10723627e-01 3.94317806e-01 3.90563488e-01 3.88537765e-01
 4.05466437e-01 4.11486149e-01 4.08193827e-01 4.01187748e-01
 4.11302328e-01 3.98264498e-01 4.05416012e-01 4.01079983e-01
 4.08923268e-01 3.92693877e-01 4.05599087e-01 3.98890883e-01
 4.36477959e-01 4.45410490e-01 4.37024534e-01 4.47363615e-01
 4.31729376e-01 4.32840765e-01 4.17301744e-01 4.40901786e-01
 4.28488642e-01 4.44797933e-01 4.34371889e-01 4.37350988e-01
 4.40236628e-01 4.23423529e-01 4.32874441e-01 4.40287441e-01
 4.49238956e-01 4.37933981e-01 4.39907283e-01 4.42348868e-01
 4.43060130e-01 4.38751400e-01 4.27230924e-01 4.25937384e-01
 4.35909063e-01 4.47974235e-01 4.44140047e-01 4.54459995e-01
 4.33811307e-01 4.25765842e-01 4.48996991e-01 4.47046250e-01
 4.38288838e-01 4.40304667e-01 4.49503422e-01 4.28400338e-01
 4.39976633e-01 4.07378405e-01 3.99544716e-01 4.11873370e-01
 3.97418082e-01 4.07982767e-01 4.07492727e-01 4.01324242e-01
 4.00799930e-01 4.04515624e-01 3.97270352e-01 3.92782867e-01
 4.11093265e-01 4.04683918e-01 3.92232418e-01 3.84181112e-01
 4.01487470e-01 4.02462065e-01 4.11155611e-01 3.97540122e-01
 4.05683190e-01 4.06186908e-01 4.13480192e-01 4.00283515e-01
 3.91675770e-01 4.04874265e-01 4.02058393e-01 4.03268933e-01
 4.10131693e-01 3.89804631e-01 3.99930805e-01 4.05513227e-01
 3.95225883e-01 4.04466122e-01 3.96672785e-01 4.12128568e-01
 4.01203275e-01 4.04949903e-01 4.07043695e-01 4.09766465e-01
 4.08377647e-01 4.08489943e-01 4.03252184e-01 3.79018813e-01
 4.04320449e-01 3.72315109e-01 3.91766906e-01 4.11290377e-01
 3.97463202e-01 3.94032568e-01 3.92021447e-01 3.89681280e-01
 3.94360542e-01 4.03225034e-01 3.88458818e-01 3.86988759e-01
 4.01668429e-01 3.78172010e-01 3.73878330e-01 3.72179121e-01
 3.79786402e-01 3.97696406e-01 4.08185393e-01 4.06503916e-01
 3.90846312e-01 3.91162306e-01 3.89333457e-01 3.97367507e-01
 3.96498173e-01 3.68040204e-01 3.88542533e-01 3.89474213e-01
 4.09414947e-01 3.82183552e-01 3.68352652e-01 3.99658054e-01
 3.91865373e-01 3.89492452e-01 3.93011004e-01 3.77953678e-01
 3.98040295e-01 4.04033750e-01 3.99463922e-01], shape=(675,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0.], shape=(675,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.14844939, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0065_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.4634835  0.46997312 0.4681779  0.47711197 0.45003864 0.44687125
 0.44682333 0.45778075 0.45646468 0.47281873 0.4722488  0.47653535
 0.47715276 0.46761727], shape=(14,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(14,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.2158803, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/four1.smt2-0033_000.smt2
true label:[1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]
true label rank:[2 1 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2]
predicted label:tf.Tensor(
[0.46906838 0.47491184 0.4713197  0.47779912 0.4165196  0.42282382
 0.41276777 0.40777436 0.4126324  0.41625628 0.40548277 0.41985518
 0.4134254  0.42015827 0.42442295 0.4074272  0.42645612 0.42413545
 0.42820022 0.41090614], shape=(20,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.21582308, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/NetBSD_g_Ctoc.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[1.5047235e-08 1.3588575e-06 2.7992018e-09 5.7640204e-10 8.8887009e-06
 9.7678210e-10 1.5150875e-09 3.5475916e-09 5.2066780e-12 4.2677257e-06], shape=(10,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(10,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(9.9069225e-12, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/seesaw.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[2.9787103e-10 2.0451780e-07 2.4415000e-11 1.0317165e-10 2.6099320e-07
 2.1991090e-10 1.3365872e-07 9.0184010e-10], shape=(8,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0.], shape=(8,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1]
mse:tf.Tensor(1.5976324e-14, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/gj2007_m_3_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.46595585 0.47491923 0.47595593 0.46880236 0.47001895 0.45220393
 0.4625507  0.47308436 0.4677664  0.4793324  0.47215512 0.44657236
 0.46715307 0.46860692 0.4632778  0.4501139  0.46077272 0.4760296
 0.46491808 0.45393026], shape=(20,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.2855497, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/apache-get-tag.i.p+nlh-reducer.c-1_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.4327705  0.42712367 0.39713323 0.45175242 0.46126664 0.45463768
 0.2593742  0.33120626 0.46453676 0.45722616], shape=(10,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(10,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.347875, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/PRODUCER_CONSUMER_all_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2
 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1 1 1 1 1 1 2 2 1
 1 1 2 2 2 2 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 2 1 2 2 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[1.02388859e-03 8.64723325e-03 1.27041340e-03 8.52847099e-03
 1.78476870e-02 1.89048052e-03 2.35199928e-04 5.90369105e-03
 2.25093961e-03 1.60165995e-01 1.00062579e-01 1.39108300e-03
 3.22490931e-02 1.20391160e-01 7.32204020e-02 3.61856818e-03
 4.28719819e-02 1.57593489e-02 1.28748327e-01 5.78139880e-05
 1.13010406e-03 7.26521015e-04 2.66671181e-04 1.12572312e-03
 2.57478654e-02 8.34465027e-04 3.06728393e-01 2.14639038e-01
 2.51504093e-01 3.95512670e-01 2.91125596e-01 3.15277338e-01
 2.99831212e-01 2.65757620e-01 2.04864532e-01 3.43138069e-01
 2.90248513e-01 2.78365076e-01 3.47888947e-01 4.35507745e-01
 1.31557316e-01 2.66161084e-01 3.40147555e-01 2.72300959e-01
 2.57247955e-01 4.42209601e-01 1.46009743e-01 3.60665262e-01
 2.16094553e-01 2.41589159e-01 3.47603112e-01 1.87314630e-01
 1.06441945e-01 1.90724909e-01 1.56676620e-01 1.89116418e-01
 3.13564450e-01 1.12137556e-01 1.28274232e-01 1.48407221e-01
 3.72931063e-01 4.15779948e-01 3.05418849e-01 2.77073979e-01
 3.72041106e-01 3.97302091e-01 4.11890268e-01 3.76746625e-01
 3.36232841e-01 3.66477311e-01 3.59231532e-01 3.19538534e-01
 3.61524820e-01 3.04969966e-01 2.37890869e-01 3.52389276e-01
 4.67692524e-01 4.73646760e-01 4.69067752e-01 4.72342461e-01
 4.69958037e-01 4.67849761e-01 4.69405621e-01 4.70277309e-01
 4.60273296e-01 4.71373826e-01 4.62060124e-01 4.40338969e-01
 4.41389889e-01 4.44120079e-01 4.41564083e-01 4.38891232e-01
 4.40180540e-01 4.38786149e-01 4.44664359e-01 4.42173749e-01
 4.42663878e-01 4.41592455e-01 4.01902080e-01 4.32864636e-01
 3.80987763e-01 4.40270126e-01 4.30647701e-01 4.39135492e-01
 4.07806993e-01 4.24638063e-01 4.42028165e-01 4.15930092e-01
 4.31288600e-01 4.80196714e-01 4.07234371e-01 4.26903397e-01
 4.28896785e-01 3.42399955e-01 4.38605100e-01 3.60186011e-01
 3.11006665e-01 3.52235049e-01 3.87452364e-01 3.75623792e-01
 4.14144456e-01 3.74734640e-01 4.03933555e-01 4.30796534e-01
 4.27174538e-01 3.63078684e-01 4.13488537e-01 4.52016473e-01
 4.12955463e-01 4.61548090e-01 4.41829681e-01 4.56233025e-01
 4.51935649e-01 4.34461325e-01 4.63906169e-01 4.58438069e-01
 4.31553364e-01 4.34303701e-01 4.16509002e-01 4.59447265e-01
 4.39448059e-01 4.16553289e-01 4.50901955e-01 4.61807996e-01
 4.61082608e-01 4.54551339e-01 4.39316034e-01 1.92617623e-11
 2.17693960e-05 1.23262164e-10 7.49911289e-17 6.80498583e-12
 1.44436376e-06 3.22720484e-06 1.11007164e-13 3.62532337e-10
 1.51139996e-15 8.68098482e-07 8.70582369e-07 1.30358198e-11
 2.39699602e-07 6.84746169e-07 7.89756918e-15 7.77928051e-08
 2.07275996e-09 4.21215457e-20 1.81296677e-12], shape=(167,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(167,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.20560202, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/dillig01.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.03080818 0.0490565  0.0707587  0.04760617 0.21082208 0.05468318
 0.03072849 0.04921466], shape=(8,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0.], shape=(8,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.007678918, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0140_000.smt2
true label:[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0]
true label rank:[1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 2 2 1 1 2 2 1 2 2
 1 1 2 2 1 1 2 2 1 1 2 2 1 1 2 2 1]
predicted label:tf.Tensor(
[0.44400632 0.4619097  0.46931112 0.42572814 0.43600678 0.4131105
 0.40942997 0.4250425  0.43396682 0.44756114 0.42579865 0.41899702
 0.44906938 0.4387909  0.45308855 0.4187938  0.42748773 0.43674538
 0.42237076 0.4031573  0.45326045 0.4500166  0.45456418 0.45947033
 0.45815262 0.45823348 0.4594304  0.4564542  0.46313113 0.4575323
 0.48209387 0.476481   0.4818994  0.47706988 0.40288225 0.44087827
 0.46754873 0.45116815 0.4743506  0.47246122 0.47695747 0.48248297
 0.46518117 0.47431207 0.46613416 0.47760305 0.46774814 0.4569003
 0.4577702  0.47289076 0.46717462 0.4733022  0.46745715 0.46616715], shape=(54,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.], shape=(54,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.24753495, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/metros_4_e3_1091_e2_1317_000.smt2
true label:[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]
true label rank:[1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 2 1 1 1 2 2
 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 2 2 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 2 1
 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1
 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1
 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1
 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1
 1 1 2 1 1 1 1 1 2 1 1 1 1 1 2 1 1]
predicted label:tf.Tensor(
[0.14792252 0.17956379 0.11988598 0.16454509 0.22902727 0.13037255
 0.122008   0.2675294  0.14130253 0.37454516 0.37835935 0.12333232
 0.29117513 0.34106156 0.31672317 0.20027253 0.23809004 0.361341
 0.5094723  0.08106172 0.09039733 0.19028178 0.12359688 0.10393259
 0.26470378 0.09781966 0.216153   0.06852463 0.13805315 0.23866552
 0.22038543 0.17376027 0.16406754 0.1712965  0.08931348 0.20270538
 0.28471363 0.15823302 0.17308378 0.4374605  0.16393948 0.19587034
 0.40916935 0.15321818 0.3816424  0.397981   0.39692727 0.39413768
 0.36843318 0.37287214 0.37878126 0.37987962 0.36102986 0.37801376
 0.35688502 0.35987568 0.3685684  0.35081667 0.38527873 0.37617928
 0.35509455 0.3801767  0.34761423 0.3085697  0.33897406 0.37308243
 0.3719319  0.37569827 0.38599908 0.38745192 0.37801176 0.4117377
 0.40986052 0.41599604 0.40995294 0.39947903 0.39801407 0.41800117
 0.38389352 0.4002017  0.41635543 0.39125866 0.4090017  0.421777
 0.3851149  0.40238178 0.40643287 0.42013952 0.4347436  0.3885758
 0.38516614 0.4127803  0.42215416 0.4233419  0.40888643 0.42891812
 0.3972128  0.41246378 0.39529067 0.33760136 0.26834804 0.4532174
 0.38679487 0.37329817 0.35437799 0.3670983  0.25782186 0.34116954
 0.41216022 0.32391512 0.35157877 0.31441528 0.33760887 0.31985193
 0.41719744 0.27477646 0.27984196 0.30543575 0.31448722 0.3648498
 0.33257347 0.35712045 0.29596084 0.28906527 0.38945422 0.3897211
 0.33159682 0.33793443 0.3120258  0.41795984 0.36679137 0.4138179
 0.34371346 0.37227154 0.34576458 0.3437972  0.35337007 0.3250587
 0.30617943 0.3388999  0.39249104 0.4074954  0.43281046 0.36701506
 0.4146992  0.4139509  0.42266676 0.3418677  0.38075596 0.33044374
 0.30915707 0.31451252 0.2614687  0.37699965 0.36544293 0.3231038
 0.36568958 0.29524547 0.28022236 0.24980599 0.26774368 0.3914209
 0.37661383 0.26006752 0.28087407 0.31103164 0.40514922 0.35648456
 0.3637855  0.3487628  0.3941374  0.3639186  0.34786463 0.30948597
 0.42656487 0.28623807 0.31167108 0.32724902 0.2964366  0.39523137
 0.4366459  0.39414856 0.3859262  0.40713742 0.22946465 0.3077992
 0.41650334 0.28818393 0.36698776 0.33774304 0.3133769  0.41868198
 0.42313161 0.31419444 0.3143975  0.40465394 0.13270539 0.20921919
 0.20545945 0.24894479 0.34620738 0.18933156 0.20733526 0.3508622
 0.08451474 0.2050694  0.16335052 0.37286055 0.26467645 0.25054848
 0.38200384 0.38731536 0.37785512 0.40661827 0.39785516 0.41840163
 0.33814728 0.35689175 0.44295293 0.45739755 0.4272551  0.39721316
 0.34117424 0.3189965  0.3643793  0.42065093 0.3158338  0.39838076
 0.4479409  0.45751646 0.44480437 0.41529894 0.4537065  0.39750272
 0.4531439  0.44431674 0.40165794 0.4678384  0.4699619  0.43483505
 0.4600031  0.43985695 0.45808735 0.40534544 0.427837   0.42306614
 0.41161656 0.45782092 0.4212584  0.4691312  0.44773018 0.4543073
 0.47019917 0.4431376  0.4163421  0.39824304 0.3667112  0.38283306
 0.40989327 0.39240715 0.46599138 0.43222046 0.3763982  0.41571337
 0.41778332 0.41093338 0.389444   0.40378642 0.39422372 0.41428244
 0.39916548 0.41248822 0.39791223 0.40891066 0.4293918  0.40241468
 0.44826233 0.4154598  0.4406267  0.3972077  0.39690226 0.39796034
 0.43238407 0.41563988 0.16839352 0.30476326 0.30446395 0.24432781
 0.33353734 0.31202176 0.2391021  0.39730513 0.19778529 0.19573852
 0.27443647 0.20989105 0.42266893 0.19349495 0.19120577 0.4952284
 0.11922672 0.17568868 0.28929693 0.48146445 0.43754598 0.4389977
 0.47833523 0.45808625 0.45564193 0.44412935 0.47009966 0.44163907
 0.46534985 0.44437975 0.44041756 0.4226194  0.42479786 0.45610255
 0.4231203  0.46104127 0.44784302 0.45944518 0.43345493 0.42710114
 0.42845997 0.4335723  0.42536378 0.4306933  0.42051858 0.42987472
 0.42740136 0.43257362 0.43057734 0.42020902 0.421311   0.42146692
 0.4249029  0.42059165 0.4175306  0.42559087 0.41679403 0.4292129
 0.44961315 0.4438344  0.39804998 0.45357114 0.42595762 0.45324695
 0.42320198 0.4469874  0.43967852 0.4138568  0.43554813 0.44634104
 0.46309352 0.38802707 0.45009995 0.45057005 0.41063094 0.4609048
 0.44945756 0.4213215  0.45402157 0.44543302 0.45969412 0.45427394
 0.45385918 0.4068225  0.41398472 0.39886627 0.4247374  0.4354344
 0.4137203  0.3857334  0.40840068 0.39131042 0.4173404  0.40649337
 0.38436797 0.40534878 0.40979546 0.38303137 0.42674407 0.38939556
 0.40120405 0.41816723 0.4271585  0.4053983  0.37504104 0.39977407
 0.38416848 0.42350823 0.39788967 0.4331236  0.37948623 0.4468485
 0.43328014 0.3717978  0.44449952 0.38627824 0.39871693 0.44917676
 0.44126028 0.40164533 0.4233431  0.412995   0.42354968 0.4188664
 0.40483046 0.413113   0.41232154 0.408597   0.40796226 0.36440572
 0.4137727  0.2724372  0.38479406 0.37683707 0.35311747 0.36884838
 0.40577155 0.36521888 0.40525967 0.39365524 0.3494519  0.3949809
 0.39160842 0.3274603  0.37331337 0.39372814 0.30873337 0.4230559
 0.37575442 0.33951712 0.36904442 0.41996175 0.3295625  0.3455302
 0.3798221  0.34959036 0.32084724 0.3800264  0.41803074 0.4301551
 0.42905262 0.42528245 0.41327307 0.41194522 0.42812687 0.41639248
 0.43498534 0.40989658 0.43667448 0.4401616  0.43914625 0.40094763
 0.40803054 0.41798413 0.43519408 0.4104582  0.41906667 0.43630424
 0.42493674 0.43546942 0.40599433 0.42042738 0.40948552 0.47114366
 0.43910348 0.42014307 0.47292605 0.45856422 0.44374162 0.46699077
 0.46449164 0.42809343 0.44740006 0.42195886 0.4664596  0.39552
 0.4490915  0.41309217 0.43890318 0.4264326  0.46404862 0.36347967
 0.4189621  0.4197463  0.45093152 0.41067868 0.43459734 0.3693471
 0.43791243 0.42066902 0.43879417 0.4093017  0.41940027 0.44361368], shape=(498,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(498,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.1822987, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/08.c_000.smt2
true label:[0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0]
true label rank:[1 2 2 1 1 1 2 2 1 1 1 2 2 1 1 1 2 2 1 1 2 2 1]
predicted label:tf.Tensor(
[0.4661452  0.45886406 0.460574   0.4462475  0.45076138 0.42872575
 0.38155952 0.42730004 0.40119004 0.446001   0.47451794 0.4760974
 0.4799666  0.47439745 0.47925103 0.47211885 0.47170088 0.4762678
 0.47611213 0.4610067  0.46774995 0.44590524 0.46810868], shape=(23,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(23,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.24814352, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/SYNAPSE_3_e7_1444_e7_638_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1]
predicted label:tf.Tensor(
[0.2167646  0.27765405 0.37643024 0.33645752 0.3846501  0.26946592
 0.13878873 0.3364488  0.21917087 0.38716292 0.43159944 0.27173713
 0.3388304  0.42719054 0.34173703 0.25261942 0.31846696 0.35324386
 0.38602352 0.18012387 0.25563934 0.24809891 0.2531742  0.2726739
 0.33640492 0.24227887 0.33841735 0.20965698 0.24624112 0.41525492
 0.4104858  0.40387085 0.4029169  0.3880455  0.39652404 0.39735466
 0.4028458  0.4072373  0.40209544 0.4115397  0.40798184 0.4026308
 0.40883058 0.41938663 0.4211232  0.40673158 0.42984018 0.431748
 0.41575855 0.44153088 0.4267043  0.449539   0.43287206 0.4332342
 0.43290612 0.44091833 0.4249379  0.43035948 0.4343423  0.42401153
 0.43801722 0.4342673  0.4242323  0.4567677  0.47355285 0.47771093
 0.46993074 0.45702258 0.46488866 0.46360463 0.45872286 0.46287334
 0.4708007  0.45482248 0.4630884  0.47846177 0.46748552 0.4797864
 0.47629854 0.4769482  0.4705754  0.48168012 0.48543498 0.48462605
 0.4814408  0.48411766 0.48403245 0.46474153 0.46864697 0.45860714
 0.46563637 0.47531334 0.47924066 0.4714958  0.47001818 0.4774744
 0.46592873 0.46770507 0.39731055 0.33188644 0.33342558 0.43917418
 0.3479274  0.4075089  0.32910743 0.39747685 0.28045213 0.4113043
 0.3993882  0.4231208  0.3611397  0.32943746 0.18595403 0.03597882
 0.29686487 0.02709058 0.02768001 0.06834555 0.0430015  0.13444346
 0.03506196 0.04451108 0.00964433 0.0879024  0.07154614 0.155548
 0.06782341 0.02247429 0.42629147 0.44552675 0.4035478  0.46870336
 0.4303774  0.43795708 0.4272014  0.42304492 0.44424862 0.46144724
 0.4431876  0.4306709  0.45714572 0.44768694 0.43431067 0.4473176
 0.4503011  0.46742013 0.4488545  0.42519563 0.45589754], shape=(149,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0.], shape=(149,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1]
mse:tf.Tensor(0.15284042, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/break_safe.c-1_000.smt2
true label:[0, 1, 1, 0, 1, 1, 1]
true label rank:[1 2 2 1 2 2 2]
predicted label:tf.Tensor(
[0.46798462 0.48331487 0.4673035  0.47206938 0.44241643 0.4876303
 0.48310578], shape=(7,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0.], shape=(7,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1]
mse:tf.Tensor(0.26188427, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/count_by_2_m_nest_000.smt2
true label:[1, 1, 1]
true label rank:[1 1 1]
predicted label:tf.Tensor([0.48118255 0.47760093 0.4733641 ], shape=(3,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)
predicted label rank:[1 1 1]
mse:tf.Tensor(0.2731392, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/bandec.smt2-0131_000.smt2
true label:[1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1]
true label rank:[2 2 1 1 2 2 1 2 1 2 2 2 1 1 1 1 1 2]
predicted label:tf.Tensor(
[0.4527427  0.45930028 0.45449254 0.45681688 0.4571466  0.4528346
 0.45731577 0.45262796 0.44205365 0.44186798 0.42982757 0.44119498
 0.44030365 0.4395143  0.4308808  0.42629355 0.4536016  0.44083932], shape=(18,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(18,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.25150263, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0278_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[2 2 2 ... 2 2 2]
predicted label:tf.Tensor([0.4828855  0.47685713 0.46273428 ... 0.2541321  0.07821903 0.28798807], shape=(1042,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(1042,), dtype=float32)
predicted label rank:[1 1 1 ... 1 1 1]
mse:tf.Tensor(0.36366695, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/spline-fixed.smt2-0001_000.smt2
true label:[1, 1]
true label rank:[1 1]
predicted label:tf.Tensor([0.4779178  0.48033762], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 0.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.2713094, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/bandec.smt2-0033_000.smt2
true label:[1, 1, 1]
true label rank:[1 1 1]
predicted label:tf.Tensor([0.47687343 0.4744165  0.47231096], shape=(3,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)
predicted label rank:[1 1 1]
mse:tf.Tensor(0.2761184, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/spline-fixed.smt2-0003_000.smt2
true label:[1, 1, 1]
true label rank:[1 1 1]
predicted label:tf.Tensor([0.4741839  0.4744165  0.47293577], shape=(3,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)
predicted label rank:[1 1 1]
mse:tf.Tensor(0.27683908, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/bouncy_two_counters_equality_000.smt2
true label:[1, 1, 1, 1, 0]
true label rank:[2 2 2 2 1]
predicted label:tf.Tensor([0.47439015 0.48067164 0.4730447  0.46949577 0.46189034], shape=(5,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.2636854, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/bandec.smt2-0036_000.smt2
true label:[0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]
true label rank:[1 2 2 2 1 1 1 1 1 1 1 2 2 2]
predicted label:tf.Tensor(
[0.42800558 0.43353942 0.44323805 0.42683938 0.42339754 0.41851372
 0.44131464 0.426766   0.41327035 0.41650677 0.43739727 0.4183691
 0.4200406  0.42508918], shape=(14,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(14,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.2439019, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0002_000.smt2
true label:[1, 0]
true label rank:[2 1]
predicted label:tf.Tensor([0.47493297 0.4836747 ], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 0.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.25481832, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/SYNAPSE_123_e8_953_e7_1465_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[7.09110172e-05 1.63808465e-03 1.41879245e-05 8.64386559e-04
 1.64720416e-03 1.02958671e-04 2.27652308e-05 2.18182802e-04
 9.92405185e-05 5.94925582e-02 5.21350205e-02 1.21562807e-04
 7.18563795e-03 4.06106412e-02 1.81275606e-03 1.78724527e-04
 1.07443035e-02 1.46670043e-02 8.68436992e-02 1.06099867e-06
 9.32397525e-05 1.31666660e-04 6.54712348e-05 7.55213186e-05
 5.58689237e-03 2.37077475e-04 9.16360204e-06 2.58013915e-06
 1.18943735e-05 6.58506155e-03 1.25655532e-03 9.13446420e-05
 8.05020332e-04 8.93324614e-04 3.26996269e-05 3.69968146e-01
 3.75470459e-01 3.83675992e-01 3.89908642e-01 3.66149724e-01
 3.72890919e-01 4.00893480e-01 3.65230381e-01 3.93001676e-01
 3.58379960e-01 4.03879404e-01 3.81859213e-01 4.12092358e-01
 3.79491985e-01 3.56540054e-01 3.68730158e-01 3.77390027e-01
 3.46582890e-01 3.64360988e-01 3.99117470e-01 3.62985492e-01
 4.65691745e-01 4.41218972e-01 4.36487019e-01 4.26437110e-01
 4.40411955e-01 4.37458038e-01 4.12664026e-01 4.27810550e-01
 4.36622590e-01 4.38518077e-01 4.39651072e-01 4.22058910e-01
 4.59789932e-01 4.36055332e-01 4.41945434e-01 4.34080064e-01
 4.69850540e-01 4.43223119e-01 4.65286314e-01 4.56478089e-01
 4.62166399e-01 4.62272495e-01 4.60113943e-01 4.72372353e-01
 4.61557925e-01 4.58576351e-01 4.60185200e-01 4.64403659e-01
 4.66021419e-01 4.66592729e-01 4.69745606e-01 4.82416868e-01
 4.72016811e-01 4.56990838e-01 4.60099190e-01 4.70918596e-01
 4.78818059e-01 4.81236339e-01 4.70681906e-01 4.75303382e-01
 4.21629250e-01 4.58873093e-01 4.58839566e-01 4.55410242e-01
 4.21694279e-01 4.58548844e-01 4.40471560e-01 4.53575522e-01
 4.40850496e-01 4.48703080e-01 4.26431596e-01 4.38926697e-01
 4.42397684e-01 4.36375260e-01 4.36913937e-01 4.25419748e-01
 4.43900317e-01 4.18600857e-01 4.36917871e-01 4.23026532e-01
 4.51640964e-01 4.13581491e-01 4.39959854e-01 4.59134430e-01
 4.16855216e-01 4.61333305e-01 4.43771243e-01 4.61242914e-01
 4.57143754e-01 4.62122381e-01 4.61053550e-01 4.53769773e-01
 4.50910300e-01 4.45451796e-01 4.48751062e-01 4.65747058e-01
 4.61004913e-01 4.52827662e-01 4.56347346e-01 3.48294228e-01
 4.39896524e-01 3.93366754e-01 2.52518415e-01 3.93510908e-01
 3.78659934e-01 3.91726196e-01 3.82359058e-01 3.21637511e-01
 3.75166476e-01 4.34518397e-01 4.15423185e-01 3.97245169e-01
 3.81714791e-01 3.28136235e-01 3.33979547e-01 4.16813552e-01
 2.31001586e-01 3.62792671e-01 3.16073567e-01 2.75910735e-01
 3.91509712e-01 2.33094484e-01 2.54303694e-01 1.69535697e-01
 2.03971148e-01 3.87910485e-01 3.12574983e-01 2.48375654e-01
 2.87100852e-01 2.46571511e-01 4.65373784e-01 3.06746960e-01
 3.25282902e-01 2.26224333e-01 3.27079058e-01 3.27406287e-01
 3.33418727e-01 2.32085943e-01 4.17559117e-01 2.89223969e-01
 2.98154473e-01 3.19931746e-01 2.98757195e-01 3.03423375e-01
 4.31605667e-01 3.25162083e-01 2.95652926e-01 3.91496301e-01
 2.83478111e-01 2.58869469e-01 3.32448334e-01 3.38491350e-01
 3.78601551e-01 2.89115965e-01 4.27195966e-01 3.85934889e-01
 3.58964890e-01 3.17269325e-01 3.30546647e-01 4.06547189e-01
 2.68008947e-01 2.94742972e-01 2.42537349e-01 3.04820061e-01
 3.56643707e-01 2.78156430e-01 3.05626124e-01 3.30186069e-01
 3.54737908e-01 2.79607236e-01 2.97120094e-01 2.96516567e-01
 3.26381326e-01 3.46250474e-01 3.95316809e-01 2.85548627e-01
 3.46399367e-01 4.06131238e-01 3.78801495e-01 4.00901437e-01
 3.00782859e-01 2.41375685e-01 3.68225574e-01 3.93184811e-01
 3.95613134e-01 3.21539879e-01 2.51269072e-01 2.66140550e-01
 2.81943232e-01 3.46377432e-01 2.77358592e-01 4.58757430e-01
 4.59894776e-01 4.59598154e-01 4.53205794e-01 4.37898695e-01
 4.41088438e-01 4.38816011e-01 4.43117946e-01 4.47881967e-01
 4.41178918e-01 4.75958437e-01 4.53529418e-01 4.56297904e-01
 4.57889438e-01 4.55549419e-01 4.61806118e-01 4.47754234e-01
 4.56490755e-01 4.41118240e-01 4.51609969e-01 4.58108008e-01
 4.46558982e-01 4.57900673e-01 4.50455874e-01 4.62353051e-01
 4.67532158e-01 4.58461791e-01 4.39427555e-01 4.26066160e-01
 4.28017884e-01 4.28409159e-01 4.26852107e-01 4.27905679e-01
 4.32193428e-01 4.32041496e-01 4.29689944e-01 4.34579849e-01
 4.38111752e-01 4.40200895e-01 4.43321586e-01 4.22524035e-01
 4.25854385e-01 4.27267313e-01 4.45082963e-01 4.28098202e-01
 4.12903875e-01 4.31283802e-01 4.26027179e-01 4.17808950e-01
 4.16045576e-01 4.29188013e-01 4.39152747e-01 4.32672799e-01
 4.20943916e-01], shape=(281,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(281,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.1479812, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/s3_clnt_2_true-unreach-call_true-termination.cil.c.flat_000.smt2
true label:[0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0]
true label rank:[1 2 2 1 2 1 1 1 2 2 2 1 2 1 1 1 1 1 1 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 1 1
 1 2 1 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 2 1 1 2 1]
predicted label:tf.Tensor(
[1.50561213e-01 1.07804179e-01 7.60628283e-02 1.77648455e-01
 2.44217485e-01 8.03722739e-02 2.08700299e-02 8.23251605e-02
 8.66236091e-02 3.08153093e-01 3.39987576e-01 8.91456008e-02
 2.39298582e-01 3.14703256e-01 1.40941441e-01 1.92254186e-02
 4.25915718e-02 8.49819779e-02 4.88572031e-01 8.82476568e-04
 6.58175349e-03 1.67149305e-02 1.55430138e-02 1.38559341e-02
 1.07752234e-01 7.92044401e-03 1.46505225e-12 1.60213787e-10
 6.20674137e-11 2.79697247e-06 7.70192491e-06 9.78571961e-07
 5.64731126e-05 1.37625463e-07 1.73178316e-09 2.56150961e-04
 1.30286813e-03 1.72867110e-09 1.24836879e-08 1.20979249e-02
 9.69018554e-09 8.25261459e-09 4.75585461e-04 2.19287450e-08
 2.53724835e-07 2.95549631e-04 2.34239850e-11 3.60488892e-04
 2.56005904e-07 5.37782907e-04 1.70112413e-09 9.37153341e-11
 5.75334713e-09 3.71890930e-12 1.99066634e-14 5.78402812e-11
 5.10585226e-13 2.76367691e-14 3.53841614e-08 1.91115734e-11
 3.02862202e-09 1.77383423e-04 9.68037499e-13 7.68648451e-14
 1.34700585e-07], shape=(65,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(65,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.28785113, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/barthe2-big2_merged_safe.c-1_000.smt2
true label:[0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1]
true label rank:[1 2 1 2 2 2 2 1 2 2 2 2]
predicted label:tf.Tensor(
[0.47489166 0.4893165  0.46582586 0.4501856  0.458197   0.4527894
 0.41466162 0.46529737 0.45577228 0.47253847 0.46661624 0.4724518 ], shape=(12,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(12,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.27457723, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/dillig33.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[5.9542060e-04 5.0185919e-03 2.8543460e-05 3.1912327e-04 1.2340844e-03
 1.5151585e-05 2.5635090e-05 1.6087294e-04 4.4688655e-05 6.2299371e-03], shape=(10,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(10,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(6.6007283e-06, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0017_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.4617686  0.4675614  0.47714454 0.4670847  0.47801092 0.46345532
 0.45076594 0.46200708], shape=(8,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0.], shape=(8,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.21720058, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/reverse_div_unsafe.c_000.smt2
true label:[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.33989745 0.3482459  0.3454233  0.3428747  0.33888534 0.3390187
 0.34834218 0.33692634 0.35857093 0.344499   0.34047997 0.33980012
 0.34217364 0.34208906 0.34832734 0.34394276 0.3496397  0.34060937
 0.332976   0.35124528 0.34099054 0.3405329  0.33341128 0.3518266
 0.35263628 0.34038687 0.34880674 0.3399436  0.35260573 0.34638566
 0.335629   0.34912694 0.3409633  0.33678415 0.33715516 0.33794188
 0.34537482 0.33944327 0.33822876 0.34915268 0.33056083 0.3367729
 0.34043437 0.33866665 0.34264013 0.34360087 0.33988923 0.3514184
 0.33092803 0.3456439  0.33600253 0.36184388 0.35205755 0.34850967
 0.33078203 0.36406586 0.32942885 0.34190017 0.35261285 0.35961115
 0.33807996 0.34604713 0.34368825 0.3380856  0.33817816 0.35135895
 0.345397   0.33667585 0.34164307 0.34472692 0.3395583  0.33821005
 0.35372084 0.34454677 0.34510714 0.33676356 0.34139124 0.3469041
 0.32636046 0.35150802 0.34132233 0.33841348 0.33083928 0.34560636
 0.3463297  0.3465919  0.34572238 0.33227283 0.33232543 0.32596672
 0.329486   0.34257942 0.33042476 0.32952255 0.33646262 0.35340464
 0.32472175 0.32849723 0.33641058 0.3371833  0.3288375  0.32212308
 0.3387633  0.3402661  0.35639143 0.329055   0.3208951  0.34323758
 0.3268965  0.33467233 0.3348791  0.33310223 0.33274314 0.31969464
 0.32811087 0.32275996 0.34578604 0.3324007  0.3223673  0.34964067
 0.33002347 0.33374697 0.3440163  0.33080986 0.32656562 0.33198065
 0.33170056 0.3347171  0.32356706 0.34215474 0.3226036  0.33514816
 0.33105326 0.31678432 0.33192378 0.33456334 0.32822442 0.32363483
 0.32789028 0.33633506 0.32948038 0.33770543 0.33390808 0.33606178
 0.3484217  0.336782   0.3368665  0.31276622 0.34890914 0.32718635
 0.32835406 0.3418615  0.342883   0.34363258 0.3351013  0.33956808
 0.32589927 0.33336258 0.33294466 0.3432719  0.32913867 0.33649263
 0.34370685 0.3211612  0.33159137 0.3339137  0.3255988  0.3335349
 0.32614022 0.32783926 0.33330593 0.344947   0.33840445 0.33226192
 0.3512991  0.33044297 0.34031087 0.33167922 0.32513106 0.31925535
 0.33710963 0.33522442 0.33789372 0.3202263  0.314842   0.33385152
 0.33986598 0.33116847 0.33491868 0.33085585 0.33945578 0.3327027
 0.34749436 0.33162734 0.3250907  0.33929804 0.33343816 0.31445438
 0.33952242 0.34919503 0.34299278 0.32672322 0.33451796 0.34898603
 0.32996404 0.32992777 0.33105144 0.33612353 0.33287448 0.33330193
 0.35003936 0.36850494 0.34997267 0.3677528  0.35535443 0.36553383
 0.3660378  0.35982075 0.35179812 0.346426   0.36211067 0.35977829
 0.36236584 0.38445318 0.35474116 0.37487847 0.34581757 0.35202146
 0.370559   0.35833102 0.36611098 0.3714309  0.36980635 0.3606025
 0.37132412 0.3580473  0.3592287  0.36378753 0.3562526  0.3693794
 0.36205536 0.36416152 0.35576373 0.36458057 0.3548427  0.35942167
 0.36917955 0.3652201  0.3678956  0.36505997 0.3671524  0.35171738
 0.35590065 0.3615186  0.35768908 0.3494926  0.3702128  0.35879347
 0.35294968 0.34652764 0.35015547 0.35904604 0.3639723  0.38047355
 0.37148347 0.3659241  0.37080473 0.3581316  0.36156243 0.34838203
 0.35772318 0.3572111  0.3434626  0.34856123 0.35861826 0.351848
 0.34210736 0.3485684  0.35722452 0.3437966  0.36228654 0.3597113
 0.36623314 0.3644097  0.36250585 0.3453982  0.34456494 0.36501533
 0.35969406 0.35634828 0.3599894  0.363254   0.358291   0.38326356
 0.36398655 0.36168283 0.36950177 0.3642785  0.35667253 0.3666495
 0.3431648  0.35949466 0.36323825 0.3467549  0.36239433 0.35253474
 0.35002393 0.36206573 0.35293525 0.35348952 0.35341638 0.3755373
 0.34371006 0.3563977  0.34496295 0.3604353  0.37008303 0.35056984
 0.36492926 0.34998727 0.37115413 0.3608982  0.35610828 0.35780078
 0.3555451  0.35809767 0.34981012 0.34874797 0.3739357  0.34992483
 0.34727335 0.36687034 0.3640554  0.36504495 0.35726762 0.36841494
 0.35824636 0.3683433  0.3720839  0.35771793 0.35999817 0.35284543
 0.34573686 0.3549806  0.35116595 0.37171128 0.34681603 0.3518387
 0.34023654 0.34513855 0.36855274 0.3602711  0.36990786 0.35649627
 0.35660943 0.3561055  0.36479098 0.3323391  0.32179275 0.3394065
 0.34495008 0.35384437 0.35357904 0.34012008 0.34835157 0.33771887
 0.33578935 0.33635736 0.33442932 0.3344438  0.3542698  0.3462049
 0.3368792  0.32537854 0.33599955 0.3418272  0.34477508 0.31948164
 0.33289427 0.3311454  0.3413794  0.33379537 0.3380347  0.34492427
 0.33475095 0.35110664 0.32966542 0.3393985  0.3270827  0.34035337
 0.3429172  0.3421296  0.32694805 0.33171117 0.33310288 0.33898354
 0.32772827 0.3456781  0.33116567 0.33306426 0.31434345 0.34577334
 0.32100683 0.34453404 0.33030206 0.32561445 0.33247268 0.33130172
 0.3392623  0.33093357 0.3274027  0.34474322 0.3271734  0.33402526
 0.3298855  0.33001834 0.34118813 0.33246732 0.3363111  0.32233453
 0.3399321  0.33856225 0.34258687 0.34093204 0.3422749  0.35253978
 0.33136934 0.3393988  0.32693535 0.325618   0.32303077 0.32764477
 0.3249873  0.33800563 0.33194196 0.32412744 0.32493737 0.31148642
 0.33996832 0.3302415  0.3475131  0.35215414 0.34001464 0.35177922
 0.34492287 0.33497834 0.34100634 0.329818   0.33306718 0.32814595
 0.35797954 0.33809817 0.345671   0.32879868 0.33418262 0.33879942
 0.34226066 0.34356993 0.3406947  0.34650797 0.3395152  0.3444475
 0.3373365  0.33752108 0.33169866 0.3428196  0.3368707  0.3434794
 0.33602643 0.34131315 0.32779565 0.32776275 0.34287027 0.33114514
 0.33083692 0.3273788  0.34977317 0.32758284 0.34252787 0.32968915
 0.3264684  0.32952946 0.34302327 0.34237367 0.34581846 0.3440976
 0.3278523  0.3237112  0.3395124  0.3324635  0.3273501  0.3531667
 0.34925514 0.33317482 0.32600057 0.33664238 0.3374975  0.33459783
 0.35002536 0.34044403 0.33259577 0.32812592 0.33598953 0.3415966
 0.34308586 0.32471144 0.33738822 0.33186755 0.34114587 0.3364854
 0.34697035 0.33858562 0.34976712 0.33866036 0.3408795  0.3393436
 0.33746877 0.34020388 0.33814567 0.34735087 0.34429735 0.32966697
 0.3173356  0.3409156  0.3274484  0.3435038  0.34078774 0.32921928
 0.39890566 0.40659094 0.41444835 0.40375513 0.40804228 0.39936817
 0.4016352  0.39868975 0.39617682 0.40437683 0.4001629  0.4088621
 0.3953878  0.4118302  0.4029023  0.4010075  0.3987909  0.4000764
 0.40896776 0.40619764 0.3943798  0.40459913 0.40291128 0.4018089
 0.40588242 0.39251444 0.40346867 0.3881692  0.40702465 0.39685926
 0.4017663  0.39524934 0.39421582 0.40097836 0.40185934 0.40385237
 0.3881868  0.39887387 0.3977385  0.40409622 0.4010756  0.3929175
 0.39623907 0.40016973 0.4009926  0.4050867  0.39616737 0.4079696
 0.39793646 0.39339983 0.40741372 0.39356458 0.39218816 0.40855142
 0.39475903 0.41326317 0.40692505 0.4101277  0.39842623 0.40520716
 0.39687127 0.39850077 0.40389702 0.39728212 0.40705112 0.40321815
 0.40536684 0.4049904  0.40828967 0.40034676 0.39519656 0.40379545
 0.40499228 0.4071256  0.394426   0.4008981  0.39078933 0.39084047
 0.4029844  0.39608353 0.40008727 0.40365624 0.39414367 0.40042493
 0.4054337  0.39575902 0.40195554 0.39812136 0.398356   0.40867037
 0.41076177 0.40591508 0.4074338  0.4011972  0.40412733 0.40824834
 0.3954046  0.40283242 0.40999037 0.40520167 0.3919297  0.3928655
 0.40125173 0.40005252 0.40741974 0.4101519  0.39952132 0.39868337
 0.40013707 0.40027007 0.40006894 0.4000863  0.39889228 0.39293683
 0.4025609  0.38634542 0.40495053 0.40709996 0.40026763 0.4061417
 0.40071136 0.40542555 0.39157856 0.4120423  0.40534586 0.40225813
 0.4066202  0.39433303 0.40270066 0.43962437 0.44357246 0.45162117
 0.4501069  0.44497746 0.45354694 0.45040715 0.45431796 0.44721606
 0.44176346 0.45699897 0.4518     0.45600128 0.4469123  0.4416807
 0.45866102 0.4473443  0.45197886 0.4529108  0.44099125 0.45194176
 0.45385143 0.45021737 0.45524582 0.45812118 0.4630788  0.46204254
 0.45090264 0.45791072 0.46177757 0.4544106  0.45097962 0.45855135
 0.450579   0.45073867 0.45780522 0.45734265 0.4531118  0.4521836
 0.45073432 0.44338927 0.4571245  0.44561112 0.45422056 0.4602839
 0.45556423 0.44814408 0.45459363 0.45500648 0.46390527 0.45655787
 0.45899707 0.45144072 0.45708513 0.3945841  0.38740897 0.3727448
 0.38726956 0.38514382 0.37767828 0.3858437  0.3803931  0.39023182
 0.38455108 0.38483405 0.3870092  0.39046687 0.38702947 0.38052076
 0.39124304 0.38094485 0.39171037 0.3811259  0.3861244  0.38970816
 0.38389552 0.38527638 0.3897435  0.38901314 0.37995934 0.38641143
 0.3870833  0.39335606 0.39647338 0.38886118 0.38769305 0.39547846
 0.38614225 0.39113247 0.3846894  0.38582286 0.3857566  0.3843274
 0.3979112  0.3978588  0.40140247 0.39902967 0.40394193 0.3936119
 0.39906767 0.39096153 0.39956442 0.4003535  0.39488912 0.40086782
 0.3916204  0.40103093 0.4039387  0.3958355  0.39584458 0.39934447
 0.39654738 0.39722252 0.39956015 0.39845026 0.39808008 0.39683872
 0.40415847 0.3974482  0.39752415 0.39915472 0.40378714 0.4018004
 0.4051774  0.39398366 0.39709684 0.40445393 0.39611357 0.4041912
 0.4007377  0.39863628 0.39731854 0.39806792 0.39752576 0.39771226
 0.39314747 0.39772433 0.3920754  0.40151674], shape=(796,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0.], shape=(796,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.16214964, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/four1.smt2-0046_000.smt2
true label:[1, 0, 1, 1, 1, 1]
true label rank:[2 1 2 2 2 2]
predicted label:tf.Tensor([0.4781258  0.46733284 0.47574875 0.4776347  0.4784299  0.46627995], shape=(6,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0.], shape=(6,), dtype=float32)
predicted label rank:[1 1 1 1 1 1]
mse:tf.Tensor(0.26589164, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/PRODUCER_CONSUMER_3_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 1 1 1 2 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1
 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[6.19534694e-05 2.63708830e-03 5.36763446e-06 8.25613737e-04
 6.59760833e-03 1.52349472e-04 1.96270266e-05 1.46836042e-04
 4.09509303e-05 1.19541585e-01 3.83004248e-02 2.76565552e-04
 4.93758917e-03 6.46176934e-02 1.36280656e-02 1.02657090e-04
 3.14411521e-03 3.32954526e-03 4.25770819e-01 7.16657155e-07
 6.51802984e-05 5.04137279e-06 1.04726296e-05 8.70421354e-05
 6.15319610e-03 9.89930559e-05 9.99513577e-05 2.39066243e-01
 2.56120026e-01 4.22403991e-01 3.06755662e-01 2.94444203e-01
 3.16688001e-01 3.06656241e-01 2.48815775e-01 3.20328772e-01
 4.07693565e-01 3.23101044e-01 3.24964225e-01 4.10837382e-01
 2.94337809e-01 3.45021814e-01 4.10747945e-01 3.35823476e-01
 4.30307508e-01 4.86293018e-01 2.76762366e-01 4.59070385e-01
 3.23168606e-01 4.62039620e-01 3.05375963e-01 3.89366806e-01
 2.78442800e-01 3.56311500e-01 3.61847818e-01 3.87852639e-01
 3.92620444e-01 4.57121104e-01 4.66883242e-01 4.70813453e-01
 4.61059779e-01 4.63343143e-01 4.65013862e-01 4.57773596e-01
 4.55664605e-01 4.56483424e-01 4.61082548e-01 4.57778096e-01
 4.58818138e-01 4.63796854e-01 4.64208007e-01 4.69508320e-01
 4.55997527e-01 4.62185830e-01 4.62194860e-01 4.66664463e-01
 4.61049676e-01 4.65617329e-01 4.68622476e-01 4.08341944e-01
 4.34273481e-01 4.17288929e-01 4.34132606e-01 4.44692880e-01
 4.29117382e-01 4.38702375e-01 4.12040949e-01 4.21890855e-01
 4.31491762e-01 4.13703829e-01 4.26391721e-01 3.90815407e-01
 4.33339119e-01 4.26547617e-01 1.93924963e-01 2.78790265e-01
 3.13271314e-01 3.11721355e-01 1.79945081e-01 2.58270741e-01
 1.99103355e-01 2.78783083e-01 2.88300723e-01 3.48288029e-01
 2.84466773e-01 1.84651464e-01 3.36521029e-01 2.30139226e-01
 4.64926302e-01 4.66999292e-01 4.55852479e-01 4.37144876e-01
 4.60802197e-01 4.62711543e-01 4.71034855e-01 4.72344428e-01
 4.58579510e-01 4.69541967e-01 4.61955518e-01 4.67604011e-01
 4.55818057e-01 4.55323905e-01 4.67452496e-01 4.61721331e-01
 4.68358099e-01 4.67091203e-01 4.64341700e-01 4.63165700e-01
 4.53439265e-01 4.60420877e-01 4.55459297e-01 4.67639744e-01
 4.59007174e-01 4.59587812e-01 4.62268829e-01 4.60663557e-01
 4.59425151e-01 4.72229272e-01 4.74694103e-01 4.62208152e-01
 4.53132331e-01 4.57242787e-01 4.67718780e-01 4.58588272e-01
 4.66078937e-01 4.52039748e-01 8.58757794e-02 5.88105917e-02
 1.07621878e-01 1.38482451e-02 9.47043300e-03 9.53701138e-03
 1.72417313e-01 3.10367346e-03 1.61176026e-02 5.40184975e-03
 9.84203815e-03 1.20122373e-01 1.94410533e-01 2.05598772e-02
 3.02931964e-02 1.81483090e-01 1.07195973e-03 8.34014118e-02
 7.52307773e-02 1.10051036e-03 1.48494840e-02 2.85871625e-02], shape=(168,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(168,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.16785316, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/gcd01_true-unreach-call_true-no-overflow_true-termination_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.46449572 0.4681936  0.46740192 0.46622097 0.46153504 0.45241156
 0.42804858 0.44632438], shape=(8,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0.], shape=(8,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.2952058, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/loop__upcount_000.smt2
true label:[1, 1, 1, 1]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([0.45963857 0.4669913  0.48230895 0.44189268], shape=(4,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)
predicted label rank:[1 1 1 1]
mse:tf.Tensor(0.28889412, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0264_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.0000000e+00 7.9832700e-35 0.0000000e+00 0.0000000e+00 2.2093523e-27
 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.5929095e-01 4.8184830e-01
 3.7541494e-01 3.6612886e-01 3.9804098e-01 3.7945110e-01 3.7379584e-01
 3.7618181e-01 3.6761391e-01 3.7507442e-01 3.6707431e-01 3.4292436e-01
 4.5028773e-01 3.8221344e-01 4.1023839e-01 4.1377872e-01 3.5327357e-01
 3.8729775e-01 3.6692542e-01 2.2148028e-01 2.8067601e-01 4.0073848e-01
 3.7528822e-01 3.0894935e-01 3.7136969e-01 2.6793295e-01 2.5878635e-01
 3.2985276e-01 3.9044601e-01 3.9347133e-01 3.6469522e-01 4.4189593e-01
 3.1377596e-01 4.2935327e-01 4.5010537e-01 3.7266311e-01 4.0823275e-01
 4.7559035e-01 3.2724547e-01 4.3276921e-01 3.8147044e-01 4.1758019e-01
 3.7196943e-01 3.9471900e-01 3.2531518e-01 3.8281375e-01 3.7659019e-01
 3.8337880e-01 4.4259241e-01 3.7238920e-01 3.3194983e-01 3.2681555e-01
 2.9473728e-01 3.5991070e-01 3.2662830e-01 2.7331927e-01 3.8967294e-01
 4.0064785e-01 3.5787287e-01 3.8217586e-01 3.4471399e-01 3.7448585e-01
 3.6636901e-01 3.2414407e-01 3.6596841e-01 3.0665267e-01 2.8645176e-01
 3.0942222e-01 3.2173425e-01 3.7310809e-01 4.0427589e-01 4.0412927e-01
 3.3024806e-01 3.8408011e-01 2.9038376e-01 3.8653606e-01 3.7765035e-01
 2.8406847e-01 3.4785837e-01 3.3970714e-01 3.6223328e-01 3.5378635e-01
 2.9681921e-01 4.6100315e-01 3.5063225e-01 2.6415876e-01 4.2754096e-01
 2.9878688e-01 2.4991813e-01 3.4030485e-01 4.3071857e-01 3.3874124e-01
 3.2889038e-01 4.3896550e-01 4.3431395e-01 4.2800659e-01 3.1540415e-01
 4.0082407e-01 3.2618564e-01 4.0450639e-01 3.4712633e-01 3.1663677e-01
 4.3874159e-01 3.5043433e-01 3.3809155e-01 2.8649116e-01 4.2279941e-01
 2.7911302e-01 3.0388594e-01 3.3639547e-01 3.4257424e-01 3.5499007e-01
 3.5591367e-01 3.3257946e-01 1.9922462e-01 3.1358635e-01 3.9007413e-01
 3.9164630e-01 2.9612088e-01 3.2382554e-01 3.9881876e-01 3.4606051e-01
 3.8977870e-01 4.2273909e-01 3.3727986e-01 3.2314724e-01 3.1748110e-01
 3.4819287e-01 3.5453236e-01 3.9182425e-01 2.3941907e-01 3.1343234e-01
 4.5349801e-01 3.5167783e-01 4.2501113e-01 3.2560238e-01 3.4489813e-01
 3.9497718e-01 3.1754577e-01 3.7619081e-01 3.7126023e-01 3.6531866e-01
 3.6326364e-01 4.4498473e-01 2.4208748e-01 4.2855421e-01 3.7772995e-01
 3.7817961e-01 4.2189378e-01 2.7705282e-01 3.1993443e-01 3.2364702e-01
 4.3197459e-01 4.3292367e-01 3.9325294e-01 2.5685057e-01 3.4616330e-01
 3.7821355e-01 4.4655856e-01 3.0694363e-01 3.6433303e-01 3.0398798e-01
 4.5673430e-01 3.4440011e-01 3.4400940e-01 2.7284363e-01 4.2425165e-01
 2.7562380e-01 3.1863272e-01 3.0981651e-01 3.5348839e-01 3.3721185e-01
 4.3750736e-01 3.6020637e-01 3.0680019e-01 4.5380780e-01 1.9300416e-01
 3.2396439e-01 3.6167467e-01 2.4299932e-01 3.5723293e-01 3.4590530e-01
 3.6518431e-01 4.1658744e-01 4.2224377e-01 2.7261046e-01 3.5097146e-01
 4.3561602e-01 3.1776929e-01 3.2169467e-01 3.3487040e-01 3.2611698e-01
 3.8390034e-01 2.6231611e-01 3.2373166e-01 4.4513476e-01 4.1635793e-01
 3.8108057e-01 3.5562426e-01 3.3039665e-01 4.0067166e-01 4.1961876e-01
 4.1119727e-01 3.2492155e-01 2.9506886e-01 4.2799664e-01 3.6994505e-01
 4.2591891e-01 2.7694097e-01 3.6708027e-01 4.3220210e-01 4.9396810e-01
 4.3852273e-01 3.3980602e-01 2.8808850e-01 2.3470438e-01 3.5211143e-01
 4.2901152e-01 2.9893008e-01 3.7161359e-01 4.2496979e-01 3.3070576e-01
 4.4006771e-01 3.9299440e-01 3.9924893e-01 3.0524367e-01 3.9589405e-01
 2.6587260e-01 3.4046316e-01 4.1000846e-01 4.1316012e-01 3.6171147e-01
 3.7228161e-01 4.2700642e-01 4.1825944e-01 2.7322650e-01 3.7858856e-01
 2.7364382e-01 2.9044920e-01 3.2027727e-01 2.9212493e-01 4.2956385e-01
 4.0600976e-01 4.4963956e-01 4.7647142e-01 3.6393535e-01 3.8403234e-01
 3.6909682e-01 2.5594509e-01 2.9769558e-01 3.7775108e-01 2.7781484e-01
 3.8631129e-01 3.6236325e-01 2.8586283e-01 2.8869438e-01 4.0840632e-01
 3.8141948e-01 2.4612215e-01 3.7627971e-01 3.5793096e-01 3.7971368e-01
 3.1669217e-01 3.3230072e-01 3.9756885e-01 3.3456397e-01 4.1790307e-01
 3.9291459e-01 3.9275333e-01 4.1388583e-01 3.7814930e-01 4.0369937e-01
 2.2212645e-01 2.9361159e-01 4.0444398e-01 3.0348071e-01 3.0162060e-01
 3.8528779e-01 2.6524395e-01 3.6253196e-01 3.4320837e-01 3.8775745e-01
 2.6327357e-01 4.2814928e-01 3.8548636e-01 3.9738271e-01 4.1234717e-01
 3.4538651e-01 4.4997057e-01 3.4667999e-01 3.4401196e-01 4.7373870e-01
 3.0922669e-01 3.8846666e-01 3.7880868e-01 4.2845231e-01 3.6710310e-01
 4.0641123e-01 3.9825410e-01 3.8117939e-01 4.1713730e-01 4.4361359e-01
 5.0578147e-01 3.3703744e-01 3.8384533e-01 4.5089886e-01 4.2559555e-01
 2.9722381e-01 3.6550122e-01 3.9879316e-01 3.7981662e-01 3.9847335e-01
 4.2403299e-01 2.5863701e-01 3.3977056e-01 3.9439830e-01 4.1044796e-01
 3.7567133e-01 3.1530160e-01 3.3553255e-01 2.5623882e-01 4.3057519e-01
 4.2896625e-01 4.0554684e-01 3.6727363e-01 4.1913044e-01 3.8464025e-01
 4.2729062e-01 2.4546939e-01 3.6122838e-01 3.9653569e-01 2.7087969e-01
 3.4957445e-01 2.9820630e-01 2.7464962e-01 3.9350408e-01 3.1502751e-01
 2.6464099e-01 2.7908367e-01 3.0900091e-01 4.0157315e-01 3.0347437e-01
 4.6257868e-01 3.5237378e-01 4.7853121e-01 3.8641930e-01 4.0690327e-01
 2.3868480e-01 2.8892145e-01 3.2263780e-01 3.2583421e-01 3.9931366e-01
 3.4787059e-01 3.1952810e-01 4.1938466e-01 3.4103423e-01 3.4800446e-01
 4.2139596e-01 3.0090863e-01 3.4209949e-01 3.1306478e-01 3.0436260e-01
 3.5967562e-01 2.9832608e-01 4.2146641e-01 2.6514530e-01 3.4724611e-01
 3.0007058e-01 4.4562942e-01 2.4795651e-01 3.9204830e-01 4.1718411e-01
 2.6760912e-01 3.9712006e-01 3.6116517e-01 2.8204757e-01 3.5916162e-01
 3.1559688e-01 3.8669938e-01 4.0731806e-01 3.8352603e-01 4.3178630e-01
 3.9097098e-01 3.1326991e-01 3.1753141e-01 3.3453676e-01 3.4916893e-01
 4.2860991e-01 3.8667971e-01 2.9795778e-01 4.0549049e-01 3.2011908e-01
 3.3365029e-01 4.1198272e-01 3.1636554e-01 2.6203573e-01 3.5811698e-01
 2.6297557e-01 3.9324290e-01 3.1268913e-01 3.7146822e-01 3.6784011e-01
 3.0685809e-01 3.7771428e-01 2.2370276e-01 3.9044735e-01 2.8071523e-01
 3.9531693e-01 2.6407009e-01 4.8279145e-01 3.3591342e-01 3.2635796e-01
 3.9412904e-01 3.1529224e-01 3.0672371e-01 4.1710824e-01 3.6119285e-01
 3.2178158e-01 3.0736640e-01 3.0033129e-01 3.2005951e-01 3.1840026e-01
 2.8182966e-01 3.2087535e-01 3.3067125e-01 2.4945453e-01 3.5412717e-01
 2.9609287e-01 4.1357961e-01 3.3560961e-01 3.9671677e-01 2.7088398e-01
 3.0174011e-01 4.1966695e-01 2.8878862e-01 3.3983272e-01 4.1738701e-01
 2.8817052e-01 3.5861951e-01 3.8221973e-01 4.2387587e-01 3.0425388e-01
 4.0488917e-01 4.1509938e-01 2.8434289e-01 2.9264629e-01 4.0923262e-01
 3.1761038e-01 4.0390098e-01 3.7922868e-01 3.5810679e-01 3.8401625e-01
 3.2254285e-01 4.6307322e-01 3.6752707e-01 4.0952495e-01 3.9593422e-01
 4.8807177e-01 3.7245387e-01 2.8945899e-01 3.7882090e-01 2.6469433e-01
 3.7090912e-01 2.8730357e-01 3.3157697e-01 3.2862934e-01 2.6674408e-01
 3.7675864e-01 3.0229911e-01 2.1338156e-01 4.3309370e-01 3.4601295e-01
 3.9314279e-01 3.4242111e-01 3.4120929e-01 4.2730319e-01 4.0004924e-01
 3.5971689e-01 3.6206943e-01 3.6853868e-01 3.8697463e-01 3.4800261e-01
 3.6182725e-01 3.1923378e-01 3.6356845e-01 4.8266581e-01 3.8809204e-01
 3.8716519e-01 3.2560104e-01 3.1565723e-01 4.1418535e-01 4.2204189e-01
 4.4972020e-01 4.1453195e-01 4.2434847e-01 4.3359774e-01 4.4803667e-01
 4.2408830e-01 4.3723735e-01], shape=(507,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0.], shape=(507,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.13016176, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/28.c_000.smt2
true label:[0, 1, 1, 0, 1, 1, 1, 0, 1, 0]
true label rank:[1 2 2 1 2 2 2 1 2 1]
predicted label:tf.Tensor(
[0.46631432 0.4721312  0.46826047 0.48333263 0.4752074  0.47127277
 0.44713584 0.47829574 0.48972645 0.48911443], shape=(10,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(10,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.26014495, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/minepump_spec4_product57_true-unreach-call.cil.c.flat_000.smt2
true label:[1, 1, 1]
true label rank:[1 1 1]
predicted label:tf.Tensor([4.9351101e-14 3.1490810e-10 2.1098087e-15], shape=(3,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)
predicted label rank:[1 1 1]
mse:tf.Tensor(1.0, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/chc-lia-lin-0125_000.smt2
true label:[1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0]
true label rank:[2 1 1 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 2 1 1 1 2
 2 1 1 1]
predicted label:tf.Tensor(
[4.65994888e-24 3.49744338e-17 1.37403385e-19 5.33815436e-32
 6.13421683e-12 1.80952046e-18 2.46221166e-19 7.74939467e-23
 2.85869132e-33 6.01834900e-19 7.64138690e-07 9.26059269e-32
 1.26057330e-24 4.48061456e-14 8.46839136e-16 2.10318199e-20
 6.10137984e-20 4.82264646e-14 1.38171017e-02 6.86040348e-37
 1.35155570e-26 3.73253556e-25 1.12252661e-29 1.39492687e-26
 5.59544464e-18 1.25601172e-19 1.21417075e-30 4.67606176e-25
 2.21167469e-24 4.50106659e-15 1.58541833e-14 3.31794969e-14
 5.54329330e-16 7.38431478e-17 8.20605556e-25 2.38153308e-15
 3.85642558e-08 5.59029574e-28 6.21835682e-25 5.44987167e-09
 4.88083312e-22], shape=(41,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(41,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1]
mse:tf.Tensor(0.36585832, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/four1.smt2-0044_000.smt2
true label:[1, 0, 1, 1, 1, 1]
true label rank:[2 1 2 2 2 2]
predicted label:tf.Tensor([0.4767242  0.46733284 0.47574875 0.4776347  0.4784299  0.46627995], shape=(6,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0.], shape=(6,), dtype=float32)
predicted label rank:[1 1 1 1 1 1]
mse:tf.Tensor(0.2661358, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/apache-get-tag.i.v+nlh-reducer.c-1_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.46397147 0.4848576  0.4217475  0.45251247 0.48443455 0.47078538
 0.24196339 0.37117934], shape=(8,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0.], shape=(8,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.33784097, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/count_by_1_variant_true-unreach-call.c.flat_000.smt2
true label:[1]
true label rank:[1]
predicted label:tf.Tensor([0.48199838], shape=(1,), dtype=float32)
rounded label:tf.Tensor([0.], shape=(1,), dtype=float32)
predicted label rank:[1]
mse:tf.Tensor(0.2683257, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/test_locks_10.c-1_000.smt2
true label:[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]
true label rank:[1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1
 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1
 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 2 1 2 1 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1
 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2
 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1
 2 1 2]
predicted label:tf.Tensor(
[0.40913475 0.4210912  0.43809032 0.4080532  0.4211396  0.41251785
 0.40484935 0.4143459  0.40585917 0.4154504  0.42122385 0.38287276
 0.4403414  0.4038267  0.40120572 0.4031169  0.42129683 0.4279694
 0.41663083 0.37306184 0.3912491  0.3848992  0.40600887 0.40428644
 0.40189078 0.40449566 0.41613376 0.39606878 0.39269692 0.42857778
 0.41055307 0.42297703 0.39267397 0.38194436 0.431933   0.42199412
 0.4391398  0.41982746 0.43246207 0.42640144 0.42135057 0.44497374
 0.43972042 0.44687414 0.45654437 0.44367123 0.42581326 0.45023704
 0.4231201  0.443293   0.42693636 0.44980666 0.41513747 0.4304486
 0.4448746  0.44297144 0.4336614  0.4268228  0.45687395 0.4202916
 0.43563342 0.4466952  0.43093723 0.44180238 0.43732435 0.47600624
 0.42563793 0.41519204 0.395105   0.44217566 0.4344385  0.4528852
 0.41806734 0.45799536 0.42830998 0.42455262 0.4086847  0.45514175
 0.44813424 0.4473682  0.44482553 0.45340386 0.45175794 0.43213388
 0.44816047 0.44280988 0.45609203 0.46151793 0.44861233 0.44210744
 0.44429266 0.44604862 0.42357    0.45950928 0.44411433 0.4666409
 0.4158638  0.47548115 0.48258966 0.46646422 0.4381961  0.4723027
 0.47216028 0.46984312 0.44941723 0.47050297 0.45441157 0.4660413
 0.45107824 0.46977556 0.44764435 0.45065382 0.44640204 0.42951596
 0.47951904 0.44174394 0.44849694 0.4330595  0.4423397  0.46264544
 0.43428767 0.46619904 0.46070078 0.44945264 0.45849064 0.46130908
 0.45768842 0.45613533 0.43666053 0.46813008 0.45098466 0.4651024
 0.46118954 0.4445742  0.44210145 0.45720416 0.4550822  0.46090418
 0.4423933  0.4433757  0.47291026 0.44762775 0.45073813 0.44943103
 0.46595475 0.46028346 0.47065747 0.44107416 0.43764004 0.4352542
 0.43233585 0.45696226 0.4433937  0.45636383 0.44688436 0.43901482
 0.43306777 0.43034935 0.43882143 0.43515638 0.4365836  0.45665956
 0.43739945 0.43992424 0.440078   0.46710443 0.46209186 0.4477263
 0.47702536 0.43948624 0.47238633 0.44358516 0.42484623 0.4252131
 0.46076608 0.4531549  0.4097549  0.43405908 0.4040215  0.40334296
 0.42574927 0.3963364  0.40206188 0.41956657 0.4009152  0.3648118
 0.42353156 0.44527906 0.4171374  0.40897274 0.45548725 0.44525507
 0.4408449  0.40314075 0.41784567 0.4425655  0.4114895  0.4156486
 0.43180686 0.4307566  0.42311367 0.41547775 0.41577983 0.45009208
 0.4445383  0.4162514  0.41912404 0.4395013  0.45358098 0.46194285
 0.47270286 0.45748925 0.4452337  0.48017305 0.4522868  0.46474475
 0.44981167 0.43325615 0.46249107 0.46446458 0.46823472 0.45699796
 0.44639984 0.46270704 0.44006294], shape=(225,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(225,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1]
mse:tf.Tensor(0.23475105, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/stalmark_000.smt2
true label:[0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1]
predicted label:tf.Tensor([0.32257092 0.33044943 0.3114897  0.3384537  0.4073682  0.31063664], shape=(6,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0.], shape=(6,), dtype=float32)
predicted label rank:[1 1 1 1 1 1]
mse:tf.Tensor(0.11454493, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/tridag.smt2-0024_000.smt2
true label:[1, 1, 1, 1]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([0.4788597 0.4756991 0.4436526 0.4825084], shape=(4,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)
predicted label rank:[1 1 1 1]
mse:tf.Tensor(0.28094965, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/03.c_000.smt2
true label:[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 2 2 2 2 2 2 2 2 2 2]
predicted label:tf.Tensor(
[0.47649017 0.47814155 0.48303142 0.46878475 0.46453565 0.4752507
 0.4611403  0.48243582 0.45925167 0.48369926 0.48179832], shape=(11,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(11,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.27242362, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/dillig17.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[5.0225854e-04 1.7743796e-02 4.7672191e-05 3.6683679e-04 9.7482204e-03
 4.7421455e-04 8.4482963e-05 7.9584122e-04 2.6270453e-05], shape=(9,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(9,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(4.568059e-05, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-mono-direction-layer-graph/test_data/MOESI_2_e8_101_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1
 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1]
predicted label:tf.Tensor(
[1.93134142e-07 6.40687504e-05 4.45540934e-07 4.27974697e-07
 3.40640545e-04 3.73799139e-07 1.37788177e-07 1.12469672e-06
 1.22359989e-08 1.35773420e-03 1.64368749e-03 1.20365939e-06
 2.25344183e-06 1.36510134e-02 1.53785944e-03 6.46262606e-07
 1.76906586e-04 5.12173283e-05 3.75582129e-01 6.41579428e-11
 5.96011684e-10 2.24828351e-08 5.94417244e-08 1.71084693e-07
 1.67071819e-04 4.24352692e-07 6.36009301e-10 5.83659698e-09
 6.01677286e-09 2.33257051e-05 7.97643588e-05 1.35632963e-05
 1.74969435e-04 1.02327496e-04 3.63755923e-08 6.85155392e-04
 2.18471885e-03 7.38601443e-07 5.24917232e-06 1.09270632e-01
 1.20521122e-08 1.11855534e-05 1.23649836e-03 1.29783211e-06
 4.75854085e-06 6.86776638e-03 1.21831816e-08 1.13624334e-03
 3.64162588e-05 1.15540624e-03 1.24380492e-07 2.52311185e-08
 8.18781842e-08 4.98407626e-09 1.03275756e-11 3.51343125e-01
 3.48014027e-01 3.23031187e-01 3.57745647e-01 3.52230191e-01
 3.13162327e-01 3.34612906e-01 3.05611819e-01 2.88968444e-01
 3.29188347e-01 3.25062037e-01 3.27549607e-01 3.71783793e-01
 3.20821106e-01 3.45129013e-01 3.44304085e-01 3.38626504e-01
 3.36134434e-01 3.04750770e-01 3.15337718e-01 3.09850007e-01
 2.96664238e-01 3.58218104e-01 3.22263658e-01 3.65064919e-01
 3.46952111e-01 3.08439255e-01 3.43599319e-01 3.18908572e-01
 3.53505701e-01 3.21854085e-01 3.49666953e-01 3.34003091e-01
 3.20204377e-01 3.17850351e-01 3.42774808e-01 3.64046425e-01
 3.44006062e-01 4.42069322e-01 4.21463042e-01 4.33928251e-01
 4.23948407e-01 4.28295642e-01 4.35651869e-01 4.28204685e-01
 4.35656160e-01 4.37513620e-01 4.25229520e-01 4.36276495e-01
 4.32056338e-01 4.10186827e-01 4.25388485e-01 4.33861434e-01
 4.20891553e-01 4.38579738e-01 4.20278072e-01 4.15244132e-01
 4.30178523e-01 4.28215742e-01 4.26011562e-01 4.11288917e-01
 4.13728684e-01 4.29172486e-01 4.23270583e-01 4.26439911e-01
 4.22791779e-01 4.32762563e-01 4.16120172e-01 4.16716546e-01
 4.32844400e-01 4.18937415e-01 4.32087451e-01 4.18977857e-01
 4.17756289e-01 3.55785996e-01 4.02807564e-01 4.63609695e-01
 3.67739350e-01 3.73255193e-01 3.38154823e-01 3.41250837e-01
 3.81383121e-01 3.42501670e-01 2.66430020e-01 3.18740785e-01
 3.73894811e-01 4.72702920e-01 4.71413732e-01 4.67983156e-01
 4.71501410e-01 4.75818664e-01 4.76386160e-01 4.68570024e-01
 4.84651178e-01 4.81719106e-01 4.84004557e-01 4.88543093e-01
 4.83763188e-01 4.80564505e-01 4.85178828e-01 4.75392252e-01
 4.73194212e-01 4.79799271e-01 4.78448898e-01 4.77222145e-01
 4.76162672e-01 4.76515621e-01 4.75446343e-01 4.71435070e-01
 4.76615697e-01 4.75322545e-01 4.75627095e-01 4.69005883e-01
 4.73081172e-01 4.72357512e-01 4.64447260e-01 4.71119821e-01
 4.64902401e-01 4.61338490e-01 4.80322570e-01 4.59589452e-01
 4.70144778e-01 4.60687965e-01 4.60135669e-01 4.75148529e-01
 4.86066043e-01 4.64853317e-01 4.76607829e-01 4.75932509e-01
 4.53574836e-01 4.54029262e-01 4.84294146e-01 4.57722932e-01
 4.69669551e-01 4.47255462e-01 4.67160404e-01 4.60152447e-01
 4.46119845e-01 4.24053609e-01 4.67508107e-01 4.58926588e-01
 4.39865679e-01 4.20359850e-01 4.66871470e-01 4.59797800e-01
 4.56484318e-01 4.29313779e-01 4.18104172e-01 4.30481553e-01
 4.13080633e-01 4.27816570e-01 4.30740982e-01 4.25997823e-01
 4.34867680e-01 4.05726135e-01 4.15494531e-01 4.26900089e-01
 4.19614971e-01 4.31221426e-01 3.99768233e-01 4.24908936e-01
 4.27248687e-01 4.21022505e-01 4.32914853e-01 4.19976413e-01
 4.27105993e-01 4.28867400e-01 4.19113100e-01 4.25009519e-01
 4.17265475e-01 4.30152029e-01 4.16636080e-01 4.29292887e-01
 4.13230985e-01 4.27247047e-01 4.21754569e-01 4.17199522e-01
 4.19776589e-01 4.18170363e-01 4.30231631e-01 4.23152924e-01
 4.15830255e-01 4.33438778e-01 4.27157074e-01 4.30050999e-01
 4.61928308e-01 4.48943555e-01 4.77406025e-01 4.36248243e-01
 4.44726139e-01 4.28419411e-01 4.28586364e-01 4.21099126e-01
 4.31761682e-01 4.68595326e-01 4.54607874e-01 4.68176901e-01
 4.70133483e-01 4.56764966e-01 4.60254759e-01 4.48196650e-01
 4.04673517e-01 4.42332000e-01 4.40513045e-01 4.21577215e-01
 4.66630846e-01 4.52582985e-01 4.29680377e-01 4.15964544e-01
 4.21999693e-01 4.10389423e-01 3.76210481e-01 3.79650533e-01
 4.07284379e-01 3.95818770e-01 3.82197320e-01 3.74980897e-01
 3.79442126e-01 3.78212005e-01 4.14608836e-01 3.67890477e-01
 3.98001522e-01 4.05014783e-01 4.36165333e-01 4.17901486e-01
 3.64795566e-01 4.11628246e-01 3.83570641e-01 3.94708186e-01
 3.60367239e-01 4.11406636e-01 3.76531273e-01 4.12098646e-01
 4.16948855e-01 4.31682259e-01 4.07130718e-01 4.11604166e-01
 4.22479928e-01 4.02765423e-01 4.17385221e-01 4.21580940e-01
 4.39868212e-01 4.19427395e-01 4.17302310e-01 4.28634793e-01
 4.13100421e-01 4.23488081e-01 4.05662000e-01 4.22497332e-01
 4.21388865e-01 4.22427177e-01 4.16007221e-01 4.25019085e-01
 4.26326096e-01 4.12038386e-01 4.18735534e-01 4.20680821e-01
 4.04339314e-01 4.12778974e-01 4.20802057e-01 4.62411970e-01
 4.63400871e-01 4.56431091e-01 4.69770610e-01 4.65469897e-01
 4.67491955e-01 4.62976903e-01 4.60249931e-01 4.66925502e-01
 4.67609584e-01 4.69150513e-01 4.62144107e-01 4.58247393e-01
 4.64189470e-01 4.62979257e-01 4.64002609e-01 4.64338124e-01
 4.67266440e-01 4.62705255e-01 4.78328317e-01 4.55498248e-01
 4.54311669e-01 4.60528761e-01 4.70558882e-01 4.69942689e-01
 4.56925690e-01 4.56850380e-01 4.10931408e-01 4.18001831e-01
 4.16335940e-01 4.15080309e-01 4.17403758e-01 4.22919989e-01
 4.19329703e-01 4.14731950e-01 4.24025536e-01 4.16725099e-01
 4.31015790e-01 4.16403323e-01 4.13942963e-01 4.10269946e-01
 4.14248437e-01 4.13253754e-01 4.15906042e-01 4.09169436e-01
 4.02920008e-01 4.18802291e-01 4.20156807e-01 4.20352638e-01
 4.17220116e-01 4.40034807e-01 4.04123843e-01 4.37906712e-01
 4.17780012e-01 4.30410385e-01 4.32317644e-01 4.08560157e-01
 4.11543578e-01 4.01228398e-01 4.08076614e-01 4.07076716e-01
 4.00208920e-01 3.94914985e-01 4.02416050e-01 4.08663094e-01
 4.06183124e-01 4.11631167e-01 4.07239437e-01 4.11173582e-01
 3.97746265e-01 4.11830664e-01 4.07053977e-01 4.13128972e-01
 4.17756617e-01 4.03847158e-01 4.16095346e-01 4.24180865e-01
 4.23238665e-01 4.09511209e-01 3.90570879e-01 3.90875638e-01
 4.14173514e-01 3.40678334e-01 3.62859070e-01 3.55254531e-01
 3.50864708e-01 3.72027993e-01 3.35461378e-01 3.81824553e-01
 3.59853148e-01 3.25623155e-01 3.60697448e-01 3.70014817e-01
 3.61357540e-01 3.63288224e-01 3.52199793e-01 3.45962048e-01
 3.62086296e-01 3.95246357e-01 3.75076771e-01 3.87795627e-01
 3.48246247e-01 3.88307571e-01 3.80608499e-01 3.59824955e-01
 3.56961608e-01 3.60158384e-01 3.96921873e-01 3.79388660e-01
 3.60684276e-01 3.39862615e-01 3.97438645e-01 3.61446798e-01
 3.75307113e-01 3.63215744e-01 3.83185387e-01 3.69335473e-01
 3.57682824e-01 3.74295056e-01 3.52278769e-01 2.84299254e-02
 1.74972564e-01 1.27089232e-01 1.63070709e-01 4.12488580e-02
 4.50238883e-02 2.99750924e-01 1.01884216e-01 1.17983609e-01
 2.19418585e-01 2.38266289e-02 1.02626085e-01 2.59840935e-01
 2.51227468e-01 4.43923175e-02 1.50137633e-01 1.31093472e-01
 2.31818259e-02 2.66758204e-02 2.64261842e-01 3.79763246e-02
 1.29046023e-01 1.64267123e-01 6.37782514e-02 2.15611964e-01
 4.99951541e-02 2.17806637e-01 1.91323727e-01 2.28419542e-01
 1.83160365e-01 3.23116004e-01 1.93907678e-01 3.88276577e-02
 2.49729097e-01 3.72982323e-02 5.68118989e-02 8.16542506e-02
 1.27183944e-01 1.32088780e-01 5.26064038e-02 1.53012067e-01
 7.38163292e-02 3.66876572e-01 4.32851046e-01 4.20193464e-01
 4.30035651e-01 4.09849167e-01 4.44934607e-01 4.46234286e-01
 4.54381734e-01 4.26806450e-01 4.05477762e-01 4.52004105e-01
 4.58577871e-01 4.46325243e-01 4.18085396e-01 3.97851676e-01
 4.80036259e-01 4.40587342e-01 4.42141622e-01 4.46096599e-01
 4.57366079e-01 4.34321791e-01 4.10782725e-01 4.10315931e-01
 4.62589353e-01 3.93039048e-01 4.78170633e-01 4.47171986e-01
 4.30507898e-01 4.42823082e-01 4.57661033e-01 3.82751137e-01
 4.38095599e-01 4.49839056e-01 4.56023932e-01 4.07773495e-01
 4.29412454e-01 4.12752390e-01 3.93508017e-01 4.04864609e-01
 4.08131897e-01 4.06555563e-01 4.12521362e-01 4.09038246e-01
 4.09032881e-01 4.13392186e-01 4.11773682e-01 4.08583462e-01
 4.14469510e-01 3.93163919e-01 3.93374979e-01 4.13484007e-01
 3.85088980e-01 4.10543203e-01 4.03393745e-01 4.11237180e-01
 3.94661874e-01 3.98791939e-01 4.27540421e-01 3.92555296e-01
 4.01470482e-01 3.88272136e-01 4.02016282e-01 3.86010885e-01
 4.10675585e-01 4.00614291e-01 4.17461425e-01 3.97601753e-01
 4.04433608e-01 4.12388325e-01 4.15864766e-01 4.02783990e-01
 4.13011134e-01 3.94895673e-01 4.42461193e-01 4.45002973e-01
 4.31494623e-01 4.54233736e-01 4.52376574e-01 4.35895741e-01
 4.34598088e-01 4.35477376e-01 4.48559821e-01 4.44418401e-01
 4.27513450e-01 4.43184584e-01 4.40575898e-01 4.44232672e-01
 4.36340034e-01 4.49564755e-01 4.39496189e-01 4.48562384e-01
 4.44860935e-01 4.38062847e-01 4.43748921e-01 4.36418086e-01
 4.27144766e-01 4.48544979e-01 4.30331469e-01 4.54457223e-01
 4.31079388e-01 4.27245259e-01 4.36653525e-01 4.45489824e-01
 4.34697658e-01 4.49409425e-01 4.36839849e-01 4.58319336e-01
 4.47408438e-01 4.25235450e-01 4.56319511e-01 3.95049334e-01
 4.02452201e-01 3.99127334e-01 4.00728375e-01 4.07962620e-01
 3.97654563e-01 3.97642553e-01 3.95599812e-01 4.06291842e-01
 4.10264850e-01 4.02506292e-01 4.10423875e-01 4.05018419e-01
 3.96495700e-01 3.92718643e-01 4.02163029e-01 3.98116827e-01
 4.01430070e-01 3.99041533e-01 4.09032792e-01 4.08314705e-01
 4.09112275e-01 4.05000865e-01 4.13605809e-01 3.98129672e-01
 4.00220513e-01 4.14005309e-01 4.12586510e-01 4.00056005e-01
 4.01556849e-01 4.03301716e-01 4.03239369e-01 4.05341864e-01
 4.03726459e-01 3.91692877e-01 4.03230309e-01 4.04977709e-01
 4.04744327e-01 4.03417021e-01 4.09483969e-01 4.06123400e-01
 3.92715752e-01 3.86957347e-01 3.97858113e-01 3.95261765e-01
 4.05662417e-01 3.85956883e-01 4.15748566e-01 3.67661178e-01
 4.15009737e-01 3.99933368e-01 3.90877426e-01 4.01722103e-01
 3.98556292e-01 3.92601788e-01 3.92391384e-01 3.82410765e-01
 3.98148835e-01 4.09431666e-01 3.94028902e-01 4.05201584e-01
 4.09191221e-01 3.83747071e-01 3.88650537e-01 3.92610252e-01
 3.83790731e-01 3.95052612e-01 3.94694984e-01 3.91441703e-01
 3.91333789e-01 4.10846293e-01 3.96095663e-01 4.00894165e-01
 4.14393425e-01 3.85948777e-01 4.03119832e-01 3.96344095e-01
 4.10640001e-01 3.67063761e-01 3.79931688e-01 4.01473105e-01
 3.93358737e-01], shape=(669,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(669,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1]
mse:tf.Tensor(0.15152547, shape=(), dtype=float32)
-------
mean(mse_list):0.23689185
