best_valid_epoch:55.0
train loss:0.010311994
valid loss:0.1946476
test loss list:tf.Tensor(0.25938788, shape=(), dtype=float32)
mean test loss:0.25938788
mean loss list:tf.Tensor(0.18364939, shape=(), dtype=float32)
mean mean loss:0.18364939
accuracy list:[<tf.Tensor: shape=(), dtype=float64, numpy=0.5761257302383291>]
mean accuracy:0.5761257302383291
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/21.c_000.smt2
true label:[0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1]
true label rank:[1 2 1 1 2 2 1 2 1 1 2 2 1 2 1 1 2 2 2 1 2 1 1 2 2]
predicted label:tf.Tensor(
[0.50924253 0.475891   0.4630643  0.5202621  0.4756889  0.50473034
 0.49674898 0.505954   0.47833607 0.4950813  0.4959928  0.5035851
 0.5182152  0.5003251  0.5076991  0.5342264  0.5601648  0.49441275
 0.4985288  0.50754493 0.48749727 0.49891198 0.4943505  0.4986308
 0.4971029 ], shape=(25,), dtype=float32)
rounded label:tf.Tensor(
[1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0.
 0.], shape=(25,), dtype=float32)
predicted label rank:[2 1 1 2 1 2 1 2 1 1 1 2 2 2 2 2 2 1 1 2 1 1 1 1 1]
mse:tf.Tensor(0.251371, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/PRODUCER_CONSUMER_all_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2
 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1 1 1 1 1 1 2 2 1
 1 1 2 2 2 2 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 2 1 2 2 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[8.30822110e-01 4.41843390e-01 5.15808463e-01 7.22731471e-01
 3.66549611e-01 3.59741896e-01 2.90584862e-02 8.62567306e-01
 6.32115480e-05 7.01221824e-02 2.49736905e-02 1.76340044e-02
 1.21798217e-02 1.21992826e-03 1.79220140e-02 8.85794520e-01
 9.99179482e-01 7.29611993e-01 4.04723585e-02 1.36332810e-02
 4.32834204e-05 9.84609127e-04 1.71244144e-04 7.23312736e-01
 9.90243793e-01 9.98851299e-01 3.31779391e-01 5.16700208e-01
 3.55454385e-01 3.84354264e-01 4.50254560e-01 5.59790492e-01
 3.28072011e-01 5.14801025e-01 3.54131609e-01 3.61098796e-01
 5.37125051e-01 6.72883272e-01 6.38513029e-01 4.58792448e-01
 5.88229477e-01 4.57296014e-01 8.29052806e-01 4.14210886e-01
 3.43518436e-01 7.69028544e-01 8.48891556e-01 7.24004030e-01
 8.46827149e-01 7.40251839e-02 2.68575430e-01 5.76377332e-01
 4.34966207e-01 5.47829866e-01 5.97488761e-01 7.85931349e-01
 2.19098061e-01 8.57548475e-01 3.28735530e-01 7.69393742e-01
 6.66521847e-01 3.88000846e-01 2.53849357e-01 4.13538158e-01
 7.94291735e-01 5.37281573e-01 6.66217268e-01 5.78920424e-01
 3.87415677e-01 3.89329195e-01 6.67479873e-01 4.70827371e-01
 7.13642478e-01 5.25246799e-01 4.03251410e-01 6.65215313e-01
 4.92252052e-01 4.82847840e-01 4.80997473e-01 4.87909138e-01
 4.77051705e-01 4.75797415e-01 4.77494240e-01 4.91842210e-01
 4.90030676e-01 4.80220258e-01 4.78089988e-01 4.85629708e-01
 4.66860294e-01 4.71778810e-01 4.86499280e-01 4.83333468e-01
 4.89883155e-01 4.81438190e-01 4.80303824e-01 4.72234011e-01
 4.76650804e-01 4.80160624e-01 4.59859192e-01 4.41803098e-01
 4.80400115e-01 4.84857321e-01 4.34338033e-01 4.84326631e-01
 4.17768449e-01 4.67544556e-01 4.23749775e-01 5.05478799e-01
 4.82971787e-01 5.37995815e-01 4.63572115e-01 4.90762562e-01
 5.05121469e-01 4.45538759e-01 5.07262707e-01 4.78800297e-01
 3.36077869e-01 5.82820952e-01 3.17988455e-01 4.61838871e-01
 5.80661535e-01 5.88941514e-01 2.93176770e-01 3.70609045e-01
 6.41441584e-01 6.37471437e-01 3.43278289e-01 4.35412616e-01
 5.54228663e-01 3.95756662e-01 4.73556876e-01 4.65249896e-01
 4.24004287e-01 5.14493465e-01 4.56879467e-01 4.64136839e-01
 4.68589902e-01 4.64094996e-01 4.49414551e-01 5.09540498e-01
 5.24643123e-01 4.94143903e-01 5.11702895e-01 4.30586547e-01
 4.62250680e-01 4.79323477e-01 4.63827759e-01 8.29940327e-05
 1.18964314e-02 4.57861171e-09 7.24716003e-08 1.98411942e-03
 2.17908328e-05 1.59564614e-03 1.00000000e+00 1.11361398e-04
 3.40898633e-02 3.38731682e-10 9.99432206e-01 9.96020913e-01
 2.67673433e-01 5.25576688e-05 9.99997258e-01 1.00000000e+00
 4.28169966e-04 1.00000000e+00 1.46249235e-02], shape=(167,), dtype=float32)
rounded label:tf.Tensor(
[1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.
 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.
 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0.
 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0.], shape=(167,), dtype=float32)
predicted label rank:[2 1 2 2 1 1 1 2 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2
 2 2 1 2 1 2 1 1 2 2 2 2 1 1 2 1 2 2 2 1 2 1 2 2 1 1 1 2 2 2 2 1 1 2 1 2 2
 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1
 1 2 1 2 1 1 2 1 1 2 2 1 1 2 2 1 1 2 1 1 1 1 2 1 1 1 1 1 2 2 1 2 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 2 2 1 1 2 2 1 2 1]
mse:tf.Tensor(0.31412086, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/nest-if3_true-unreach-call.c.flat_000.smt2
true label:[1, 1, 0, 1, 1, 1, 1]
true label rank:[2 2 1 2 2 2 2]
predicted label:tf.Tensor(
[0.49693114 0.5046048  0.4799462  0.4771174  0.49792585 0.52907544
 0.50712603], shape=(7,), dtype=float32)
rounded label:tf.Tensor([0. 1. 0. 0. 0. 1. 1.], shape=(7,), dtype=float32)
predicted label rank:[1 2 1 1 1 2 2]
mse:tf.Tensor(0.24557461, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0091_000.smt2
true label:[0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0]
true label rank:[1 2 2 1 1 1 2 2 1 1 1 2 2 1 1 1 2 2 1 1 2 2 1]
predicted label:tf.Tensor(
[0.49125972 0.51080227 0.48118597 0.51099646 0.46786958 0.50879765
 0.46325916 0.50236917 0.38205114 0.4405282  0.5008547  0.49980703
 0.5101451  0.49904138 0.4988112  0.49526986 0.50080436 0.5077337
 0.47736883 0.49730757 0.47642288 0.4746417  0.47461262], shape=(23,), dtype=float32)
rounded label:tf.Tensor([0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.], shape=(23,), dtype=float32)
predicted label rank:[1 2 1 2 1 2 1 2 1 1 2 1 2 1 1 1 2 2 1 1 1 1 1]
mse:tf.Tensor(0.24307527, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/const_1-1.c-1_000.smt2
true label:[1, 1]
true label rank:[1 1]
predicted label:tf.Tensor([0.5065144 0.5037897], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.24487635, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/NetBSD_glob3_iny.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[9.8649001e-01 1.0000000e+00 9.8711503e-01 9.9999797e-01 6.5920913e-01
 2.7147526e-01 4.4574872e-11 6.2613732e-01 3.3092637e-19 1.1987125e-05], shape=(10,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 0. 0. 1. 0. 0.], shape=(10,), dtype=float32)
predicted label rank:[2 2 2 2 2 1 1 2 1 1]
mse:tf.Tensor(0.4847858, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/minepump_spec2_product60_true-unreach-call.cil.c.flat_000.smt2
true label:[1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1]
predicted label:tf.Tensor([0.9990821  1.         0.9979042  0.9995379  0.87296414], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.0032287114, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/s3_clnt_2_true-unreach-call_true-termination.cil.c.flat_000.smt2
true label:[0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0]
true label rank:[1 2 2 1 2 1 1 1 2 2 2 1 2 1 1 1 1 1 1 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 1 1
 1 2 1 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 2 1 1 2 1]
predicted label:tf.Tensor(
[5.95549464e-01 5.40853500e-01 3.32274079e-01 4.10476983e-01
 3.76601696e-01 8.62707615e-01 3.78017604e-01 5.68222284e-01
 1.64121687e-02 4.01017368e-01 4.29766476e-02 1.09834015e-01
 3.04135233e-01 3.18411887e-02 7.81063139e-01 7.96685636e-01
 9.88455415e-01 8.48328829e-01 1.06018096e-01 2.39834964e-01
 3.96102667e-03 9.86093283e-03 4.31358814e-03 8.03344131e-01
 7.51608551e-01 7.02574849e-01 8.25688140e-09 9.99707878e-01
 8.26923497e-06 7.65760069e-06 3.93539667e-04 1.80245310e-01
 1.62968448e-07 9.90244150e-01 8.15838575e-04 2.10872075e-09
 9.78773713e-01 5.73930740e-01 9.99998987e-01 7.24732876e-04
 9.99888062e-01 6.69869781e-02 9.99994993e-01 1.74731016e-03
 1.88738406e-02 9.99993801e-01 9.99824584e-01 9.99000669e-01
 1.00000000e+00 2.85954320e-06 9.97240841e-01 6.30810857e-01
 6.01942658e-01 2.98632205e-01 1.00000000e+00 9.99996185e-01
 8.61797392e-01 1.00000000e+00 1.45566077e-07 7.75099814e-01
 1.32262707e-04 8.15475821e-01 3.02744219e-10 9.97004926e-01
 9.98664618e-01], shape=(65,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1.
 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.
 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1.], shape=(65,), dtype=float32)
predicted label rank:[2 2 1 1 1 2 1 2 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 2 2 2 1 2 1 1 1 1 1 2 1 1 2
 2 2 1 2 1 2 1 1 2 2 2 2 1 2 2 2 1 2 2 2 2 1 2 1 2 1 2 2]
mse:tf.Tensor(0.4579636, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/08.c_000.smt2
true label:[0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0]
true label rank:[1 2 2 1 1 1 2 2 1 1 1 2 2 1 1 1 2 2 1 1 2 2 1]
predicted label:tf.Tensor(
[0.49125972 0.51080227 0.48118597 0.51099646 0.46786958 0.50879765
 0.46325916 0.50236917 0.38205114 0.4405282  0.5008547  0.49980703
 0.5101451  0.49904138 0.4988112  0.49526986 0.50080436 0.5077337
 0.47736883 0.49730757 0.47642288 0.4746417  0.47461262], shape=(23,), dtype=float32)
rounded label:tf.Tensor([0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.], shape=(23,), dtype=float32)
predicted label rank:[1 2 1 2 1 2 1 2 1 1 2 1 2 1 1 1 2 2 1 1 1 1 1]
mse:tf.Tensor(0.24307527, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0002_000.smt2
true label:[1, 0]
true label rank:[2 1]
predicted label:tf.Tensor([0.4935469 0.5107132], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 2]
mse:tf.Tensor(0.25866136, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/barthe2_merged_safe.c-1_000.smt2
true label:[0, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 2 2 2 2 2 2 2 2 2]
predicted label:tf.Tensor(
[0.5071138  0.50570256 0.49351305 0.50382054 0.47293404 0.49139088
 0.5030304  0.5127204  0.47833484 0.487399  ], shape=(10,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 0. 0. 1. 1. 0. 0.], shape=(10,), dtype=float32)
predicted label rank:[2 2 1 2 1 1 2 2 1 1]
mse:tf.Tensor(0.25600138, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0036_000.smt2
true label:[0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1]
predicted label:tf.Tensor([0.6304753  0.3886306  0.36985207 0.5314017  0.41603917 0.7994294 ], shape=(6,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 1. 0. 1.], shape=(6,), dtype=float32)
predicted label rank:[2 1 1 2 1 2]
mse:tf.Tensor(0.29664782, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/dillig01.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.71024644 0.4600597  0.37124008 0.7283975  0.12017092 0.91009206
 0.21056408 0.9222683 ], shape=(8,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 1. 0. 1. 0. 1.], shape=(8,), dtype=float32)
predicted label rank:[2 1 1 2 1 2 1 2]
mse:tf.Tensor(0.39026397, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/gj2007_m_3_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.50377464 0.5169982  0.48111016 0.5247403  0.49029362 0.50413
 0.49283597 0.53882194 0.44470227 0.48749232 0.4588684  0.47436702
 0.43253297 0.48460802 0.51028806 0.52020067 0.52749145 0.4815818
 0.4569716  0.47694257], shape=(20,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.], shape=(20,), dtype=float32)
predicted label rank:[2 2 1 2 1 2 1 2 1 1 1 1 1 1 2 2 2 1 1 1]
mse:tf.Tensor(0.2604267, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/car_4_e3_57_e4_1047_000.smt2
true label:[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1
 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1
 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1
 2 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1
 2 1 1 2 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1
 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[7.84177065e-01 5.24394453e-01 4.48297560e-01 5.85718930e-01
 1.84614003e-01 7.28162110e-01 4.62377787e-01 7.32481480e-01
 7.71828592e-02 4.00927514e-01 2.79508024e-01 1.89020872e-01
 3.11719239e-01 2.85540521e-01 2.35940099e-01 2.93789804e-01
 8.91617417e-01 4.81700033e-01 2.05005199e-01 3.09653312e-01
 2.27514505e-01 1.22695774e-01 1.71302587e-01 7.37435222e-01
 7.70757437e-01 8.39104176e-01 2.95446396e-01 7.17256427e-01
 2.56555349e-01 1.95126742e-01 3.31799090e-01 2.69655526e-01
 4.28736210e-04 7.56391406e-01 8.08404386e-02 1.49644315e-02
 6.14667535e-01 8.24995041e-01 9.46323752e-01 2.89664567e-02
 9.50261652e-01 2.21257716e-01 9.87311363e-01 2.82383263e-01
 1.37268305e-01 9.20183301e-01 8.82933617e-01 3.03383708e-01
 8.58942628e-01 2.63583660e-03 7.53353834e-01 5.96198618e-01
 1.23478889e-01 4.49642301e-01 9.95150924e-01 9.91848111e-01
 6.50341690e-01 9.99254107e-01 2.82320082e-02 7.09874511e-01
 7.21030533e-01 4.35021192e-01 1.32524967e-03 6.49707198e-01
 9.70701098e-01 9.26415563e-01 9.45484877e-01 9.69302118e-01
 1.58221841e-01 2.67991185e-01 7.29165316e-01 2.29394436e-01
 9.85095024e-01 2.44321644e-01 1.07490331e-01 8.58063221e-01
 3.31634343e-01 1.96149051e-02 4.18375432e-01 7.42593408e-01
 1.53644383e-01 2.58741528e-01 3.73934537e-01 5.81099153e-01
 7.28508174e-01 6.82974339e-01 2.22534299e-01 5.56456804e-01
 3.64229143e-01 6.27880454e-01 6.07073188e-01 6.39974713e-01
 5.48753977e-01 4.16994691e-01 2.85729647e-01 4.95107681e-01
 2.04527676e-02 8.66292000e-01 1.59823984e-01 6.82249427e-01
 9.58296180e-01 9.82097507e-01 2.45953470e-01 9.57386851e-01
 7.32046962e-01 6.84788525e-02 2.59100348e-01 9.80153680e-03
 2.37671584e-01 9.99923944e-01 4.72505689e-02 5.09745479e-02
 1.39779150e-02 3.17878366e-01 2.89433628e-01 1.02607280e-01
 3.20279658e-01 2.77976781e-01 1.20496750e-02 8.33959460e-01
 5.39159775e-02 8.39643478e-01 1.02596283e-02 8.31034899e-01
 8.04789126e-01 9.18208838e-01 6.27776086e-02 2.46812403e-02
 5.71679175e-02 9.98711824e-01 1.74699157e-01 8.65517974e-01
 3.11568379e-01 9.39303041e-01 6.26350284e-01 2.09725410e-01
 2.04428047e-01 9.41809237e-01 1.35149956e-02 9.18063998e-01
 1.30260348e-01 4.85927463e-02 4.99118596e-01 4.80687171e-01
 4.60842788e-01 4.85141426e-01 4.93672311e-01 4.76258397e-01
 4.65081394e-01 5.06805003e-01 5.23244381e-01 4.71729755e-01
 4.97809827e-01 4.91551012e-01 4.81574327e-01 5.13636768e-01
 5.13457716e-01 5.03040493e-01 4.99304652e-01 4.87183213e-01
 4.98862654e-01 5.01900196e-01 5.08003652e-01 5.32887340e-01
 5.05525231e-01 4.89630878e-01 5.20569980e-01 4.98823524e-01
 4.90976572e-01 5.08102477e-01 4.80468124e-01 4.78330165e-01
 5.01948595e-01 5.03661335e-01 4.95054811e-01 4.92021501e-01
 4.89748329e-01 4.98683840e-01 4.93118078e-01 4.85621095e-01
 5.04891336e-01 4.91881877e-01 4.49847519e-01 4.57246989e-01
 4.55676794e-01 4.46593225e-01 4.42294359e-01 4.51918662e-01
 4.34358269e-01 4.56160992e-01 4.59191382e-01 4.54537213e-01
 4.44055885e-01 4.37914312e-01 4.55149442e-01 4.45602268e-01
 4.72408921e-01 4.67335194e-01 4.69444454e-01 4.74157691e-01
 5.07736325e-01 4.76656646e-01 4.51938063e-01 4.92517829e-01
 4.79649663e-01 4.92754012e-01 4.94981706e-01 4.69229102e-01
 4.61219341e-01 4.89007890e-01 4.54934657e-01 4.82475877e-01
 4.65905726e-01 4.67747331e-01 4.79205728e-01 4.91582870e-01
 4.73541170e-01 4.58187550e-01 4.77801055e-01 4.77552861e-01
 4.87881720e-01 4.57992435e-01 5.18617153e-01 4.82678443e-01
 4.88581777e-01 4.96201605e-01 4.67205942e-01 4.68210459e-01
 4.74080950e-01 4.91987705e-01 4.79232311e-01 4.76602554e-01
 4.83089238e-01 4.75813806e-01 4.84146774e-01 4.69130814e-01
 4.91932690e-01 4.63372648e-01 4.52271402e-01 4.95336980e-01
 4.55457985e-01 4.73349929e-01 4.94148761e-01 4.99390811e-01
 4.67908949e-01 4.67247218e-01 4.73982155e-01 4.73540276e-01
 4.75102156e-01 4.80741262e-01 1.65376395e-01 5.00896573e-02
 3.10075313e-01 9.69465554e-01 6.86392844e-01 8.71721208e-02
 1.22320890e-01 9.60612237e-01 3.42432201e-01 5.96780300e-01
 4.86195952e-01 4.67962682e-01 4.67607945e-01 4.53899473e-01
 4.62281793e-01 4.66895252e-01 4.52432603e-01 4.72429663e-01
 4.78632092e-01 4.93805140e-01 4.48852301e-01 4.93677169e-01
 5.72426975e-01 4.48647201e-01 4.79760587e-01 3.52991164e-01
 4.68501896e-01 3.49789917e-01 5.67959726e-01 6.42100215e-01
 5.15696466e-01 4.88785207e-01 5.65272152e-01 4.62712914e-01
 5.08885920e-01 4.84923452e-01 4.79372740e-01 5.15844047e-01
 4.72508341e-01 4.78327215e-01 4.98838454e-01 4.65787917e-01
 4.64757621e-01 4.92449611e-01 4.94115412e-01 4.97495085e-01
 4.99300122e-01 5.43951154e-01 4.94408101e-01 4.79826629e-01
 3.96623462e-01 5.33392668e-01 4.40541148e-01 4.06061530e-01
 4.70603853e-01 4.68763411e-01 5.22336781e-01 4.70768780e-01
 5.11031508e-01 4.42296684e-01 5.19000411e-01 4.60377276e-01
 3.95368934e-01 4.63774443e-01 5.03434777e-01 5.02756298e-01
 4.72685099e-01 4.78281319e-01 5.00579894e-01 5.25876105e-01
 5.11029720e-01 4.87464190e-01 4.90872622e-01 5.05797207e-01
 4.10827160e-01 4.59788889e-01 4.75571960e-01 5.22747934e-01
 5.05483508e-01 5.34992337e-01], shape=(330,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.
 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0.
 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0.
 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0.
 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0.
 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1.], shape=(330,), dtype=float32)
predicted label rank:[2 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 2 2 1 2 1 1 1 1 1 2 1 1 2
 2 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 2 2 2 2 1 2 2 1 1 2 2 2 2 2 1 1 2 1 2 1
 1 2 1 1 1 2 1 1 1 2 2 2 1 2 1 2 2 2 2 1 1 1 1 2 1 2 2 2 1 2 2 1 1 1 1 2 1
 1 1 1 1 1 1 1 1 2 1 2 1 2 2 2 1 1 1 2 1 2 1 2 2 1 1 2 1 2 1 1 1 1 1 1 1 1
 1 2 2 1 1 1 1 2 2 2 1 1 1 2 2 2 2 1 2 1 1 2 1 1 2 2 1 1 1 1 1 1 2 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 2 2 1 2 1 2 1 1 2 1 1 1 1 1 1 1 1
 1 2 1 1 1 2 1 1 1 1 2 1 2 1 2 1 1 1 2 2 1 1 2 2 2 1 1 2 1 1 1 2 2 2]
mse:tf.Tensor(0.28730723, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/stalmark_000.smt2
true label:[0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1]
predicted label:tf.Tensor([0.5671091  0.45624864 0.45332387 0.5962014  0.40815642 0.6400962 ], shape=(6,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 1. 0. 1.], shape=(6,), dtype=float32)
predicted label rank:[2 1 1 2 1 2]
mse:tf.Tensor(0.2778415, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/minepump_spec5_product56_true-unreach-call.cil.c.flat_000.smt2
true label:[1, 1, 1, 1]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([1.         1.         0.01270929 1.        ], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1.], shape=(4,), dtype=float32)
predicted label rank:[2 2 1 2]
mse:tf.Tensor(0.24368575, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0303_000.smt2
true label:[0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1]
true label rank:[1 2 1 ... 2 2 2]
predicted label:tf.Tensor([0.49776793 0.5274556  0.49595055 ... 0.47873887 0.5014465  0.50274855], shape=(1640,), dtype=float32)
rounded label:tf.Tensor([0. 1. 0. ... 0. 1. 1.], shape=(1640,), dtype=float32)
predicted label rank:[1 2 1 ... 1 2 2]
mse:tf.Tensor(0.2621483, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0276_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[1.5246946e-01 1.0000000e+00 1.7081828e-09 1.0000000e+00 9.8689026e-01
 7.9723441e-07 1.0000000e+00 5.0911659e-01 4.9954745e-01 4.7242019e-01
 4.4200563e-01 4.6270475e-01 4.4781384e-01 4.5086190e-01 4.6495813e-01
 4.8635262e-01 4.8280135e-01 4.9667200e-01 4.9028724e-01 4.8298278e-01
 4.8462787e-01 4.7019342e-01 4.9164924e-01 4.6686095e-01 4.9878550e-01
 4.9496409e-01 4.7436982e-01 4.8160824e-01 4.8922881e-01 4.9140877e-01
 4.9829710e-01 5.0459754e-01 4.9801388e-01 4.9708807e-01 4.8007941e-01
 4.8935869e-01 4.6961400e-01 4.8577794e-01 4.6804744e-01 5.1006556e-01
 4.9426544e-01 5.0052333e-01 5.0237584e-01 4.8304430e-01 4.8933652e-01
 4.9277148e-01 5.1422560e-01 4.8714012e-01 5.0137258e-01 4.8857638e-01
 4.9410751e-01 4.9920115e-01 4.7723281e-01 4.8402706e-01 4.8362097e-01
 4.9543211e-01 4.7460046e-01 5.0574493e-01 4.6093252e-01 5.0272650e-01
 4.8536354e-01 5.0677013e-01 4.7924581e-01 5.0523961e-01 4.9798882e-01
 4.6429378e-01 5.1515454e-01 4.9880269e-01 4.8996478e-01 4.9180987e-01
 5.0137496e-01 4.9961317e-01 5.2448124e-01 4.8089713e-01 4.7982311e-01
 5.0882202e-01 4.9471262e-01 4.7918653e-01 4.8076367e-01 4.7386956e-01
 4.6681964e-01 4.9878502e-01 5.0167269e-01 4.9961138e-01 5.0793236e-01
 4.9819675e-01 4.7295472e-01 4.2611033e-01 4.0584928e-01 4.9610412e-01
 5.0348359e-01 5.5775851e-01 4.9276063e-01 4.6240929e-01 3.9533159e-01
 6.1189020e-01 4.8662066e-01 4.9350527e-01 4.8324960e-01 5.5058342e-01
 5.6799018e-01 6.3846570e-01 4.6807039e-01 6.1894739e-01 5.0846821e-01
 4.2074129e-01 5.3816229e-01 4.7387853e-01 5.4272127e-01 7.7731502e-01
 4.5855135e-01 4.2827395e-01 3.8129941e-01 5.8714992e-01 5.0423819e-01
 5.0697702e-01 4.9007827e-01 4.9875584e-01 3.5332817e-01 5.7221329e-01
 4.5575890e-01 5.2917278e-01 4.2825264e-01 5.9586990e-01 6.1296272e-01
 6.2354434e-01 4.2234075e-01 5.0298738e-01 3.8465255e-01 6.9036180e-01
 4.3120092e-01 4.2630988e-01 4.1525647e-01 4.4642782e-01 4.5083305e-01
 3.7862056e-01 4.8556113e-01 5.5086380e-01 3.4571224e-01 5.1438600e-01
 4.1887707e-01 4.2756474e-01 4.7344321e-01 6.5573281e-01 3.5434562e-01
 4.5421380e-01 6.0322702e-01 5.5311352e-01 3.5121328e-01 6.0947394e-01
 6.4102978e-01 5.0981379e-01 4.7037110e-01 5.4791558e-01 4.0407547e-01
 4.8827025e-01 5.0581402e-01 4.0097564e-01 4.2490938e-01 6.0020655e-01
 4.2480454e-01 4.4593632e-01 5.8917171e-01 4.7791153e-01 5.6576461e-01
 5.6168467e-01 4.2442295e-01 5.2202243e-01 4.8517394e-01 3.8063371e-01
 3.7687966e-01 4.2881650e-01 3.5173449e-01 5.1797062e-01 4.6460205e-01
 4.0705779e-01 4.5110369e-01 4.4765052e-01 5.2575624e-01 3.1635258e-01
 4.1373104e-01 5.1642203e-01 4.4970715e-01 4.5359540e-01 6.6200608e-01
 5.2261436e-01 5.6958878e-01 6.4535296e-01 4.7907948e-01 5.4794693e-01
 6.1963421e-01 5.7451355e-01 5.8656603e-01 4.0412617e-01 5.3037852e-01
 2.9331714e-01 4.1402191e-01 6.5825665e-01 5.4134446e-01 4.7636154e-01
 5.5688292e-01 3.1951088e-01 3.0193397e-01 3.2487720e-01 3.6432722e-01
 5.8208323e-01 6.5243030e-01 4.6026278e-01 3.5464853e-01 5.6400186e-01
 4.5115861e-01 3.6890244e-01 4.6176115e-01 4.3949208e-01 5.1672471e-01
 6.7422128e-01 6.6786557e-01 4.2050719e-01 6.1570668e-01 4.9765587e-01
 5.0961190e-01 6.2650442e-01 5.0251621e-01 4.6221286e-01 5.1204836e-01
 4.8502979e-01 3.1721312e-01 4.2551041e-01 5.5371362e-01 4.9590024e-01
 2.7550161e-01 4.3536830e-01 3.4727275e-01 3.4938949e-01 5.3721941e-01
 7.4864483e-01 5.9176773e-01 6.9493687e-01 2.7110288e-01 3.7041140e-01
 3.6202949e-01 3.8151869e-01 4.6821174e-01 5.5745661e-01 5.9383643e-01
 5.3549469e-01 5.6301641e-01 4.2439979e-01 4.5699298e-01 6.6298997e-01
 4.4765040e-01 3.5296476e-01 4.1820842e-01 5.8652735e-01 4.9990192e-01
 3.7584636e-01 3.3944684e-01 6.4535677e-01 3.7581578e-01 5.0862932e-01
 4.9857050e-01 6.0534561e-01 5.5953586e-01 5.1335841e-01 4.6704468e-01
 5.1548415e-01 5.6493074e-01 4.8904705e-01 5.1609838e-01 6.2036425e-01
 4.0441597e-01 5.6298047e-01 5.3833294e-01 5.0061828e-01 4.9513596e-01
 3.3079401e-01 3.7707171e-01 3.2661015e-01 4.5572317e-01 5.6101972e-01
 4.9440980e-01 4.2922786e-01 4.1358152e-01 3.5628980e-01 5.4547167e-01
 4.0789825e-01 6.7415613e-01 5.0216669e-01 5.0729305e-01 6.3710141e-01
 4.7188187e-01 4.0280962e-01 3.8109961e-01 6.2989616e-01 7.8187764e-01
 4.4730794e-01 6.1097312e-01 5.8140320e-01 5.3229302e-01 4.3686163e-01
 3.3563769e-01 6.5814298e-01 5.4961139e-01 2.4872831e-01 3.9202759e-01
 1.7117810e-01 5.2180147e-01 6.2658656e-01 2.9636094e-01 3.7846091e-01
 6.3638544e-01 4.0381354e-01 4.0417692e-01 3.4862664e-01 5.3246498e-01
 6.1643112e-01 5.3009468e-01 3.8562500e-01 5.6714821e-01 5.2445132e-01
 4.6157959e-01 4.8569137e-01 5.3182614e-01 6.3333219e-01 5.2706754e-01
 4.9431381e-01 3.9466915e-01 4.7087473e-01 5.2220535e-01 6.2532216e-01
 4.3236029e-01 3.6006874e-01 6.3739443e-01 3.9923555e-01 5.2010083e-01
 4.5370919e-01 2.8779534e-01 5.1263636e-01 6.6901112e-01 3.5623574e-01
 4.3869877e-01 5.0649178e-01 4.1943726e-01 4.0538064e-01 4.5003450e-01
 4.7788435e-01 4.3809882e-01 4.6177438e-01 4.1363180e-01 4.6520108e-01
 4.9058026e-01 5.3268415e-01 3.7382704e-01 5.6741500e-01 4.9284300e-01
 4.4372553e-01 4.5716065e-01 4.1705799e-01 5.8161461e-01 4.5113391e-01
 5.3404164e-01 3.9904124e-01 5.1596934e-01 4.2112604e-01 3.7035143e-01
 5.1318568e-01 5.3854477e-01 5.0112444e-01 4.4286004e-01 5.7833701e-01
 4.1734970e-01 4.9710929e-01 5.1663816e-01 4.2987925e-01 3.1319493e-01
 5.0759953e-01 4.7836095e-01 4.6649072e-01 3.5838085e-01 5.3568566e-01
 3.7045673e-01 4.5539623e-01 5.4093343e-01 6.7260158e-01 3.3060282e-01
 4.7095311e-01 5.2769899e-01 6.1379397e-01 4.7054815e-01 5.6023318e-01
 4.3825585e-01 5.8430225e-01 3.7844211e-01 4.7928101e-01 4.3824825e-01
 5.7805526e-01 5.0238526e-01 2.6598483e-01 4.4479001e-01 5.5186129e-01
 5.4199016e-01 5.9230363e-01 7.3130935e-01 5.4931474e-01 5.7779944e-01
 5.9165132e-01 5.7292175e-01 3.5997725e-01 6.6900384e-01 5.0831723e-01
 4.8238787e-01 5.5863941e-01 3.8674822e-01 4.7646981e-01 6.3172531e-01
 5.9457934e-01 4.5615712e-01 3.5275525e-01 5.4275942e-01 4.9406591e-01
 5.5427408e-01 5.4744399e-01 5.7307565e-01 5.7333869e-01 3.5408312e-01
 6.3381082e-01 4.7362903e-01 3.9589873e-01 5.9708512e-01 5.8812755e-01
 4.5045346e-01 4.8662975e-01 4.6856615e-01 4.6712974e-01 4.2249405e-01
 5.4617167e-01 5.6519824e-01 6.8800777e-01 5.0656319e-01 5.3592187e-01
 3.7373215e-01 5.4121435e-01 6.3863516e-01 5.8613962e-01 3.6592436e-01
 5.6552553e-01 5.1834774e-01 4.3997857e-01 4.9126428e-01 5.5517441e-01
 5.0731289e-01 5.0130504e-01 4.8064166e-01 5.1445442e-01 3.7727338e-01
 5.4422140e-01 4.7379833e-01 5.6547421e-01 4.9624762e-01 6.0576797e-01
 5.4727888e-01 6.9451582e-01 4.3044481e-01 4.8874369e-01 5.7713723e-01
 5.3710616e-01 5.1909047e-01 5.3705174e-01 5.9726828e-01 3.8129637e-01
 4.6394578e-01 3.7995175e-01 5.5684835e-01 4.7836348e-01 5.1267725e-01
 5.4028958e-01 5.2436787e-01 6.0510415e-01 3.5923797e-01 4.8058450e-01
 4.9301094e-01 4.7897440e-01 6.0307175e-01 4.4556290e-01 5.6485617e-01
 4.6454492e-01 3.8148528e-01 5.5331171e-01 5.4698139e-01 4.2568299e-01
 4.0944973e-01 6.0614753e-01 5.7123977e-01 5.2609581e-01 4.5284906e-01
 3.3949882e-01 4.7084028e-01 4.4803277e-01 4.0388367e-01 5.1697695e-01
 5.8643365e-01 3.5730940e-01 4.5756745e-01 4.9885711e-01 4.2050722e-01
 5.0996780e-01 4.3513691e-01 5.2796239e-01 5.2321601e-01 4.8026317e-01
 5.0307024e-01 4.8415306e-01 4.8704863e-01 5.2635533e-01], shape=(514,), dtype=float32)
rounded label:tf.Tensor(
[0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.
 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1.
 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.
 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1.
 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1.
 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0.
 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1.
 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1.
 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0.
 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0.
 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.
 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1.
 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0.
 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0.
 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1.
 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0.
 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.
 0. 1. 0. 1. 1. 0. 1. 0. 0. 1.], shape=(514,), dtype=float32)
predicted label rank:[1 2 1 2 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 2 1 2 2 1 1 1 2 1 2 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1 1 2 1 2 1
 1 2 1 1 1 1 1 1 2 1 2 1 1 1 1 1 2 2 1 1 1 2 1 1 1 2 2 2 1 2 2 1 2 1 2 2 1
 1 1 2 2 2 1 1 1 2 1 2 1 2 2 2 1 2 1 2 1 1 1 1 1 1 1 2 1 2 1 1 1 2 1 1 2 2
 1 2 2 2 1 2 1 1 2 1 1 2 1 1 2 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 2 1 1 2
 2 2 2 1 2 2 2 2 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2 1 1 1 1 2 2 2 1 2 1 2 2
 2 1 2 1 1 1 2 1 1 1 1 1 2 2 2 2 1 1 1 1 1 2 2 2 2 1 1 2 1 1 1 2 1 1 1 2 1
 2 1 2 2 2 1 2 2 1 2 2 1 2 2 2 1 1 1 1 1 2 1 1 1 1 2 1 2 2 2 2 1 1 1 2 2 1
 2 2 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 2 2 1 1 2 2 2 1 1 1 2 2 1 1 2
 1 2 1 1 2 2 1 1 2 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 2 1 2
 1 1 2 1 1 2 1 1 1 2 1 1 2 2 1 1 2 2 1 2 1 2 1 1 1 2 2 1 1 2 2 2 2 2 2 2 2
 1 2 2 1 2 1 1 2 2 1 1 2 1 2 2 2 2 1 2 1 1 2 2 1 1 1 1 1 2 2 2 2 2 1 2 2 2
 1 2 2 1 1 2 2 2 1 2 1 2 1 2 1 2 2 2 1 1 2 2 2 2 2 1 1 1 2 1 2 2 2 2 1 1 1
 1 2 1 2 1 1 2 2 1 1 2 2 2 1 1 1 1 1 2 2 1 1 1 1 2 1 2 2 1 2 1 1 2]
mse:tf.Tensor(0.2527545, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/reverse_div_unsafe.c_000.smt2
true label:[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.51845086 0.52707905 0.50125116 0.5166421  0.4978614  0.5299496
 0.5054358  0.51852167 0.50302833 0.52412206 0.5171229  0.516441
 0.51424724 0.5146469  0.5058563  0.53395194 0.54244184 0.52781034
 0.5007231  0.5015247  0.49554953 0.50693053 0.52550286 0.5109021
 0.5119316  0.5236614  0.5413812  0.50136805 0.51606166 0.50388634
 0.5015108  0.51709986 0.5319023  0.49840823 0.52412546 0.50441784
 0.5188223  0.52024996 0.516442   0.4931681  0.5224175  0.5108178
 0.48246977 0.5205953  0.5257257  0.5174913  0.52315867 0.52541465
 0.5316149  0.5148892  0.5320016  0.49833256 0.51617163 0.5095113
 0.5170996  0.5093341  0.5057768  0.5326521  0.52952415 0.50916207
 0.5212743  0.5084431  0.5204445  0.510794   0.52521014 0.50818294
 0.5148322  0.51884747 0.5069202  0.48434108 0.53995794 0.5208936
 0.52431434 0.5014171  0.51535386 0.52830434 0.5343856  0.51282734
 0.51819587 0.5139508  0.5024509  0.5324034  0.52437925 0.51647794
 0.5033658  0.5036324  0.49129242 0.4827861  0.4711136  0.4782273
 0.48672462 0.4911954  0.48969266 0.48057944 0.46324563 0.48429292
 0.50015837 0.45297322 0.47226167 0.44756323 0.46298257 0.4769298
 0.47522962 0.45911184 0.47311595 0.47051638 0.4486503  0.50161153
 0.46948856 0.5050798  0.4397661  0.46502048 0.4447552  0.4429384
 0.47987935 0.4907157  0.47366557 0.46738628 0.47252765 0.46200436
 0.47021163 0.46698588 0.4867897  0.4727737  0.45013976 0.48037878
 0.44805452 0.45576507 0.46471128 0.46034566 0.47985727 0.4910077
 0.46814883 0.4451149  0.46281826 0.43987432 0.4728968  0.44707653
 0.46933144 0.46661627 0.4955069  0.4697183  0.4670846  0.45767632
 0.45044586 0.46940598 0.4669897  0.44022503 0.4972081  0.47436193
 0.48536372 0.44853133 0.46346313 0.45052838 0.4739376  0.48570588
 0.44027507 0.4766493  0.4779235  0.4654735  0.48873797 0.48566526
 0.46455762 0.49516067 0.4740436  0.46835527 0.4694814  0.448687
 0.46684617 0.45567447 0.46880895 0.46801487 0.4773261  0.47138578
 0.44498616 0.46701527 0.4521129  0.45953512 0.4957342  0.4666219
 0.44418654 0.48186338 0.4947049  0.4626199  0.43637282 0.4654682
 0.46200022 0.48867258 0.47391665 0.46520638 0.49749115 0.47701126
 0.45152557 0.46463746 0.44758397 0.50039625 0.4680758  0.46694878
 0.45398468 0.48988262 0.50859576 0.47956127 0.4705428  0.47692758
 0.450906   0.4510756  0.49573484 0.49203986 0.4229902  0.48422813
 0.4965992  0.4811538  0.49024826 0.4995758  0.49910042 0.4892364
 0.518389   0.48299995 0.50969994 0.4813854  0.47967306 0.49592745
 0.4837748  0.50450754 0.47162393 0.49298432 0.46226978 0.500879
 0.4916942  0.5011642  0.49307248 0.48008335 0.45984048 0.45166147
 0.4903203  0.5081744  0.47585723 0.50430447 0.46589488 0.480697
 0.48041457 0.45786247 0.49116498 0.46167928 0.48861808 0.46666726
 0.506804   0.46109915 0.4952263  0.48825002 0.48588026 0.48006448
 0.4778107  0.5082605  0.49208587 0.48273996 0.46918768 0.4650449
 0.47568998 0.48634687 0.4807502  0.48738882 0.48766533 0.48534447
 0.48513356 0.4758935  0.4981013  0.4752743  0.496532   0.4885611
 0.46454257 0.48244014 0.49885175 0.5115714  0.47551048 0.4710493
 0.4977974  0.47494754 0.48955178 0.4974869  0.4814812  0.49126026
 0.47631976 0.47531402 0.48738936 0.4862064  0.50321835 0.4898024
 0.49959382 0.4917882  0.48798463 0.4936296  0.49319494 0.47627994
 0.51197934 0.48265246 0.5038843  0.4876132  0.47960484 0.47310475
 0.47629732 0.48481005 0.49067903 0.46895888 0.4959274  0.4944198
 0.49311486 0.505148   0.4810814  0.47425735 0.5051209  0.48780492
 0.5046926  0.4585958  0.4933612  0.50184935 0.49000373 0.47021985
 0.49824396 0.49491554 0.50218767 0.47620445 0.49362528 0.52061236
 0.48057812 0.48582304 0.4956162  0.47940665 0.4911952  0.50244784
 0.48848423 0.4845116  0.5053035  0.4597478  0.47099277 0.4809182
 0.48135638 0.48246723 0.5235282  0.47848356 0.4883342  0.47920898
 0.49062192 0.49149084 0.4774821  0.47801292 0.47647262 0.49478278
 0.47152174 0.4848998  0.50364995 0.48254138 0.48479348 0.50468916
 0.48410413 0.482634   0.48939177 0.47472197 0.49360406 0.4558153
 0.465278   0.4890061  0.48856366 0.48342925 0.5078969  0.47011793
 0.4883758  0.45046186 0.4946631  0.47534698 0.49623573 0.4780881
 0.46839672 0.4819615  0.4903425  0.46546218 0.47285676 0.4965324
 0.48979855 0.46707416 0.46601415 0.4680157  0.50558335 0.4624149
 0.48754582 0.4921226  0.44659272 0.49051297 0.5024248  0.47582996
 0.4745215  0.45825717 0.45805472 0.4624465  0.47727704 0.48783305
 0.45668164 0.48066115 0.48014066 0.46052876 0.45946932 0.49838567
 0.4830741  0.4810873  0.4704191  0.4632779  0.45025244 0.47785595
 0.44689274 0.46580243 0.46398786 0.4673782  0.50233656 0.48420832
 0.4566322  0.4720884  0.5056691  0.47002625 0.49055666 0.47451305
 0.50749385 0.48645487 0.48164588 0.504692   0.47609237 0.4567966
 0.47779524 0.47140822 0.488523   0.4938193  0.46661314 0.4718416
 0.4567478  0.48158297 0.47797915 0.46812442 0.5082681  0.49185562
 0.49553612 0.4897706  0.4816502  0.46216443 0.466085   0.47391424
 0.4841379  0.5028781  0.4849859  0.5162209  0.4957738  0.50300586
 0.4917319  0.47668386 0.48710492 0.4907112  0.47159564 0.47837272
 0.48630565 0.49939457 0.50553745 0.4824773  0.51275325 0.48631316
 0.47963053 0.47273883 0.4737948  0.46552554 0.44625524 0.4902637
 0.46810225 0.44916824 0.4887302  0.4718876  0.4989894  0.45712268
 0.47335544 0.46943495 0.47807792 0.47769868 0.4727437  0.48193297
 0.49299073 0.4763778  0.5015369  0.473225   0.44729862 0.48509875
 0.44382825 0.50535655 0.5003197  0.48544312 0.49105194 0.47379467
 0.4810286  0.4958368  0.4929984  0.4768343  0.49088278 0.49994457
 0.497163   0.51075315 0.47601253 0.46228296 0.48997194 0.4741989
 0.46446845 0.46029922 0.47030747 0.46916068 0.48320502 0.46689364
 0.49977288 0.4724504  0.45953134 0.48258126 0.487865   0.46342304
 0.45704627 0.4687148  0.48916855 0.4531186  0.4732521  0.49288654
 0.47652805 0.50636756 0.49194637 0.47155982 0.44574046 0.49381936
 0.49046838 0.49317265 0.4933692  0.48572484 0.48399058 0.49124637
 0.48657596 0.4827367  0.4808093  0.49120682 0.49094322 0.49995002
 0.4831233  0.48952982 0.49505106 0.48786885 0.49386793 0.48786652
 0.48106286 0.48862424 0.48923025 0.4868715  0.48154497 0.47575298
 0.48655444 0.48984584 0.4867993  0.47972822 0.47502145 0.487374
 0.4788048  0.48746198 0.4868265  0.49257007 0.48849252 0.48815545
 0.48762667 0.48170552 0.4826094  0.48621872 0.4855378  0.48715055
 0.4883649  0.49334323 0.48774424 0.48134527 0.48295078 0.4825503
 0.49188754 0.4868316  0.48261422 0.4891085  0.48637477 0.4831452
 0.49212524 0.4875583  0.49323982 0.48260757 0.4777457  0.47466588
 0.48897138 0.4913476  0.49433059 0.4912654  0.48050633 0.4803329
 0.49296942 0.48862085 0.4875711  0.4934897  0.48635793 0.47955784
 0.48808002 0.49397132 0.49570382 0.4853064  0.49357098 0.49385974
 0.48597205 0.47762674 0.496781   0.50182056 0.48297888 0.49712646
 0.496506   0.4879683  0.48089236 0.48135823 0.47891623 0.49225637
 0.4834009  0.4761833  0.48690724 0.48573157 0.48846504 0.4898178
 0.4810065  0.4918854  0.48326132 0.48929363 0.48035535 0.48488453
 0.48435605 0.48201638 0.47632608 0.48985007 0.49466836 0.4860317
 0.48968944 0.4837902  0.48082265 0.48725602 0.48406577 0.48383093
 0.4944492  0.49160865 0.48907816 0.47898784 0.49757725 0.49178255
 0.48759377 0.47797778 0.49643385 0.48467186 0.4844324  0.48977163
 0.4850577  0.49077109 0.49253896 0.4581313  0.4575866  0.48426282
 0.4728719  0.45642763 0.4521576  0.46965596 0.45499772 0.45017856
 0.45993066 0.47435257 0.464051   0.4663257  0.46937022 0.46028504
 0.4512208  0.4879171  0.4562362  0.4788188  0.4525522  0.45658407
 0.4654886  0.47239214 0.4776412  0.48144883 0.48994347 0.49264345
 0.48730704 0.49711093 0.4795914  0.48309046 0.48176676 0.46930522
 0.47273737 0.4771539  0.4539073  0.48982894 0.47123867 0.4821222
 0.48470324 0.4722917  0.47531027 0.4725311  0.47809634 0.47001234
 0.4855487  0.47757414 0.48028797 0.48094693 0.48294973 0.48274925
 0.49400064 0.48103702 0.49026245 0.5249862  0.5072922  0.51808363
 0.51734835 0.50433916 0.5100394  0.5128902  0.50843775 0.5260024
 0.51588035 0.5034512  0.50843966 0.5023879  0.5045111  0.50642526
 0.5122231  0.5197055  0.5255835  0.5030697  0.48750597 0.49496177
 0.51308566 0.5180892  0.50899494 0.5117869  0.52004015 0.5082174
 0.4973808  0.5076673  0.51933163 0.5083682  0.5102316  0.5126284
 0.517594   0.52416956 0.5127341  0.5008302  0.5130469  0.5110572
 0.46920455 0.45650557 0.46608198 0.46752688 0.46029434 0.4621396
 0.47104445 0.46343648 0.4586348  0.46774504 0.4678783  0.46035576
 0.47114116 0.47253096 0.4619953  0.46486306 0.45980892 0.4587274
 0.47165087 0.46656123 0.46698022 0.45882314 0.46538436 0.45392442
 0.47117725 0.45451978 0.48472264 0.47460935 0.4478166  0.45373958
 0.4601228  0.4637641  0.4772969  0.45882106 0.4558048  0.46048743
 0.45050997 0.46454826 0.4624794  0.4581546  0.45956296 0.45927325
 0.47054946 0.4667774  0.45109254 0.44388995], shape=(796,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1.
 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0.], shape=(796,), dtype=float32)
predicted label rank:[2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2
 2 2 1 2 2 1 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1
 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1
 2 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 1 2
 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1
 1 2 1 2 1 2 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 1 2
 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.2385088, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0264_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[1.0000000e+00 1.0000000e+00 4.6685832e-07 9.9976999e-01 9.3653703e-01
 9.5936614e-01 1.0000000e+00 1.0000000e+00 4.8510751e-01 5.0411570e-01
 4.6021679e-01 4.4604027e-01 4.5733568e-01 4.5450616e-01 4.6293196e-01
 4.6635836e-01 4.4750860e-01 4.1521135e-01 4.4118929e-01 3.3933759e-01
 3.2540330e-01 3.2787293e-01 2.2110572e-01 5.2427268e-01 6.7439699e-01
 5.0629497e-01 3.6763996e-01 7.0641840e-01 3.4956846e-01 4.7104988e-01
 4.7183487e-01 4.2034355e-01 2.4396059e-01 5.2576220e-01 5.1561421e-01
 3.0884713e-01 5.6636155e-01 6.6198671e-01 5.8175838e-01 4.5219541e-01
 6.4048553e-01 4.4486833e-01 7.3189270e-01 4.5067519e-01 4.5609993e-01
 5.8921397e-01 5.9790862e-01 4.5643362e-01 6.1267489e-01 2.2717142e-01
 4.7063339e-01 4.6460298e-01 4.5211536e-01 4.9027792e-01 6.0823220e-01
 6.1203742e-01 4.3448889e-01 6.0921758e-01 3.5204056e-01 5.6191021e-01
 5.5392677e-01 4.8219907e-01 3.2120630e-01 5.4316378e-01 7.5501597e-01
 3.9066756e-01 5.6900215e-01 6.9021702e-01 3.0419177e-01 4.2876127e-01
 6.7357004e-01 4.1641825e-01 6.9365138e-01 5.3904927e-01 4.0175930e-01
 6.0704559e-01 5.9562290e-01 3.4437937e-01 3.9811671e-01 6.1480749e-01
 1.7554665e-01 2.1230417e-01 4.0753102e-01 6.1118966e-01 7.4383008e-01
 4.5525280e-01 3.6966568e-01 4.2930800e-01 4.8936203e-01 5.8261645e-01
 5.2839422e-01 5.6600356e-01 5.9453750e-01 5.2763528e-01 4.1579646e-01
 5.9402627e-01 4.8701340e-01 5.9116846e-01 5.0939494e-01 5.5917019e-01
 5.7069761e-01 4.0362731e-01 4.9446455e-01 5.9785575e-01 4.8890418e-01
 4.5690799e-01 6.7522836e-01 4.2520994e-01 4.7492975e-01 7.8118098e-01
 5.1165605e-01 3.7658063e-01 3.8338977e-01 5.8338368e-01 5.3286690e-01
 4.5943975e-01 4.7492656e-01 6.1726815e-01 3.3870563e-01 5.7748228e-01
 4.5307887e-01 5.9440494e-01 3.3088946e-01 4.4446427e-01 5.9824133e-01
 5.9128463e-01 4.5368516e-01 3.9134437e-01 3.8310993e-01 6.6576624e-01
 5.1608717e-01 5.5112284e-01 4.3026978e-01 5.6283921e-01 5.6742722e-01
 4.5543194e-01 5.1203209e-01 4.1847974e-01 3.0017906e-01 5.5491722e-01
 4.1998714e-01 4.2308640e-01 3.9951092e-01 5.9347153e-01 3.2402277e-01
 5.2125740e-01 6.1231613e-01 5.9896028e-01 4.2976451e-01 5.2304518e-01
 5.6306279e-01 3.5821509e-01 3.3159080e-01 5.4192036e-01 4.4591948e-01
 5.8715737e-01 6.1550272e-01 4.0194860e-01 3.4994018e-01 3.9832634e-01
 5.7113975e-01 6.2032866e-01 4.5663130e-01 5.1199210e-01 6.3528883e-01
 6.0249048e-01 4.5047233e-01 4.9651113e-01 6.1103022e-01 4.0555233e-01
 3.2221350e-01 3.5028481e-01 4.2446572e-01 4.4177032e-01 4.2253470e-01
 3.6478707e-01 5.5613202e-01 4.3113858e-01 4.7554860e-01 3.5823804e-01
 4.4246688e-01 5.3699666e-01 4.4189674e-01 5.6834453e-01 6.8232554e-01
 6.0519195e-01 5.5488580e-01 6.7102808e-01 3.6062896e-01 4.9315724e-01
 5.3537959e-01 6.3330865e-01 5.3072554e-01 3.8180441e-01 5.0131345e-01
 1.8575764e-01 2.7277032e-01 7.0156527e-01 5.2872872e-01 4.1336238e-01
 6.7209780e-01 3.1913137e-01 3.1097701e-01 3.5335577e-01 4.9184826e-01
 5.5383027e-01 7.0275003e-01 5.5131000e-01 3.8009983e-01 4.3352139e-01
 3.8099104e-01 3.5819137e-01 4.1684723e-01 2.6689005e-01 6.7613447e-01
 6.6018641e-01 6.4163375e-01 5.5052859e-01 5.0829691e-01 4.6469843e-01
 5.7098335e-01 6.3898969e-01 5.2413744e-01 4.6424922e-01 4.8195907e-01
 4.9500367e-01 4.4513762e-01 2.8876922e-01 5.3254586e-01 5.0530583e-01
 3.4549814e-01 4.8803550e-01 3.8528764e-01 2.5160170e-01 6.8687868e-01
 6.9038630e-01 4.4857046e-01 4.8172498e-01 3.7001312e-01 3.1359723e-01
 3.4785795e-01 3.0326369e-01 4.2476100e-01 4.7759846e-01 6.1268127e-01
 5.1463157e-01 5.8773792e-01 4.9269333e-01 3.4410942e-01 7.1967661e-01
 4.0830559e-01 3.4116209e-01 4.2212331e-01 6.0302389e-01 5.6717181e-01
 2.5387645e-01 2.7901310e-01 6.1635154e-01 5.0881231e-01 5.4889548e-01
 5.3558630e-01 6.1339456e-01 5.7566988e-01 5.5744588e-01 4.8865980e-01
 5.6793225e-01 5.8650756e-01 4.7741535e-01 4.7729573e-01 5.0349700e-01
 4.3640882e-01 5.2409095e-01 5.3857386e-01 5.1698154e-01 5.0772160e-01
 3.6450881e-01 3.1264830e-01 3.1409854e-01 6.1833280e-01 5.4006249e-01
 5.3634107e-01 5.1782316e-01 5.6046784e-01 3.4434414e-01 6.2463516e-01
 3.8253057e-01 5.6103706e-01 4.4021085e-01 4.2417687e-01 5.1296681e-01
 4.4214839e-01 5.1630658e-01 4.4567358e-01 6.5452963e-01 7.6723915e-01
 4.5965648e-01 4.3432295e-01 6.7388141e-01 6.3346416e-01 4.1575766e-01
 2.4798569e-01 6.2670684e-01 4.8988858e-01 1.2455207e-01 3.8256031e-01
 1.9009399e-01 5.6317312e-01 6.0185397e-01 3.6159569e-01 4.5778933e-01
 5.6385022e-01 4.4628367e-01 5.1240909e-01 2.4831536e-01 4.3406212e-01
 6.7307001e-01 4.8251784e-01 4.0836155e-01 4.3661380e-01 5.7488531e-01
 5.3154564e-01 4.8197514e-01 2.8990519e-01 6.3249350e-01 3.1488061e-01
 5.4739767e-01 3.9877567e-01 4.5859805e-01 4.7688571e-01 6.2220663e-01
 4.4204286e-01 3.4114867e-01 6.8983167e-01 3.8892895e-01 5.3567398e-01
 4.9695858e-01 3.1465805e-01 6.0332274e-01 7.8250670e-01 2.8132150e-01
 3.5133871e-01 5.1497614e-01 3.9516848e-01 2.7599198e-01 4.2284471e-01
 4.7947720e-01 3.5736883e-01 4.7842607e-01 4.0439063e-01 3.6619276e-01
 4.7605729e-01 6.6592836e-01 2.8828996e-01 5.3816944e-01 3.9248559e-01
 4.6676877e-01 3.9779189e-01 2.7141738e-01 5.4719478e-01 4.2383343e-01
 4.1714483e-01 2.9288548e-01 6.8399107e-01 5.2015209e-01 3.0779052e-01
 5.0522012e-01 5.2354854e-01 5.5827802e-01 2.9237139e-01 5.4925025e-01
 3.9035726e-01 6.1746281e-01 4.7009072e-01 3.0992007e-01 3.0846065e-01
 6.7355549e-01 6.0883683e-01 4.6646795e-01 4.3601462e-01 4.9261934e-01
 4.7780293e-01 4.0009695e-01 5.4472119e-01 7.4743462e-01 2.8867853e-01
 3.9827180e-01 5.9199274e-01 4.2549202e-01 6.3093400e-01 5.4165924e-01
 4.9462855e-01 3.4392124e-01 2.8617352e-01 4.1841853e-01 4.4660756e-01
 5.6143063e-01 5.6886888e-01 2.0847833e-01 4.0981168e-01 5.2802962e-01
 7.0843804e-01 6.2876230e-01 8.0200613e-01 5.8465844e-01 5.7808417e-01
 5.2903128e-01 5.4574829e-01 4.2315617e-01 6.5401053e-01 5.2738148e-01
 4.8202989e-01 5.9755307e-01 3.7301153e-01 4.4573399e-01 4.3935910e-01
 4.9686727e-01 3.7384567e-01 4.0892804e-01 6.2776339e-01 5.1886731e-01
 5.1353830e-01 6.7722595e-01 6.2815547e-01 4.3913299e-01 4.8259285e-01
 6.3323230e-01 4.7471038e-01 3.0643386e-01 5.7198697e-01 5.4610467e-01
 5.1213717e-01 2.5627476e-01 4.7377574e-01 3.5415339e-01 4.1555658e-01
 5.9662867e-01 6.1923283e-01 5.6209314e-01 4.8739338e-01 5.5932391e-01
 3.5915053e-01 7.1077394e-01 7.0769018e-01 5.3706354e-01 4.6016830e-01
 5.4668826e-01 4.7384524e-01 2.9335320e-01 4.2005900e-01 4.7279617e-01
 5.7188594e-01 5.0360519e-01 5.3745097e-01 6.2387419e-01 4.6846956e-01
 5.0980163e-01 5.9562588e-01 5.1825166e-01 6.4195514e-01 5.2602285e-01
 5.7804608e-01 6.8533367e-01 3.8501328e-01 5.8348536e-01 6.9476771e-01
 5.6023145e-01 5.8584982e-01 4.8062763e-01 5.9266621e-01 3.4224802e-01
 4.9217242e-01 4.0498373e-01 6.1322141e-01 4.9155253e-01 5.2858770e-01
 4.2591280e-01 6.3506711e-01 5.3143764e-01 3.7341473e-01 4.8895964e-01
 4.2587593e-01 3.1961817e-01 6.0813415e-01 4.5940009e-01 6.0276896e-01
 3.6568087e-01 2.7096167e-01 5.7695556e-01 5.6073302e-01 4.5004404e-01
 4.2452252e-01 7.0741045e-01 6.1833262e-01 4.1044962e-01 4.8078573e-01
 3.7850690e-01 4.4451040e-01 5.2007341e-01 5.3297073e-01 4.9841055e-01
 5.0925398e-01 4.5966154e-01 5.1094705e-01 5.2740675e-01 4.9575052e-01
 5.0438035e-01 4.9488789e-01], shape=(507,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1.
 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1.
 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1.
 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.
 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1.
 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0.
 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.
 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0.
 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1.
 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0.
 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0.
 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1.
 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0.
 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1.
 0. 1. 0.], shape=(507,), dtype=float32)
predicted label rank:[2 2 1 2 2 2 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 2 1 1 1 1 1 2 2 1 2
 2 2 1 2 1 2 1 1 2 2 1 2 1 1 1 1 1 2 2 1 2 1 2 2 1 1 2 2 1 2 2 1 1 2 1 2 2
 1 2 2 1 1 2 1 1 1 2 2 1 1 1 1 2 2 2 2 2 1 2 1 2 2 2 2 1 1 2 1 1 2 1 1 2 2
 1 1 2 2 1 1 2 1 2 1 2 1 1 2 2 1 1 1 2 2 2 1 2 2 1 2 1 1 2 1 1 1 2 1 2 2 2
 1 2 2 1 1 2 1 2 2 1 1 1 2 2 1 2 2 2 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 2
 2 2 2 1 1 2 2 2 1 2 1 1 2 2 1 2 1 1 1 1 2 2 2 1 1 1 1 1 1 2 2 2 2 2 1 2 2
 2 1 1 1 1 1 2 2 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 2 2 1 1 2 1 1 1 2 2 1 1 2 2
 2 2 2 2 2 1 2 2 1 1 2 1 2 2 2 2 1 1 1 2 2 2 2 2 1 2 1 2 1 1 2 1 2 1 2 2 1
 1 2 2 1 1 2 1 1 1 1 2 2 1 1 2 1 2 1 1 2 1 1 1 2 2 1 1 2 1 2 1 1 1 2 1 1 2
 1 2 1 1 2 2 1 1 2 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 2 2 1 2 2 2 1 2
 1 2 1 1 1 2 2 1 1 1 1 1 2 2 1 1 2 1 2 2 1 1 1 1 1 2 2 1 1 2 2 2 2 2 2 2 2
 1 2 2 1 2 1 1 1 1 1 1 2 2 2 2 2 1 1 2 1 1 2 2 2 1 1 1 1 2 2 2 1 2 1 2 2 2
 1 2 1 1 1 1 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 1 2 1 1 1 2 1 2 1 2 2 1 1 1
 1 2 1 2 1 1 2 2 1 1 2 2 1 1 1 1 2 2 1 2 1 2 2 1 2 1]
mse:tf.Tensor(0.26146582, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/rotation_vc.correct.1.nts_000.smt2
true label:[0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1]
true label rank:[1 2 2 1 2 2 2 1 2 2 2 1 2 2 1 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2
 1 2 2 1 2 2 1 2 2 1 2 2 2 1 2 2 1 2 1 2 2 1 2 1 2 2 1 1 2 2 1 2 2 1 2 2 1
 2 2 1 2 2]
predicted label:tf.Tensor(
[0.48883277 0.26656133 0.4968274  0.468267   0.29260367 0.7816557
 0.3395265  0.49835846 0.48100227 0.50087273 0.4830476  0.48910207
 0.49226978 0.50650644 0.50513273 0.5575607  0.5789035  0.5072446
 0.50253296 0.5092889  0.4817729  0.46840268 0.4864774  0.50259644
 0.52910084 0.43515792 0.514253   0.55026686 0.54286224 0.4660368
 0.4957076  0.50147    0.36605364 0.48831978 0.5455097  0.39191052
 0.5579544  0.5119785  0.50810015 0.47654778 0.49673283 0.50743115
 0.5752698  0.44113368 0.35884517 0.54570854 0.4851336  0.45619994
 0.59804475 0.36741823 0.50105965 0.4943613  0.48499376 0.44769883
 0.5160723  0.50232536 0.4910915  0.54923904 0.49263382 0.5083829
 0.5966126  0.46960405 0.39150617 0.48447186 0.52242327 0.46206817
 0.5310788  0.53303605 0.40296155 0.46162233 0.6068902  0.45876896
 0.6063712  0.5079838  0.49930036 0.5161834  0.5278187  0.4725606
 0.48715252], shape=(79,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1.
 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0.
 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0.
 1. 1. 0. 1. 1. 0. 0.], shape=(79,), dtype=float32)
predicted label rank:[1 1 1 1 1 2 1 1 1 2 1 1 1 2 2 2 2 2 2 2 1 1 1 2 2 1 2 2 2 1 1 2 1 1 2 1 2
 2 2 1 1 2 2 1 1 2 1 1 2 1 2 1 1 1 2 2 1 2 1 2 2 1 1 1 2 1 2 2 1 1 2 1 2 2
 1 2 2 1 1]
mse:tf.Tensor(0.26572013, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/minepump_spec3_product49_true-unreach-call.cil.c.flat_000.smt2
true label:[1, 1, 0, 1, 1]
true label rank:[2 2 1 2 2]
predicted label:tf.Tensor([0.7752967  0.73721325 0.36300868 0.93009394 0.9907079 ], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 1.], shape=(5,), dtype=float32)
predicted label rank:[2 2 1 2 2]
mse:tf.Tensor(0.05125939, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/nest-len.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[9.9283326e-01 3.2487264e-01 1.3027608e-02 9.9854064e-01 9.9984324e-01
 7.7428216e-01 2.6387775e-06 9.9999166e-01 6.2164565e-11], shape=(9,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 1. 1. 1. 0. 1. 0.], shape=(9,), dtype=float32)
predicted label rank:[2 1 1 2 2 2 1 2 1]
mse:tf.Tensor(0.5208551, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/count_by_2_m_nest_000.smt2
true label:[1, 1, 1]
true label rank:[1 1 1]
predicted label:tf.Tensor([0.5200334  0.47666907 0.5029444 ], shape=(3,), dtype=float32)
rounded label:tf.Tensor([1. 0. 1.], shape=(3,), dtype=float32)
predicted label rank:[2 1 2]
mse:tf.Tensor(0.25043583, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/metros_4_e3_1091_e3_522_000.smt2
true label:[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]
true label rank:[1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1
 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1
 2 1 1 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 2 1 1 2 2 1 1 1 1 2 2 1 1 1 1
 1 1 1 2 1 2 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1
 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1
 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1
 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1
 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1
 1 2 1 1]
predicted label:tf.Tensor(
[0.42466184 0.6103069  0.41924018 0.5807295  0.26686025 0.63460624
 0.5004704  0.7180635  0.03476396 0.47979948 0.06558603 0.27985662
 0.31001166 0.2774892  0.42357323 0.71353054 0.82920516 0.533767
 0.34251487 0.43431187 0.20239052 0.082297   0.07650471 0.46094918
 0.89126515 0.75153315 0.16476399 0.9048061  0.22688511 0.2456519
 0.2570191  0.24898347 0.16857558 0.6362446  0.27252567 0.20891735
 0.6569189  0.72478163 0.7569252  0.31011432 0.8414936  0.28850734
 0.816381   0.21007743 0.25420547 0.6820223  0.8260834  0.500586
 0.52570987 0.42235434 0.48255926 0.51893055 0.48013616 0.47845587
 0.5444624  0.51195663 0.4946384  0.5001828  0.4712057  0.49509808
 0.5080972  0.5055341  0.4375671  0.49073556 0.52742624 0.49911505
 0.5085681  0.50418794 0.5156815  0.47224835 0.57650334 0.49601123
 0.5419619  0.56569153 0.47443604 0.582928   0.4645884  0.44925925
 0.4705864  0.55022955 0.41429266 0.5053928  0.44482258 0.5611657
 0.54329145 0.49522626 0.44523755 0.5198527  0.5019933  0.4974512
 0.50729835 0.48920292 0.5205341  0.53086615 0.46105742 0.5809119
 0.5220066  0.54555815 0.471024   0.5363421  0.5634168  0.5515364
 0.46873143 0.5982862  0.48185733 0.39251518 0.53619665 0.49672976
 0.5327932  0.71465683 0.3467023  0.32010502 0.6457007  0.50493705
 0.5270846  0.51984316 0.45135012 0.50169486 0.28409538 0.5797929
 0.5095616  0.59377515 0.44670343 0.62346023 0.59222245 0.32475471
 0.4069198  0.5158053  0.41377342 0.7163355  0.5183168  0.5691368
 0.47373942 0.5080182  0.5714014  0.35624254 0.46245164 0.5363233
 0.34108543 0.5741664  0.46426773 0.487386   0.5626128  0.65653074
 0.29860362 0.47841218 0.64082694 0.5252273  0.2805241  0.5654635
 0.57767034 0.5856254  0.45883736 0.572767   0.42728096 0.6471709
 0.56764    0.49417192 0.36762053 0.51742023 0.3609544  0.4967962
 0.3447044  0.49275616 0.5400915  0.532771   0.36639643 0.41439787
 0.393597   0.37007362 0.27449483 0.26146597 0.344526   0.50029075
 0.324896   0.46121547 0.5324911  0.40712297 0.49792728 0.22857732
 0.4914853  0.48209682 0.3281371  0.54237574 0.6525858  0.62890536
 0.55941314 0.5468779  0.43941003 0.4527949  0.50309896 0.60073435
 0.54293936 0.48101628 0.5815438  0.22627822 0.39691582 0.6963565
 0.43766415 0.54524624 0.66878164 0.3990546  0.32434487 0.28448194
 0.35679603 0.5216888  0.879058   0.47745362 0.22563252 0.47120026
 0.33095282 0.23325601 0.31224638 0.39627066 0.73926747 0.82070434
 0.9084692  0.48179322 0.6160533  0.5617988  0.55266297 0.7929651
 0.54066014 0.4657777  0.5158942  0.48573953 0.41096172 0.4236733
 0.37538296 0.43844447 0.39805064 0.53448075 0.39379677 0.37967125
 0.4929042  0.6030748  0.49254754 0.52946657 0.3701319  0.37932947
 0.4647298  0.448132   0.4443004  0.4948031  0.49458364 0.4830578
 0.47391173 0.4268731  0.44344485 0.5176097  0.43293566 0.51432854
 0.42875826 0.5320851  0.4693487  0.4257326  0.3830109  0.51987195
 0.44989616 0.42609257 0.48661977 0.5807226  0.48059264 0.5499233
 0.4987444  0.53612113 0.53365594 0.48321941 0.49423218 0.4506649
 0.46049732 0.45627466 0.506758   0.4034118  0.51196635 0.4243489
 0.3263443  0.3911863  0.48420006 0.5043313  0.4518937  0.4693585
 0.45600474 0.46904603 0.48838085 0.49355093 0.45549956 0.47906244
 0.45705947 0.46354097 0.48180377 0.4524816  0.48029643 0.44722646
 0.49451023 0.47207662 0.49567446 0.48876435 0.48663074 0.47893116
 0.10063508 0.766438   0.35777336 0.15740919 0.3215826  0.10747334
 0.6161244  0.5172872  0.38687262 0.20969298 0.64115506 0.28091964
 0.42568442 0.33525997 0.40662837 0.6212461  0.66056037 0.4101038
 0.51600176 0.5280751  0.51198167 0.5354328  0.45996162 0.56311256
 0.48880285 0.5195611  0.47508243 0.49381384 0.49945945 0.52624446
 0.53793013 0.49408042 0.51260006 0.47726777 0.5435971  0.49667758
 0.52127    0.5139245  0.6106541  0.49124122 0.5052078  0.49673557
 0.5183419  0.5009746  0.48988712 0.49772918 0.50426495 0.49305
 0.5035466  0.5139582  0.49038914 0.50468326 0.50436246 0.50370115
 0.49863827 0.4974333  0.4907616  0.4975143  0.50179416 0.4837222
 0.507656   0.42564186 0.45259207 0.51570034 0.46018595 0.47332585
 0.4912228  0.5176189  0.48888648 0.44238737 0.48516425 0.4626352
 0.45511734 0.52232885 0.40940386 0.4713447  0.50329274 0.49934795
 0.4857033  0.5846694  0.49833623 0.4864218  0.46596107 0.54346514
 0.45934364 0.51253027 0.5161765  0.5642104  0.52580625 0.45541602
 0.5241844  0.5509634  0.46521    0.5459392  0.46858415 0.5015588
 0.49373013 0.45726246 0.50297415 0.4987015  0.4363396  0.4930482
 0.5347719  0.4843283  0.4587657  0.5064211  0.45652837 0.48396665
 0.46778014 0.49840537 0.48256052 0.4908936  0.47696328 0.49826026
 0.4764763  0.48321918 0.45376587 0.4358457  0.51294196 0.5618941
 0.52140677 0.5285674  0.5185145  0.48803166 0.48919228 0.48972335
 0.465502   0.47393534 0.49624777 0.45102632 0.5145345  0.46934462
 0.5210423  0.49745324 0.48494276 0.47489002 0.5229667  0.56132615
 0.53029317 0.41119674 0.48115987 0.54865426 0.49367407 0.5207009
 0.5584843  0.49283877 0.5628066  0.4340174  0.4597984  0.41538128
 0.49921665 0.49906984 0.4988232  0.5713143  0.47428754 0.5818169
 0.46967852 0.5150951  0.51527965 0.5125294  0.41745573 0.58304363
 0.3988111  0.3882063  0.52542716 0.5153204  0.46678934 0.4850871
 0.5074982  0.47686794 0.4853792  0.47434166 0.47464857 0.49788627
 0.5137458  0.4880076  0.5014818  0.51765364 0.46786425 0.5077032
 0.49879384 0.48766497 0.5110691  0.4867338  0.5476078  0.4953208
 0.49471542 0.5044516  0.49596313 0.49519083 0.4855582  0.45863274
 0.47220123 0.46700528 0.48737437 0.48405877 0.5127216  0.4430829
 0.50540644 0.54317296 0.4369304  0.4577545  0.48575723 0.4833759
 0.49934626 0.45595226 0.5043036  0.48975724 0.41590106 0.44721746
 0.49667314 0.46712607 0.4786626  0.4974054  0.5144835  0.5596377
 0.5136314  0.47682402 0.54860866 0.5456462  0.4952468  0.43618238], shape=(522,), dtype=float32)
rounded label:tf.Tensor(
[0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.
 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.
 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0.
 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1.
 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1.
 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1.
 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.
 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.
 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.
 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0.
 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1.
 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0.], shape=(522,), dtype=float32)
predicted label rank:[1 2 1 2 1 2 2 2 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 1 1 2
 2 2 1 2 1 2 1 1 2 2 2 2 1 1 2 1 1 2 2 1 2 1 1 2 2 1 1 2 1 2 2 2 1 2 1 2 2
 1 2 1 1 1 2 1 2 1 2 2 1 1 2 2 1 2 1 2 2 1 2 2 2 1 2 2 2 1 2 1 1 2 1 2 2 1
 1 2 2 2 2 1 2 1 2 2 2 1 2 2 1 1 2 1 2 2 2 1 2 2 1 1 2 1 2 1 1 2 2 1 1 2 2
 1 2 2 2 1 2 1 2 2 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 2 2
 2 2 2 1 1 2 2 2 1 2 1 1 2 1 2 2 1 1 1 1 2 2 1 1 1 1 1 1 1 2 2 2 1 2 2 2 2
 2 1 2 1 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 1 1 2 1
 1 1 2 1 2 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 1 2 2 1 2 2 2 2 1 2 1 2 1 1 1 2 2 1 2
 1 2 1 2 2 2 1 2 1 2 2 1 1 2 1 2 2 1 2 2 2 1 1 1 1 2 1 2 1 1 2 1 1 1 2 1 1
 1 1 1 2 1 1 2 1 1 2 1 1 1 2 1 2 2 2 2 1 2 2 1 2 1 2 1 1 2 1 1 1 2 1 1 2 1
 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 2 1 2 1 1 1 2 2 2 1 1 2 1 2
 2 1 2 1 1 1 1 1 1 2 1 2 1 2 2 2 1 2 1 1 2 2 1 1 2 1 1 1 1 1 2 1 2 2 1 2 1
 1 2 1 2 1 1 2 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 2 1
 2 2 1 1]
mse:tf.Tensor(0.24865234, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/test_locks_8.c-1_000.smt2
true label:[0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0]
true label rank:[1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 1 2 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 2 1
 2 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 2 1
 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1]
predicted label:tf.Tensor(
[0.51939243 0.50959873 0.469312   0.5140423  0.4614015  0.5036577
 0.4797163  0.49833164 0.43381068 0.50109756 0.46008667 0.45470467
 0.516171   0.5010623  0.5024653  0.47686914 0.5205519  0.48484915
 0.48841074 0.46903965 0.47798088 0.46181792 0.4586458  0.4738309
 0.53262436 0.53520113 0.47159037 0.48170164 0.5102564  0.4826665
 0.4831186  0.47812295 0.493315   0.5180551  0.539945   0.48167297
 0.5212112  0.57523876 0.5102336  0.47725403 0.5227343  0.4705103
 0.54034734 0.48106602 0.4690376  0.51859975 0.5181663  0.4878096
 0.47980323 0.48830795 0.46060705 0.51056427 0.4890678  0.47107053
 0.4989146  0.51843387 0.5017303  0.4915714  0.48129514 0.48442525
 0.48117337 0.5033714  0.43056956 0.5105039  0.52414787 0.5120339
 0.51692784 0.54790795 0.46998873 0.44979137 0.48818558 0.5003828
 0.56867707 0.51662713 0.47300336 0.5122996  0.47837558 0.46934217
 0.4684708  0.50311935 0.44599652 0.44754115 0.50673324 0.5080359
 0.53036296 0.47059405 0.4690954  0.5167139  0.4734551  0.56189847
 0.51087815 0.48793107 0.518543   0.51420766 0.49022433 0.4741657
 0.4986487  0.5122723  0.43320373 0.47714803 0.5229765  0.53976864
 0.46904758 0.5227317  0.47459808 0.45976627 0.524482   0.4679378
 0.5023267  0.5680341  0.51106477 0.43555358 0.4302551  0.54191464
 0.4484297  0.4861663  0.4649124  0.5075943  0.4782223  0.5293635
 0.46937883 0.44995427 0.50405943 0.48045474 0.4684465  0.5073918
 0.47266528 0.49024755 0.49015808 0.49224055 0.49177247 0.43377927
 0.43910456 0.4986719  0.45138216 0.47936875 0.45322278 0.4748123
 0.44091058 0.47149146 0.43959403 0.49874482 0.4258202  0.52286786], shape=(144,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0.
 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1.
 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0.
 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1.
 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.], shape=(144,), dtype=float32)
predicted label rank:[2 2 1 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 1 2 2 1 2
 2 2 1 2 1 2 1 1 2 2 1 1 1 1 2 1 1 1 2 2 1 1 1 1 2 1 2 2 2 2 2 1 1 1 2 2 2
 1 2 1 1 1 2 1 1 2 2 2 1 1 2 1 2 2 1 2 2 1 1 1 2 1 1 2 2 1 2 1 1 2 1 2 2 2
 1 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2]
mse:tf.Tensor(0.24635445, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/test_locks_12.c-1_000.smt2
true label:[0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2
 1 2 1 2 1 2 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 2
 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1
 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1
 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1
 1 1 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 2 1
 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 1 2
 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.49194723 0.49835253 0.4811664  0.50661093 0.4993825  0.514918
 0.5022725  0.52360684 0.42105    0.49306893 0.46251816 0.46147084
 0.52285147 0.49778593 0.49528044 0.5080206  0.5572012  0.48646206
 0.45831028 0.46116087 0.47079268 0.4572734  0.49027342 0.48073652
 0.53407985 0.49418855 0.46013904 0.50318867 0.4999248  0.4823755
 0.4811273  0.50215346 0.479021   0.52105474 0.47039238 0.44705015
 0.5310805  0.47189078 0.46498707 0.50340956 0.48135763 0.48661232
 0.50920516 0.46708786 0.5375657  0.5147598  0.49124834 0.4686137
 0.52290213 0.47461227 0.468626   0.48818222 0.49755326 0.49056607
 0.505355   0.5096328  0.48105565 0.5314403  0.48596886 0.49132937
 0.5028891  0.50359064 0.4489246  0.47496277 0.54978377 0.4927911
 0.5222444  0.50428236 0.44833955 0.47760648 0.47439966 0.4845532
 0.492803   0.49456224 0.48753288 0.49574327 0.50199896 0.4609021
 0.47090936 0.44546497 0.48423508 0.44830257 0.47497696 0.4752984
 0.47418973 0.48008502 0.46634284 0.4743661  0.45932525 0.48435026
 0.50413036 0.55389315 0.5165847  0.484865   0.45337266 0.49487433
 0.515508   0.52740383 0.49002802 0.5317355  0.524378   0.51503557
 0.4658473  0.49443474 0.4961234  0.44782177 0.50394404 0.4832794
 0.50916815 0.5336899  0.45851243 0.44658798 0.5175383  0.48418278
 0.4524885  0.43162093 0.46976522 0.50167924 0.457511   0.50711197
 0.485635   0.4478843  0.46566522 0.482174   0.5219415  0.4622526
 0.46737048 0.46984512 0.43126756 0.5361276  0.5280673  0.49543497
 0.49915642 0.4775713  0.5269091  0.50550675 0.43420437 0.48598638
 0.4470234  0.5055486  0.5003839  0.51348114 0.49536303 0.5193341
 0.45030946 0.46729577 0.53298277 0.45500863 0.44295633 0.51161265
 0.5041103  0.4410271  0.47002316 0.5311229  0.45947084 0.47854787
 0.437895   0.46572655 0.47203952 0.46231067 0.45828044 0.5076154
 0.443529   0.51543885 0.5042952  0.4975547  0.47259313 0.4908204
 0.46737567 0.47420043 0.47830197 0.4772296  0.46447957 0.5009613
 0.46659642 0.45710984 0.4613182  0.45060235 0.479406   0.43620405
 0.4705113  0.49970537 0.49912077 0.5085712  0.5207757  0.4874249
 0.51217514 0.4927867  0.48254406 0.49812376 0.4907787  0.49320626
 0.49487114 0.49909088 0.5066708  0.49951994 0.49472547 0.49834356
 0.5060531  0.49524593 0.49145755 0.479193   0.47029784 0.46443477
 0.4865309  0.48496985 0.51123315 0.51391083 0.44335556 0.47450706
 0.4644668  0.49176    0.48138976 0.47991753 0.49116042 0.4627844
 0.5206745  0.45057884 0.5118977  0.48194456 0.48983285 0.4773571
 0.4374522  0.50310665 0.4763347  0.4843322  0.42077163 0.43399453
 0.4670781  0.44461787 0.47073323 0.46806943 0.465201   0.40938
 0.5507532  0.5977255  0.48932025 0.53433746 0.46368816 0.49630052
 0.47532752 0.47747725 0.51394475 0.51008654 0.5285023  0.51870716
 0.5178501  0.47826236 0.5038688  0.55099416 0.5309028  0.4459272
 0.48267043 0.5479929  0.5409156  0.5085878  0.47582507 0.51163524
 0.46558273 0.46518993 0.51142    0.4810157  0.49540424 0.4734027
 0.4573863  0.4969777  0.48640564 0.50815797 0.4658519  0.49757636
 0.47606814 0.4768821  0.46508008 0.44360155 0.5185149  0.47892812
 0.5016794  0.48495698 0.5363481  0.53018975 0.46956426 0.5007687
 0.52081573 0.45844784 0.5357809  0.48030224 0.551562   0.5288716
 0.51439947 0.48229918 0.49016348 0.46660495 0.47704953 0.4525051
 0.5616187  0.54465574 0.5223499  0.5121089  0.43100262 0.48662406
 0.40271538 0.56708395 0.5174532  0.43295264 0.46957517 0.40337545
 0.4753236  0.5003908  0.43730927 0.42638436 0.5396436  0.5097804
 0.5004085  0.46271127 0.4976527  0.49398676 0.52759534 0.46721905
 0.5203419  0.507521   0.5231445  0.50377756 0.47354674 0.53642267], shape=(324,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1.
 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0.
 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1.
 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1.
 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1.], shape=(324,), dtype=float32)
predicted label rank:[1 1 1 2 1 2 2 2 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 2 1 1 2 1 1 1 2 1 2 1 1 2
 1 1 2 1 1 2 1 2 2 1 1 2 1 1 1 1 1 2 2 1 2 1 1 2 2 1 1 2 1 2 2 1 1 1 1 1 1
 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 2 2 1 2 2 2 1 1 1 1 2 1 2 2 1
 1 2 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 1 1 1 2 2 2 1 2 1 1 2 1
 1 2 2 1 1 2 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2
 1 2 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 2 1 1 1
 1 2 1 1 1 1 1 1 1 1 1 1 2 2 1 2 1 1 1 1 2 2 2 2 2 1 2 2 2 1 1 2 2 2 1 2 1
 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 1 2 2 1 2 2 1 2 1 2 2 2 1 1 1 1 1 2 2
 2 2 1 1 1 2 2 1 1 1 1 2 1 1 2 2 2 1 1 1 2 1 2 2 2 2 1 2]
mse:tf.Tensor(0.24684459, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/bandec.smt2-0131_000.smt2
true label:[1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1]
true label rank:[2 2 1 1 2 2 1 2 1 2 2 2 1 1 1 1 1 2]
predicted label:tf.Tensor(
[0.48976934 0.50949097 0.5015571  0.51206344 0.5033736  0.49009112
 0.50070363 0.5078671  0.4634576  0.47609663 0.48916122 0.48420697
 0.49052832 0.49247235 0.51009315 0.4775248  0.4923711  0.50011426], shape=(18,), dtype=float32)
rounded label:tf.Tensor([0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.], shape=(18,), dtype=float32)
predicted label rank:[1 2 2 2 2 1 2 2 1 1 1 1 1 1 2 1 1 2]
mse:tf.Tensor(0.24967782, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/inductive5_000.smt2
true label:[0, 1]
true label rank:[1 2]
predicted label:tf.Tensor([0.49482223 0.51474655], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 2]
mse:tf.Tensor(0.24015999, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/12.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0]
true label rank:[1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1
 1 2 1 1 2 2 1]
predicted label:tf.Tensor(
[0.4874404  0.49596128 0.5348846  0.5173902  0.47540185 0.5249399
 0.4066823  0.53816676 0.378972   0.48900637 0.45105767 0.47952276
 0.48330158 0.4810216  0.46765557 0.46073538 0.5452309  0.5038777
 0.45455223 0.46520472 0.49657875 0.50018716 0.4890117  0.4972408
 0.51270986 0.5131791  0.5060763  0.49719507 0.5013134  0.4932872
 0.4978718  0.49549258 0.49879757 0.49260712 0.49924877 0.49408433
 0.541482   0.55368966 0.5411817  0.4727992  0.49740618 0.50074404
 0.5012782  0.4865087 ], shape=(44,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.
 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0.], shape=(44,), dtype=float32)
predicted label rank:[1 1 2 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 2 2 2 1 2 1 1 1 1 1 1 1 2
 2 2 1 1 2 2 1]
mse:tf.Tensor(0.252786, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/bouncy_one_counter_000.smt2
true label:[1, 1, 0, 0, 0, 0]
true label rank:[2 2 1 1 1 1]
predicted label:tf.Tensor([0.50122136 0.5090702  0.4802469  0.50801945 0.49497122 0.53643775], shape=(6,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 0. 1.], shape=(6,), dtype=float32)
predicted label rank:[2 2 1 2 1 2]
mse:tf.Tensor(0.2518792, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/bandec.smt2-0238_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1]
true label rank:[2 2 2 2 2 2 2 2 1 1 2 2 1 2 2 2 1 1 2 2]
predicted label:tf.Tensor(
[0.50344175 0.50042224 0.4908777  0.50712204 0.49363324 0.49242386
 0.49859262 0.50944215 0.47916824 0.5006427  0.5044419  0.4829467
 0.50069326 0.48788026 0.49940178 0.5039093  0.5083551  0.49933088
 0.48354277 0.4954664 ], shape=(20,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0.], shape=(20,), dtype=float32)
predicted label rank:[2 2 1 2 1 1 1 2 1 2 2 1 2 1 1 2 2 1 1 1]
mse:tf.Tensor(0.25181252, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/s3_clnt_1.cil-1.c-1_000.smt2
true label:[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]
true label rank:[1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1
 1 1 2 2 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1
 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 1
 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1
 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1
 1 2 2 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 1 2 2 2]
predicted label:tf.Tensor(
[4.7419146e-01 5.3035420e-01 4.6199036e-01 4.7961891e-01 4.3211374e-01
 5.2116781e-01 4.3947873e-01 5.0644839e-01 3.8729233e-01 4.6673015e-01
 3.9150101e-01 4.7662795e-01 4.9868497e-01 4.4343439e-01 4.3780696e-01
 5.1418668e-01 5.0411004e-01 5.0461441e-01 4.2367601e-01 4.6299359e-01
 4.5396560e-01 3.8600594e-01 4.4256425e-01 4.7108182e-01 4.6362534e-01
 4.9393660e-01 4.5978165e-01 4.9587473e-01 4.4492728e-01 4.4553649e-01
 4.6529579e-01 3.7916714e-01 6.4196573e-09 8.8577676e-01 5.2195787e-04
 3.5134981e-05 9.8144889e-01 9.9070597e-01 9.9414718e-01 2.4391681e-02
 9.9762464e-01 9.2247725e-03 9.9288201e-01 4.0808037e-01 1.5066564e-03
 9.9537075e-01 9.9975193e-01 9.8366618e-01 5.3516734e-01 1.4461052e-05
 9.8406935e-01 7.7646160e-01 2.1401936e-01 9.1015089e-01 9.9953222e-01
 9.9991512e-01 5.4895121e-01 9.9999785e-01 9.5797359e-06 9.9661589e-01
 5.0192863e-01 4.9178857e-01 4.8700902e-01 4.9038291e-01 5.0385600e-01
 5.0389034e-01 5.0069517e-01 5.2375996e-01 4.6985063e-01 4.7920173e-01
 4.8998713e-01 5.0170273e-01 5.2947247e-01 5.0813645e-01 4.9182644e-01
 5.0656807e-01 4.9094573e-01 4.9764186e-01 4.9686423e-01 4.8605478e-01
 4.7691637e-01 5.0707757e-01 4.8346278e-01 5.0261509e-01 5.0691086e-01
 4.9330890e-01 5.0035143e-01 4.9751130e-01 4.6801537e-01 5.0687838e-01
 5.0613457e-01 4.8899528e-01 4.7906420e-01 4.7274488e-01 4.9624908e-01
 4.7799671e-01 4.8254970e-01 4.6803975e-01 5.0436175e-01 4.8170832e-01
 4.7481254e-01 4.9069321e-01 4.9458390e-01 4.8020840e-01 4.8737648e-01
 4.8187244e-01 5.0983173e-01 5.0966954e-01 5.1036602e-01 4.9221894e-01
 4.6796831e-01 4.8879978e-01 4.7532484e-01 4.7047043e-01 5.0386965e-01
 4.9256229e-01 4.9320394e-01 4.8146918e-01 4.8867339e-01 4.6385920e-01
 4.7349352e-01 4.4489780e-01 4.7594717e-01 4.7248670e-01 4.6329054e-01
 4.9361435e-01 4.4255835e-01 4.7485939e-01 4.7673196e-01 4.5405099e-01
 4.6877962e-01 4.6848521e-01 4.5916894e-01 4.6888375e-01 4.7051489e-01
 4.6429080e-01 4.3788844e-01 4.3391675e-01 4.7199437e-01 4.7316843e-01
 4.8413882e-01 4.7922575e-01 4.7388086e-01 4.6969861e-01 4.5159668e-01
 4.8049000e-01 4.7410345e-01 4.4254783e-01 4.6745044e-01 4.8880377e-01
 4.9827257e-01 4.7081351e-01 5.0776118e-01 5.2309406e-01 4.9051088e-01
 4.9449456e-01 4.7756281e-01 4.6848851e-01 4.6688381e-01 4.5083162e-01
 4.6184501e-01 5.0030255e-01 5.0960988e-01 4.8065609e-01 4.9998775e-01
 4.7999933e-01 4.9068829e-01 4.8800302e-01 4.7234908e-01 4.6475103e-01
 4.5148033e-01 4.7721833e-01 4.7125378e-01 5.1857787e-01 4.6688420e-01
 4.9467671e-01 4.9742550e-01 4.8480299e-01 4.7787267e-01 4.3195060e-01
 4.9582928e-01 4.9240875e-01 5.1302612e-01 4.8384863e-01 5.2771199e-01
 4.5506904e-01 5.3995872e-01 5.5858427e-01 4.6127799e-01 4.7789341e-01
 4.9103189e-01 5.1332706e-01 4.4215992e-01 4.4563136e-01 4.6954164e-01
 4.8014230e-01 4.8928148e-01 5.6144172e-01 5.2615297e-01 5.0080991e-01
 5.1231837e-01 4.6723050e-01 4.9390143e-01 4.4443601e-01 4.0878704e-01
 4.7526479e-01 5.3409809e-01 4.5668125e-01 4.7495401e-01 4.7949088e-01
 5.1792014e-01 4.9950859e-01 5.1180363e-01 4.5294863e-01 5.4053384e-01
 5.0996530e-01 5.1492459e-01 5.0097954e-01 5.6224811e-01 4.8239690e-01
 5.4095596e-01 5.3687090e-01 5.0875610e-01 4.7062221e-01 4.9829477e-01
 4.7526950e-01 4.7658741e-01 4.9039197e-01 4.9790171e-01 5.0238764e-01
 4.8953515e-01 4.9054116e-01 4.5453185e-01 3.9397150e-01 5.0172806e-01
 5.9126735e-01 4.7079119e-01 4.4301522e-01 4.4652885e-01 3.9640436e-01
 4.3765524e-01 4.6172786e-01 4.8293105e-01 4.6884066e-01 4.7592703e-01
 4.5942336e-01 4.5494404e-01 4.6499252e-01 4.5756572e-01 5.0384063e-01
 4.5542756e-01 4.5377514e-01 4.9383610e-01 4.8618203e-01 4.5754555e-01
 4.7542322e-01 4.5306697e-01 4.4291151e-01 4.6262577e-01 4.5275238e-01
 4.5142180e-01 4.4795460e-01 4.9784210e-01 4.3445078e-01 4.4502497e-01
 4.4405144e-01 4.5646742e-01 4.9747843e-01 4.8199639e-01 4.7190055e-01
 4.8766077e-01 4.5169383e-01 4.7289497e-01 4.4838279e-01 4.8617345e-01
 4.6902484e-01 4.2669642e-01 4.8024234e-01 4.9998647e-01 4.8729283e-01
 4.4976386e-01 4.9811462e-01 4.9362159e-01 4.6766010e-01 5.0021005e-01
 4.5617864e-01 4.3297845e-01 5.0975692e-01 4.6299765e-01 4.7471291e-01
 4.7491515e-01 4.6681383e-01 4.4065946e-01 4.5257786e-01 4.9734491e-01
 4.9276921e-01], shape=(296,), dtype=float32)
rounded label:tf.Tensor(
[0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.
 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1.
 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1.
 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0.], shape=(296,), dtype=float32)
predicted label rank:[1 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2
 2 2 1 2 1 2 1 1 2 2 2 2 1 2 2 1 2 2 2 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2
 1 2 1 1 1 1 1 2 1 2 2 1 2 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 2 1 1
 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 2 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 2
 1 2 2 1 1 1 2 1 1 1 1 1 2 2 2 2 1 1 1 1 1 2 1 1 1 2 1 2 1 2 2 2 2 2 1 2 2
 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.2626292, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/s3_srvr_1a.cil.c-1_000.smt2
true label:[1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1]
true label rank:[2 2 1 1 1 1 2 1 1 1 2 2]
predicted label:tf.Tensor(
[0.49734393 0.66909623 0.25578567 0.24543694 0.49207747 0.92705804
 0.6736941  0.50969446 0.4632598  0.48460382 0.4982848  0.4934951 ], shape=(12,), dtype=float32)
rounded label:tf.Tensor([0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.], shape=(12,), dtype=float32)
predicted label rank:[1 2 1 1 1 2 2 2 1 1 1 1]
mse:tf.Tensor(0.24278189, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0065_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.5048003  0.49924013 0.49506557 0.500866   0.47381338 0.5280161
 0.50441664 0.5111072  0.44494602 0.4929309  0.49632862 0.493533
 0.52204263 0.4810903 ], shape=(14,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0.], shape=(14,), dtype=float32)
predicted label rank:[2 1 1 2 1 2 2 2 1 1 1 1 2 1]
mse:tf.Tensor(0.24670278, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/count_by_1_variant_true-unreach-call.c.flat_000.smt2
true label:[1]
true label rank:[1]
predicted label:tf.Tensor([0.5009267], shape=(1,), dtype=float32)
rounded label:tf.Tensor([1.], shape=(1,), dtype=float32)
predicted label rank:[1]
mse:tf.Tensor(0.24907419, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/metros_1_e2_1102_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1
 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1
 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1
 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2
 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1
 1 1 1 1 1 2 2 1 1 1 2 1 2 1 2 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 2 2 1
 1 1 1 1 1 1 2 2 2 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 2 2 1 1 2 1 1 2 1 1 1 1 1
 1 2 2 2 2 1 1 1 1 2 1 1 1 1 2 1 1 2 2 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1 2 2 2
 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 2 1 2 2 1 1 2 2 1 1 1 1 1 1 1 1 1 2 2 1 2
 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1
 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 2 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 2 1 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 1 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[3.9547494e-01 5.7431364e-01 4.9435627e-01 4.6115488e-01 4.7455165e-01
 7.8717619e-01 7.0771813e-02 9.0764010e-01 3.7562847e-04 1.8635270e-01
 2.0558834e-03 1.0586143e-02 3.2810596e-01 3.0629635e-03 4.0983146e-01
 6.7688507e-01 9.0649152e-01 8.1695122e-01 1.3220701e-01 2.9222518e-02
 1.6863048e-03 4.8574805e-04 3.4864247e-03 8.8485986e-01 9.8584288e-01
 9.7651362e-01 1.4181346e-02 8.1107306e-01 2.8010935e-02 1.5245855e-02
 5.6170374e-02 2.4472585e-01 1.0403544e-02 6.5100211e-01 2.2623444e-01
 2.1196723e-02 8.3566475e-01 9.5857239e-01 9.6350205e-01 8.3051473e-02
 8.9857996e-01 1.5750200e-01 9.1025174e-01 8.6754292e-02 1.0212755e-01
 5.8277005e-01 6.5975988e-01 5.0294095e-01 5.1728183e-01 2.8998387e-01
 5.2626461e-01 4.7285432e-01 4.3883774e-01 5.2026927e-01 6.5288591e-01
 7.0083630e-01 4.8289090e-01 7.8140557e-01 3.5439885e-01 5.0998265e-01
 6.4784771e-01 5.3655362e-01 3.1511211e-01 5.5985904e-01 7.6699173e-01
 4.4733346e-01 5.8021533e-01 6.8302500e-01 4.1824478e-01 4.0138301e-01
 5.8147788e-01 5.2333802e-01 6.9424266e-01 5.5957121e-01 3.7407380e-01
 6.2402081e-01 5.1738280e-01 2.9356924e-01 4.5635217e-01 6.6348398e-01
 2.1624416e-01 4.6968913e-01 4.0094656e-01 7.3810583e-01 5.6179035e-01
 5.5370140e-01 3.4786570e-01 3.9747289e-01 4.5120719e-01 5.6243402e-01
 5.3080326e-01 5.6783050e-01 5.2257037e-01 3.6748379e-01 2.4995697e-01
 6.2325740e-01 4.2197531e-01 5.2923310e-01 4.1390318e-01 5.2439022e-01
 6.0661161e-01 7.6009393e-01 4.5915934e-01 5.4466057e-01 4.6868744e-01
 4.6954474e-01 5.6023568e-01 6.2559855e-01 5.3049469e-01 6.9268525e-01
 3.1147128e-01 3.2532713e-01 4.4699675e-01 6.9984645e-01 5.4205698e-01
 6.2749881e-01 4.2396426e-01 5.2930945e-01 3.4944567e-01 6.1126429e-01
 3.8810396e-01 4.1622970e-01 4.2265350e-01 6.8933356e-01 6.2016380e-01
 5.5828804e-01 4.0593454e-01 4.7318622e-01 3.4386113e-01 6.5750229e-01
 3.6786443e-01 5.2749532e-01 3.7539107e-01 6.5272588e-01 5.5800545e-01
 5.2433062e-01 4.1374707e-01 4.2736179e-01 3.7959042e-01 5.3452939e-01
 4.0439737e-01 3.9086673e-01 4.3693957e-01 6.7443067e-01 4.2920077e-01
 4.8268884e-01 5.2645552e-01 5.2871883e-01 4.6528432e-01 5.5704141e-01
 5.3182137e-01 5.0203860e-01 4.8617634e-01 5.5369723e-01 4.9229506e-01
 5.5380732e-01 4.6960923e-01 4.4635358e-01 4.5681441e-01 4.8127618e-01
 5.0407612e-01 5.4489797e-01 4.4762126e-01 4.7936007e-01 5.0840169e-01
 5.3255779e-01 4.5385605e-01 5.0224304e-01 4.7739598e-01 4.5804918e-01
 4.7242880e-01 4.5427507e-01 4.6868777e-01 4.8443949e-01 4.5132014e-01
 5.0350648e-01 4.8674881e-01 4.9143755e-01 5.1790249e-01 4.7646955e-01
 5.0665569e-01 4.6626157e-01 4.7411358e-01 5.0933743e-01 5.7225263e-01
 4.9442220e-01 5.2450746e-01 5.1947111e-01 4.7914672e-01 5.4746461e-01
 5.2177954e-01 5.2861297e-01 4.9106544e-01 4.7052753e-01 5.2314091e-01
 3.8315922e-01 4.4636762e-01 5.9901845e-01 5.3570110e-01 4.6542779e-01
 5.2133191e-01 4.4845319e-01 4.7365725e-01 4.5843920e-01 4.5359969e-01
 4.4558221e-01 5.6300688e-01 5.1408678e-01 4.5134169e-01 4.7831655e-01
 4.9454677e-01 4.2251664e-01 5.0069886e-01 4.7783613e-01 5.9229100e-01
 4.8472905e-01 5.6318152e-01 4.7141087e-01 5.1274770e-01 4.4139421e-01
 5.6513071e-01 5.0399590e-01 4.5016876e-01 5.1383311e-01 4.6651375e-01
 4.6686190e-01 4.6219116e-01 4.1498658e-01 4.6204183e-01 4.4688800e-01
 4.7501129e-01 4.4417977e-01 4.5683715e-01 4.3304110e-01 4.3183106e-01
 5.3549325e-01 4.7790930e-01 5.4465693e-01 4.1756108e-01 4.3256146e-01
 4.4150743e-01 4.2253512e-01 4.6922117e-01 5.0855583e-01 5.3069866e-01
 4.5428941e-01 4.8817986e-01 4.5333308e-01 4.1052368e-01 4.9859679e-01
 4.6028683e-01 4.6688962e-01 4.4260967e-01 5.3423738e-01 4.5340151e-01
 4.0134203e-01 4.4716257e-01 4.8960826e-01 4.5038781e-01 4.6115503e-01
 4.8384896e-01 5.2052408e-01 5.5405051e-01 4.7437054e-01 5.1577431e-01
 5.0477910e-01 4.6551800e-01 4.9564534e-01 5.0225395e-01 5.0191945e-01
 4.5342910e-01 4.5189357e-01 4.8790762e-01 4.5255053e-01 4.8738748e-01
 4.2323214e-01 4.4934502e-01 4.7385931e-01 5.0953752e-01 5.0290579e-01
 4.6095777e-01 5.1521069e-01 5.1094633e-01 4.9528560e-01 5.2003354e-01
 4.8648033e-01 5.0989872e-01 4.9575970e-01 4.7905475e-01 4.6894705e-01
 4.5445919e-01 4.5043874e-01 4.4271097e-01 5.1546073e-01 5.0717956e-01
 4.5319980e-01 4.4091567e-01 4.8461962e-01 4.6374705e-01 4.9571967e-01
 3.9517274e-01 5.1575577e-01 4.9915856e-01 4.7517917e-01 4.4618902e-01
 2.1660242e-05 8.7151647e-01 9.4579542e-01 5.6215823e-03 6.8470538e-03
 9.9827039e-01 1.9927025e-03 3.7276745e-04 9.8304451e-03 7.7910978e-01
 9.8743373e-01 2.5850338e-01 1.1478275e-02 2.8289843e-01 7.7580917e-01
 9.2004770e-01 1.4008510e-01 1.8738776e-02 5.6894225e-01 1.0069311e-03
 8.0644637e-01 1.2398034e-02 2.2428089e-01 4.8997840e-01 5.0361860e-01
 5.0090998e-01 4.9127778e-01 4.8351955e-01 4.9903178e-01 4.6547064e-01
 4.8581967e-01 4.8015237e-01 4.7624221e-01 5.0893331e-01 4.8809588e-01
 4.7864768e-01 4.7776192e-01 4.9633327e-01 4.7858137e-01 4.5269281e-01
 4.5434755e-01 4.5757192e-01 5.1064605e-01 5.0794089e-01 5.0396079e-01
 4.2784354e-01 4.6320060e-01 5.0023454e-01 5.1581663e-01 4.7027773e-01
 4.7952047e-01 4.3250078e-01 4.4186500e-01 5.0761533e-01 4.9793258e-01
 4.7194418e-01 4.5303482e-01 5.4897588e-01 5.2624375e-01 4.5801461e-01
 4.8100734e-01 4.7913545e-01 4.8907742e-01 4.9089399e-01 5.4360020e-01
 4.8076481e-01 5.2726239e-01 5.1616102e-01 4.7375458e-01 5.2266467e-01
 5.0113678e-01 5.9865183e-01 4.9566773e-01 4.4019336e-01 5.5502564e-01
 4.4026390e-01 4.5334855e-01 5.6015784e-01 7.6622766e-01 2.7397567e-01
 3.9138672e-01 6.3678473e-01 4.0559953e-01 5.1312894e-01 4.4144776e-01
 5.3190726e-01 4.3625143e-01 4.1265973e-01 6.3232017e-01 4.2271399e-01
 6.2634856e-01 4.3977237e-01 2.1626523e-01 4.4513372e-01 6.1493176e-01
 5.8736044e-01 6.2419623e-01 7.6868713e-01 6.1704874e-01 5.2423984e-01
 4.5316783e-01 5.3013474e-01 3.4772992e-01 6.6460598e-01 5.7380879e-01
 4.9252629e-01 4.7621644e-01 4.4423658e-01 4.2459336e-01 5.0800288e-01
 4.5844033e-01 5.0346982e-01 4.8638111e-01 4.7506696e-01 4.9484190e-01
 4.8556998e-01 5.4722190e-01 5.2717936e-01 4.8985976e-01 4.6757719e-01
 5.4721874e-01 4.8639205e-01 4.8080739e-01 5.3221458e-01 4.8269570e-01
 4.7926345e-01 5.5118364e-01 4.9136579e-01 5.0388914e-01 4.6906400e-01
 4.9920818e-01 5.0581884e-01 5.1401615e-01 5.3010154e-01 5.3843737e-01
 4.7901416e-01 5.2479190e-01 5.2205372e-01 5.2801973e-01 4.9228966e-01
 4.9753767e-01 4.7701782e-01 4.1285828e-01 5.0931305e-01 5.3890616e-01
 5.2810031e-01 5.1389086e-01 5.1159692e-01 5.1345623e-01 4.6873412e-01
 4.8821902e-01 5.1746923e-01 4.7857052e-01 4.5196268e-01 5.3130108e-01
 5.2498537e-01 5.5938339e-01 4.8006842e-01 4.9246159e-01 5.0080812e-01
 5.0365144e-01 4.6545824e-01 5.2314836e-01 4.8399350e-01 4.7956401e-01
 4.9019748e-01 4.8955801e-01 5.0138205e-01 4.8082590e-01 5.0396842e-01
 5.1410049e-01 5.5626470e-01 4.9907032e-01 4.4978997e-01 5.0843364e-01
 4.4640583e-01 4.5989364e-01 4.7599006e-01 4.8273504e-01 4.6693078e-01
 4.9100816e-01 4.7927490e-01 4.9860176e-01 4.0209323e-01 5.5130035e-02
 6.3097173e-01 9.9035800e-01 9.9292123e-01 6.3706625e-01 9.0787542e-01
 8.3799660e-03 3.5593846e-01 7.4983358e-02 2.0276451e-01 5.8942473e-01
 9.6190113e-01 2.6726425e-03 1.6577154e-01 5.5343318e-01 1.9812623e-01
 8.7982482e-01 5.4991812e-01 9.8606861e-01 8.1356549e-01 9.7815251e-01
 7.9016471e-01 4.4951549e-01 8.3895671e-01 9.1156167e-01 2.9524282e-01
 6.4192039e-01 5.6009060e-01 2.0119947e-01 8.3474374e-01 8.9452463e-01
 1.0455608e-01 2.9680207e-01 6.8227822e-01 4.8477179e-01 1.7331299e-01
 5.9158063e-01 5.8286524e-01 4.3565610e-01 2.8821301e-01 4.4241789e-01
 8.3266687e-01 3.9237037e-01 5.7670712e-01 5.1054800e-01 7.1902049e-01
 5.0066471e-01 4.9458402e-01 4.9381411e-01 5.0902146e-01 5.1164252e-01
 5.2393132e-01 4.9528316e-01 4.8388889e-01 4.9898544e-01 5.0578064e-01
 4.9610153e-01 5.1032084e-01 5.0701511e-01 5.1155311e-01 5.0265115e-01
 5.1072013e-01 5.0392061e-01 5.0000209e-01 5.0911021e-01 4.8820493e-01
 5.1286906e-01 5.2537268e-01 4.3989989e-01 5.6617856e-01 4.2965651e-01
 6.6564965e-01 4.0853515e-01 3.7869322e-01 4.6575189e-01 5.3155577e-01
 5.1439279e-01 5.0686610e-01 4.6114528e-01 5.6893116e-01 4.7616416e-01
 5.0184405e-01 4.2071867e-01 4.8037732e-01 5.2233696e-01 4.0454727e-01
 4.9684161e-01 5.0896293e-01 5.0139773e-01 4.6525761e-01 4.8385876e-01
 4.8282242e-01 4.7158444e-01 4.7132027e-01 4.7291920e-01 4.9286348e-01
 4.7543758e-01 4.4396949e-01 4.4496018e-01 4.4973361e-01 5.0928479e-01
 5.0808871e-01 4.7920778e-01 5.3873092e-01 4.8279065e-01 4.2383498e-01
 4.3410537e-01 4.7285467e-01 4.4961792e-01 4.4555509e-01 4.6883488e-01
 4.5275217e-01 5.0853807e-01 5.0774568e-01 4.9311191e-01 5.7096177e-01
 4.8912632e-01 5.3427684e-01 4.9232787e-01 4.6837160e-01 4.9383831e-01
 4.4774649e-01 4.9758282e-01 5.7410288e-01 4.9487612e-01 4.4722211e-01
 5.2920741e-01 5.2363265e-01 4.2618960e-01 4.8319787e-01 4.8176149e-01
 5.5888718e-01 4.6286166e-01 4.7710794e-01 4.8838767e-01 4.5406350e-01
 5.3661370e-01 4.4451460e-01 5.3739423e-01 5.0135297e-01 4.6605381e-01
 5.3036344e-01 5.1016241e-01 4.3212289e-01 4.7197619e-01 5.3968638e-01
 4.1739902e-01 5.0446218e-01 4.6528810e-01 4.9948660e-01 5.0495863e-01
 5.2964747e-01 5.2263248e-01 5.2187675e-01 4.9075168e-01 5.1880789e-01
 5.7150376e-01 4.5759746e-01 4.8774326e-01 4.8622912e-01 4.8198140e-01
 5.1908195e-01 4.8406249e-01 5.0963700e-01 5.1436150e-01 5.4345441e-01
 5.3710634e-01 5.0941026e-01 4.9144015e-01 5.1219678e-01 4.9897587e-01
 5.0592476e-01 5.1631898e-01 5.2044767e-01 5.0801539e-01 4.7661743e-01
 4.8156932e-01 4.7330096e-01 5.3665060e-01 5.2477771e-01 5.1632279e-01
 4.9253121e-01 5.1613861e-01 5.0029099e-01 5.1227015e-01 4.9784094e-01
 5.0653839e-01 5.2204764e-01 5.1208258e-01 5.0703460e-01 4.9878055e-01
 4.9840999e-01 5.0313336e-01 5.1734310e-01 4.8909175e-01 5.0547361e-01
 5.0004023e-01 5.0493199e-01 4.9039215e-01 4.9036795e-01 4.8323834e-01
 4.8964161e-01 4.9275619e-01 5.0556469e-01 4.9594194e-01 4.9968001e-01
 4.9889883e-01 4.9599168e-01 4.9485824e-01 5.0310296e-01 4.9112040e-01
 4.8858601e-01 5.0244939e-01 5.0023776e-01], shape=(703,), dtype=float32)
rounded label:tf.Tensor(
[0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.
 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.
 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1.
 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1.
 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0.
 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.
 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.
 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.
 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1.
 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0.
 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1.
 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.
 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1.
 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0.
 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0.
 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1.
 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 1. 0. 0. 1. 1.], shape=(703,), dtype=float32)
predicted label rank:[1 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 2 2 2 1 2 1 1 1 1 1 2 1 1 2
 2 2 1 2 1 2 1 1 2 2 2 2 1 2 1 1 2 2 2 1 2 1 2 2 2 1 2 2 1 2 2 1 1 2 2 2 2
 1 2 2 1 1 2 1 1 1 2 2 2 1 1 1 2 2 2 2 1 1 2 1 2 1 2 2 2 1 2 1 1 2 2 2 2 1
 1 1 2 2 2 1 2 1 2 1 1 1 2 2 2 1 1 1 2 1 2 1 2 2 2 1 1 1 2 1 1 1 2 1 1 2 2
 1 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 2 1 1 2 2
 1 2 2 1 2 2 2 1 1 2 1 1 2 2 1 2 1 1 1 1 1 2 2 1 1 1 1 2 1 2 1 2 1 2 1 2 2
 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 2 2 1 2 2 1 1 2 2 1 1 1 1 1 1 1 1 2 2 1 2 2 1 2 1 2 1 1 1 1 1 1 2 2 1
 1 1 1 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 2 1 1 1 2 2 1 1 2 1 2 1 1 1 2 2 1 1
 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 1 1 2 2 1 1 1 1 2 1 1 1 2 2 1 1 1 1 1 2
 1 2 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 1 2 1 2 1 1 2 1 2 1 1 1 2 2 2 2 2 2 1 2
 1 2 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2 1 1 2 1 1 2 1 2 1 1 2 2 2 2 1 2 2 2
 1 1 1 1 2 2 2 2 2 2 1 1 2 1 1 2 2 2 1 1 2 2 1 2 1 1 1 1 2 1 2 2 2 1 1 2 1
 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 2 2 1 1 2 1 2 2 2 2 2 2 1 2 2 1 2 2 1
 2 2 1 1 2 1 1 2 2 1 1 1 2 1 2 2 2 2 1 1 2 2 2 1 1 1 2 1 2 2 2 2 2 2 2 2 1
 2 2 1 2 1 2 1 1 1 2 2 2 1 2 1 2 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1
 2 1 1 1 1 1 1 1 1 2 2 1 2 1 2 1 1 1 1 1 2 1 1 2 2 1 1 1 2 1 1 1 1 2 1 2 2
 1 2 2 1 1 2 1 2 1 1 2 2 2 2 1 2 2 1 1 1 1 2 1 2 2 2 2 2 1 2 1 2 2 2 2 1 1
 1 2 2 2 1 2 2 2 1 2 2 2 2 1 1 2 2 1 2 2 2 1 1 1 1 1 2 1 1 1 1 1 2 1 1 2 2]
mse:tf.Tensor(0.27364582, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/gcd01_true-unreach-call_true-no-overflow_true-termination_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.5032504  0.503408   0.4959481  0.49828464 0.4706473  0.5321156
 0.48623118 0.52534175], shape=(8,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 0. 0. 1. 0. 1.], shape=(8,), dtype=float32)
predicted label rank:[2 2 1 1 1 2 1 2]
mse:tf.Tensor(0.24844241, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/loop__upcount_000.smt2
true label:[1, 1, 1, 1]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([0.52432066 0.53991354 0.46000198 0.52392256], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1.], shape=(4,), dtype=float32)
predicted label rank:[2 2 1 2]
mse:tf.Tensor(0.2390495, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0000_000.smt2
true label:[1, 1]
true label rank:[1 1]
predicted label:tf.Tensor([0.49317825 0.5128238 ], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 2]
mse:tf.Tensor(0.24710445, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/traverse3_unsafe.c_000.smt2
true label:[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 2 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 2 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 2 1 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.5038802  0.5412795  0.52472657 0.5056211  0.49591747 0.52267385
 0.50574225 0.5228624  0.5049013  0.49973208 0.51151484 0.5091497
 0.50728744 0.5064603  0.51181257 0.52834433 0.5252682  0.51324683
 0.5187644  0.5016386  0.49211305 0.5156554  0.5135559  0.5006626
 0.51538897 0.52180403 0.5323042  0.5064508  0.49917194 0.4840495
 0.5346428  0.5139676  0.5098264  0.51957    0.51718974 0.505752
 0.5112954  0.5056453  0.5076289  0.5047171  0.520265   0.500885
 0.50936943 0.5323234  0.50093    0.5086454  0.5042541  0.5064971
 0.5365804  0.5160022  0.5110834  0.5078505  0.5190174  0.5216229
 0.51773137 0.51400715 0.50673485 0.5259422  0.54132396 0.5161637
 0.5047723  0.50654936 0.5136623  0.50735855 0.5226098  0.46127728
 0.481386   0.45682588 0.4642731  0.46915135 0.5153077  0.48213738
 0.45330086 0.44046327 0.46961617 0.50052994 0.48721898 0.4610808
 0.46716002 0.48443043 0.45855603 0.46759728 0.48055953 0.48498628
 0.457807   0.47184035 0.45597905 0.46654135 0.45648047 0.47673807
 0.48124316 0.48022318 0.46715367 0.47240332 0.4742593  0.43974966
 0.4786192  0.4420942  0.47301444 0.45727447 0.43446013 0.47361684
 0.47378016 0.46984    0.46660972 0.46373633 0.45547026 0.4993839
 0.45848328 0.46897063 0.45051396 0.45945022 0.44529775 0.44290644
 0.4745941  0.46831793 0.46939912 0.4651066  0.4677715  0.47070163
 0.45725244 0.45381522 0.48229602 0.49076837 0.45957902 0.4786337
 0.44537455 0.45133004 0.47310215 0.46212378 0.4630744  0.5140205
 0.49226132 0.46081305 0.46413943 0.46253362 0.4685051  0.44843912
 0.48107913 0.46809238 0.47093764 0.48690945 0.46418107 0.46371478
 0.461484   0.47020993 0.4646918  0.46003404 0.45322266 0.4700088
 0.46049064 0.45186213 0.46962848 0.42602333 0.48247844 0.4594487
 0.44604054 0.47577715 0.45492375 0.47022933 0.45222846 0.48854843
 0.48809004 0.45639205 0.48938942 0.5136642  0.50462466 0.50635135
 0.5072244  0.4876424  0.4868207  0.49102604 0.49978378 0.49153894
 0.48831862 0.5084486  0.48935446 0.504876   0.49607593 0.49724987
 0.48480368 0.50302416 0.4637633  0.51899725 0.5003968  0.5033399
 0.47332603 0.50999063 0.4895114  0.49408767 0.5020585  0.5253223
 0.5067052  0.49182472 0.5001453  0.513653   0.47349808 0.514291
 0.51245517 0.46920165 0.5117435  0.4740071  0.4945265  0.49914145
 0.49810848 0.5042038  0.5092802  0.4660134  0.50602007 0.48226872
 0.49772623 0.4807315  0.47761452 0.4852034  0.5222985  0.49450445
 0.5111202  0.51166284 0.49550468 0.5036815  0.52684003 0.5085876
 0.49618027 0.5004529  0.48822325 0.5060387  0.48680678 0.5008782
 0.49389818 0.47965136 0.48875    0.4922385  0.47632465 0.4494198
 0.5003506  0.5253136  0.47560367 0.51257133 0.48421916 0.50158143
 0.5004335  0.45829287 0.4925004  0.49871907 0.5009114  0.5059361
 0.5059717  0.48457977 0.503392   0.48794648 0.49484432 0.4768695
 0.47229713 0.52463824 0.5019517  0.47714683 0.477642   0.50086886
 0.5074918  0.5032931  0.4846076  0.49974984 0.49227485 0.49301162
 0.50435823 0.5027917  0.4939291  0.47011665 0.5111662  0.49712908
 0.47283605 0.4753181  0.49984154 0.4964619  0.4916758  0.4824989
 0.48702696 0.48717037 0.4971255  0.51581967 0.51071    0.49090266
 0.4745457  0.47826007 0.50424546 0.47986388 0.520955   0.52068186
 0.5057437  0.46702105 0.4831149  0.5016548  0.50352997 0.52099764
 0.48610753 0.495284   0.50252324 0.47998863 0.48341572 0.4804125
 0.4825986  0.4434749  0.48209623 0.5071986  0.46558416 0.49186817
 0.49802822 0.50918525 0.4893975  0.42927846 0.4677195  0.46997088
 0.48067722 0.47281894 0.5033281  0.48821893 0.47542995 0.4985695
 0.48993364 0.4433399  0.4446831  0.4581286  0.45953172 0.49542755
 0.45893872 0.46892375 0.46608898 0.48319414 0.43994835 0.4347428
 0.47188026 0.46419686 0.46971828 0.46072546 0.4736701  0.4489681
 0.48930186 0.4487277  0.47155815 0.50240386 0.470474   0.48105434
 0.48183954 0.49406517 0.5014049  0.44690433 0.46401215 0.5019198
 0.48798004 0.4543921  0.48071578 0.4946124  0.45917577 0.47684813
 0.47179523 0.4778743  0.46214217 0.46950945 0.4828216  0.4559554
 0.483098   0.48357964 0.47176713 0.47224605 0.4960114  0.49634317
 0.49450052 0.44266486 0.4695912  0.51825756 0.49592483 0.49310288
 0.47168761 0.506546   0.50581294 0.47364184 0.4853669  0.47489482
 0.46932292 0.46537796 0.47305548 0.48240283 0.47984943 0.48677418
 0.4860981  0.49071485 0.4788189  0.492046   0.5051242  0.47432327
 0.4518956  0.47894013 0.47657752 0.49099457 0.47932824 0.46399382
 0.468928   0.47981748 0.49119812 0.487299   0.4805858  0.46592695
 0.46217322 0.47565237 0.4778921  0.48106933 0.46239042 0.49234948
 0.4532345  0.46432    0.45362327 0.4793418  0.5084198  0.46555588
 0.4657538  0.47835252 0.5137991  0.4928073  0.4878449  0.44070253
 0.49284872 0.47077924 0.47778776 0.50076693 0.47619694 0.46255842
 0.47637352 0.471941   0.48265767 0.45111853 0.5085822  0.47643405
 0.4616444  0.47911802 0.48702013 0.49216872 0.51016366 0.4814583
 0.4899069  0.49264896 0.48320386 0.48754308 0.49693874 0.46870047
 0.49378204 0.4872166  0.4771693  0.48365474 0.49444655 0.46674737
 0.4933554  0.471659   0.49479824 0.5044036  0.4769333  0.48418626
 0.47481737 0.46969485 0.48514172 0.48734078 0.48598632 0.47724557
 0.4814813  0.46351922 0.50030917 0.48093757 0.47585517 0.46609318
 0.4814392  0.5058802  0.4945952  0.48131207 0.46828297 0.49315238
 0.47893098 0.47080547 0.48551846 0.48383605 0.47660694 0.48479193
 0.47740126 0.48453978 0.48512    0.48348224 0.47995448 0.47073722
 0.4539891  0.5052173  0.47805107 0.4727862  0.49652338 0.4770853
 0.49137527 0.4861761  0.49071142 0.47919443 0.4830825  0.49354914
 0.479503   0.47326148 0.4832325  0.47837034 0.48842162 0.4952256
 0.4770498  0.50605303 0.49760762 0.46976146 0.492057   0.48008832
 0.47790682 0.46164715 0.47016248 0.480843   0.48826352 0.46377295
 0.48905194 0.50445616 0.46099687 0.45768198 0.48024714 0.48702776
 0.4716434  0.49467975 0.4805583  0.47752428 0.49891943 0.4685017
 0.50075585 0.50177866 0.49768445 0.47413757 0.48490793 0.49491993
 0.47302374 0.4915148  0.4739461  0.47433013 0.47121942 0.5091325
 0.48363844 0.49626556 0.47025794 0.4907375  0.4757578  0.49388987
 0.47594786 0.4918344  0.46066445 0.5055157  0.4880523  0.47310606
 0.47798687 0.4723836  0.49091822 0.47341865 0.45755935 0.50136447
 0.4569348  0.49684253 0.48348424 0.48195565 0.4659027  0.4900628
 0.4689514  0.48130205 0.46532327 0.49012467 0.47837844 0.48665184
 0.49920833 0.4843684  0.47835532 0.49097732 0.49083978 0.46965063
 0.4729592  0.49057785 0.48315594 0.49210447 0.49397004 0.492599
 0.4964732  0.48241878 0.48911804 0.48342094 0.45763984 0.47197175
 0.49321842 0.4792757  0.47578382 0.4822615  0.4876851  0.48465583
 0.48353925 0.47672004 0.48411506 0.49700826 0.4850622  0.4896853
 0.47478992 0.4855733  0.4737397  0.47227475 0.4819069  0.48228362
 0.51007706 0.5183052  0.4976686  0.48197442 0.48821443 0.5117055
 0.5025106  0.4848426  0.5127259  0.48948067 0.4915867  0.4884789
 0.45301184 0.50197154 0.4846651  0.5060487  0.47862026 0.50237715
 0.5031533  0.50644946 0.4783534  0.5114243  0.48207155 0.49724963
 0.48591036 0.49457642 0.48935357 0.47885302 0.5052517  0.4844043
 0.50559306 0.48103586 0.49978203 0.5224295  0.48335496 0.49465486
 0.4944668  0.45726663 0.489923   0.5026819  0.509954   0.51763654
 0.50834185 0.47721708 0.47228017 0.47465757 0.482308   0.5006716
 0.5017509  0.48551503 0.48802423 0.5072474  0.4719652  0.5166856
 0.4984552  0.4865283  0.46973726 0.47133315 0.49061906 0.4644751
 0.46154916 0.4965973  0.49251118 0.48959392 0.49327725 0.5000884
 0.47916058 0.5090839  0.4866587  0.50767463 0.5162952  0.48796293
 0.4960125  0.4956448  0.4960395  0.5140915  0.51158434 0.4904751
 0.49873558 0.50445336 0.501538   0.5086426  0.49655366 0.48858428
 0.500133   0.5050149  0.50346094 0.50285065 0.48135668 0.48735523
 0.4953775  0.49734995 0.5117349  0.49399236 0.49040428 0.50171214
 0.49399027 0.505698   0.48443457 0.49804643 0.496823   0.5026697
 0.4999181  0.46391937 0.4801116  0.4585203  0.4841827  0.46998474
 0.47729278 0.4801182  0.47565916 0.45573977 0.46778405 0.46473145
 0.4747697  0.47027156 0.47528896 0.47373822 0.47134173 0.47464976
 0.47873145 0.47251615 0.46945363 0.4739956  0.4743666  0.47721726
 0.47159746 0.46579084 0.4800394  0.4707005  0.46987024 0.45949018
 0.47955087 0.48297635 0.4801863  0.47944975 0.48291078 0.4696028
 0.5014995  0.46879476 0.4844906  0.4725417  0.48236644 0.4792484
 0.4814782  0.47830376 0.49242708 0.48047993 0.4814517  0.45772853
 0.4536538  0.49467638 0.46909577 0.4873213  0.47381416 0.48550662
 0.48088488 0.47390753 0.4850237  0.47709    0.49057022 0.46890804
 0.48783508 0.47527075 0.4791459  0.48369747 0.47841117 0.4687174
 0.4703816  0.47650844 0.49405915 0.4951462  0.49576715 0.4841218
 0.46827787 0.47200862 0.47924888 0.4648648  0.47244284 0.45342213
 0.4814329  0.45943028 0.46808785 0.4791468  0.4616185  0.47209868
 0.45076615 0.4791516  0.48575023 0.47828048 0.47655624 0.46612245
 0.46651742 0.4771149  0.47822326 0.46990758 0.46613607 0.476765
 0.47036412 0.47181094 0.48296794 0.47141984 0.46307442 0.46778142
 0.46842113 0.47136208 0.47714502 0.45911556 0.47604582 0.47349846
 0.46495575 0.46930537 0.47539425 0.46436846 0.48330534 0.47177672
 0.4668208  0.45560992 0.47242722 0.48003954], shape=(826,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.
 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.
 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1.
 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0.
 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1.
 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0.
 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1.
 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1.
 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1.
 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(826,), dtype=float32)
predicted label rank:[2 2 2 2 1 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 2 1 1 1
 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 2 1 2 1 1 1 2 1 2 2
 2 1 2 1 1 2 2 2 1 2 2 1 2 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2
 1 2 1 2 1 2 1 1 1 1 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 2 1 1 1 1 2 2 1 1 2 2
 2 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 2 2 2 1 1 2 2 2 1 1
 2 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2
 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 2 1 2 1 1 1 1 2 1 2 1 2 2 2 1 2 1
 1 1 1 1 1 2 1 2 1 1 2 1 1 1 1 1 2 2 2 2 1 1 1 1 2 2 1 1 2 1 2 1 1 1 1 1 1
 1 1 1 1 1 2 1 2 1 2 2 1 1 1 1 2 2 1 1 2 2 2 1 1 2 2 2 2 1 1 1 1 2 1 1 2 1
 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.23799182, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/bound.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[9.5672464e-01 5.4289782e-01 3.9290199e-01 9.3691492e-01 2.3785365e-01
 9.9885678e-01 1.0703334e-01 8.4539008e-01 6.1874164e-07 1.8932298e-01], shape=(10,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 0. 1. 0. 1. 0. 0.], shape=(10,), dtype=float32)
predicted label rank:[2 2 1 2 1 2 1 2 1 1]
mse:tf.Tensor(0.40585145, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/while_after_while_if_merged_safe.c-1_000.smt2
true label:[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0]
true label rank:[2 1 1 1 1 2 1 1 2 1 2 2 1 1 1 2 2 1]
predicted label:tf.Tensor(
[0.49205932 0.5026822  0.502126   0.49548176 0.49924964 0.48235595
 0.48000252 0.4955654  0.47486198 0.49134645 0.4569084  0.46313748
 0.5100521  0.51097256 0.5017475  0.4918101  0.49685326 0.50323826], shape=(18,), dtype=float32)
rounded label:tf.Tensor([0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1.], shape=(18,), dtype=float32)
predicted label rank:[1 2 2 1 1 1 1 1 1 1 1 1 2 2 2 1 1 2]
mse:tf.Tensor(0.25775218, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/MOESI_2_e8_926_e8_2138_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1
 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1]
predicted label:tf.Tensor(
[9.9926388e-01 9.0598875e-01 1.3580561e-02 9.7516942e-01 1.7299113e-01
 9.8234892e-01 3.6468714e-02 5.8982944e-01 8.1295531e-07 5.8842063e-02
 1.5428662e-04 5.8940053e-04 3.5688281e-04 3.8394370e-05 2.7140081e-03
 9.2829859e-01 9.9978936e-01 8.9773333e-01 1.5627652e-02 6.2052667e-02
 1.1432637e-06 1.8919731e-05 3.8138439e-09 9.0312463e-01 9.9696887e-01
 9.9997246e-01 2.0881098e-06 9.7661185e-01 1.0043383e-03 6.8566034e-05
 1.2326953e-01 5.8308542e-03 4.5908462e-05 9.6220875e-01 3.6157072e-03
 3.0184267e-05 9.9013680e-01 9.4269907e-01 9.9957490e-01 5.6903362e-03
 9.7691762e-01 1.7271757e-02 9.8119795e-01 8.5381567e-03 1.0243058e-03
 9.7836846e-01 9.8197007e-01 9.8604763e-01 7.6595867e-01 7.3412430e-06
 4.7055104e-01 1.4692813e-02 6.3383549e-02 7.9719472e-01 9.9957323e-01
 5.8639044e-01 5.1545143e-01 5.2536845e-01 4.5071521e-01 5.0043786e-01
 4.6058500e-01 4.7987247e-01 4.9278513e-01 4.9076429e-01 4.4517940e-01
 5.1507348e-01 5.6358826e-01 4.8881593e-01 4.5114836e-01 4.8072249e-01
 6.1328369e-01 5.0809509e-01 5.0016612e-01 5.1099747e-01 4.5318446e-01
 5.7152706e-01 5.1479256e-01 4.1343957e-01 4.6848124e-01 4.4674414e-01
 4.2572129e-01 4.4729730e-01 4.5150998e-01 5.0017548e-01 5.2351856e-01
 5.3582597e-01 4.5210770e-01 4.7639403e-01 5.2863610e-01 5.0153410e-01
 5.0690645e-01 5.0350493e-01 5.5725521e-01 5.0769395e-01 4.9250019e-01
 5.2752513e-01 5.0793636e-01 5.2633131e-01 5.0007010e-01 5.2522427e-01
 5.2311355e-01 5.3300858e-01 5.0247389e-01 5.3653032e-01 5.1459354e-01
 4.8445496e-01 5.0923210e-01 4.8912796e-01 5.3270096e-01 5.2280480e-01
 5.1585609e-01 4.8959503e-01 4.9773252e-01 4.9245656e-01 4.9269986e-01
 5.0139600e-01 4.8529670e-01 5.0899738e-01 4.9452531e-01 4.7014254e-01
 4.8561159e-01 4.9357471e-01 4.8395032e-01 4.9911445e-01 4.8692352e-01
 4.9751046e-01 4.8054442e-01 4.7641170e-01 4.8981598e-01 6.1818773e-01
 3.2351664e-01 5.4432774e-01 4.6517745e-01 6.3608754e-01 4.2077953e-01
 4.9907842e-01 3.9416641e-01 4.6027941e-01 3.4730256e-01 6.3718492e-01
 5.2222300e-01 4.9410912e-01 4.8652941e-01 4.8465559e-01 4.9496377e-01
 4.8915428e-01 4.9630877e-01 4.9614650e-01 4.8603386e-01 4.9863353e-01
 5.1334018e-01 4.6996209e-01 4.9990186e-01 4.9219671e-01 4.9178332e-01
 5.0102258e-01 4.8811328e-01 4.9638072e-01 5.0349134e-01 4.9508762e-01
 5.0386673e-01 5.0002491e-01 4.8601311e-01 4.9018201e-01 4.9111193e-01
 4.8946097e-01 4.8717728e-01 5.0203037e-01 4.9677244e-01 4.8052120e-01
 4.7845519e-01 4.7044763e-01 4.7001857e-01 4.9110219e-01 4.7626087e-01
 4.7065666e-01 4.8141286e-01 4.7080964e-01 4.9111328e-01 4.7721303e-01
 5.0556916e-01 4.9751213e-01 4.8970011e-01 5.0048530e-01 4.8618743e-01
 4.9185911e-01 5.1566803e-01 4.9490514e-01 4.7664070e-01 4.7493580e-01
 5.1044756e-01 5.0546485e-01 5.1373535e-01 4.5520616e-01 4.5528868e-01
 4.2437342e-01 4.7240803e-01 5.5187881e-01 4.8519328e-01 4.9311844e-01
 4.7630495e-01 4.6801430e-01 4.6771422e-01 4.6065208e-01 4.5181471e-01
 4.8723558e-01 4.9412805e-01 4.7278428e-01 4.6624595e-01 5.0101370e-01
 4.7040305e-01 4.8116603e-01 4.8163870e-01 4.7929883e-01 4.7972623e-01
 4.9975815e-01 4.8943955e-01 4.7689676e-01 4.7263864e-01 4.8180541e-01
 4.8170805e-01 4.7017118e-01 4.6770620e-01 4.7873980e-01 4.8900673e-01
 4.8289567e-01 4.7348395e-01 4.6351153e-01 4.8038304e-01 4.5586112e-01
 4.9544609e-01 4.6142697e-01 4.3900421e-01 4.7252834e-01 4.7720379e-01
 4.6749240e-01 4.8078349e-01 4.7878733e-01 4.2761585e-01 4.7239152e-01
 4.6938032e-01 4.5467216e-01 4.8720619e-01 4.9205187e-01 5.5943578e-01
 5.2519190e-01 5.2122158e-01 4.6197233e-01 4.8866495e-01 5.3381699e-01
 5.0287527e-01 4.4662920e-01 4.7373223e-01 5.1849681e-01 4.8916724e-01
 4.7076696e-01 4.6439335e-01 4.8739946e-01 4.7686735e-01 4.9487540e-01
 4.7980747e-01 5.8583701e-01 5.0470477e-01 4.8340839e-01 4.6816278e-01
 4.7631103e-01 4.8087284e-01 4.8857784e-01 4.9684289e-01 4.5315996e-01
 4.5179701e-01 4.2610323e-01 4.9512547e-01 4.5267534e-01 4.8162478e-01
 4.3586260e-01 4.5215315e-01 4.4776684e-01 5.0125867e-01 4.9572197e-01
 4.7559679e-01 4.9390593e-01 4.6333948e-01 4.5104772e-01 4.9275485e-01
 4.1171926e-01 5.2237338e-01 5.0158834e-01 4.9669939e-01 5.1031411e-01
 4.8683909e-01 4.9162221e-01 4.8379713e-01 5.0491202e-01 4.9730512e-01
 5.1573086e-01 5.0274795e-01 4.8877937e-01 5.0445336e-01 4.8466578e-01
 4.8860064e-01 5.2176893e-01 5.0490510e-01 4.8590642e-01 4.8682374e-01
 5.0996852e-01 4.7931334e-01 4.9785623e-01 4.9974072e-01 4.9372986e-01
 4.9793369e-01 4.9459377e-01 4.7642013e-01 4.8624906e-01 4.6902692e-01
 5.0084102e-01 5.1901013e-01 5.1285410e-01 5.0411963e-01 5.2903968e-01
 4.9109086e-01 4.9934065e-01 5.1075637e-01 5.0043380e-01 5.1724577e-01
 4.9617183e-01 5.1463938e-01 5.1354438e-01 5.1594782e-01 4.9202055e-01
 5.0301045e-01 5.1491868e-01 5.1937985e-01 5.0833994e-01 5.1033223e-01
 4.8439062e-01 4.9236980e-01 5.1399851e-01 4.8748487e-01 4.7855592e-01
 5.0140417e-01 5.1726776e-01 4.8104098e-01 4.5588902e-01 4.8742461e-01
 4.7184202e-01 4.6088052e-01 4.7932392e-01 4.6994543e-01 4.7007021e-01
 4.6996537e-01 4.7144836e-01 4.8455960e-01 4.6236667e-01 4.7307861e-01
 4.7539556e-01 4.7772935e-01 4.7590372e-01 4.8840290e-01 4.5528454e-01
 4.6533552e-01 4.6356457e-01 4.5770782e-01 4.8020288e-01 4.5186031e-01
 4.5824111e-01 4.6032009e-01 4.4451132e-01 4.8716569e-01 4.7535494e-01
 4.9339521e-01 4.6958309e-01 4.9103454e-01 4.8700041e-01 4.9953485e-01
 4.8863390e-01 4.7521070e-01 4.7873557e-01 4.7769576e-01 4.7190639e-01
 4.6363235e-01 4.7735608e-01 5.0767249e-01 4.8056987e-01 4.5771825e-01
 4.9098128e-01 4.9272057e-01 4.9141654e-01 4.8352453e-01 4.8430321e-01
 4.8499760e-01 4.6935710e-01 4.7203043e-01 4.8556179e-01 4.7256297e-01
 4.7725129e-01 4.7522807e-01 4.2368579e-01 4.9920073e-01 5.0667733e-01
 4.4657189e-01 4.9686438e-01 5.4419571e-01 5.0189358e-01 4.7012141e-01
 5.0575775e-01 5.0254583e-01 4.8929983e-01 5.5866581e-01 4.8835194e-01
 4.7805914e-01 5.0926059e-01 4.8670051e-01 4.7740078e-01 5.0853568e-01
 4.7132286e-01 5.3133774e-01 5.2017236e-01 4.9778953e-01 4.8247486e-01
 5.2968282e-01 5.3924280e-01 5.3072488e-01 4.9818084e-01 5.6046164e-01
 5.6895363e-01 5.0253057e-01 5.1344168e-01 4.9060792e-01 5.0828350e-01
 4.7587523e-01 5.0789046e-01 4.6560198e-01 5.3201598e-01 4.5234221e-01
 6.6839719e-01 5.0925410e-01 6.6403693e-01 4.4477001e-01 7.8811824e-01
 2.0720825e-01 6.7074186e-01 6.0208577e-01 4.0080747e-01 2.2378892e-01
 6.0150570e-01 4.9727610e-01 2.1037146e-01 3.2207265e-01 5.3225380e-01
 6.8081653e-01 5.6138533e-01 5.0933748e-01 7.8650057e-01 1.5160555e-01
 6.7864907e-01 9.0061855e-01 6.3574463e-01 3.2146099e-01 5.9206009e-01
 8.1429756e-01 8.0350268e-01 2.6432580e-01 4.6019948e-01 4.0895003e-01
 5.2826554e-01 3.2292509e-01 7.3179829e-01 6.4170086e-01 1.3640934e-01
 3.4833038e-01 3.4055853e-01 4.5929652e-01 7.7825612e-01 5.3335011e-01
 3.3873704e-01 7.6078075e-01 4.6389428e-01 3.9730895e-01 5.0360149e-01
 4.8466825e-01 4.3825448e-01 5.0132644e-01 4.5943463e-01 5.3120124e-01
 4.6930382e-01 4.3712395e-01 5.2209133e-01 5.2928466e-01 4.8284429e-01
 4.7938192e-01 5.2552742e-01 4.9587744e-01 4.6472362e-01 4.8946437e-01
 4.1387010e-01 4.8775956e-01 5.0701761e-01 4.9292862e-01 5.1133746e-01
 5.2149326e-01 4.3286699e-01 5.0753188e-01 5.0669426e-01 4.8818517e-01
 5.1604944e-01 4.2711070e-01 5.6582677e-01 4.9444494e-01 5.4919070e-01
 4.5841864e-01 4.8287919e-01 5.2574378e-01 5.1382810e-01 4.9160397e-01
 4.9370918e-01 5.1274741e-01 5.0790292e-01 5.0488544e-01 4.7392276e-01
 5.0113732e-01 5.1480728e-01 5.3167212e-01 5.0944567e-01 4.9829376e-01
 5.1507676e-01 5.0151032e-01 5.0373393e-01 5.0511277e-01 5.1386076e-01
 5.1288652e-01 5.2598882e-01 5.1951575e-01 5.1376343e-01 5.0387520e-01
 5.2194834e-01 5.1909047e-01 5.1830089e-01 5.0319910e-01 5.2253097e-01
 5.0638050e-01 5.2079684e-01 5.0085980e-01 4.9917635e-01 4.9685019e-01
 5.0749874e-01 5.2431166e-01 5.1038414e-01 5.1942128e-01 5.0430256e-01
 5.0516129e-01 5.1961607e-01 5.4735816e-01 4.9955148e-01 5.4324746e-01
 4.9097615e-01 5.1968873e-01 5.0247997e-01 5.5975485e-01 5.2520132e-01
 5.3071672e-01 5.3059381e-01 5.4112023e-01 5.2376336e-01 5.0260270e-01
 5.2342314e-01 5.4055530e-01 5.2655464e-01 5.4550397e-01 5.3956139e-01
 5.2766913e-01 4.9943781e-01 5.2342641e-01 5.2826059e-01 5.0724888e-01
 5.1033777e-01 5.1514041e-01 5.3558558e-01 5.1721716e-01 5.3538519e-01
 5.0751275e-01 5.2055347e-01 4.9455118e-01 4.8611742e-01 5.1768720e-01
 5.0323409e-01 4.9563950e-01 5.0372595e-01 4.8790002e-01 5.0468612e-01
 4.9715680e-01 4.9520102e-01 4.6758559e-01 5.0349951e-01 4.5997125e-01
 4.7933009e-01 5.2027142e-01 4.9880055e-01 4.7491115e-01 4.8661241e-01
 4.8034424e-01 4.8579878e-01 4.7782931e-01 5.0534749e-01 4.9259624e-01
 5.2752888e-01 5.1203531e-01 4.9135259e-01 4.9434343e-01 5.3466916e-01
 5.0329840e-01 4.9113405e-01 4.9291757e-01 4.9723566e-01 4.8483151e-01
 4.8872566e-01 4.9063891e-01 4.7387010e-01 4.9416563e-01 5.1206607e-01
 4.8743799e-01 5.1415682e-01 5.0596339e-01 4.8746049e-01 4.8933375e-01
 4.8682374e-01 4.8517525e-01 5.1275361e-01 5.0991952e-01 4.7837490e-01
 4.7242805e-01 5.0633496e-01 4.9118578e-01 4.6002594e-01 5.0659007e-01
 4.4681975e-01 5.2357590e-01 5.0432611e-01 5.0355142e-01 5.3959042e-01
 4.9314374e-01 4.6428403e-01 5.1643258e-01 4.2842913e-01 5.1688755e-01
 5.5600256e-01 5.2256471e-01 5.0003636e-01 4.7156987e-01 5.1227617e-01
 4.7959876e-01 4.7547561e-01 5.0683296e-01 5.2309108e-01 5.1927257e-01
 4.9183425e-01 5.2304649e-01 5.2123100e-01 4.9454370e-01 5.2040589e-01
 5.1174372e-01 4.7309470e-01 4.6483976e-01 4.6757281e-01 4.9145740e-01
 5.1812619e-01 4.6279892e-01 5.2398789e-01 4.8944342e-01], shape=(669,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.
 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.
 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1.
 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.
 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0.
 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0.
 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1.
 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1.
 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1.
 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0.
 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0.], shape=(669,), dtype=float32)
predicted label rank:[2 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 2 2 2 1 2 1 1 1 1 1 2 1 1 2
 2 2 1 2 1 2 1 1 2 2 2 2 1 1 1 1 2 2 2 2 2 1 2 1 1 1 1 1 2 2 1 1 1 2 2 2 2
 1 2 2 1 1 1 1 1 1 2 2 2 1 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 1 2 1 2 2 2
 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1 1 2 2 1 1 1 1 1 1 1
 1 1 2 1 1 1 1 2 1 1 2 1 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1
 1 2 1 1 1 2 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 2 2 1 1 2 1 1 1 1 1
 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 2 1 1 1 2 1 2
 2 1 2 1 1 2 2 1 1 2 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 2 2 2 1 2 2 2 1 2 2 2
 2 2 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 2 1 2 2
 1 2 1 1 2 1 1 2 1 2 2 1 1 2 2 2 1 2 2 2 2 1 2 1 2 1 2 1 2 2 2 1 2 1 2 2 1
 1 2 1 1 1 2 2 2 2 2 1 2 2 2 1 2 2 2 1 1 1 2 1 2 2 1 1 1 1 2 2 1 2 1 1 2 1
 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1 1 2 1 2 2 1 2 2 1 2 1 2 1 2 1 1 2 2 1 1 2 2
 2 1 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 1 2
 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 1 1 2 2 1 2 1 2 1 1
 1 2 1 1 2 1 1 1 1 1 1 2 1 2 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 2 2
 1 1 2 1 1 2 1 2 2 2 2 1 1 2 1 2 2 2 2 1 2 1 1 2 2 2 1 2 2 1 2 2 1 1 1 1 2
 1 2 1]
mse:tf.Tensor(0.26131693, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/002-horn_000.smt2
true label:[1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0]
true label rank:[2 1 1 2 1 1 2 1 1 2 1 1]
predicted label:tf.Tensor(
[0.52048147 0.5045123  0.48520473 0.4940035  0.49517447 0.5032438
 0.4866095  0.49892098 0.47249764 0.4644441  0.46181524 0.44552818], shape=(12,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], shape=(12,), dtype=float32)
predicted label rank:[2 2 1 1 1 2 1 1 1 1 1 1]
mse:tf.Tensor(0.24239282, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/apache-get-tag.i.v+lhb-reducer.c-1_000.smt2
true label:[1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1]
predicted label:tf.Tensor([0.54134625 0.49060693 0.50066876 0.5050376  0.3812256  0.60961473], shape=(6,), dtype=float32)
rounded label:tf.Tensor([1. 0. 1. 1. 0. 1.], shape=(6,), dtype=float32)
predicted label rank:[2 1 2 2 1 2]
mse:tf.Tensor(0.24990775, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/25.c_000.smt2
true label:[0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0]
true label rank:[1 2 2 2 2 1 1 2 2 2 2 1 1 2 2 2 2 1 1 2 2 2 2 1 1 2 2 2 2 1]
predicted label:tf.Tensor(
[0.50172645 0.5088143  0.47432005 0.4974604  0.49026805 0.5028969
 0.49448806 0.4909404  0.48427323 0.49195263 0.48818985 0.49809968
 0.53395027 0.48775607 0.49887004 0.54425204 0.564613   0.5621111
 0.48349807 0.47638896 0.47784925 0.4733682  0.44102788 0.5178691
 0.48429528 0.49214253 0.48305434 0.48007405 0.49102232 0.49002874], shape=(30,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0.], shape=(30,), dtype=float32)
predicted label rank:[2 2 1 1 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1]
mse:tf.Tensor(0.25840124, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/four1.smt2-0027_000.smt2
true label:[1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]
true label rank:[2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2]
predicted label:tf.Tensor(
[0.5021079  0.4963857  0.4800105  0.47064906 0.50481343 0.48538047
 0.48405683 0.5012966  0.47084284 0.4814277  0.48771912 0.49665162
 0.4903474  0.49445686 0.5113521  0.4902244  0.47001076], shape=(17,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0.], shape=(17,), dtype=float32)
predicted label rank:[2 1 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1]
mse:tf.Tensor(0.24784434, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/break_safe.c-1_000.smt2
true label:[0, 1, 1, 0, 1, 1, 1]
true label rank:[1 2 2 1 2 2 2]
predicted label:tf.Tensor(
[0.5091612  0.5098873  0.49622077 0.49589077 0.5108425  0.50043106
 0.5010799 ], shape=(7,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 0. 1. 1. 1.], shape=(7,), dtype=float32)
predicted label rank:[2 2 1 1 2 2 2]
mse:tf.Tensor(0.24813174, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/metros_3_e3_1275_e2_454_000.smt2
true label:[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]
true label rank:[1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 2 1 1 1 2 2
 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 2 2 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 2 1
 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1
 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1
 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1
 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1
 1 1 2 1 1 1 1 1 2 1 1 1 1 1 2 1 1]
predicted label:tf.Tensor(
[0.6297089  0.39053184 0.574673   0.5545839  0.2251969  0.79357994
 0.39894602 0.75829744 0.18352777 0.29045796 0.15463844 0.20812199
 0.4041476  0.1042062  0.41030222 0.5791587  0.92892075 0.5696331
 0.21640924 0.24289289 0.16735408 0.17358848 0.13931856 0.74873936
 0.791968   0.5966937  0.07724077 0.64776766 0.12922588 0.09951246
 0.29588455 0.3656929  0.15117308 0.45201853 0.23632693 0.21699023
 0.5708099  0.82014775 0.7247489  0.54675484 0.6991646  0.3277084
 0.60745597 0.40573654 0.4743922  0.55863583 0.5605895  0.51637065
 0.5348368  0.46745008 0.48853442 0.49554062 0.46529478 0.47313318
 0.5453418  0.5324896  0.46531102 0.4623687  0.45677832 0.5075644
 0.4809359  0.5394058  0.4231676  0.4924571  0.4959846  0.5221265
 0.5341037  0.50714767 0.47874883 0.49287555 0.59872735 0.48505822
 0.6142578  0.5211554  0.4477985  0.5688447  0.48706567 0.52778316
 0.4567298  0.53716934 0.4222893  0.43542734 0.4781211  0.5541183
 0.54758596 0.5208454  0.4518776  0.48461214 0.49140716 0.4997078
 0.48262212 0.55425185 0.5086287  0.50007856 0.45615992 0.53990614
 0.45760733 0.5351227  0.41560888 0.5157177  0.55127865 0.5618266
 0.5229958  0.7414459  0.50559396 0.41207263 0.30508214 0.48928574
 0.49319258 0.7331022  0.4694993  0.33675915 0.4148713  0.6078208
 0.5415889  0.4003949  0.49089596 0.44603485 0.3213407  0.55244815
 0.3710534  0.5927216  0.48638424 0.54285294 0.6107909  0.54167575
 0.44467944 0.43030515 0.29367197 0.7027054  0.3676676  0.64387125
 0.46813008 0.49484333 0.45226616 0.400138   0.4620611  0.5553973
 0.4778522  0.57730556 0.51874167 0.47791278 0.41503605 0.6671416
 0.2795707  0.42572477 0.6781466  0.5162957  0.29226953 0.63797027
 0.5746833  0.4065019  0.39219776 0.56873935 0.36675617 0.6553246
 0.54377264 0.36740512 0.28997546 0.4282287  0.42096555 0.6397043
 0.34370416 0.43854952 0.43902844 0.53782034 0.4863038  0.3844285
 0.5550211  0.31463832 0.38775316 0.32806462 0.34066913 0.41746807
 0.40552348 0.5850086  0.43960628 0.39770812 0.6152076  0.2670828
 0.37769896 0.5131914  0.35664088 0.41528523 0.67017895 0.5754296
 0.592799   0.4007204  0.5038394  0.4664219  0.5625939  0.6489793
 0.5831859  0.4105101  0.5264115  0.2508782  0.19955248 0.85225713
 0.48840767 0.61344075 0.5978377  0.48625892 0.2139748  0.19037476
 0.214008   0.80274117 0.8865262  0.5122413  0.30994916 0.5653173
 0.2715369  0.41621196 0.4429882  0.37626764 0.6167236  0.5321131
 0.51151955 0.49343833 0.48568454 0.52475554 0.56536436 0.528553
 0.48421046 0.40514794 0.47568867 0.49973556 0.40804747 0.43482244
 0.46373358 0.4363957  0.44958827 0.4545651  0.42292067 0.38435584
 0.45317534 0.5119749  0.4959564  0.49570656 0.4261537  0.45638776
 0.42360136 0.41851795 0.46143374 0.514202   0.5367999  0.47217667
 0.54217285 0.46597812 0.4126913  0.57980937 0.46066716 0.4113127
 0.41896588 0.5876445  0.5029855  0.45889598 0.37755796 0.5611248
 0.39420226 0.5648412  0.55530185 0.50341314 0.4591811  0.3952794
 0.47701138 0.49232635 0.47980925 0.47313008 0.49291712 0.47284976
 0.4855716  0.4954122  0.46424794 0.49560592 0.5010492  0.47884837
 0.4702694  0.45271665 0.47638905 0.4847442  0.45366737 0.47600186
 0.5072475  0.47437322 0.6226021  0.36790746 0.42983145 0.56305695
 0.31498128 0.5593784  0.28763416 0.27188975 0.3218298  0.46952155
 0.7600509  0.5930241  0.75054634 0.594211   0.66412157 0.349946
 0.08874249 0.7888584  0.44867072 0.38244614 0.48253256 0.48057643
 0.4782638  0.5323487  0.44457355 0.46885058 0.5133295  0.49771678
 0.49870607 0.48020342 0.47837687 0.5115638  0.49076128 0.4919647
 0.4790863  0.53361094 0.57227856 0.49313834 0.4961289  0.49110755
 0.49892324 0.49476275 0.48612133 0.5035221  0.49596196 0.4862542
 0.503026   0.4955417  0.49525833 0.49594018 0.50128114 0.5024269
 0.4947443  0.4863017  0.48931187 0.49465945 0.48762715 0.4911921
 0.43294528 0.50924087 0.47351152 0.4076013  0.41420826 0.47824237
 0.47607082 0.48348337 0.4690424  0.41304317 0.47779483 0.5619013
 0.50977427 0.47246015 0.46232915 0.5124272  0.46467656 0.4682524
 0.48190346 0.5757957  0.42459878 0.46959823 0.4950063  0.46715704
 0.5646148  0.47105333 0.5307419  0.5267689  0.4664314  0.51279587
 0.48438    0.53264153 0.4750266  0.4738636  0.44934148 0.53482425
 0.5044346  0.51936233 0.5734056  0.5091137  0.49655062 0.49921858
 0.52852905 0.4453826  0.5328932  0.52944446 0.52042425 0.5320387
 0.44003674 0.48786855 0.5416656  0.46068498 0.48006496 0.47718018
 0.5075155  0.4791099  0.4969099  0.49073246 0.50315577 0.47521862
 0.39322937 0.5206265  0.49134356 0.44504577 0.5422641  0.5145786
 0.53812087 0.47010633 0.50711775 0.48768684 0.47877023 0.52669686
 0.5389262  0.58855265 0.46907264 0.47078222 0.42063275 0.5794715
 0.5103047  0.5098262  0.49761662 0.45611542 0.47774595 0.33886904
 0.49542078 0.4919979  0.59567696 0.5163555  0.5082113  0.55193675
 0.47448686 0.41905117 0.57436883 0.50286835 0.41364792 0.5364901
 0.5360797  0.5623557  0.43208343 0.44313398 0.52580917 0.51144075
 0.48657194 0.54114914 0.49783653 0.5020409  0.49814686 0.48935902
 0.48648286 0.49758002 0.504459   0.5030751  0.5093446  0.5062798
 0.489945   0.51652676 0.5237848  0.51335603 0.519432   0.49588504
 0.47791883 0.5050053  0.4829561  0.5279096  0.49476838 0.39963847
 0.45857653 0.51547575 0.5338918  0.53023875 0.4882964  0.4926552
 0.49680123 0.5173491  0.4699993  0.5087304  0.51084346 0.4151561
 0.50839037 0.50987995 0.49524072 0.47850242 0.49710107 0.584477
 0.53132176 0.54265803 0.5079261  0.47597954 0.4656637  0.5218877
 0.5033204  0.49521312 0.49212843 0.4438727  0.51553667 0.54754776], shape=(498,), dtype=float32)
rounded label:tf.Tensor(
[1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.
 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1.
 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0.
 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.
 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1.
 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1.
 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1.
 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1.
 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1.
 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.
 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1.
 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0.
 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1.], shape=(498,), dtype=float32)
predicted label rank:[2 1 2 2 1 2 1 2 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 2 2 2 1 2 1 1 1 1 1 1 1 1 2
 2 2 2 2 1 2 1 1 2 2 2 2 1 1 1 1 1 2 2 1 1 1 2 1 2 1 1 1 2 2 2 1 1 2 1 2 2
 1 2 1 2 1 2 1 1 1 2 2 2 1 1 1 1 1 2 2 2 1 2 1 2 1 2 2 2 2 2 2 1 1 1 1 2 1
 1 1 2 2 1 1 1 1 2 1 2 1 2 2 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 1 2 1 1 2 2
 1 2 2 1 1 2 1 2 2 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 2 1 1 2 1 1 2
 2 2 1 2 1 2 2 2 1 2 1 1 2 1 2 2 1 1 1 1 2 2 2 1 2 1 1 1 1 2 2 2 1 1 2 2 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 2 1 1 2 1 1 1 2 2 1 1 2 1
 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 2
 2 2 2 1 1 2 1 1 1 1 1 2 1 1 2 1 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1 2 1 1 2 1 1
 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 1 1 2 1 2 2
 1 2 1 2 1 1 1 2 2 2 2 2 1 1 2 1 2 2 2 2 1 1 2 1 1 1 2 1 1 1 2 1 1 2 1 1 2
 2 2 1 2 1 1 2 2 2 1 1 1 2 2 2 1 1 1 1 1 1 2 2 2 2 1 1 2 2 1 2 2 2 1 1 2 2
 1 2 1 2 1 1 1 1 2 2 2 2 1 2 2 2 2 1 1 2 1 2 1 1 1 2 2 2 1 1 1 2 1 2 2 1 2
 2 1 1 1 2 2 2 2 1 1 2 2 1 1 1 2 2]
mse:tf.Tensor(0.24616599, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/03.c_000.smt2
true label:[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 2 2 2 2 2 2 2 2 2 2]
predicted label:tf.Tensor(
[0.5007324  0.4919164  0.49592942 0.49450216 0.5032376  0.48921683
 0.50878656 0.50570315 0.40812686 0.489406   0.45773518], shape=(11,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0.], shape=(11,), dtype=float32)
predicted label rank:[2 1 1 1 2 1 2 2 1 1 1]
mse:tf.Tensor(0.26516917, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/durationThm_3_e2_63_e7_21_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.78490734 0.15414304 0.19790259 0.61391205 0.7105514  0.9479468
 0.18089056], shape=(7,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 1. 1. 1. 0.], shape=(7,), dtype=float32)
predicted label rank:[2 1 1 2 2 2 1]
mse:tf.Tensor(0.3560144, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/barthe2-big2_merged_safe.c-1_000.smt2
true label:[0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1]
true label rank:[1 2 1 2 2 2 2 1 2 2 2 2]
predicted label:tf.Tensor(
[0.51424885 0.4960783  0.47613284 0.5152361  0.51718    0.56315845
 0.46480745 0.5279193  0.44613183 0.47603932 0.44219425 0.44317043], shape=(12,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0.], shape=(12,), dtype=float32)
predicted label rank:[2 1 1 2 2 2 1 2 1 1 1 1]
mse:tf.Tensor(0.2643062, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/listcounter.correct.nts_000.smt2
true label:[1, 1, 1, 1, 1, 0, 1, 0, 1, 0]
true label rank:[2 2 2 2 2 1 2 1 2 1]
predicted label:tf.Tensor(
[0.5067128  0.49337375 0.49778923 0.47763407 0.49573115 0.5049438
 0.4889703  0.49368113 0.4784723  0.499031  ], shape=(10,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 0. 0. 1. 0. 0. 0. 0.], shape=(10,), dtype=float32)
predicted label rank:[2 1 1 1 1 2 1 1 1 1]
mse:tf.Tensor(0.2560235, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/metros_4_e3_1091_e2_1317_000.smt2
true label:[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]
true label rank:[1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 2 1 1 1 2 2
 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 2 2 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 2 1
 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1
 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1
 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1
 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1
 1 1 2 1 1 1 1 1 2 1 1 1 1 1 2 1 1]
predicted label:tf.Tensor(
[0.6297089  0.39053184 0.574673   0.5545839  0.2251969  0.79357994
 0.39894602 0.75829744 0.18352777 0.29045796 0.15463844 0.20812199
 0.4041476  0.1042062  0.41030222 0.5791587  0.92892075 0.5696331
 0.21640924 0.24289289 0.16735408 0.17358848 0.13931856 0.74873936
 0.791968   0.5966937  0.07724077 0.64776766 0.12922588 0.09951246
 0.29588455 0.3656929  0.15117308 0.45201853 0.23632693 0.21699023
 0.5708099  0.82014775 0.7247489  0.54675484 0.6991646  0.3277084
 0.60745597 0.40573654 0.4743922  0.55863583 0.5605895  0.51637065
 0.5348368  0.46745008 0.48853442 0.49554062 0.46529478 0.47313318
 0.5453418  0.5324896  0.46531102 0.4623687  0.45677832 0.5075644
 0.4809359  0.5394058  0.4231676  0.4924571  0.4959846  0.5221265
 0.5341037  0.50714767 0.47874883 0.49287555 0.59872735 0.48505822
 0.6142578  0.5211554  0.4477985  0.5688447  0.48706567 0.52778316
 0.4567298  0.53716934 0.4222893  0.43542734 0.4781211  0.5541183
 0.54758596 0.5208454  0.4518776  0.48461214 0.49140716 0.4997078
 0.48262212 0.55425185 0.5086287  0.50007856 0.45615992 0.53990614
 0.45760733 0.5351227  0.41560888 0.5157177  0.55127865 0.5618266
 0.5229958  0.7414459  0.50559396 0.41207263 0.30508214 0.48928574
 0.49319258 0.7331022  0.4694993  0.33675915 0.4148713  0.6078208
 0.5415889  0.4003949  0.49089596 0.44603485 0.3213407  0.55244815
 0.3710534  0.5927216  0.48638424 0.54285294 0.6107909  0.54167575
 0.44467944 0.43030515 0.29367197 0.7027054  0.3676676  0.64387125
 0.46813008 0.49484333 0.45226616 0.400138   0.4620611  0.5553973
 0.4778522  0.57730556 0.51874167 0.47791278 0.41503605 0.6671416
 0.2795707  0.42572477 0.6781466  0.5162957  0.29226953 0.63797027
 0.5746833  0.4065019  0.39219776 0.56873935 0.36675617 0.6553246
 0.54377264 0.36740512 0.28997546 0.4282287  0.42096555 0.6397043
 0.34370416 0.43854952 0.43902844 0.53782034 0.4863038  0.3844285
 0.5550211  0.31463832 0.38775316 0.32806462 0.34066913 0.41746807
 0.40552348 0.5850086  0.43960628 0.39770812 0.6152076  0.2670828
 0.37769896 0.5131914  0.35664088 0.41528523 0.67017895 0.5754296
 0.592799   0.4007204  0.5038394  0.4664219  0.5625939  0.6489793
 0.5831859  0.4105101  0.5264115  0.2508782  0.19955248 0.85225713
 0.48840767 0.61344075 0.5978377  0.48625892 0.2139748  0.19037476
 0.214008   0.80274117 0.8865262  0.5122413  0.30994916 0.5653173
 0.2715369  0.41621196 0.4429882  0.37626764 0.6167236  0.5321131
 0.51151955 0.49343833 0.48568454 0.52475554 0.56536436 0.528553
 0.48421046 0.40514794 0.47568867 0.49973556 0.40804747 0.43482244
 0.46373358 0.4363957  0.44958827 0.4545651  0.42292067 0.38435584
 0.45317534 0.5119749  0.4959564  0.49570656 0.4261537  0.45638776
 0.42360136 0.41851795 0.46143374 0.514202   0.5367999  0.47217667
 0.54217285 0.46597812 0.4126913  0.57980937 0.46066716 0.4113127
 0.41896588 0.5876445  0.5029855  0.45889598 0.37755796 0.5611248
 0.39420226 0.5648412  0.55530185 0.50341314 0.4591811  0.3952794
 0.47701138 0.49232635 0.47980925 0.47313008 0.49291712 0.47284976
 0.4855716  0.4954122  0.46424794 0.49560592 0.5010492  0.47884837
 0.4702694  0.45271665 0.47638905 0.4847442  0.45366737 0.47600186
 0.5072475  0.47437322 0.6226021  0.36790746 0.42983145 0.56305695
 0.31498128 0.5593784  0.28763416 0.27188975 0.3218298  0.46952155
 0.7600509  0.5930241  0.75054634 0.594211   0.66412157 0.349946
 0.08874249 0.7888584  0.44867072 0.38244614 0.48253256 0.48057643
 0.4782638  0.5323487  0.44457355 0.46885058 0.5133295  0.49771678
 0.49870607 0.48020342 0.47837687 0.5115638  0.49076128 0.4919647
 0.4790863  0.53361094 0.57227856 0.49313834 0.4961289  0.49110755
 0.49892324 0.49476275 0.48612133 0.5035221  0.49596196 0.4862542
 0.503026   0.4955417  0.49525833 0.49594018 0.50128114 0.5024269
 0.4947443  0.4863017  0.48931187 0.49465945 0.48762715 0.4911921
 0.43294528 0.50924087 0.47351152 0.4076013  0.41420826 0.47824237
 0.47607082 0.48348337 0.4690424  0.41304317 0.47779483 0.5619013
 0.50977427 0.47246015 0.46232915 0.5124272  0.46467656 0.4682524
 0.48190346 0.5757957  0.42459878 0.46959823 0.4950063  0.46715704
 0.5646148  0.47105333 0.5307419  0.5267689  0.4664314  0.51279587
 0.48438    0.53264153 0.4750266  0.4738636  0.44934148 0.53482425
 0.5044346  0.51936233 0.5734056  0.5091137  0.49655062 0.49921858
 0.52852905 0.4453826  0.5328932  0.52944446 0.52042425 0.5320387
 0.44003674 0.48786855 0.5416656  0.46068498 0.48006496 0.47718018
 0.5075155  0.4791099  0.4969099  0.49073246 0.50315577 0.47521862
 0.39322937 0.5206265  0.49134356 0.44504577 0.5422641  0.5145786
 0.53812087 0.47010633 0.50711775 0.48768684 0.47877023 0.52669686
 0.5389262  0.58855265 0.46907264 0.47078222 0.42063275 0.5794715
 0.5103047  0.5098262  0.49761662 0.45611542 0.47774595 0.33886904
 0.49542078 0.4919979  0.59567696 0.5163555  0.5082113  0.55193675
 0.47448686 0.41905117 0.57436883 0.50286835 0.41364792 0.5364901
 0.5360797  0.5623557  0.43208343 0.44313398 0.52580917 0.51144075
 0.48657194 0.54114914 0.49783653 0.5020409  0.49814686 0.48935902
 0.48648286 0.49758002 0.504459   0.5030751  0.5093446  0.5062798
 0.489945   0.51652676 0.5237848  0.51335603 0.519432   0.49588504
 0.47791883 0.5050053  0.4829561  0.5279096  0.49476838 0.39963847
 0.45857653 0.51547575 0.5338918  0.53023875 0.4882964  0.4926552
 0.49680123 0.5173491  0.4699993  0.5087304  0.51084346 0.4151561
 0.50839037 0.50987995 0.49524072 0.47850242 0.49710107 0.584477
 0.53132176 0.54265803 0.5079261  0.47597954 0.4656637  0.5218877
 0.5033204  0.49521312 0.49212843 0.4438727  0.51553667 0.54754776], shape=(498,), dtype=float32)
rounded label:tf.Tensor(
[1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.
 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1.
 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0.
 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.
 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1.
 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1.
 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1.
 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1.
 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1.
 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.
 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1.
 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0.
 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1.], shape=(498,), dtype=float32)
predicted label rank:[2 1 2 2 1 2 1 2 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 2 2 2 1 2 1 1 1 1 1 1 1 1 2
 2 2 2 2 1 2 1 1 2 2 2 2 1 1 1 1 1 2 2 1 1 1 2 1 2 1 1 1 2 2 2 1 1 2 1 2 2
 1 2 1 2 1 2 1 1 1 2 2 2 1 1 1 1 1 2 2 2 1 2 1 2 1 2 2 2 2 2 2 1 1 1 1 2 1
 1 1 2 2 1 1 1 1 2 1 2 1 2 2 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 1 2 1 1 2 2
 1 2 2 1 1 2 1 2 2 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 2 1 1 2 1 1 2
 2 2 1 2 1 2 2 2 1 2 1 1 2 1 2 2 1 1 1 1 2 2 2 1 2 1 1 1 1 2 2 2 1 1 2 2 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 2 1 1 2 1 1 1 2 2 1 1 2 1
 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 2
 2 2 2 1 1 2 1 1 1 1 1 2 1 1 2 1 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1 2 1 1 2 1 1
 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 1 1 2 1 2 2
 1 2 1 2 1 1 1 2 2 2 2 2 1 1 2 1 2 2 2 2 1 1 2 1 1 1 2 1 1 1 2 1 1 2 1 1 2
 2 2 1 2 1 1 2 2 2 1 1 1 2 2 2 1 1 1 1 1 1 2 2 2 2 1 1 2 2 1 2 2 2 1 1 2 2
 1 2 1 2 1 1 1 1 2 2 2 2 1 2 2 2 2 1 1 2 1 2 1 1 1 2 2 2 1 1 1 2 1 2 2 1 2
 2 1 1 1 2 2 2 2 1 1 2 2 1 1 1 2 2]
mse:tf.Tensor(0.24616599, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/test_locks_10.c-1_000.smt2
true label:[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]
true label rank:[1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1
 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1
 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 2 1 2 1 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1
 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2
 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1
 2 1 2]
predicted label:tf.Tensor(
[0.47210768 0.5592864  0.463938   0.4801763  0.4697696  0.53672487
 0.47695497 0.53735316 0.36442456 0.52037245 0.43669945 0.4861986
 0.45671016 0.49304172 0.5308882  0.53146076 0.49251166 0.4927347
 0.43647757 0.425226   0.4457131  0.4478535  0.41028422 0.49813703
 0.5259978  0.48746276 0.52237356 0.4824458  0.51787996 0.45892927
 0.482012   0.5072193  0.4545424  0.49101827 0.5415502  0.47974926
 0.51068485 0.51754314 0.51222724 0.4649851  0.5128213  0.4919391
 0.56115335 0.4813184  0.4745026  0.5237458  0.573094   0.50506496
 0.534824   0.43106207 0.48896396 0.49904418 0.50623953 0.51011074
 0.516922   0.5362519  0.5077419  0.53280336 0.4684866  0.4972313
 0.5126938  0.52264756 0.47973737 0.44945905 0.5507005  0.50194776
 0.49964684 0.48581615 0.45096022 0.47955287 0.46865812 0.49347296
 0.5352154  0.5047411  0.47814947 0.50839615 0.5197349  0.48010382
 0.4483438  0.53134966 0.4438846  0.5401717  0.4872836  0.5408551
 0.5476772  0.5186215  0.46775532 0.47814718 0.5302941  0.47657228
 0.49157372 0.533172   0.5087131  0.46408963 0.4672628  0.5068077
 0.4914661  0.49241626 0.49265856 0.5384107  0.4771503  0.54973626
 0.4798632  0.4880492  0.48845258 0.47886533 0.4826141  0.47973785
 0.480969   0.5272     0.50413686 0.4666362  0.60335714 0.5669791
 0.4918753  0.49172392 0.4987968  0.55119747 0.4912829  0.49801204
 0.4570764  0.4865883  0.45212033 0.4784833  0.47487038 0.49253073
 0.4816334  0.48281842 0.46098164 0.50148135 0.46884644 0.4607999
 0.44550386 0.45010284 0.53094405 0.47626725 0.44386926 0.4564753
 0.4466981  0.5037618  0.46062264 0.4784453  0.49413285 0.51074576
 0.45092636 0.43768483 0.49805525 0.5043894  0.49097508 0.44652677
 0.49348238 0.4777447  0.49625546 0.51185316 0.47630504 0.47863206
 0.43499362 0.44530374 0.46935117 0.4494712  0.46516067 0.4987512
 0.48119605 0.50271    0.52731806 0.51912916 0.47724918 0.49000058
 0.46502417 0.46773514 0.45618817 0.46826    0.4738957  0.5076498
 0.49280205 0.5008689  0.4631974  0.48257375 0.46578914 0.4574245
 0.48827356 0.49028042 0.44499713 0.45442784 0.47916958 0.48879617
 0.47291958 0.47712895 0.4775745  0.47377726 0.49184442 0.46062094
 0.49885583 0.47049522 0.47484967 0.48534152 0.4614962  0.49329937
 0.4942213  0.4580023  0.5287828  0.46806106 0.50115633 0.47146732
 0.4570111  0.48689044 0.5381471  0.50204724 0.5036999  0.49755326
 0.5073574  0.47655898 0.504535   0.4997593  0.5278347  0.5225738
 0.57514536 0.47908497 0.4931645  0.5249437  0.55363417 0.5557854
 0.49187613 0.5026159  0.49844658], shape=(225,), dtype=float32)
rounded label:tf.Tensor(
[0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.
 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.
 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1.
 1. 0. 0. 1. 1. 1. 0. 1. 0.], shape=(225,), dtype=float32)
predicted label rank:[1 2 1 1 1 2 1 2 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 2 1 2 1 1 2 1 1 2 1 2
 2 2 1 2 1 2 1 1 2 2 2 2 1 1 1 2 2 2 2 2 2 1 1 2 2 1 1 2 2 1 1 1 1 1 1 2 2
 1 2 2 1 1 2 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2
 1 2 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 2
 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 2 2 2 1 2 1 2 1 2 2 2 1 1 2 2 2
 1 2 1]
mse:tf.Tensor(0.24761851, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/nested4.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.9049765  0.5218663  0.39519802 0.8126892  0.07529309 0.8097218
 0.19028047 0.91730595], shape=(8,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 0. 1. 0. 1.], shape=(8,), dtype=float32)
predicted label rank:[2 2 1 2 1 2 1 2]
mse:tf.Tensor(0.43086842, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/minepump_spec2_product64_true-unreach-call.cil.c.flat_000.smt2
true label:[1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1]
predicted label:tf.Tensor([0.99973375 1.         0.9999527  1.         0.00150564], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 0.], shape=(5,), dtype=float32)
predicted label rank:[2 2 2 2 1]
mse:tf.Tensor(0.19939822, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/MOESI_2_e8_101_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1
 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1]
predicted label:tf.Tensor(
[9.9988782e-01 9.9484009e-01 1.3961852e-02 9.0767062e-01 5.2366847e-01
 9.9594271e-01 1.2742281e-03 2.8680858e-01 3.1346598e-08 1.2324482e-02
 1.3549644e-05 6.7043879e-06 2.3009232e-05 2.0335632e-07 5.9685111e-04
 8.9534426e-01 9.9999928e-01 9.9563539e-01 6.9504976e-04 1.0404885e-03
 2.8475484e-09 1.6752724e-06 3.7294859e-12 9.8538017e-01 9.9982464e-01
 9.9999785e-01 1.4340355e-08 9.9610353e-01 1.9484758e-04 8.0325958e-07
 1.3153255e-02 7.0480436e-02 7.5549519e-06 9.8237586e-01 1.6834736e-03
 1.2101609e-07 9.9865067e-01 9.7278142e-01 9.9962729e-01 1.9505620e-04
 9.9463367e-01 7.3665380e-03 9.8186660e-01 6.6426814e-02 3.0061603e-04
 9.9186510e-01 9.8950243e-01 9.9888754e-01 9.5278746e-01 7.3478686e-06
 2.3110881e-01 2.1520257e-04 3.0787826e-02 8.5158265e-01 9.9996626e-01
 5.7274747e-01 4.9180275e-01 5.2525979e-01 4.7388458e-01 4.7178066e-01
 4.7555164e-01 4.9849892e-01 4.2922634e-01 5.0207549e-01 5.6237054e-01
 5.0198942e-01 5.2261001e-01 5.0920177e-01 4.3378407e-01 4.8244426e-01
 5.5630165e-01 4.7811693e-01 4.7356650e-01 5.2376908e-01 4.7306669e-01
 5.6957161e-01 5.7000041e-01 4.0688962e-01 5.1415986e-01 4.6696052e-01
 4.0916255e-01 4.5881885e-01 5.1104540e-01 5.1290911e-01 5.2208120e-01
 4.4695008e-01 4.6864626e-01 4.8847553e-01 4.8216075e-01 4.8542193e-01
 5.0724322e-01 5.0083524e-01 5.2777529e-01 5.2392948e-01 5.0615913e-01
 5.3300565e-01 5.1836425e-01 5.0969017e-01 4.8282346e-01 5.1120257e-01
 5.2673680e-01 5.0647908e-01 4.9010569e-01 5.1007724e-01 5.0764090e-01
 4.9651852e-01 5.3900027e-01 5.0724834e-01 5.2420324e-01 5.5681235e-01
 5.1115024e-01 5.0788873e-01 4.7488907e-01 4.8579034e-01 4.9372914e-01
 4.8028487e-01 4.9125221e-01 5.0179875e-01 4.8709622e-01 5.0225532e-01
 4.8874757e-01 4.8054746e-01 4.8345295e-01 5.1156306e-01 4.9984404e-01
 4.7075760e-01 4.8976019e-01 4.8295987e-01 4.8396513e-01 6.8726206e-01
 3.9309731e-01 5.3860039e-01 4.7218084e-01 5.7748991e-01 4.6013185e-01
 5.1672322e-01 3.5823664e-01 5.1988405e-01 3.6445290e-01 6.4471871e-01
 4.0528482e-01 4.9651316e-01 5.1262790e-01 4.9198058e-01 4.9127769e-01
 4.9644911e-01 4.9437049e-01 4.9699748e-01 4.9068296e-01 5.0080997e-01
 5.0112796e-01 4.8938280e-01 4.8242939e-01 4.9746272e-01 4.9857330e-01
 5.0187951e-01 4.8864850e-01 5.0957084e-01 4.8553923e-01 4.9458227e-01
 5.0598055e-01 5.0299191e-01 4.9314326e-01 4.9737138e-01 4.8796430e-01
 4.9534750e-01 4.8721743e-01 4.9214119e-01 4.9959108e-01 4.7237453e-01
 4.9562201e-01 4.8072863e-01 4.7025239e-01 4.9908480e-01 4.8409298e-01
 4.9309173e-01 4.7937939e-01 4.4877806e-01 4.9396434e-01 4.8028028e-01
 4.7391275e-01 5.0998670e-01 4.9678582e-01 4.7654626e-01 5.1223052e-01
 4.8796475e-01 5.0734586e-01 4.9656668e-01 4.7065023e-01 4.8062882e-01
 4.9305177e-01 5.1123029e-01 5.1887971e-01 5.0708336e-01 4.7867844e-01
 4.0924442e-01 4.6841413e-01 4.8877952e-01 4.9976283e-01 5.0354642e-01
 5.0380880e-01 4.3504608e-01 4.8167232e-01 4.9226546e-01 4.5846468e-01
 4.8441225e-01 5.0035274e-01 4.8427916e-01 4.6520436e-01 4.6208021e-01
 4.6094242e-01 4.7532740e-01 4.8184645e-01 4.6768034e-01 4.7700304e-01
 4.7650397e-01 4.9393654e-01 4.4989991e-01 4.8670483e-01 4.7999510e-01
 4.9627304e-01 4.7427827e-01 4.7065198e-01 4.7732389e-01 4.9553978e-01
 4.7490001e-01 4.5754680e-01 4.5963201e-01 4.7201875e-01 4.6724138e-01
 4.9224329e-01 4.9123091e-01 4.6464002e-01 4.7209182e-01 4.8178905e-01
 4.8174182e-01 4.9240893e-01 4.9684083e-01 4.3906879e-01 4.6823704e-01
 4.4463825e-01 4.7845718e-01 5.0682700e-01 4.9086481e-01 5.4714888e-01
 4.9209756e-01 5.4435509e-01 4.8176742e-01 4.5293114e-01 5.1653308e-01
 4.8029622e-01 4.4188523e-01 4.8530066e-01 5.2905327e-01 5.2601075e-01
 4.5774078e-01 4.5898965e-01 4.9330482e-01 4.7915205e-01 5.4850060e-01
 4.6819341e-01 5.4328424e-01 5.4425627e-01 4.7474673e-01 4.7877598e-01
 4.8089892e-01 4.7097927e-01 5.0765383e-01 4.9341428e-01 5.2557117e-01
 4.8065832e-01 4.5833701e-01 4.8639172e-01 4.6059489e-01 4.8421785e-01
 4.7108924e-01 4.4828302e-01 4.2345378e-01 4.8954695e-01 5.4358268e-01
 4.5012841e-01 4.8410070e-01 4.8600224e-01 4.8521128e-01 4.8785448e-01
 4.3162727e-01 5.2917057e-01 5.0996786e-01 5.0235635e-01 4.8922816e-01
 4.9373853e-01 4.9800682e-01 4.6916646e-01 4.8726621e-01 5.0683761e-01
 4.9036592e-01 4.8891354e-01 4.8365980e-01 4.9030966e-01 4.9643987e-01
 4.8254126e-01 5.3531200e-01 5.3281039e-01 4.7701260e-01 4.9619067e-01
 4.9345517e-01 5.0644100e-01 4.9745506e-01 5.1091921e-01 4.9455470e-01
 5.0000989e-01 5.1425940e-01 4.8153168e-01 4.8215553e-01 4.7520542e-01
 4.9184579e-01 5.1039886e-01 5.1644641e-01 5.2386880e-01 5.1547515e-01
 4.8681059e-01 4.8741370e-01 4.9652541e-01 5.1973164e-01 4.9732935e-01
 4.9246487e-01 4.8502260e-01 5.1575601e-01 5.0587815e-01 5.4554212e-01
 5.0567883e-01 5.0468349e-01 5.2739239e-01 5.1350164e-01 4.8284796e-01
 5.0585008e-01 4.9141547e-01 4.8669598e-01 5.1080912e-01 4.7087857e-01
 5.0714576e-01 5.0363415e-01 4.5475540e-01 4.4872990e-01 4.6838671e-01
 4.6177441e-01 4.6579400e-01 5.0175166e-01 4.7409776e-01 4.6274704e-01
 4.6475685e-01 4.7586459e-01 4.7969669e-01 4.7049868e-01 4.8080438e-01
 4.6368042e-01 4.7284317e-01 4.6275240e-01 5.0248545e-01 4.5077986e-01
 4.6895596e-01 4.6067336e-01 4.5931053e-01 4.6530160e-01 4.6985096e-01
 4.7152665e-01 4.5571283e-01 4.2927861e-01 4.7166762e-01 4.8129785e-01
 4.7487879e-01 4.7740462e-01 4.8441851e-01 4.9650702e-01 4.7539347e-01
 4.7410047e-01 4.8935229e-01 4.8120064e-01 4.8296562e-01 4.9406046e-01
 4.6452269e-01 4.6927759e-01 4.8329353e-01 4.7990867e-01 4.5855623e-01
 4.7280726e-01 4.8200148e-01 4.8813632e-01 4.8873386e-01 4.8482215e-01
 4.7673792e-01 4.7248170e-01 4.6044901e-01 4.7613758e-01 4.7722974e-01
 4.7580424e-01 4.7640160e-01 4.7458434e-01 5.1581156e-01 5.2200609e-01
 4.5816383e-01 5.3670102e-01 5.9785730e-01 5.4261690e-01 4.9381161e-01
 4.9623942e-01 4.8758003e-01 4.9780697e-01 5.4811805e-01 4.7472394e-01
 4.8043951e-01 5.5781174e-01 4.6918625e-01 4.6555746e-01 4.8786703e-01
 4.8938888e-01 4.9736330e-01 4.8816168e-01 5.1571095e-01 4.6546212e-01
 4.9555904e-01 5.3432763e-01 5.0558746e-01 5.1198465e-01 5.1594496e-01
 5.6084585e-01 4.8074195e-01 5.1188046e-01 5.1913011e-01 4.9981111e-01
 4.9995765e-01 5.1705319e-01 4.8219261e-01 4.8312786e-01 5.1827264e-01
 7.3635107e-01 6.7648745e-01 5.9951431e-01 4.3796226e-01 5.4656470e-01
 7.8692675e-02 7.1932852e-01 8.4105456e-01 5.9713852e-01 1.2330580e-01
 5.2035117e-01 7.5386202e-01 2.5048047e-02 5.3522009e-01 6.7139620e-01
 8.2849550e-01 5.9831965e-01 3.2784504e-01 3.3845347e-01 1.5900838e-01
 6.7922676e-01 6.7585939e-01 7.6823747e-01 3.2060784e-01 3.9509088e-01
 9.0011734e-01 9.1653222e-01 2.3334286e-01 3.5978675e-01 4.3307206e-01
 6.1312020e-01 8.3657920e-01 8.2182467e-01 7.9366207e-01 5.1462710e-02
 3.4920666e-01 2.4896213e-01 5.7727140e-01 5.2677697e-01 3.2467216e-01
 4.0108436e-01 5.2529413e-01 4.6515808e-01 4.2888856e-01 4.9751458e-01
 4.6454138e-01 4.3416739e-01 4.9967521e-01 4.6270886e-01 5.0435209e-01
 4.9025756e-01 4.3848854e-01 5.0685549e-01 4.8502037e-01 4.1736546e-01
 4.2336699e-01 5.0823241e-01 5.3085363e-01 4.7291255e-01 4.7364002e-01
 4.8222265e-01 5.0331968e-01 5.3567678e-01 5.0941622e-01 5.1701170e-01
 5.2353442e-01 3.9891243e-01 4.3980271e-01 4.9541187e-01 4.9148545e-01
 5.2262437e-01 4.6281043e-01 5.6849062e-01 5.0205803e-01 5.3643668e-01
 4.9923792e-01 5.0403035e-01 4.8282233e-01 5.2352840e-01 5.1895756e-01
 4.9399099e-01 4.9895266e-01 5.3022879e-01 5.1502728e-01 5.0828719e-01
 4.7956917e-01 5.1463580e-01 5.1643950e-01 4.9671641e-01 5.1652610e-01
 4.8757240e-01 4.9917731e-01 5.2452976e-01 4.9152282e-01 5.2037311e-01
 5.1731229e-01 5.1606697e-01 5.2020448e-01 5.2039564e-01 5.1656920e-01
 5.0663608e-01 4.8858315e-01 5.2391595e-01 4.9454138e-01 5.2485412e-01
 5.2065814e-01 5.3587085e-01 4.9439752e-01 5.1769453e-01 5.1712936e-01
 5.2599174e-01 5.1489460e-01 5.1514012e-01 4.9417579e-01 5.0318849e-01
 5.2527082e-01 5.0781947e-01 5.2784353e-01 5.1383036e-01 5.4167253e-01
 4.8598126e-01 5.1229292e-01 5.1589131e-01 5.3212321e-01 4.7479108e-01
 5.0560629e-01 5.3566176e-01 5.0825149e-01 5.2897096e-01 5.0608248e-01
 5.2001125e-01 5.0973767e-01 5.4491013e-01 5.2842253e-01 5.0124055e-01
 5.0258338e-01 5.1540732e-01 4.9990332e-01 5.0495267e-01 5.1511729e-01
 4.9852937e-01 5.1783818e-01 5.3003341e-01 5.2322966e-01 5.2829307e-01
 5.0936615e-01 5.1589054e-01 4.7459787e-01 5.0975847e-01 5.1334894e-01
 5.0004131e-01 4.9029741e-01 4.7952402e-01 4.7055241e-01 5.0383520e-01
 5.1062202e-01 4.9228749e-01 5.0770503e-01 5.0598007e-01 4.9142337e-01
 4.5680907e-01 5.1102209e-01 4.9129122e-01 4.7961152e-01 4.8130047e-01
 4.8152092e-01 5.0355232e-01 5.2748865e-01 5.0438666e-01 4.6421894e-01
 4.7910404e-01 4.9826831e-01 4.9279457e-01 4.9242875e-01 4.8238578e-01
 4.8946589e-01 4.7905102e-01 5.1797032e-01 4.7071636e-01 5.1185155e-01
 4.8246935e-01 4.7832555e-01 4.6757019e-01 4.8777154e-01 4.8342046e-01
 4.8418045e-01 5.0326198e-01 5.1602811e-01 4.9816427e-01 5.2363670e-01
 4.7771183e-01 4.7080463e-01 4.9566820e-01 5.1971805e-01 4.9730903e-01
 4.7398296e-01 4.9869999e-01 5.0456560e-01 5.0623655e-01 5.3263718e-01
 4.3220663e-01 4.9242172e-01 5.1887232e-01 5.1086622e-01 5.2262861e-01
 4.5656097e-01 4.3018875e-01 5.1916033e-01 4.4804728e-01 5.1364964e-01
 5.5603337e-01 5.0459778e-01 5.2704072e-01 5.3615117e-01 5.0734878e-01
 4.8583090e-01 4.7429332e-01 4.9375558e-01 5.0807780e-01 5.2198231e-01
 5.0708723e-01 5.0195068e-01 5.0791156e-01 4.9104252e-01 5.3724527e-01
 5.1457286e-01 4.8933548e-01 4.9748570e-01 5.0250739e-01 5.2604967e-01
 5.0063211e-01 4.1862428e-01 5.2646643e-01 4.5343348e-01], shape=(669,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.
 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.
 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0.
 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.
 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1.
 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.
 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1.
 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.
 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1.
 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1.
 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0.
 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1.
 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1.
 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.
 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0.], shape=(669,), dtype=float32)
predicted label rank:[2 2 1 2 2 2 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 2 2 2 1 2 1 1 1 1 1 2 1 1 2
 2 2 1 2 1 2 1 1 2 2 2 2 1 1 1 1 2 2 2 1 2 1 1 1 1 1 2 2 2 2 2 1 1 2 1 1 2
 1 2 2 1 2 1 1 1 2 2 2 1 1 1 1 1 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2 1 2 2 2 2 2
 2 1 1 1 1 1 2 1 2 1 1 1 2 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 2 1 1 1 1 1
 1 2 2 1 1 1 1 2 1 2 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2
 1 2 1 1 1 1 2 2 2 1 1 1 1 1 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 1 2 1 1 1 2 2 1 1 1 1
 2 1 2 2 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 2 2 1 1 1 1 1 2 1
 1 1 1 1 1 2 2 1 1 1 2 1 2 1 2 2 1 1 1 1 2 2 2 2 1 1 1 2 1 1 1 2 2 2 2 2 2
 2 1 2 1 1 2 1 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 1 1 1
 1 2 1 1 2 1 1 1 1 1 1 2 1 1 2 2 2 2 2 1 2 2 1 1 2 1 1 2 2 2 2 1 2 1 2 2 2
 1 2 2 1 2 2 2 2 1 1 1 2 2 2 1 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 1 1 2 1 1 1 1
 1 1 1 2 1 1 2 1 1 1 2 2 1 1 1 2 2 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1 2 2 1 1 2
 2 2 1 2 2 1 2 1 1 2 1 2 2 2 2 2 2 2 1 2 1 2 2 2 1 2 2 2 2 2 1 2 2 2 2 2 2
 1 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 2 2 2 1 2 2 2 1 1 1 2 2 1
 2 2 1 1 2 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 2 2 1 2 1 1 1 2
 1 1 1 2 2 2 1 1 2 2 2 1 1 2 1 2 2 2 2 2 2 1 1 1 2 2 2 2 2 1 2 2 1 1 2 2 2
 1 2 1]
mse:tf.Tensor(0.26387447, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0115_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[9.5825690e-01 4.1564220e-01 5.0617129e-02 9.2519629e-01 1.5438619e-01
 9.1846943e-01 7.5840950e-04 9.9600923e-01 1.0496071e-08 3.3828679e-01
 1.4695100e-05 2.4598837e-04], shape=(12,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0.], shape=(12,), dtype=float32)
predicted label rank:[2 1 1 2 1 2 1 2 1 1 1 1]
mse:tf.Tensor(0.32695493, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/jm2006_true-unreach-call.c.flat_000.smt2
true label:[0, 0, 0, 0]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([0.5019264 0.5296793 0.4889497 0.5053626], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1.], shape=(4,), dtype=float32)
predicted label rank:[2 2 1 2]
mse:tf.Tensor(0.25673836, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/28.c_000.smt2
true label:[0, 1, 1, 0, 1, 1, 1, 0, 1, 0]
true label rank:[1 2 2 1 2 2 2 1 2 1]
predicted label:tf.Tensor(
[0.49640977 0.49670288 0.4959547  0.4950162  0.50150126 0.4940275
 0.5219449  0.5262651  0.49278778 0.49298403], shape=(10,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 1. 0. 1. 1. 0. 0.], shape=(10,), dtype=float32)
predicted label rank:[1 1 1 1 2 1 2 2 1 1]
mse:tf.Tensor(0.25091317, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/tridag.smt2-0024_000.smt2
true label:[1, 1, 1, 1]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([0.49872735 0.5068562  0.4961862  0.511806  ], shape=(4,), dtype=float32)
rounded label:tf.Tensor([0. 1. 0. 1.], shape=(4,), dtype=float32)
predicted label rank:[1 2 1 2]
mse:tf.Tensor(0.24665672, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/minepump_spec5_product47_true-unreach-call.cil.c.flat_000.smt2
true label:[1, 1, 1, 1]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([1.000000e+00 1.000000e+00 1.527965e-04 1.000000e+00], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1.], shape=(4,), dtype=float32)
predicted label rank:[2 2 1 2]
mse:tf.Tensor(0.24992359, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/bandec.smt2-0210_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1]
true label rank:[2 2 2 2 2 2 2 2 2 1 1 2 2 1 2 2 2 1 1 2 2]
predicted label:tf.Tensor(
[0.49636748 0.49641335 0.496118   0.5010821  0.5115591  0.49374413
 0.4813951  0.52209496 0.46545652 0.5081974  0.4733964  0.49607337
 0.5066629  0.4931785  0.51046306 0.5064912  0.5174462  0.5109332
 0.47516167 0.48787642 0.47099698], shape=(21,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0.], shape=(21,), dtype=float32)
predicted label rank:[1 1 1 2 2 1 1 2 1 2 1 1 2 1 2 2 2 2 1 1 1]
mse:tf.Tensor(0.2502824, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0259_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]
predicted label:tf.Tensor(
[0.50503755 0.5049375  0.49864477 0.52327746 0.51350445 0.49623436
 0.5057135  0.47902238 0.4404403  0.46997738 0.47699907 0.4747204
 0.50694555 0.4462907  0.48375657 0.4948955  0.52587837 0.4789268
 0.4811808  0.503873   0.4863206  0.49637127 0.50439465 0.5100682
 0.5074409  0.50903517 0.53440386 0.47578853 0.5332074  0.4727432
 0.4646232  0.50880116 0.47351006 0.48710215 0.51428944 0.4844167
 0.48623407 0.4943883  0.49105003 0.49561432 0.5029973  0.4909155
 0.51355225 0.49939394 0.49237671 0.503051   0.48829567 0.48561567
 0.5002667  0.42464617 0.46674913 0.5038207  0.49179965 0.48603794
 0.5580608  0.53295344 0.49510807 0.57130915 0.4401939  0.43297955
 0.5018505  0.4963609  0.42830306 0.51949185 0.49941888 0.45510176
 0.5521747  0.41373166 0.34085768 0.47184074 0.55956596 0.43323633
 0.7542677  0.53114593 0.4001254  0.6784899  0.515103   0.38812914
 0.4398508  0.48142335 0.22582436 0.228706   0.3922478  0.54399586
 0.6342341  0.5704055  0.40579435 0.49659926 0.42843908 0.59697795
 0.5889616  0.5104725  0.5236373  0.43240327 0.40500757 0.5127127
 0.4520661  0.5577173  0.49235585 0.49110857 0.50601923 0.5448412
 0.4740494  0.5552831  0.5177606  0.46022117 0.509816   0.4553438
 0.49957773 0.65794885 0.4267925  0.45119405 0.49262914 0.5019655
 0.4793005  0.48801264 0.40633726 0.4089005  0.05429253 0.71556264
 0.20091721 0.7153999  0.2245104  0.84022284 0.79864573 0.61321354
 0.11111322 0.2882077  0.33864582 0.9739045  0.5029595  0.83010435
 0.12395087 0.7130773  0.7595941  0.5188352  0.48021916 0.47219887
 0.46250904 0.538985   0.483601   0.5147672  0.4648382  0.4905991
 0.46263304 0.49951205 0.48356798 0.49863634 0.47915006 0.5901178
 0.49892277 0.46706364 0.50228    0.50732374 0.5197243  0.5042584
 0.48622268 0.49344957 0.49286652 0.4864259  0.4938405  0.49740216
 0.48953244 0.4914907  0.501497   0.5089863  0.5141713  0.47524226
 0.54090333 0.46163684 0.4292108  0.4686878  0.446847   0.5495664
 0.5135616  0.46150023 0.49004632 0.45979953 0.56149656 0.43162996
 0.46013588 0.5337633  0.39652768 0.42969716 0.6048549  0.4767887
 0.556744   0.534533   0.45733917 0.48568642 0.5573595  0.52240723
 0.5962132  0.40368894 0.47280428 0.36858806 0.414992   0.8166709
 0.64118946 0.5148051  0.6475311  0.4022619  0.08374506 0.14863369
 0.14610839 0.72990626 0.9415263  0.6731455  0.14395455 0.58875525
 0.29724044 0.12491006 0.28806347 0.20565122 0.7839153  0.51832336
 0.6010399  0.4713548  0.5261461  0.49071372 0.56712943 0.6020187
 0.51516676 0.4293809  0.48999536 0.43124935 0.40074858 0.37081596
 0.5014456  0.57402474 0.39916098 0.4087428  0.4410303  0.42053574
 0.46838242 0.5788285  0.51267844 0.49585533 0.4415152  0.4026091
 0.4468484  0.43153226 0.489989   0.4768979  0.5680519  0.49640754
 0.56504303 0.42454413 0.47372094 0.5159519  0.47381556 0.48042247
 0.48428166 0.5136792  0.48751667 0.47806856 0.47787893 0.47637403
 0.48593944 0.49120718 0.48747653 0.5010607  0.5094844  0.4801476
 0.5401087  0.47352546 0.51133686 0.47994524 0.52139455 0.52981824
 0.55230635 0.5008334  0.47576424 0.46726462 0.47043392 0.4259309
 0.4414891  0.440385   0.5227445  0.51775426 0.48893672 0.48939863
 0.4749514  0.42912865 0.6196265  0.49753743 0.5164899  0.51105267
 0.5070634  0.5041884  0.4961116  0.50344825 0.50907415 0.51422507
 0.56078523 0.56600803 0.54784495 0.52010936 0.43770027 0.48647204
 0.5065509  0.5043703  0.50622773 0.48713073 0.505748   0.49076873
 0.51125413 0.5247162  0.48242152 0.49662873 0.4928556  0.50795656
 0.4964644  0.49616206 0.48780748 0.56427497 0.54231584 0.4858353
 0.4999901  0.54057115 0.49415556 0.51589596 0.45562693 0.5467768
 0.4724808  0.6346447  0.46403685 0.4710954  0.48822638 0.48841712
 0.40911403 0.33224273 0.55783325 0.47786954 0.45113006 0.48562297
 0.44980848 0.46215317 0.64415354 0.38450295 0.5118969  0.45051336
 0.4949744  0.38255313 0.42440343 0.41225848 0.4477681  0.4495143
 0.48263597 0.5183849  0.47017476 0.5157623  0.50291    0.514257
 0.45399874 0.4823786  0.4696672  0.49719882 0.5278792  0.49872315
 0.5149008  0.46150604 0.47269356 0.48518625 0.49745753 0.51471305
 0.51200145 0.48904058 0.48010457 0.52703524 0.4997141  0.50759643
 0.5178844  0.49208832 0.5118892  0.5103004  0.5150656  0.5205777
 0.5183905  0.50222796 0.49661258 0.45678073 0.5346467  0.55337626
 0.42983523 0.51351184 0.57439256 0.51679164 0.51425576 0.47441489
 0.5130133  0.52892697 0.5006489  0.5110409  0.48629382 0.44833437
 0.51619613 0.4496503  0.4854957  0.544539   0.49481025 0.4813689
 0.55916977 0.56794167 0.51406145 0.5034585  0.5323268  0.51732683
 0.52199715 0.5264946  0.51594925 0.52148753 0.44735837 0.45267448
 0.4804325  0.36116713 0.46154982 0.50200415 0.54566276 0.5334194
 0.5147445  0.5189982  0.51660794 0.44473368 0.4108408  0.6176726
 0.5131209  0.38931757 0.5357406  0.49494657 0.516923   0.4289199
 0.47767475 0.47294348 0.42571694 0.53203624 0.5303983  0.5703739
 0.4934342  0.5474845  0.4080968  0.54704195 0.4977083  0.49834353
 0.44913438 0.43374234 0.53355706 0.37466183 0.47516516 0.45834535
 0.5020487  0.54063815 0.46017262 0.48658544 0.33527803 0.5326514
 0.5599714  0.4257796  0.4133058  0.51899016 0.47573918 0.6168616
 0.42190364 0.589231   0.52226824 0.5394606  0.5332202  0.56963074
 0.50379777 0.512851   0.42922315 0.4134857  0.6249845  0.62607765
 0.51459575 0.40563303 0.5991101  0.5135687  0.51290077 0.45890233
 0.48357928 0.5405799  0.51174504 0.5177043  0.4805578  0.453822
 0.45866373 0.51220477 0.5057023  0.47939175 0.4030031  0.5616567
 0.4934211  0.4730405  0.4876122  0.365543   0.48575747 0.54725015
 0.5224384  0.49544835 0.47987247 0.38974902 0.47546536 0.48761624
 0.5129721  0.49888572 0.45948052 0.6289685  0.5566605  0.55018836
 0.49177322 0.48667264 0.52714825 0.59736943 0.50356144 0.4912707
 0.48582235 0.5070843  0.50123453 0.6053279  0.471353   0.5172986
 0.6081768  0.5174287  0.4462223  0.50732446 0.5571805  0.49466
 0.47706246 0.48130137 0.49575728 0.46880078 0.51230484 0.4872335
 0.48912364 0.49129453 0.49284363 0.5000746  0.49700367 0.49995637
 0.48705497 0.515079   0.4934838  0.46063492 0.4596346  0.46764502
 0.5866005  0.50464    0.5651216  0.4511501  0.47782335 0.53681636
 0.56446147 0.48876494 0.49507317 0.5019595  0.5350269  0.50852877
 0.519088   0.4929359  0.53494656 0.36695457 0.43093428 0.43318617
 0.57276565 0.55246633 0.52305675 0.5225915  0.5759337  0.45908752
 0.50196403 0.5189053  0.4382401  0.6632567  0.50566745 0.5516848
 0.4637511  0.5029751  0.4643135  0.4934049  0.46983856 0.45007023
 0.39418113 0.45241696 0.49839023 0.5900965  0.46287557 0.40934023
 0.48874503 0.6305238  0.55760777 0.62827665 0.55606043 0.5057688
 0.4898138  0.42223677 0.5638916  0.43856397 0.50303787 0.46434382
 0.47824103 0.3997938  0.53664726 0.49404225 0.5590187  0.5251261
 0.53048587 0.5161017  0.4837773  0.48195037 0.47884867 0.5025752
 0.5131223  0.50261825 0.50743234 0.5079356  0.49823663 0.46949765
 0.47479972 0.46887922 0.5260131  0.52262306 0.49819818 0.5052789
 0.50994736 0.49037296 0.477238   0.51426125 0.4804626  0.4571981
 0.47031063 0.51662946 0.47288153 0.43566945 0.56038654 0.4353458
 0.48704734 0.51939833 0.47468334 0.5846822  0.43829504 0.42555824
 0.5317984  0.411622   0.4776388  0.575482   0.5603209  0.4809455
 0.4802993  0.43643716 0.52093583 0.43219578 0.4556768  0.5026367
 0.5306853  0.48754686 0.4446483 ], shape=(657,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1.
 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0.
 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.
 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1.
 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.
 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1.
 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1.
 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.
 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1.
 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1.
 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1.
 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0.
 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1.
 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0.
 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1.
 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0.
 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1.
 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0.
 0. 0. 1. 0. 0. 1. 1. 0. 0.], shape=(657,), dtype=float32)
predicted label rank:[2 2 1 2 2 1 2 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 2 2 2 2 2 1 2 1 1 2 1 1 2 1 1
 1 1 1 2 1 2 1 1 2 1 1 2 1 1 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 2 1 1 1 2 1 2 2
 1 2 2 1 1 1 1 1 1 2 2 2 1 1 1 2 2 2 2 1 1 2 1 2 1 1 2 2 1 2 2 1 2 1 1 2 1
 1 1 2 1 1 1 1 1 2 1 2 1 2 2 2 1 1 1 2 2 2 1 2 2 2 1 1 1 2 1 2 1 1 1 1 1 1
 1 2 1 1 2 2 2 2 1 1 1 1 1 1 1 1 2 2 2 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 2
 1 2 2 1 1 2 2 2 1 1 1 1 2 2 2 2 1 1 1 1 2 2 2 1 2 1 1 1 1 2 2 2 1 2 1 2 2
 2 1 1 1 1 1 2 2 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1
 1 1 2 2 1 2 1 2 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 1 1 2 1 2 2 2 2 1 2 2 2 2 2
 2 2 1 1 2 2 2 1 2 1 2 2 1 1 1 2 1 1 1 2 2 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 2
 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 2 1 2 2 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2
 1 2 2 1 2 2 2 2 2 2 1 1 2 2 1 2 2 2 2 1 2 2 2 2 1 1 2 1 1 2 1 1 2 2 2 2 2
 2 2 2 2 2 1 1 1 1 1 2 2 2 2 2 2 1 1 2 2 1 2 1 2 1 1 1 1 2 2 2 1 2 1 2 1 1
 1 1 2 1 1 1 2 2 1 1 1 2 2 1 1 2 1 2 1 2 2 2 2 2 2 2 1 1 2 2 2 1 2 2 2 1 1
 2 2 2 1 1 1 2 2 1 1 2 1 1 1 1 1 2 2 1 1 1 1 1 2 1 1 2 2 2 1 1 2 2 2 1 1 2
 2 2 1 2 2 2 1 2 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 1 2 2 2 1 1 2 2 1 1
 2 2 2 2 1 2 1 1 1 2 2 2 2 2 1 2 2 1 2 2 2 1 2 1 1 1 1 1 1 1 2 1 1 1 2 2 2
 2 2 1 1 2 1 2 1 1 1 2 1 2 2 2 2 1 1 1 2 2 2 2 2 1 1 1 1 2 2 1 2 2 1 1 2 1
 1 1 2 1 1 2 1 1 2 1 2 1 1 2 1 1 2 2 1 1 1 2 1 1 2 2 1 1]
mse:tf.Tensor(0.25917992, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/bouncy_two_counters_equality_000.smt2
true label:[1, 1, 1, 1, 0]
true label rank:[2 2 2 2 1]
predicted label:tf.Tensor([0.51014996 0.49401513 0.5073438  0.5023987  0.50942075], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 0. 1. 1. 1.], shape=(5,), dtype=float32)
predicted label rank:[2 1 2 2 2]
mse:tf.Tensor(0.2491601, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/reverse_ret_unsafe.c_000.smt2
true label:[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2
 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2
 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.50232214 0.53506273 0.49853355 0.51991504 0.49009714 0.5240605
 0.5205868  0.52349895 0.50187176 0.50843006 0.50189286 0.5065063
 0.49705866 0.5033602  0.5224325  0.52771753 0.52908826 0.5020229
 0.5087511  0.5138673  0.49090594 0.51092786 0.5107323  0.50491726
 0.49505958 0.51938844 0.54565084 0.51477253 0.5034067  0.48451114
 0.50490093 0.509003   0.52799445 0.49240327 0.5190009  0.4846159
 0.5253987  0.51220745 0.49289653 0.48935196 0.5228391  0.48875636
 0.51064354 0.5161669  0.5167103  0.49605146 0.521379   0.50491023
 0.5193917  0.5121264  0.52391297 0.49938053 0.5173439  0.52733934
 0.5081392  0.52002114 0.5167023  0.5328249  0.53470063 0.50291723
 0.49905965 0.5167252  0.49957466 0.49166027 0.51657593 0.46952033
 0.4795119  0.45902172 0.47532398 0.48111236 0.5052379  0.47857514
 0.43852073 0.458305   0.45536107 0.49501342 0.47328952 0.45356685
 0.46809876 0.46034056 0.4524988  0.47992945 0.46577287 0.47657672
 0.48211044 0.44858453 0.42618918 0.4760707  0.47048032 0.46599048
 0.468913   0.47515798 0.46372482 0.46068704 0.46426457 0.47175962
 0.48629877 0.43216878 0.4728579  0.45197088 0.46744955 0.5094919
 0.4505648  0.4560871  0.4616121  0.46543548 0.43013725 0.4936418
 0.46233213 0.49947912 0.44926906 0.45684794 0.43503717 0.44807407
 0.47405037 0.449955   0.46341866 0.46293205 0.4588052  0.4661793
 0.44818038 0.43414965 0.48226038 0.48058778 0.44881698 0.48630482
 0.45811552 0.44330958 0.471243   0.45971012 0.44752094 0.46792066
 0.47061875 0.45344874 0.45823824 0.4312328  0.4759048  0.43814483
 0.4580235  0.46322507 0.45507818 0.48033556 0.49723014 0.47933352
 0.46061704 0.45115125 0.515166   0.5335772  0.4959103  0.50568587
 0.5079473  0.49855375 0.51215845 0.49624628 0.51114666 0.5061048
 0.4988788  0.5065819  0.50250167 0.4870976  0.5020225  0.4883835
 0.49828333 0.52061677 0.5052492  0.5077241  0.51686215 0.5088344
 0.5123481  0.5053726  0.49111673 0.48660848 0.5143672  0.5155013
 0.48789826 0.4930149  0.51902884 0.5152518  0.52056617 0.51189137
 0.48883843 0.5094233  0.48648533 0.51353675 0.50954336 0.5082615
 0.4875197  0.50586134 0.5069346  0.4895375  0.51916695 0.528248
 0.49638596 0.48150504 0.50539535 0.48694804 0.50908244 0.52511764
 0.5075258  0.49603328 0.5104538  0.4968331  0.49702126 0.51278806
 0.5126156  0.5192812  0.5247325  0.4850283  0.51109296 0.5128738
 0.5061656  0.48755807 0.50080323 0.5144043  0.5390093  0.5074204
 0.5215806  0.5139813  0.51968336 0.49363884 0.5008137  0.50801975
 0.48467636 0.53332037 0.5059885  0.5050134  0.5023028  0.5105876
 0.5040526  0.5126418  0.49393657 0.4795365  0.48701423 0.5139081
 0.51974565 0.5311333  0.48248938 0.50962865 0.4832282  0.5078794
 0.50336474 0.49587822 0.5009448  0.46326488 0.4580734  0.46246666
 0.47589368 0.46108913 0.47346836 0.47943226 0.45597622 0.4946262
 0.47942182 0.47511047 0.49039477 0.46869525 0.45612612 0.46623856
 0.45910126 0.48944703 0.46719208 0.47767588 0.461863   0.48473543
 0.46327123 0.4593886  0.47198585 0.47493604 0.46572655 0.48930675
 0.49372065 0.50177443 0.47747797 0.49762118 0.46068132 0.46945268
 0.49219468 0.50736946 0.47803575 0.4690632  0.4514195  0.47203836
 0.4846156  0.4640745  0.4814084  0.48026273 0.47262847 0.5246986
 0.47951353 0.46660042 0.48101723 0.4904857  0.5150021  0.516072
 0.4660017  0.4891545  0.4828721  0.49506268 0.47229102 0.46491092
 0.4804151  0.46644264 0.49247327 0.48154372 0.46993706 0.5003632
 0.50301075 0.5124253  0.50164205 0.4532475  0.4604584  0.46394616
 0.4977804  0.47096846 0.4944443  0.47506917 0.45889995 0.47180808
 0.5034467  0.45725754 0.4281434  0.4487413  0.4626907  0.5031401
 0.4584918  0.47678402 0.47691053 0.48622224 0.46276793 0.4602304
 0.50306064 0.47947767 0.48060372 0.4466337  0.47543845 0.46615407
 0.46523246 0.45968965 0.49134615 0.48001808 0.48380944 0.501598
 0.49222434 0.50419235 0.5037448  0.46365535 0.4766793  0.507582
 0.45779818 0.47641653 0.49685717 0.49071154 0.4647794  0.46284908
 0.4674735  0.46171537 0.47560954 0.48880145 0.47587267 0.513956
 0.48520187 0.47806495 0.49090567 0.48105612 0.49814454 0.49005795
 0.4765542  0.48532635 0.47481167 0.49007547 0.49745896 0.46410275
 0.48297966 0.47176206 0.49216387 0.5015795  0.4880342  0.49535456
 0.5021075  0.46810818 0.47413933 0.48889473 0.49228096 0.47127208
 0.4733641  0.47994474 0.47492576 0.48485744 0.49480268 0.4968036
 0.477586   0.46652612 0.48496342 0.49907678 0.48980832 0.49650618
 0.4656849  0.4788645  0.46318436 0.47003612 0.4774275  0.48577955
 0.4615043  0.48969293 0.47964445 0.47516495 0.47161844 0.45454425
 0.47206506 0.47846875 0.47036785 0.47986156 0.4812814  0.48136073
 0.5033838  0.47286484 0.4809968  0.48224723 0.4511041  0.46941644
 0.49658674 0.4892289  0.48283845 0.4912948  0.4798948  0.45744342
 0.5036383  0.4694568  0.47702032 0.48810259 0.4933973  0.48971578
 0.48778486 0.49057811 0.48808566 0.4850319  0.5084087  0.48807272
 0.49814722 0.48137498 0.47642514 0.4821629  0.5110374  0.47187188
 0.49271113 0.50796485 0.4739018  0.49653432 0.5018773  0.4698805
 0.48262003 0.48297307 0.49422082 0.47923636 0.46633393 0.48983985
 0.47800452 0.48134828 0.47764066 0.47515127 0.48429468 0.47079962
 0.4838075  0.4847746  0.48710844 0.48656613 0.44622722 0.4485081
 0.4780142  0.48846042 0.50363415 0.48733252 0.47248232 0.48937476
 0.47527122 0.46877518 0.4825044  0.49327415 0.46284622 0.48981592
 0.47588325 0.46104506 0.5014991  0.46432984 0.48568502 0.4790491
 0.49743906 0.4795641  0.49374023 0.4656598  0.47216186 0.47722566
 0.48029372 0.46056864 0.49018824 0.49024868 0.4899676  0.46943453
 0.48786348 0.48292506 0.48794562 0.46260262 0.47524115 0.48958156
 0.48409623 0.48269433 0.48533687 0.50475705 0.47249472 0.48348743
 0.50056314 0.48832348 0.48464435 0.5048859  0.48934165 0.500863
 0.5012167  0.4969229  0.49804962 0.51136565 0.48711318 0.48147047
 0.516141   0.4891397  0.494204   0.49161726 0.47235683 0.49246994
 0.47555697 0.5008883  0.4724883  0.49207076 0.48252106 0.49701712
 0.5000971  0.48639253 0.4811206  0.46875462 0.49866995 0.52342314
 0.5172253  0.52733386 0.5202248  0.5228142  0.5167552  0.5103092
 0.5033597  0.52048856 0.517519   0.52467173 0.51344216 0.5102045
 0.5100105  0.48381522 0.5173797  0.4938123  0.5060728  0.51816744
 0.50739473 0.5337543  0.5238522  0.49105552 0.5110546  0.5087002
 0.51042247 0.50589234 0.49345624 0.522661   0.49652353 0.5019086
 0.53108746 0.52173626 0.52085    0.5079463  0.5146605  0.50698835
 0.5252205  0.5065283  0.45128796 0.45192438 0.44972482 0.4430422
 0.44297397 0.43793532 0.44879833 0.45030862 0.44605175 0.45896536
 0.45126495 0.45354435 0.44633776 0.43576545 0.45198068 0.44783148
 0.45155132 0.4434294  0.43868965 0.45695078 0.45383963 0.4442188
 0.4543232  0.44821087 0.44450998 0.4547966  0.44432032 0.45210248
 0.44823578 0.4538411  0.450482   0.44918534 0.4591751  0.4474846
 0.44981956 0.44438124 0.43718308 0.43291625 0.4484045  0.4404335
 0.44024453 0.45204052 0.45353073 0.45829648 0.4512143  0.45024365
 0.4446896 ], shape=(625,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.
 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1.
 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1.
 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1.
 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.
 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1.
 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0.], shape=(625,), dtype=float32)
predicted label rank:[2 2 1 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2 1 2 2 2 1 2 1 2
 2 1 1 2 1 2 2 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2 2 1 2 1 1 2 1 1 1 1 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2
 1 2 2 1 2 1 2 2 1 2 2 1 2 1 1 2 2 2 2 2 2 2 1 1 2 2 1 1 2 2 2 2 1 2 1 2 2
 2 1 2 2 1 2 2 1 1 2 1 2 2 2 1 2 1 1 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 1 2 2
 1 2 2 2 2 2 2 2 1 1 1 2 2 2 1 2 1 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1
 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 2 1 1
 1 1 1 1 1 1 1 1 2 1 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1
 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1
 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 2 1 2 2 1
 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2
 1 2 2 2 2 2 1 2 2 2 2 1 2 1 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.2391377, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/NetBSD_g_Ctoc.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[9.9389303e-01 9.9996126e-01 6.7808634e-01 9.9999559e-01 6.0831004e-01
 9.9499983e-01 8.5614579e-07 8.4432626e-01 3.1700055e-13 1.2934387e-02], shape=(10,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 0. 1. 0. 0.], shape=(10,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 1 2 1 1]
mse:tf.Tensor(0.5520658, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/heapsort_true-unreach-call.c.flat_000.smt2
true label:[0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0]
true label rank:[1 1 1 1 1 1 2 1 1 2 1 1 2 1]
predicted label:tf.Tensor(
[5.0288665e-01 5.0934678e-01 5.0026143e-01 5.1035708e-01 5.0057548e-01
 4.9693814e-01 1.9797757e-01 9.6758831e-01 3.6961138e-03 4.7835386e-01
 2.9554367e-03 2.8125077e-02 4.8838228e-02 4.1657686e-04], shape=(14,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.], shape=(14,), dtype=float32)
predicted label rank:[2 2 2 2 2 1 1 2 1 1 1 1 1 1]
mse:tf.Tensor(0.30554873, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/hysteresis_2_000.smt2
true label:[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]
true label rank:[1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 2 2 1 1]
predicted label:tf.Tensor(
[7.8863800e-03 1.0000000e+00 7.3910475e-01 1.0000000e+00 9.4043887e-01
 1.0000000e+00 9.8867643e-01 1.0000000e+00 0.0000000e+00 9.9586072e-26
 7.9389915e-35 3.4730963e-34 2.9943875e-17 8.0059820e-22 1.3254254e-17
 9.5064902e-01 8.9170682e-01 1.0000000e+00 7.7065867e-01 3.2423653e-09], shape=(20,), dtype=float32)
rounded label:tf.Tensor([0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0.], shape=(20,), dtype=float32)
predicted label rank:[1 2 2 2 2 2 2 2 1 1 1 1 1 1 1 2 2 2 2 1]
mse:tf.Tensor(0.39588103, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/jm2006_variant_true-unreach-call.c.flat_000.smt2
true label:[1, 1, 1, 0, 1]
true label rank:[2 2 2 1 2]
predicted label:tf.Tensor([0.5026183  0.4950666  0.5036767  0.50703144 0.49704018], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 0. 1. 1. 0.], shape=(5,), dtype=float32)
predicted label rank:[2 1 2 2 1]
mse:tf.Tensor(0.2517465, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/gulwani_fig1a.c_000.smt2
true label:[0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1]
predicted label:tf.Tensor([0.63051766 0.36441314 0.3142586  0.4848152  0.5223618  0.7888729 ], shape=(6,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 0. 1. 1.], shape=(6,), dtype=float32)
predicted label rank:[2 1 1 1 2 2]
mse:tf.Tensor(0.29322267, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/pc_sfifo_2_true-unreach-call_false-termination.cil.c.flat_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0]
true label rank:[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2
 1 1]
predicted label:tf.Tensor(
[5.1721030e-01 5.1896590e-01 5.0228208e-01 4.9859977e-01 4.8948357e-01
 4.9496871e-01 4.8015642e-01 5.0175148e-01 4.7279054e-01 4.8792052e-01
 4.9954700e-01 5.1345527e-01 1.1711967e-05 1.5486484e-06 4.5841932e-04
 9.7390342e-01 1.0000000e+00 9.7102416e-01 4.2979419e-03 6.2009692e-04
 1.7551478e-08 3.8931312e-17 1.1558666e-25 4.3726653e-02 1.0000000e+00
 1.0000000e+00 9.7131187e-19 1.0000000e+00 1.5481327e-12 3.6055496e-08
 9.9999982e-01 2.8474340e-01 9.9976671e-01 2.1612644e-04 2.3284554e-04
 9.9998879e-01 1.0000000e+00 1.0000000e+00 9.8387063e-01], shape=(39,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.
 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1.], shape=(39,), dtype=float32)
predicted label rank:[2 2 2 1 1 1 1 2 1 1 1 2 1 1 1 2 2 2 1 1 1 1 1 1 2 2 1 2 1 1 2 1 2 1 1 2 2
 2 2]
mse:tf.Tensor(0.42074478, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/apache-get-tag.i.p+nlh-reducer.c-1_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.49187627 0.5155408  0.54217315 0.5214832  0.49275762 0.534323
 0.46364552 0.61568344 0.43432713 0.45825592], shape=(10,), dtype=float32)
rounded label:tf.Tensor([0. 1. 1. 1. 0. 1. 0. 1. 0. 0.], shape=(10,), dtype=float32)
predicted label rank:[1 2 2 2 1 2 1 2 1 1]
mse:tf.Tensor(0.2454472, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0265_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[1.0000000e+00 1.0000000e+00 4.6685832e-07 9.9976999e-01 9.3653703e-01
 9.5936614e-01 1.0000000e+00 1.0000000e+00 4.8510751e-01 5.0841880e-01
 4.6021679e-01 4.4604027e-01 4.5733568e-01 4.5450616e-01 4.6293196e-01
 4.6635836e-01 4.4750860e-01 4.1521135e-01 4.4118929e-01 3.3933759e-01
 3.2540330e-01 3.2787293e-01 2.2110572e-01 5.2427268e-01 6.7439699e-01
 5.0629497e-01 3.6763996e-01 7.0641840e-01 3.4956846e-01 4.7104988e-01
 4.7183487e-01 4.2034355e-01 2.4396059e-01 5.2576220e-01 5.1561421e-01
 3.0884713e-01 5.6636155e-01 6.6198671e-01 5.8175838e-01 4.5219541e-01
 6.4048553e-01 4.4486833e-01 7.3189270e-01 4.5067519e-01 4.5609993e-01
 5.8921397e-01 5.9790862e-01 4.5643362e-01 6.1267489e-01 2.2717142e-01
 4.7063339e-01 4.6460298e-01 4.5211536e-01 4.9027792e-01 6.0823220e-01
 6.1203742e-01 4.3448889e-01 6.0921758e-01 3.5204056e-01 5.6191021e-01
 5.5392677e-01 4.8219907e-01 3.2120630e-01 5.4316378e-01 7.5501597e-01
 3.9066756e-01 5.6900215e-01 6.9021702e-01 3.0419177e-01 4.2876127e-01
 6.7357004e-01 4.1641825e-01 6.9365138e-01 5.3904927e-01 4.0175930e-01
 6.0704559e-01 5.9562290e-01 3.4437937e-01 3.9811671e-01 6.1480749e-01
 1.7554665e-01 2.1230417e-01 4.0753102e-01 6.1118966e-01 7.4383008e-01
 4.5525280e-01 3.6966568e-01 4.2930800e-01 4.8936203e-01 5.8261645e-01
 5.2839422e-01 5.6600356e-01 5.9453750e-01 5.2763528e-01 4.1579646e-01
 5.9402627e-01 4.8701340e-01 5.9116846e-01 5.0939494e-01 5.5917019e-01
 5.7069761e-01 4.0362731e-01 4.9446455e-01 5.9785575e-01 4.8890418e-01
 4.5690799e-01 6.7522836e-01 4.2520994e-01 4.7492975e-01 7.8118098e-01
 5.1165605e-01 3.7658063e-01 3.8338977e-01 5.8338368e-01 5.3286690e-01
 4.5943975e-01 4.7492656e-01 6.1726815e-01 3.3870563e-01 5.7748228e-01
 4.5307887e-01 5.9440494e-01 3.3088946e-01 4.4446427e-01 5.9824133e-01
 5.9128463e-01 4.5368516e-01 3.9134437e-01 3.8310993e-01 6.6576624e-01
 5.1608717e-01 5.5112284e-01 4.3026978e-01 5.6283921e-01 5.6742722e-01
 4.5543194e-01 5.1203209e-01 4.1847974e-01 3.0017906e-01 5.5491722e-01
 4.1998714e-01 4.2308640e-01 3.9951092e-01 5.9347153e-01 3.2402277e-01
 5.2125740e-01 6.1231613e-01 5.9896028e-01 4.2976451e-01 5.2304518e-01
 5.6306279e-01 3.5821509e-01 3.3159080e-01 5.4192036e-01 4.4591948e-01
 5.8715737e-01 6.1550272e-01 4.0194860e-01 3.4994018e-01 3.9832634e-01
 5.7113975e-01 6.2032866e-01 4.5663130e-01 5.1199210e-01 6.3528883e-01
 6.0249048e-01 4.5047233e-01 4.9651113e-01 6.1103022e-01 4.0555233e-01
 3.2221350e-01 3.5028481e-01 4.2446572e-01 4.4177032e-01 4.2253470e-01
 3.6478707e-01 5.5613202e-01 4.3113858e-01 4.7554860e-01 3.5823804e-01
 4.4246688e-01 5.3699666e-01 4.4189674e-01 5.6834453e-01 6.8232554e-01
 6.0519195e-01 5.5488580e-01 6.7102808e-01 3.6062896e-01 4.9315724e-01
 5.3537959e-01 6.3330865e-01 5.3072554e-01 3.8180441e-01 5.0131345e-01
 1.8575764e-01 2.7277032e-01 7.0156527e-01 5.2872872e-01 4.1336238e-01
 6.7209780e-01 3.1913137e-01 3.1097701e-01 3.5335577e-01 4.9184826e-01
 5.5383027e-01 7.0275003e-01 5.5131000e-01 3.8009983e-01 4.3352139e-01
 3.8099104e-01 3.5819137e-01 4.1684723e-01 2.6689005e-01 6.7613447e-01
 6.6018641e-01 6.4163375e-01 5.5052859e-01 5.0829691e-01 4.6469843e-01
 5.7098335e-01 6.3898969e-01 5.2413744e-01 4.6424922e-01 4.8195907e-01
 4.9500367e-01 4.4513762e-01 2.8876922e-01 5.3254586e-01 5.0530583e-01
 3.4549814e-01 4.8803550e-01 3.8528764e-01 2.5160170e-01 6.8687868e-01
 6.9038630e-01 4.4857046e-01 4.8172498e-01 3.7001312e-01 3.1359723e-01
 3.4785795e-01 3.0326369e-01 4.2476100e-01 4.7759846e-01 6.1268127e-01
 5.1463157e-01 5.8773792e-01 4.9269333e-01 3.4410942e-01 7.1967661e-01
 4.0830559e-01 3.4116209e-01 4.2212331e-01 6.0302389e-01 5.6717181e-01
 2.5387645e-01 2.7901310e-01 6.1635154e-01 5.0881231e-01 5.4889548e-01
 5.3558630e-01 6.1339456e-01 5.7566988e-01 5.5744588e-01 4.8865980e-01
 5.6793225e-01 5.8650756e-01 4.7741535e-01 4.7729573e-01 5.0349700e-01
 4.3640882e-01 5.2409095e-01 5.3857386e-01 5.1698154e-01 5.0772160e-01
 3.6450881e-01 3.1264830e-01 3.1409854e-01 6.1833280e-01 5.4006249e-01
 5.3634107e-01 5.1782316e-01 5.6046784e-01 3.4434414e-01 6.2463516e-01
 3.8253057e-01 5.6103706e-01 4.4021085e-01 4.2417687e-01 5.1296681e-01
 4.4214839e-01 5.1630658e-01 4.4567358e-01 6.5452963e-01 7.6723915e-01
 4.5965648e-01 4.3432295e-01 6.7388141e-01 6.3346416e-01 4.3681192e-01
 2.2278449e-01 7.5121498e-01 4.5219952e-01 6.3659668e-02 3.0102307e-01
 1.1562878e-01 6.1312282e-01 5.2983063e-01 3.4528384e-01 3.3350462e-01
 4.8173246e-01 3.5253003e-01 4.4094926e-01 2.9534519e-01 4.7766995e-01
 5.0296408e-01 5.4657918e-01 4.7444755e-01 3.9108008e-01 5.4527527e-01
 4.6602499e-01 5.9728462e-01 2.9659116e-01 8.0455077e-01 3.4719431e-01
 5.0885415e-01 4.6683079e-01 4.7738370e-01 4.7658977e-01 5.9855914e-01
 4.4880760e-01 3.7102884e-01 7.2061795e-01 4.2095923e-01 4.1066122e-01
 4.7869316e-01 4.7514722e-01 4.9739677e-01 6.4270854e-01 3.7965012e-01
 3.4786683e-01 5.9972590e-01 4.1807872e-01 2.8921008e-01 5.0042874e-01
 4.4297677e-01 3.2060295e-01 4.9666250e-01 4.8638025e-01 3.7204719e-01
 4.3346581e-01 5.4400027e-01 4.8168236e-01 5.4400724e-01 3.9122835e-01
 5.2451766e-01 4.3404907e-01 2.8751677e-01 6.2665600e-01 3.5321718e-01
 5.0346708e-01 2.3991352e-01 5.2186090e-01 4.9535596e-01 3.9620030e-01
 5.0310344e-01 5.6438392e-01 4.3931788e-01 3.2180846e-01 7.0037466e-01
 4.6568137e-01 4.8079738e-01 4.4308588e-01 4.9806777e-01 4.4895929e-01
 4.3938994e-01 4.1845816e-01 5.1154113e-01 4.1089261e-01 6.4467698e-01
 4.2936486e-01 3.8824335e-01 5.3684735e-01 6.4424133e-01 2.4822599e-01
 4.7927544e-01 7.0067465e-01 5.1864338e-01 5.3625858e-01 4.7990701e-01
 3.7744182e-01 4.4859302e-01 2.9189745e-01 3.5898995e-01 4.0764886e-01
 4.3243629e-01 6.3552880e-01 2.3328549e-01 4.9652675e-01 6.0198015e-01
 5.5347431e-01 5.9570742e-01 7.7449805e-01 5.0640535e-01 5.3108191e-01
 5.9942305e-01 4.4602537e-01 3.3526874e-01 6.3579935e-01 5.8899432e-01
 5.9936243e-01 5.9065139e-01 4.4801530e-01 4.0256178e-01 5.8328062e-01
 4.1608542e-01 4.2104673e-01 5.5582470e-01 4.6231246e-01 5.0391603e-01
 5.1836354e-01 7.3376411e-01 6.1205775e-01 3.7745354e-01 4.5154423e-01
 6.4559627e-01 5.3760034e-01 3.9094558e-01 5.4899728e-01 4.4427833e-01
 5.6066716e-01 4.2851943e-01 4.7567585e-01 4.0110460e-01 3.5565966e-01
 5.9357166e-01 6.0826099e-01 5.5692458e-01 4.9557021e-01 5.4904163e-01
 3.6618325e-01 7.1639466e-01 6.9358563e-01 5.3874850e-01 4.5613074e-01
 5.5123889e-01 4.8361984e-01 2.9545477e-01 4.2640853e-01 4.7517282e-01
 5.8605015e-01 5.1077294e-01 5.3527582e-01 6.3199013e-01 4.7170293e-01
 5.1570982e-01 5.8988053e-01 5.1781750e-01 6.0674042e-01 5.2355576e-01
 5.6743360e-01 6.7203826e-01 3.8596249e-01 5.8281112e-01 6.9048476e-01
 5.5558342e-01 5.8116132e-01 4.7817072e-01 5.9046119e-01 3.2858485e-01
 4.9108174e-01 4.0562099e-01 6.1381435e-01 5.0134730e-01 5.2656853e-01
 4.2645025e-01 6.3449472e-01 5.2999282e-01 3.6422783e-01 4.8387513e-01
 4.3763256e-01 3.1976509e-01 6.1771607e-01 4.6735021e-01 6.1180174e-01
 3.7551934e-01 2.7664173e-01 5.7650691e-01 5.6718075e-01 4.5058906e-01
 4.1520780e-01 7.0526671e-01 6.0937262e-01 4.0677881e-01 4.7966513e-01
 3.8072070e-01 4.5480230e-01 5.1570636e-01 5.2290231e-01 5.0339216e-01
 5.0650305e-01 4.5712832e-01 5.1405478e-01 5.3172559e-01 4.9673143e-01
 4.9920419e-01 4.9165770e-01], shape=(507,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1.
 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1.
 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1.
 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.
 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1.
 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.
 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0.
 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0.
 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1.
 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0.
 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1.
 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0.
 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1.
 0. 0. 0.], shape=(507,), dtype=float32)
predicted label rank:[2 2 1 2 2 2 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 2 1 1 1 1 1 2 2 1 2
 2 2 1 2 1 2 1 1 2 2 1 2 1 1 1 1 1 2 2 1 2 1 2 2 1 1 2 2 1 2 2 1 1 2 1 2 2
 1 2 2 1 1 2 1 1 1 2 2 1 1 1 1 2 2 2 2 2 1 2 1 2 2 2 2 1 1 2 1 1 2 1 1 2 2
 1 1 2 2 1 1 2 1 2 1 2 1 1 2 2 1 1 1 2 2 2 1 2 2 1 2 1 1 2 1 1 1 2 1 2 2 2
 1 2 2 1 1 2 1 2 2 1 1 1 2 2 1 2 2 2 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 2
 2 2 2 1 1 2 2 2 1 2 1 1 2 2 1 2 1 1 1 1 2 2 2 1 1 1 1 1 1 2 2 2 2 2 1 2 2
 2 1 1 1 1 1 2 2 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 2 2 1 1 2 1 1 1 2 2 1 1 2 2
 2 2 2 2 2 1 2 2 1 1 2 1 2 2 2 2 1 1 1 2 2 2 2 2 1 2 1 2 1 1 2 1 2 1 2 2 1
 1 2 2 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 2 2 1 1 2 1 2 1 2 1 2 1 1 1 2 1 1 2
 1 1 1 1 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 2 1 1 2 1 2 1 2 1 1 2 2 1 1 2
 1 1 1 1 1 1 1 2 1 2 1 1 2 2 1 1 2 2 2 1 1 1 1 1 1 1 2 1 1 2 2 2 2 2 2 2 1
 1 2 2 2 2 1 1 2 1 1 2 1 2 2 2 2 1 1 2 2 1 2 1 2 1 1 1 1 2 2 2 1 2 1 2 2 2
 1 2 1 1 1 1 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 1 2 1 1 1 2 2 2 1 2 2 1 1 1
 1 2 1 2 1 1 2 2 1 1 2 2 1 1 1 1 2 2 2 2 1 2 2 1 1 1]
mse:tf.Tensor(0.2610615, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0016_000.smt2
true label:[0, 0, 0, 1]
true label rank:[1 1 1 2]
predicted label:tf.Tensor([0.5348456  0.44090852 0.47267324 0.5885767 ], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 1.], shape=(4,), dtype=float32)
predicted label rank:[2 1 1 2]
mse:tf.Tensor(0.2182873, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/cyclic.smt2-0007_000.smt2
true label:[1, 0]
true label rank:[2 1]
predicted label:tf.Tensor([0.49478468 0.5302803 ], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 2]
mse:tf.Tensor(0.26821983, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/bandec.smt2-0036_000.smt2
true label:[0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]
true label rank:[1 2 2 2 1 1 1 1 1 1 1 2 2 2]
predicted label:tf.Tensor(
[0.5008941  0.49519482 0.5113067  0.52524364 0.49285123 0.51189727
 0.506239   0.4963758  0.48716506 0.4874509  0.48184532 0.5055538
 0.499774   0.5047305 ], shape=(14,), dtype=float32)
rounded label:tf.Tensor([1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1.], shape=(14,), dtype=float32)
predicted label rank:[2 1 2 2 1 2 2 1 1 1 1 2 1 2]
mse:tf.Tensor(0.24461815, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/minepump_spec2_product58_true-unreach-call.cil.c.flat_000.smt2
true label:[1, 1, 1, 1]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([1.         1.         0.58914125 1.        ], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)
predicted label rank:[1 1 1 1]
mse:tf.Tensor(0.04220123, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/car_all_e2_108_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 2 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1
 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2
 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[9.99827147e-01 9.99997854e-01 4.18424010e-02 9.99845147e-01
 9.96735156e-01 7.03241825e-02 2.17927523e-10 9.99656737e-01
 2.06988700e-21 1.75334534e-07 6.91613593e-07 4.82972082e-12
 7.15461995e-11 3.96809050e-14 1.85373428e-05 2.54674160e-05
 9.99372780e-01 9.86224532e-01 2.07215548e-02 3.24727989e-05
 3.77604475e-17 9.97158001e-09 1.38785139e-19 2.66827166e-01
 9.99996245e-01 1.00000000e+00 8.81141270e-16 8.96858811e-01
 1.01409476e-07 5.67170551e-13 5.04404306e-04 9.94309306e-01
 4.63103236e-11 5.32380223e-01 5.15576422e-01 3.03926706e-01
 5.52193761e-01 7.15872407e-01 6.75023437e-01 4.28856313e-01
 5.89876354e-01 4.08455491e-01 4.21699643e-01 4.03601527e-01
 3.79298270e-01 4.77081299e-01 5.97902417e-01 4.76276189e-01
 5.62895477e-01 3.12782645e-01 5.82562804e-01 4.23221767e-01
 4.14450407e-01 5.42029142e-01 6.08565688e-01 7.15522647e-01
 4.71456826e-01 6.15545392e-01 4.20539111e-01 5.70569932e-01
 6.10378921e-01 5.60411096e-01 2.78061569e-01 5.10363519e-01
 7.24037290e-01 5.04718959e-01 5.85494161e-01 7.12906539e-01
 4.01131541e-01 3.99509579e-01 5.13807297e-01 4.60501015e-01
 7.42486000e-01 4.72436905e-01 3.45229864e-01 6.88496113e-01
 4.47874069e-01 2.94721425e-01 5.27865708e-01 6.46576405e-01
 1.50449216e-01 3.75174165e-01 3.49931896e-01 5.38572907e-01
 6.06555760e-01 6.17740035e-01 2.96447217e-01 4.62842166e-01
 5.47211170e-01 6.34970546e-01 5.46428382e-01 4.92812246e-01
 5.83862185e-01 4.17366147e-01 3.67627025e-01 5.57775021e-01
 3.71683002e-01 6.06875896e-01 4.81041968e-01 5.27503669e-01
 5.61808586e-01 5.97638726e-01 3.92408222e-01 6.09395981e-01
 4.98693228e-01 2.72642553e-01 4.25583422e-01 6.16240442e-01
 4.44032460e-01 6.58720255e-01 3.85247856e-01 3.60813200e-01
 6.76291287e-01 6.67016804e-01 4.90196556e-01 4.51467723e-01
 4.51430619e-01 5.50956249e-01 2.92579591e-01 5.11750460e-01
 4.33968067e-01 5.15521586e-01 3.14474612e-01 5.29915214e-01
 4.66611266e-01 5.77864289e-01 4.18419361e-01 4.39819843e-01
 3.68394583e-01 7.44750917e-01 2.04384148e-01 7.20602989e-01
 4.73416328e-01 6.15622938e-01 5.99668801e-01 5.42635739e-01
 2.13262409e-01 7.59199619e-01 7.30051696e-02 5.18359482e-01
 4.94037479e-01 5.23598731e-01 5.14757633e-01 5.01045287e-01
 4.34466183e-01 4.41383243e-01 4.87341434e-01 4.17058110e-01
 4.19640273e-01 4.66422349e-01 4.79075700e-01 4.20181453e-01
 5.31237364e-01 4.39124167e-01 4.83221292e-01 4.89345521e-01
 4.46323276e-01 5.08270025e-01 4.49458688e-01 4.63242173e-01
 4.78763819e-01 4.71276820e-01 4.75969702e-01 4.93241698e-01
 4.80461478e-01 5.39183438e-01 4.48938340e-01 4.81134325e-01
 4.86770719e-01 1.25178635e-01 9.10598040e-03 2.40357816e-02
 5.14841378e-02 2.65221298e-01 1.07007891e-01 5.66248715e-01
 8.38955402e-01 1.94278181e-01 5.44310451e-01 1.89141840e-01
 5.19342065e-01 6.05137348e-01 2.85286784e-01 4.07410264e-02
 9.03992772e-01 5.20487309e-01 7.49634743e-01 9.59940553e-01
 5.79797924e-01 5.42749882e-01 6.23721898e-01 6.08253658e-01
 6.07236147e-01 3.67727846e-01 4.46299791e-01 2.36532420e-01
 3.47866356e-01 6.01701319e-01 4.91202235e-01 5.49940526e-01
 5.74323595e-01 3.85258943e-01 2.72118509e-01 2.45851338e-01
 3.25250745e-01 4.66177493e-01 6.66492939e-01 4.34628248e-01
 4.28636640e-01 5.39881468e-01], shape=(210,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0.
 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0.
 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1.
 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.
 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1.], shape=(210,), dtype=float32)
predicted label rank:[2 2 1 2 2 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 2 2 1 2 1 1 1 2 1 2 2 1 2
 2 2 1 2 1 1 1 1 1 2 1 2 1 2 1 1 2 2 2 1 2 1 2 2 2 1 2 2 2 2 2 1 1 2 1 2 1
 1 2 1 1 2 2 1 1 1 2 2 2 1 1 2 2 2 1 2 1 1 2 1 2 1 2 2 2 1 2 1 1 1 2 1 2 1
 1 2 2 1 1 1 2 1 2 1 2 1 2 1 2 1 1 1 2 1 2 1 2 2 2 1 2 1 2 1 2 2 2 1 1 1 1
 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 2 1 2 2 1 1 2
 2 2 2 2 2 2 2 2 1 1 1 1 2 1 2 2 1 1 1 1 1 2 1 1 2]
mse:tf.Tensor(0.2913148, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/nested6.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[7.5413060e-01 2.2864163e-02 3.9188623e-02 5.1863760e-01 9.9319899e-01
 8.1092787e-01 3.3280455e-07 9.9883074e-01 1.1898536e-07], shape=(9,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 1. 1. 1. 0. 1. 0.], shape=(9,), dtype=float32)
predicted label rank:[2 1 1 2 2 2 1 2 1]
mse:tf.Tensor(0.38682973, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/dillig17.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[6.5714186e-01 1.0253212e-01 1.2653631e-01 5.1677573e-01 8.0443466e-01
 9.3537956e-01 8.2919425e-05 9.9679518e-01 1.4946457e-05], shape=(9,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 1. 1. 1. 0. 1. 0.], shape=(9,), dtype=float32)
predicted label rank:[2 1 1 2 2 2 1 2 1]
mse:tf.Tensor(0.3601186, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/loop__loop_000.smt2
true label:[1, 1, 0, 0, 1]
true label rank:[2 2 1 1 2]
predicted label:tf.Tensor([0.4855451  0.5268393  0.4843975  0.52131885 0.46022537], shape=(5,), dtype=float32)
rounded label:tf.Tensor([0. 1. 0. 1. 0.], shape=(5,), dtype=float32)
predicted label rank:[1 2 1 2 1]
mse:tf.Tensor(0.25726318, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/spline-fixed.smt2-0003_000.smt2
true label:[1, 1, 1]
true label rank:[1 1 1]
predicted label:tf.Tensor([0.49619472 0.5077138  0.4957371 ], shape=(3,), dtype=float32)
rounded label:tf.Tensor([0. 1. 0.], shape=(3,), dtype=float32)
predicted label rank:[1 2 1]
mse:tf.Tensor(0.25014886, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0260_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[1.0000000e+00 1.0000000e+00 4.6685832e-07 9.9976999e-01 9.3653703e-01
 9.5936614e-01 1.0000000e+00 1.0000000e+00 4.8510751e-01 5.0809598e-01
 4.6021679e-01 4.4604027e-01 4.5733568e-01 4.5450616e-01 4.6293196e-01
 4.6635836e-01 4.4750860e-01 4.1521135e-01 4.4118929e-01 3.3933759e-01
 3.2540330e-01 3.2787293e-01 2.2110572e-01 5.2427268e-01 6.7439699e-01
 5.0629497e-01 3.6763996e-01 7.0641840e-01 3.4956846e-01 4.7104988e-01
 4.7183487e-01 4.2034355e-01 2.4396059e-01 5.2576220e-01 5.1561421e-01
 3.0884713e-01 5.6636155e-01 6.6198671e-01 5.8175838e-01 4.5219541e-01
 6.4048553e-01 4.4486833e-01 7.3189270e-01 4.5067519e-01 4.5609993e-01
 5.8921397e-01 5.9790862e-01 4.5643362e-01 6.1267489e-01 2.2717142e-01
 4.7063339e-01 4.6460298e-01 4.5211536e-01 4.9027792e-01 6.0823220e-01
 6.1203742e-01 4.3448889e-01 6.0921758e-01 3.5204056e-01 5.6191021e-01
 5.5392677e-01 4.8219907e-01 3.2120630e-01 5.4316378e-01 7.5501597e-01
 3.9066756e-01 5.6900215e-01 6.9021702e-01 3.0419177e-01 4.2876127e-01
 6.7357004e-01 4.1641825e-01 6.9365138e-01 5.3904927e-01 4.0175930e-01
 6.0704559e-01 5.9562290e-01 3.4437937e-01 3.9811671e-01 6.1480749e-01
 1.7554665e-01 2.1230417e-01 4.0753102e-01 6.1118966e-01 7.4383008e-01
 4.5525280e-01 3.6966568e-01 4.2930800e-01 4.8936203e-01 5.8261645e-01
 5.2839422e-01 5.6600356e-01 5.9453750e-01 5.2763528e-01 4.1579646e-01
 5.9402627e-01 4.8701340e-01 5.9116846e-01 5.0939494e-01 5.5917019e-01
 5.7069761e-01 4.0362731e-01 4.9446455e-01 5.9785575e-01 4.8890418e-01
 4.5690799e-01 6.7522836e-01 4.2520994e-01 4.7492975e-01 7.8118098e-01
 5.1165605e-01 3.7658063e-01 3.8338977e-01 5.8338368e-01 5.3286690e-01
 4.5943975e-01 4.7492656e-01 6.1726815e-01 3.3870563e-01 5.7748228e-01
 4.5307887e-01 5.9440494e-01 3.3088946e-01 4.4446427e-01 5.9824133e-01
 5.9128463e-01 4.5368516e-01 3.9134437e-01 3.8310993e-01 6.6576624e-01
 5.1608717e-01 5.5112284e-01 4.3026978e-01 5.6283921e-01 5.6742722e-01
 4.5543194e-01 5.1203209e-01 4.1847974e-01 3.0017906e-01 5.5491722e-01
 4.1998714e-01 4.2308640e-01 3.9951092e-01 5.9347153e-01 3.2402277e-01
 5.2125740e-01 6.1231613e-01 5.9896028e-01 4.2976451e-01 5.2304518e-01
 5.6306279e-01 3.5821509e-01 3.3159080e-01 5.4192036e-01 4.4591948e-01
 5.8715737e-01 6.1550272e-01 4.0194860e-01 3.4994018e-01 3.9832634e-01
 5.7113975e-01 6.2032866e-01 4.5663130e-01 5.1199210e-01 6.3528883e-01
 6.0249048e-01 4.5047233e-01 4.9651113e-01 6.1103022e-01 4.0555233e-01
 3.2221350e-01 3.5028481e-01 4.2446572e-01 4.4177032e-01 4.2253470e-01
 3.6478707e-01 5.5613202e-01 4.3113858e-01 4.7554860e-01 3.5823804e-01
 4.4246688e-01 5.3699666e-01 4.4189674e-01 5.6834453e-01 6.8232554e-01
 6.0519195e-01 5.5488580e-01 6.1162126e-01 3.8514379e-01 4.5473793e-01
 5.6916839e-01 6.7393601e-01 5.7791841e-01 2.7145702e-01 5.3196687e-01
 2.2476903e-01 3.6040819e-01 6.3537455e-01 4.8982388e-01 5.1158112e-01
 5.7221609e-01 4.0675503e-01 3.3124122e-01 2.9490757e-01 3.4285882e-01
 5.4958737e-01 7.0528519e-01 4.6664506e-01 3.2822442e-01 5.1558769e-01
 5.1160574e-01 3.1652057e-01 4.3885136e-01 4.8670951e-01 6.4839280e-01
 6.0985243e-01 6.4041829e-01 5.5476528e-01 5.9459645e-01 4.9420118e-01
 6.2270737e-01 6.6800821e-01 4.2483500e-01 4.6835721e-01 5.1000285e-01
 3.5307527e-01 3.9118236e-01 3.5365805e-01 5.1890582e-01 6.2487584e-01
 2.9110560e-01 4.3698108e-01 3.4677985e-01 3.0927500e-01 4.3304634e-01
 6.9629598e-01 4.9378243e-01 5.7152236e-01 3.4045070e-01 3.8146329e-01
 3.7229469e-01 3.0868822e-01 3.9277548e-01 5.0662857e-01 5.6013781e-01
 5.2779925e-01 5.7321799e-01 3.7579876e-01 4.2594475e-01 6.8736124e-01
 3.4735405e-01 2.6550439e-01 4.5180634e-01 7.6204467e-01 5.6390679e-01
 5.0481045e-01 3.2360661e-01 6.3771427e-01 3.8303187e-01 6.2828135e-01
 5.8838344e-01 6.2237740e-01 6.0137725e-01 4.8383355e-01 4.7573388e-01
 5.7774162e-01 5.1981771e-01 4.9185765e-01 5.2170384e-01 6.1199200e-01
 4.3759716e-01 6.5351164e-01 5.5855417e-01 5.6400096e-01 5.0329322e-01
 3.9625221e-01 3.5073900e-01 3.5648054e-01 5.0887609e-01 4.1797900e-01
 5.3261554e-01 4.1193742e-01 5.1696813e-01 3.0321401e-01 5.8146578e-01
 4.0094921e-01 5.6886429e-01 4.6413836e-01 3.4663484e-01 5.3305757e-01
 4.1604090e-01 3.9045495e-01 3.5343432e-01 4.0801960e-01 6.8675870e-01
 4.7340727e-01 5.9404558e-01 6.8947726e-01 4.1464108e-01 4.9554816e-01
 3.4148943e-01 6.3326824e-01 4.9110699e-01 1.6152716e-01 4.4458213e-01
 2.9791471e-01 5.5445671e-01 5.3158265e-01 3.6153793e-01 3.4065419e-01
 4.8486501e-01 3.6050797e-01 4.2351782e-01 2.9120737e-01 4.8887253e-01
 5.1380163e-01 5.4646909e-01 4.7083974e-01 3.8959295e-01 5.4321694e-01
 4.4879231e-01 5.9735000e-01 2.9719278e-01 8.0133218e-01 3.4734839e-01
 5.0139058e-01 4.7812095e-01 4.7117791e-01 4.8093778e-01 6.0413742e-01
 4.3795297e-01 3.7015358e-01 7.1236306e-01 4.2356128e-01 4.0617657e-01
 4.7322500e-01 4.7248024e-01 4.9785367e-01 6.4923656e-01 3.7322965e-01
 3.5763991e-01 5.8704972e-01 4.4144225e-01 2.8391030e-01 4.8849404e-01
 4.3958512e-01 3.1615639e-01 5.0027496e-01 4.7718385e-01 3.8207114e-01
 4.3546480e-01 5.4479820e-01 4.8186672e-01 5.2680123e-01 4.0128344e-01
 5.2400273e-01 4.4373441e-01 2.9990354e-01 6.2949127e-01 3.5572082e-01
 5.0439191e-01 2.5611812e-01 5.4109704e-01 4.8222494e-01 4.0271270e-01
 4.9936959e-01 5.7186949e-01 4.6120864e-01 3.3560538e-01 7.0615327e-01
 4.5881537e-01 4.7425917e-01 4.5070499e-01 4.8771763e-01 4.5111844e-01
 4.6973088e-01 4.1328147e-01 5.0947732e-01 3.9697373e-01 6.3773608e-01
 4.1963300e-01 3.8603327e-01 5.3322893e-01 6.5285313e-01 2.3725328e-01
 4.7227079e-01 7.0775676e-01 5.0521380e-01 5.3507119e-01 4.8178580e-01
 3.6979139e-01 4.3848699e-01 2.9598540e-01 3.5932773e-01 4.1919100e-01
 4.3125859e-01 6.3196242e-01 2.3590389e-01 5.0984538e-01 6.0668993e-01
 5.4132712e-01 5.9221566e-01 7.6763821e-01 5.2780318e-01 5.3405362e-01
 5.8866733e-01 4.4324055e-01 3.2966432e-01 6.2746328e-01 5.8483529e-01
 5.8039874e-01 5.8995748e-01 4.5255753e-01 3.8634419e-01 6.1260766e-01
 4.2360848e-01 4.3320054e-01 5.5240154e-01 4.5911196e-01 5.0615644e-01
 5.1731586e-01 7.2484618e-01 6.1417341e-01 3.8228869e-01 4.4933909e-01
 6.4930421e-01 5.4646665e-01 3.9520788e-01 5.4488140e-01 4.4535211e-01
 5.5679888e-01 4.2772821e-01 4.6877584e-01 4.0269670e-01 3.6153743e-01
 5.9605336e-01 6.1768967e-01 5.6576288e-01 4.8807997e-01 5.6093627e-01
 3.6040232e-01 7.0945191e-01 7.0678711e-01 5.3706354e-01 4.6016830e-01
 5.4668826e-01 4.7384524e-01 2.9335320e-01 4.2005900e-01 4.7279617e-01
 5.7188594e-01 5.0360519e-01 5.3745097e-01 6.2387419e-01 4.6846956e-01
 5.0980163e-01 5.9562588e-01 5.1825166e-01 6.4195514e-01 5.2602285e-01
 5.7804608e-01 6.8533367e-01 3.8501328e-01 5.8348536e-01 6.9476771e-01
 5.6023145e-01 5.8584982e-01 4.8062763e-01 5.9266621e-01 3.4224802e-01
 4.9217242e-01 4.0498373e-01 6.1322141e-01 4.9155253e-01 5.2858770e-01
 4.2591280e-01 6.3506711e-01 5.3143764e-01 3.7341473e-01 4.8895964e-01
 4.2587593e-01 3.1961817e-01 6.0813415e-01 4.5940009e-01 6.0276896e-01
 3.6568087e-01 2.7096167e-01 5.7695556e-01 5.6073302e-01 4.5004404e-01
 4.2452252e-01 7.0741045e-01 6.1833262e-01 4.1044962e-01 4.8078573e-01
 3.7850690e-01 4.4451040e-01 5.2007341e-01 5.3297073e-01 4.9841055e-01
 5.0925398e-01 4.5966154e-01 5.1094705e-01 5.2740675e-01 4.9575052e-01
 5.0438035e-01 4.9488789e-01], shape=(507,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1.
 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1.
 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1.
 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.
 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1.
 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.
 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0.
 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.
 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0.
 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1.
 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0.
 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1.
 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0.
 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1.
 0. 1. 0.], shape=(507,), dtype=float32)
predicted label rank:[2 2 1 2 2 2 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 2 1 1 1 1 1 2 2 1 2
 2 2 1 2 1 2 1 1 2 2 1 2 1 1 1 1 1 2 2 1 2 1 2 2 1 1 2 2 1 2 2 1 1 2 1 2 2
 1 2 2 1 1 2 1 1 1 2 2 1 1 1 1 2 2 2 2 2 1 2 1 2 2 2 2 1 1 2 1 1 2 1 1 2 2
 1 1 2 2 1 1 2 1 2 1 2 1 1 2 2 1 1 1 2 2 2 1 2 2 1 2 1 1 2 1 1 1 2 1 2 2 2
 1 2 2 1 1 2 1 2 2 1 1 1 2 2 1 2 2 2 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 2
 2 2 2 1 1 2 2 2 1 2 1 1 2 1 2 2 1 1 1 1 2 2 1 1 2 2 1 1 1 2 2 2 2 2 1 2 2
 1 1 2 1 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 1 2 2 2 2 1 1 2 1 1 1 2 2 2 1 2 1
 2 2 2 2 1 1 2 2 1 2 2 1 2 2 2 2 1 1 1 2 1 2 1 2 1 2 1 2 1 1 2 1 1 1 1 2 1
 2 2 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 2 2 1 1 2 1 2 1 2 1 2 1 1 1 2 1 1 2
 1 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 2 1 2 1 1 2 1 2 1 2 1 1 1 2 1 1 2
 1 1 1 1 1 1 1 2 1 2 1 1 2 2 1 1 2 2 2 1 1 1 1 1 1 1 2 1 2 2 2 2 2 2 2 2 1
 1 2 2 2 2 1 1 2 1 1 2 1 2 2 2 2 1 1 2 2 1 2 1 2 1 1 1 1 2 2 2 1 2 1 2 2 2
 1 2 1 1 1 1 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 1 2 1 1 1 2 1 2 1 2 2 1 1 1
 1 2 1 2 1 1 2 2 1 1 2 2 1 1 1 1 2 2 1 2 1 2 2 1 2 1]
mse:tf.Tensor(0.26052958, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/nest-if.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.9559113  0.4671619  0.17980719 0.8741777  0.00616226 0.84875625
 0.18704289 0.96428204], shape=(8,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 1. 0. 1. 0. 1.], shape=(8,), dtype=float32)
predicted label rank:[2 1 1 2 1 2 1 2]
mse:tf.Tensor(0.45172173, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/SYNAPSE_3_e7_1444_e7_638_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1]
predicted label:tf.Tensor(
[0.4889425  0.38088137 0.5069924  0.43343058 0.37385547 0.7495637
 0.43012527 0.6956262  0.15008605 0.43455747 0.21655694 0.3559185
 0.5660603  0.20889494 0.35410023 0.4928436  0.78295994 0.5905184
 0.25151128 0.2735004  0.3634407  0.28358895 0.1924338  0.61414194
 0.781928   0.6218655  0.18192786 0.5275622  0.31358922 0.29395822
 0.48827705 0.5112551  0.49923003 0.5095056  0.49415198 0.48698092
 0.4811416  0.49222362 0.48449665 0.49713078 0.50134116 0.5035239
 0.50353307 0.5047194  0.48864484 0.5093489  0.48851743 0.48873305
 0.53309214 0.49204323 0.5016765  0.51034874 0.4801954  0.5299582
 0.49477306 0.51464105 0.483313   0.52989155 0.4819788  0.5098789
 0.5069235  0.5005076  0.48386037 0.49716327 0.50630724 0.5068905
 0.5042487  0.49675363 0.48775402 0.49217814 0.49382332 0.4980043
 0.52925134 0.49072662 0.48719636 0.49703294 0.49103406 0.50032747
 0.4873949  0.4875192  0.48752466 0.51113623 0.49686432 0.4834965
 0.49870598 0.49614048 0.4949498  0.50873184 0.48693413 0.5088891
 0.5030938  0.49227035 0.50848067 0.51275456 0.48222873 0.50352436
 0.5105662  0.5123139  0.46518666 0.4763727  0.53563154 0.64302677
 0.42712545 0.59609985 0.6014293  0.34908473 0.3592348  0.44747812
 0.5771591  0.81349653 0.5387759  0.3457899  0.13205135 0.786306
 0.6140634  0.25909698 0.38573596 0.48943576 0.11040768 0.7246783
 0.35162348 0.87222636 0.3367772  0.79307723 0.62663263 0.964463
 0.13006929 0.25193986 0.4378666  0.51878023 0.44449535 0.5086243
 0.4402115  0.4254864  0.52032936 0.48755607 0.46552077 0.53475803
 0.4110633  0.5470285  0.46423167 0.52041364 0.46214116 0.53180015
 0.45635852 0.4366991  0.51554024 0.4808161  0.43989772], shape=(149,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1.
 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0.
 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1.
 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1.
 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1.
 0. 0. 1. 0. 0.], shape=(149,), dtype=float32)
predicted label rank:[1 1 2 1 1 2 1 2 1 1 1 1 2 1 1 1 2 2 1 1 1 1 1 2 2 2 1 2 1 1 1 2 1 2 1 1 1
 1 1 1 2 2 2 2 1 2 1 1 2 1 2 2 1 2 1 2 1 2 1 2 2 2 1 1 2 2 2 1 1 1 1 1 2 1
 1 1 1 2 1 1 1 2 1 1 1 1 1 2 1 2 2 1 2 2 1 2 2 2 1 1 2 2 1 2 2 1 1 1 2 2 2
 1 1 2 2 1 1 1 1 2 1 2 1 2 2 2 1 1 1 2 1 2 1 1 2 1 1 2 1 2 1 2 1 2 1 1 2 1
 1]
mse:tf.Tensor(0.25009018, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/tridag.smt2-0014_000.smt2
true label:[1]
true label rank:[1]
predicted label:tf.Tensor([0.50335485], shape=(1,), dtype=float32)
rounded label:tf.Tensor([1.], shape=(1,), dtype=float32)
predicted label rank:[1]
mse:tf.Tensor(0.2466564, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/spline-fixed.smt2-0008_000.smt2
true label:[0, 1]
true label rank:[1 2]
predicted label:tf.Tensor([0.50341815 0.49210125], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 0.], shape=(2,), dtype=float32)
predicted label rank:[2 1]
mse:tf.Tensor(0.25569546, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0125_000.smt2
true label:[1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0]
true label rank:[2 1 1 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 2 1 1 1 2
 2 1 1 1]
predicted label:tf.Tensor(
[1.00000000e+00 1.00000000e+00 9.99996543e-01 1.00000000e+00
 9.77975368e-01 9.99999642e-01 8.41596126e-09 1.00000000e+00
 5.48549578e-28 8.03005232e-11 2.15946627e-19 1.95126893e-15
 7.70155526e-18 4.05876887e-21 6.34536362e-16 1.29839182e-02
 9.95375812e-01 1.00000000e+00 4.25097198e-07 5.82293991e-10
 2.18945361e-25 1.04541695e-20 1.32572241e-34 1.47419184e-01
 1.00000000e+00 1.00000000e+00 1.70760209e-25 9.99697566e-01
 3.18994641e-14 1.64246290e-11 1.24319313e-05 9.99994755e-01
 9.20037592e-18 5.93157709e-02 2.76895644e-08 3.25089517e-26
 1.00000000e+00 1.00000000e+00 1.00000000e+00 2.34055519e-03
 1.00000000e+00], shape=(41,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1.], shape=(41,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 2 2 1 2 1 1 1 2 1 1 1 1 2
 2 2 1 2]
mse:tf.Tensor(0.47929764, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/bandec.smt2-0157_000.smt2
true label:[1, 1, 1, 1]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([0.501007   0.5041574  0.49638733 0.49882782], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 0.], shape=(4,), dtype=float32)
predicted label rank:[2 2 1 1]
mse:tf.Tensor(0.24991328, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/seesaw.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.9999793  0.9993607  0.00209761 0.98258954 0.01412269 0.00936013
 0.00274056 0.9998063 ], shape=(8,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 0. 0. 0. 1.], shape=(8,), dtype=float32)
predicted label rank:[2 2 1 2 1 1 1 2]
mse:tf.Tensor(0.49550927, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/counter.correct.nts_000.smt2
true label:[1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1]
predicted label:tf.Tensor([0.5015573  0.5264792  0.49977234 0.51817393 0.5011773  0.5177213 ], shape=(6,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 1. 1.], shape=(6,), dtype=float32)
predicted label rank:[2 2 1 2 2 2]
mse:tf.Tensor(0.23941134, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/durationThm_2_e1_118_000.smt2
true label:[1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0]
true label rank:[2 2 1 1 2 2 2 2 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1]
predicted label:tf.Tensor(
[9.9932712e-01 5.8538032e-01 8.8122189e-03 9.8668897e-01 1.2859917e-01
 3.8648447e-01 1.1211634e-03 8.3312428e-01 3.3974658e-08 1.0901430e-01
 1.3808012e-03 2.1499395e-04 2.8308928e-03 3.1070908e-06 1.2339014e-01
 9.7268653e-01 9.9993575e-01 8.1412590e-01 5.0285876e-02 1.4855981e-02
 1.6337990e-05 1.9885004e-03 1.4467771e-05], shape=(23,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.], shape=(23,), dtype=float32)
predicted label rank:[2 2 1 2 1 1 1 2 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1]
mse:tf.Tensor(0.21846545, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/durationThm_1_e3_173_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[7.2216856e-01 8.4802055e-01 2.0408681e-01 9.9145830e-01 9.7294337e-01
 9.9503458e-01 6.9138408e-04 9.9990135e-01 1.3996676e-08 1.8817723e-02
 3.8549093e-05 2.0083138e-07 5.1453710e-03 1.4069687e-09], shape=(14,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0.], shape=(14,), dtype=float32)
predicted label rank:[2 2 1 2 2 2 1 2 1 1 1 1 1 1]
mse:tf.Tensor(0.371586, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/inf6.correct.nts.horn-0001_000.smt2
true label:[1, 1, 0, 0, 1, 0, 0, 0, 0, 1]
true label rank:[2 2 1 1 2 1 1 1 1 2]
predicted label:tf.Tensor(
[0.50199336 0.4976369  0.49676108 0.5044268  0.5097945  0.5243392
 0.5151338  0.49343878 0.47889444 0.5067428 ], shape=(10,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 1. 1. 1. 1. 0. 0. 1.], shape=(10,), dtype=float32)
predicted label rank:[2 1 1 2 2 2 2 1 1 2]
mse:tf.Tensor(0.24983177, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/large_const_true-unreach-call.c.flat_000.smt2
true label:[1, 1, 1, 0, 1, 1, 1]
true label rank:[2 2 2 1 2 2 2]
predicted label:tf.Tensor(
[0.53684276 0.5226649  0.36893594 0.48860553 0.4821815  0.507461
 0.503313  ], shape=(7,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 0. 0. 1. 1.], shape=(7,), dtype=float32)
predicted label rank:[2 2 1 1 1 2 2]
mse:tf.Tensor(0.2623956, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/nest-if1.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[7.2727478e-01 1.9602042e-01 1.5494245e-01 3.3497068e-01 9.2581320e-01
 9.2728120e-01 3.2480293e-05 9.9271214e-01 7.4779873e-06], shape=(9,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 0. 1. 1. 0. 1. 0.], shape=(9,), dtype=float32)
predicted label rank:[2 1 1 1 2 2 1 2 1]
mse:tf.Tensor(0.378447, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/break_single_merged_safe.c-1_000.smt2
true label:[0, 1, 0, 1, 1]
true label rank:[1 2 1 2 2]
predicted label:tf.Tensor([0.4936982  0.49944386 0.51178956 0.5462166  0.48094085], shape=(5,), dtype=float32)
rounded label:tf.Tensor([0. 0. 1. 1. 0.], shape=(5,), dtype=float32)
predicted label rank:[1 1 2 2 1]
mse:tf.Tensor(0.24631295, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0017_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.48542285 0.4886307  0.49303907 0.51008916 0.5065497  0.49933422
 0.5167004  0.5234014 ], shape=(8,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 1. 1. 0. 1. 1.], shape=(8,), dtype=float32)
predicted label rank:[1 1 1 2 2 1 2 2]
mse:tf.Tensor(0.25306618, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/id_build.i.p+sep-reducer.c-1_000.smt2
true label:[1, 1, 1]
true label rank:[1 1 1]
predicted label:tf.Tensor([0.5389634 0.5256736 0.5232148], shape=(3,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)
predicted label rank:[1 1 1]
mse:tf.Tensor(0.22162147, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/06.c_000.smt2
true label:[0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0]
true label rank:[1 2 2 1 1 2 2 1 1 2 2 1 1 2 2 1 1 2 2 1]
predicted label:tf.Tensor(
[0.49350435 0.50965255 0.46019518 0.539395   0.4857043  0.4983907
 0.4947523  0.49820942 0.4408932  0.5002336  0.46008804 0.46732205
 0.5017428  0.46306422 0.4760931  0.5105488  0.54341227 0.47535825
 0.45797542 0.4803782 ], shape=(20,), dtype=float32)
rounded label:tf.Tensor([0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0.], shape=(20,), dtype=float32)
predicted label rank:[1 2 1 2 1 1 1 1 1 2 1 1 2 1 1 2 2 1 1 1]
mse:tf.Tensor(0.2590832, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/metros_1_e8_725_e3_556_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1
 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1
 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1
 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1
 1 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 2 2 1 1 1 1 1 1
 1 2 2 2 2 1 1 2 2 1 1 2 1 2 1 1 1 1 1 1 1 2 2 2 2 1 1 1 2 1 2 1 2 1 1 1 2
 1 1 1 1 2 2 2 2 1 1 2 1 1 2 1 1 1 2 1 2 1 1 1 1 2 2 2 2 1 1 2 1 1 1 1 2 1
 2 1 1 1 1 1 1 2 2 2 2 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 1 2 2
 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 2 1 1 2
 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1
 1 2 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 2 1 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 2
 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 1 1 1 1 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[3.55998635e-01 3.20108563e-01 9.68693793e-02 1.91487044e-01
 2.83407390e-01 8.74459445e-01 3.31244588e-01 9.25071180e-01
 8.91268253e-04 1.60414279e-01 1.85903907e-03 1.00500286e-02
 2.89307535e-02 4.45330143e-03 3.09071481e-01 8.95088673e-01
 9.97891426e-01 7.88965106e-01 4.06730473e-02 1.39419079e-01
 4.08056378e-03 2.39077210e-03 1.80929899e-03 6.73260450e-01
 6.51458740e-01 9.96772051e-01 2.04111040e-02 3.88471544e-01
 4.53981161e-02 7.10815191e-03 3.62142146e-01 1.12299055e-01
 6.78062439e-03 7.76346266e-01 5.92359006e-02 8.73470306e-03
 7.37571061e-01 9.58413005e-01 9.50402439e-01 7.11010396e-02
 9.61368322e-01 2.23417491e-01 8.76836002e-01 1.82332724e-01
 2.41403282e-02 6.65324390e-01 9.31816280e-01 7.31680334e-01
 9.03535664e-01 2.64136136e-01 4.61691767e-01 4.91317838e-01
 3.90258074e-01 4.45720017e-01 6.20079875e-01 6.62751615e-01
 5.83365619e-01 7.68293500e-01 3.47321689e-01 5.58335721e-01
 5.33713400e-01 4.34251875e-01 1.60945147e-01 4.81083274e-01
 8.02945137e-01 4.24470037e-01 5.66762805e-01 5.52448392e-01
 4.33146983e-01 3.28562796e-01 7.32406259e-01 3.12582731e-01
 6.07953906e-01 5.57916641e-01 4.27408904e-01 6.46669388e-01
 4.39372301e-01 2.99970061e-01 4.40109611e-01 6.14093840e-01
 1.98157609e-01 2.36894637e-01 3.30540121e-01 7.17029095e-01
 5.31327009e-01 6.26143456e-01 2.85539687e-01 3.91365826e-01
 4.36031908e-01 4.25894886e-01 5.36197484e-01 5.53980231e-01
 6.40670419e-01 4.77397352e-01 3.28332186e-01 5.46856344e-01
 4.65984732e-01 5.07976413e-01 4.52271312e-01 5.57956338e-01
 5.80867171e-01 7.36867666e-01 3.82813126e-01 6.29930139e-01
 4.92805958e-01 3.92856628e-01 4.66242611e-01 4.91340846e-01
 5.27644813e-01 7.85187423e-01 4.41880047e-01 4.33272481e-01
 4.76039022e-01 6.51324511e-01 4.03934836e-01 4.07231271e-01
 4.46416527e-01 4.21243966e-01 3.23747218e-01 4.94539529e-01
 2.99165815e-01 5.68689525e-01 4.01616991e-01 6.83224857e-01
 5.87459624e-01 5.21349609e-01 3.31567883e-01 4.28728521e-01
 4.34984714e-01 7.23618388e-01 3.79172713e-01 5.32293975e-01
 4.16723251e-01 5.74691713e-01 6.03613257e-01 4.05764520e-01
 3.19260687e-01 4.96657610e-01 3.46272409e-01 5.26297092e-01
 4.57971752e-01 4.36662138e-01 4.39606816e-01 6.69061244e-01
 3.56900871e-01 3.81199837e-01 5.52359223e-01 4.06736076e-01
 2.53105164e-01 5.82429171e-01 5.29717803e-01 4.81768459e-01
 5.24492323e-01 5.71030855e-01 4.48525369e-01 4.05575722e-01
 5.84465623e-01 4.35266703e-01 4.83226836e-01 4.69032735e-01
 4.76300985e-01 5.16479790e-01 4.47366238e-01 4.70395625e-01
 4.81869102e-01 5.80470562e-01 4.99649137e-01 4.72844034e-01
 5.46702564e-01 4.16602910e-01 4.25009906e-01 4.92764503e-01
 4.93899971e-01 4.72304761e-01 4.73078251e-01 5.11808455e-01
 5.05480409e-01 4.93326455e-01 5.06838799e-01 4.57979500e-01
 5.29303312e-01 4.99506027e-01 4.39746231e-01 4.68980253e-01
 5.28483272e-01 4.81005400e-01 5.31226277e-01 5.03349304e-01
 4.69994515e-01 4.93372738e-01 5.18192410e-01 5.07318258e-01
 5.30340433e-01 4.85951185e-01 4.97005671e-01 4.22845751e-01
 4.21849966e-01 5.41137338e-01 5.59478164e-01 4.63732839e-01
 4.97237027e-01 4.70501572e-01 4.85627353e-01 4.46046829e-01
 4.27408993e-01 5.49370408e-01 5.54149806e-01 4.57388997e-01
 4.51481193e-01 4.99788940e-01 5.16937196e-01 4.60994661e-01
 4.54706728e-01 4.96886939e-01 5.31957269e-01 5.34515262e-01
 5.63402116e-01 4.83411491e-01 4.86672670e-01 4.85453576e-01
 5.11527002e-01 5.59096515e-01 4.90171582e-01 4.67958093e-01
 4.20369506e-01 4.80633676e-01 4.35597062e-01 5.02992392e-01
 4.79526937e-01 4.80406106e-01 4.02484000e-01 4.77176219e-01
 4.52973962e-01 4.09443527e-01 4.26295161e-01 5.45894623e-01
 4.92234230e-01 4.78473127e-01 4.26760226e-01 4.56401438e-01
 3.80889118e-01 4.55589324e-01 5.10815442e-01 5.12733996e-01
 4.94848758e-01 4.84956712e-01 4.95660037e-01 4.55826938e-01
 4.47723836e-01 4.82276112e-01 4.86214250e-01 4.55356449e-01
 4.71670955e-01 5.19934595e-01 4.57012713e-01 4.48118150e-01
 4.28204834e-01 4.82840806e-01 4.41646993e-01 4.55926746e-01
 4.82991040e-01 5.31937242e-01 4.80624586e-01 4.46305782e-01
 4.85089719e-01 4.94780183e-01 4.58378822e-01 4.93371487e-01
 4.54333872e-01 4.92337167e-01 4.62812990e-01 4.60875601e-01
 5.11504650e-01 4.65332121e-01 4.80519354e-01 4.77559447e-01
 4.32629853e-01 4.70554650e-01 5.15214443e-01 5.56424856e-01
 5.10869384e-01 4.88824129e-01 4.93892550e-01 4.45699304e-01
 5.24329424e-01 3.77758920e-01 4.60273445e-01 5.15695453e-01
 4.70589876e-01 4.34908807e-01 4.66237187e-01 4.71071005e-01
 4.43208456e-01 4.76372868e-01 5.98339021e-01 4.45638299e-01
 4.79202121e-01 5.23130715e-01 4.92964566e-01 5.05339503e-01
 4.71356541e-01 5.33980548e-01 5.05692005e-01 4.27239537e-01
 4.59433168e-01 4.49460208e-01 4.81556833e-01 4.86359239e-01
 4.91410255e-01 4.53575402e-01 5.72211087e-01 4.68357772e-01
 4.93411392e-01 4.77269322e-01 4.69099373e-01 4.95860487e-01
 4.98229712e-01 4.56529588e-01 4.95697767e-01 5.13427496e-01
 4.95793819e-01 5.01394570e-01 5.09859622e-01 5.79684019e-01
 4.54123020e-01 4.51262772e-01 4.92262006e-01 5.06187499e-01
 4.71586078e-01 4.61192727e-01 4.61921096e-01 4.66094643e-01
 5.36392927e-01 2.09331512e-02 6.99187100e-01 9.76127982e-01
 2.29364634e-03 8.91160488e-01 9.99884248e-01 4.12583351e-04
 5.22464514e-04 7.02701807e-01 7.98159838e-03 3.33487988e-04
 1.41912699e-02 1.31055266e-01 3.09166849e-01 5.48980832e-01
 2.11126804e-02 6.67612255e-02 1.02215320e-01 3.63505125e-01
 4.85989898e-01 9.98130322e-01 2.63769925e-02 1.44118696e-01
 1.52227283e-02 1.03338569e-01 6.70989931e-01 7.60926545e-01
 3.58808219e-01 1.09141797e-01 7.80643940e-01 5.95865846e-01
 2.06344426e-01 5.95742226e-01 6.88346684e-01 5.93494952e-01
 1.24615431e-01 5.64777493e-01 1.49744660e-01 6.96078598e-01
 4.50575739e-01 2.08461106e-01 1.22857183e-01 2.34721273e-01
 4.58580554e-01 4.41925377e-01 4.53880489e-01 5.24646521e-01
 4.58321691e-01 4.66847628e-01 4.98827457e-01 5.11353850e-01
 3.96388769e-01 4.78837579e-01 5.00856280e-01 4.46867943e-01
 4.86175120e-01 4.64457244e-01 4.98946160e-01 5.00807822e-01
 4.56363350e-01 5.12534499e-01 5.03219485e-01 4.80832994e-01
 5.38353443e-01 4.18343902e-01 4.80614007e-01 5.22374511e-01
 5.14194906e-01 5.30420423e-01 5.53163469e-01 5.57035506e-01
 5.39440811e-01 5.27538776e-01 5.18993855e-01 5.05648017e-01
 5.32177866e-01 5.06292641e-01 4.58150536e-01 4.96617734e-01
 5.04648268e-01 5.19898057e-01 5.33602655e-01 4.81782436e-01
 4.55210239e-01 3.82528543e-01 4.80773687e-01 4.48038340e-01
 5.49261928e-01 6.66660309e-01 5.88580191e-01 4.33537096e-01
 4.03234959e-01 5.85174918e-01 5.23711085e-01 3.35827917e-01
 6.03609085e-01 4.51873004e-01 4.27637160e-01 3.80420804e-01
 3.70463014e-01 3.81441832e-01 3.40536356e-01 5.17441452e-01
 5.10109961e-01 6.05420232e-01 4.97319430e-01 6.64697528e-01
 3.48580807e-01 5.27428031e-01 6.77502275e-01 5.18481612e-01
 4.35331106e-01 6.26659989e-01 6.07696772e-01 1.96926713e-01
 5.57064176e-01 5.44419646e-01 5.39659500e-01 5.46310246e-01
 4.28758472e-01 5.89073777e-01 5.24433196e-01 4.78714466e-01
 6.39644802e-01 5.50355375e-01 4.69750494e-01 5.46500504e-01
 5.42529166e-01 5.61464608e-01 4.63760197e-01 5.16341269e-01
 5.20411670e-01 5.24917662e-01 4.60559070e-01 5.28042257e-01
 4.94098544e-01 4.48141158e-01 4.84164298e-01 4.89995450e-01
 4.84511763e-01 4.73132700e-01 4.55269963e-01 4.56532627e-01
 4.64222968e-01 4.94334936e-01 5.12084723e-01 4.86768007e-01
 5.14595807e-01 5.41695178e-01 4.61471111e-01 4.67406929e-01
 4.75519985e-01 4.57965523e-01 4.87904906e-01 4.76887405e-01
 5.08925378e-01 4.61323202e-01 4.56320345e-01 4.95643497e-01
 4.93838966e-01 4.91020679e-01 5.04814684e-01 4.29186463e-01
 4.84586895e-01 4.61464286e-01 4.97912496e-01 4.90936875e-01
 5.32254755e-01 4.66682106e-01 5.23556113e-01 5.32834172e-01
 4.60036039e-01 5.24133205e-01 4.51610088e-01 5.86689830e-01
 5.39471209e-01 5.35692751e-01 5.27869344e-01 5.08068085e-01
 4.48400766e-01 5.49426377e-01 5.20359218e-01 4.68739212e-01
 5.00997841e-01 5.02438545e-01 4.59487289e-01 4.81703043e-01
 3.88508677e-01 5.07005334e-01 5.77674627e-01 4.71354157e-01
 4.89944696e-01 4.85866100e-01 4.84608233e-01 4.89171118e-01
 4.80576843e-01 4.82298791e-01 4.76708293e-01 4.76657778e-01
 4.90632832e-01 4.83295888e-01 4.78618115e-01 4.89257544e-01
 4.86990422e-01 4.89020139e-01 4.97510999e-01 4.93055284e-01
 4.81048971e-01 4.87892509e-01 4.84677553e-01 4.79448020e-01
 4.94871587e-01 5.01765192e-01 8.46819043e-01 9.57149863e-01
 9.71741199e-01 6.82752430e-02 1.62266493e-02 4.54172760e-01
 9.75679696e-01 1.34101301e-01 4.98856187e-01 1.67519748e-02
 7.64835596e-01 6.99964762e-01 9.77901816e-01 4.60673571e-02
 6.79773450e-01 1.28660142e-01 1.47854120e-01 6.61151886e-01
 2.51672089e-01 8.85251403e-01 2.74013162e-01 6.89632237e-01
 9.82614875e-01 2.57692397e-01 3.18724990e-01 2.14291811e-02
 1.70291364e-02 9.68776345e-01 2.88520753e-01 7.86482751e-01
 4.09150839e-01 6.95440173e-01 5.63759327e-01 4.25380975e-01
 3.84729922e-01 4.61696506e-01 2.25121498e-01 4.77453440e-01
 6.58926964e-01 8.95882130e-01 2.40204453e-01 1.72113091e-01
 5.25613427e-01 8.97747517e-01 8.15393209e-01 5.35917342e-01
 9.20146048e-01 5.53159893e-01 6.44940257e-01 4.22913820e-01
 8.51694942e-01 2.19737500e-01 4.86845970e-01 4.84769970e-01
 4.75900263e-01 4.94997889e-01 4.88365233e-01 4.85502243e-01
 4.68813807e-01 4.78103906e-01 5.00211120e-01 4.88441646e-01
 4.88983124e-01 4.84769136e-01 4.86270338e-01 4.92707580e-01
 4.98267055e-01 4.81561184e-01 4.85880762e-01 4.93025333e-01
 4.96915281e-01 4.66985703e-01 4.90133524e-01 4.85900074e-01
 4.81426597e-01 4.94344473e-01 4.54534441e-01 4.70540166e-01
 5.45513749e-01 5.02111077e-01 4.31363463e-01 5.53995609e-01
 5.45205116e-01 4.71116155e-01 4.67093050e-01 5.07378459e-01
 4.70260471e-01 4.84806478e-01 5.89861751e-01 4.05000061e-01
 5.45407355e-01 5.00723481e-01 4.49374855e-01 6.03620172e-01
 4.65441227e-01 4.15732861e-01 5.69984436e-01 3.39394510e-01
 5.24606705e-01 5.99830329e-01 4.92869794e-01 4.66197401e-01
 5.19814074e-01 3.87526780e-01 4.86279845e-01 4.68695283e-01
 4.85276282e-01 4.78397220e-01 5.08181274e-01 4.52952623e-01
 4.49193537e-01 5.12422204e-01 4.86257195e-01 4.93809342e-01
 4.22996819e-01 3.92030954e-01 4.48983371e-01 4.90218788e-01
 4.72602069e-01 4.42545176e-01 4.56392109e-01 5.10402441e-01
 4.76573765e-01 4.61208135e-01 4.69668627e-01 4.71496820e-01
 4.37438339e-01 4.82019901e-01 4.56161290e-01 4.88866657e-01
 4.48722988e-01 4.70882803e-01 5.18136203e-01 4.73574519e-01
 5.25353253e-01 4.73334104e-01 5.14716506e-01 4.97241050e-01
 4.03362900e-01 5.10625482e-01 4.72086638e-01 4.42645609e-01
 4.93371725e-01 4.99431908e-01 4.74104047e-01 5.58254838e-01
 4.43889678e-01 4.17100757e-01 4.82713014e-01 3.93514752e-01
 5.40504515e-01 5.27209699e-01 4.53964680e-01 4.63026911e-01
 4.80822802e-01 4.33327138e-01 5.03747582e-01 4.92120266e-01
 4.43137974e-01 4.32626694e-01 4.77611244e-01 5.21476150e-01
 5.56457818e-01 4.65683848e-01 4.66287732e-01 5.18226206e-01
 5.70124805e-01 5.56293249e-01 5.21203339e-01 5.28243542e-01
 4.90147918e-01 5.10808766e-01 5.19055367e-01 4.76660073e-01
 5.26783884e-01 5.16445935e-01 5.19717276e-01 5.26996672e-01
 4.77830350e-01 4.96033102e-01 5.05635560e-01 5.11502087e-01
 5.06326377e-01 4.79931712e-01 5.26748657e-01 5.17295897e-01
 5.34355998e-01 5.58384955e-01 4.74726677e-01 5.17948925e-01
 5.26128054e-01 5.41269064e-01 5.33790708e-01 4.53835130e-01
 5.09637713e-01 4.75708038e-01 5.12634516e-01 5.21309972e-01
 5.20492435e-01 5.31196952e-01 5.10566354e-01 5.33868194e-01
 5.38283587e-01 5.16842008e-01 5.19581676e-01 5.31634450e-01
 5.40070832e-01 5.29613197e-01 5.12737989e-01 5.20111680e-01
 5.23393869e-01 5.27294874e-01 5.29380798e-01 5.34575164e-01
 5.11124492e-01 5.37625790e-01 5.23262322e-01 5.32217503e-01
 5.21086812e-01 5.38358748e-01 5.24843454e-01 5.29357195e-01
 5.19168854e-01 5.28392315e-01 5.31445801e-01 5.35708070e-01
 5.23195505e-01 5.26108265e-01 5.19757092e-01 5.19500077e-01
 5.13229370e-01], shape=(777,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.
 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0.
 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1.
 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1.
 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.
 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1.
 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1.
 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0.
 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.
 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0.
 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0.
 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(777,), dtype=float32)
predicted label rank:[1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 2 1 1 2
 2 2 1 2 1 2 1 1 2 2 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1 1 2 1 2 2 1 1 2 1 2 2
 1 2 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 2 2 1 1 2 1 2 1 2 2 2 1 2 1 1 1 1 2 2 1
 1 1 2 1 1 1 1 1 1 1 2 1 2 2 2 1 1 1 2 1 2 1 2 2 1 1 1 1 2 1 1 1 2 1 1 2 1
 1 2 2 1 2 2 1 1 2 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 1 2 2 1 2 1 2 1 1 1 2
 1 2 2 1 1 2 2 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 2 2 2 1 1 1 2 2
 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 2 2 1 1 1 2 1 1 2 1 1 1 1 1 1 2 1
 1 2 1 2 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 1 1 2
 1 2 2 1 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 2 2 1 1 2 2 1 2 2 2 1 2
 1 2 1 1 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 2 2 2 2 2
 2 2 2 1 1 2 2 2 1 1 1 1 1 2 2 2 1 1 2 2 1 2 1 1 1 1 1 1 2 2 2 1 2 1 2 2 2
 1 2 2 1 2 2 2 2 1 2 2 1 2 2 1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2
 2 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 2 1 2 2 1 2 1 2 2 2 2 2 1 2 2 1 2 2
 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 2 1 1
 1 2 2 2 1 2 1 1 2 1 2 1 2 2 1 1 1 1 2 1 2 1 2 2 1 1 1 1 1 2 2 1 1 2 2 2 2
 2 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2
 1 1 2 1 1 2 1 2 2 1 2 1 1 2 1 2 2 1 1 2 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1
 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 1 2 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2
 1 1 1 1 2 2 1 1 2 2 2 2 2 1 2 2 1 2 2 2 2 1 1 2 2 2 1 2 2 2 2 1 2 2 2 2 1
 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]
mse:tf.Tensor(0.2620652, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/bandec.smt2-0181_000.smt2
true label:[1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1]
true label rank:[2 2 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 2 1 2 2 2 1 1 1 1 1 2 2]
predicted label:tf.Tensor(
[0.50474745 0.5019003  0.50792336 0.49387908 0.49233198 0.4923078
 0.47903472 0.5001106  0.49774396 0.4915107  0.47840458 0.4953204
 0.4900708  0.5071805  0.50650597 0.4939964  0.4756103  0.49196497
 0.4766905  0.506887   0.5051716  0.48945743 0.47515118 0.4999786
 0.5014164  0.49504963 0.48340636 0.51262045 0.50056624 0.48347217], shape=(30,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0.
 1. 0. 0. 1. 1. 0.], shape=(30,), dtype=float32)
predicted label rank:[2 2 2 1 1 1 1 2 1 1 1 1 1 2 2 1 1 1 1 2 2 1 1 1 2 1 1 2 2 1]
mse:tf.Tensor(0.25220144, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/16.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.5193658  0.5044555  0.49736008 0.5004493  0.46647155 0.48688015
 0.49697304 0.50275695 0.48365957 0.49575323], shape=(10,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 0. 0. 0. 1. 0. 0.], shape=(10,), dtype=float32)
predicted label rank:[2 2 1 2 1 1 1 2 1 1]
mse:tf.Tensor(0.24561253, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/MOESI_1_e3_1884_e7_1875_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[7.43148923e-01 2.52683252e-01 1.31842852e-01 3.27971607e-01
 2.04871684e-01 9.88675952e-01 8.23398829e-02 9.20133054e-01
 9.10989693e-05 1.11956745e-01 1.86970830e-03 1.88979506e-03
 3.20152938e-02 3.48651409e-03 5.43981314e-01 8.04894507e-01
 9.93620455e-01 8.55885327e-01 4.05426621e-02 4.55942750e-02
 7.41998083e-05 1.83016062e-04 4.09141740e-06 9.82010841e-01
 9.83757079e-01 9.75233316e-01 8.99881124e-04 9.64095950e-01
 8.92239809e-03 8.12947750e-04 1.51401907e-01 5.53229272e-01
 2.47400999e-03 7.93788552e-01 4.60532308e-03 7.55071640e-04
 9.93703067e-01 9.70616341e-01 9.82571959e-01 1.30698681e-02
 9.30868983e-01 1.96822882e-02 9.99817491e-01 8.55721533e-02
 2.89905667e-02 9.42656517e-01 9.32966530e-01 7.19791174e-01
 4.82068837e-01 2.04801559e-04 3.33781719e-01 6.43847466e-01
 4.91633654e-01 4.65211570e-01 5.15996873e-01 5.10135531e-01
 4.87278104e-01 4.82092589e-01 4.91298139e-01 4.96619970e-01
 4.84529585e-01 4.77828622e-01 4.76659894e-01 5.02552688e-01
 4.78340238e-01 4.91091996e-01 4.95443076e-01 4.97137725e-01
 5.22484481e-01 4.96286958e-01 5.18470764e-01 4.88506287e-01
 4.85386491e-01 4.85849619e-01 4.85454023e-01 5.12967646e-01
 4.93036658e-01 4.68398899e-01 5.03007829e-01 4.75818455e-01
 4.79554981e-01 4.97095555e-01 4.92961764e-01 6.50466621e-01
 8.30968380e-01 6.70591354e-01 3.17317307e-01 3.91209126e-01
 3.63785595e-01 6.89658761e-01 5.11530221e-01 5.85698664e-01
 6.32131755e-01 4.54391271e-01 1.92796648e-01 6.57178223e-01
 1.70848608e-01 7.16522038e-01 3.64295214e-01 6.67373836e-01
 5.27971923e-01 8.75114560e-01 1.91891551e-01 6.96798921e-01
 6.23546124e-01 2.54540741e-01 4.94182914e-01 4.36908484e-01
 3.48993123e-01 9.47103024e-01 3.79113257e-01 1.41133487e-01
 5.81328869e-01 6.60390973e-01 3.30131620e-01 4.92322028e-01
 4.58875746e-01 4.76423085e-01 2.54849851e-01 4.33163106e-01
 4.78904396e-01 4.95808542e-01 4.90269601e-01 4.66261625e-01
 4.71347868e-01 4.52780128e-01 4.47148681e-01 4.45064068e-01
 4.57391828e-01 4.37465429e-01 4.74515051e-01 4.34605062e-01
 4.69102561e-01 4.50705439e-01 4.60977256e-01 4.65177000e-01
 4.43860888e-01 4.48367476e-01 4.70166594e-01 4.52571362e-01
 4.88591909e-01 4.89362985e-01 4.47647065e-01 4.47656900e-01
 4.74139214e-01 4.89106566e-01 4.63261873e-01 4.48043585e-01
 4.85541731e-01 4.58183289e-01 4.50343221e-01 4.71961617e-01
 4.84492958e-01 4.83340323e-01 4.83475149e-01 4.92704004e-01
 4.71553594e-01 4.88134325e-01 4.80038345e-01 4.66139078e-01
 4.75990444e-01 4.75813955e-01 4.94039208e-01 4.78608280e-01
 4.70417202e-01 4.78760868e-01 4.78776813e-01 4.77050453e-01
 4.99661714e-01 4.77995098e-01 4.72786158e-01 4.84368175e-01
 4.72843051e-01 4.94964629e-01 4.62162703e-01 5.05379677e-01
 5.03400803e-01 4.76017594e-01 4.88558769e-01 4.65055674e-01
 4.78535980e-01 4.81197834e-01 4.71563488e-01 4.84040380e-01
 5.42699754e-01 3.83392751e-01 5.26338518e-01 6.60793126e-01
 4.13623035e-01 4.29498971e-01 5.62967300e-01 6.02746725e-01
 6.56387925e-01 4.87707227e-01 5.37424088e-01 2.68971115e-01
 4.57347274e-01 6.27365053e-01 4.77736056e-01 4.33984697e-01
 4.80610192e-01 4.92635101e-01 4.82484877e-01 4.87866074e-01
 4.82460916e-01 4.86260563e-01 4.92474675e-01 4.90376651e-01
 4.72813487e-01 4.85368669e-01 4.94120061e-01 4.98252124e-01
 4.91996288e-01 4.65680182e-01 4.85825717e-01 4.92842019e-01
 4.89645749e-01 4.79922384e-01 4.98703510e-01 4.92757559e-01
 4.96003896e-01 4.85525250e-01 5.06762326e-01 5.01657426e-01
 4.97152984e-01 4.98983383e-01 4.80750978e-01 4.88555789e-01
 4.96441156e-01 4.89969343e-01 5.03077507e-01 4.90936488e-01
 4.92699444e-01 4.86620516e-01 4.71209437e-01 4.84440774e-01
 4.88555759e-01 4.83021051e-01 4.63404924e-01 4.78506595e-01
 4.83009338e-01 4.66351300e-01 4.82761323e-01 4.83692974e-01
 4.94517624e-01 4.95196164e-01 4.77624983e-01 4.75025058e-01
 4.84258235e-01 4.79080737e-01 4.88333762e-01 4.78755325e-01
 4.62700248e-01 5.20684898e-01 4.91207361e-01 4.81376886e-01
 4.48118955e-01 4.84040469e-01 4.62454617e-01 5.25965750e-01
 4.61639524e-01 5.32082558e-01 5.07296383e-01 4.71456409e-01
 4.93270338e-01 4.92699742e-01 4.86981601e-01 4.81738061e-01
 4.86910135e-01 4.92564619e-01 4.98955339e-01 4.91704881e-01
 4.91077125e-01 4.77311015e-01 4.91622120e-01 4.89551485e-01
 4.81990963e-01 4.89945441e-01 4.76606429e-01 4.88276273e-01
 4.80610490e-01 4.77213115e-01 4.80820954e-01 4.87019449e-01
 4.87387717e-01 4.85110432e-01 4.92866546e-01 5.01230359e-01
 5.01093984e-01 4.96555328e-01 5.00829041e-01 4.90741342e-01
 4.85591650e-01 4.94269103e-01 4.93713379e-01 5.10911763e-01
 4.98330206e-01 4.88802612e-01 4.95634645e-01 5.04495323e-01
 4.96424168e-01 4.99287993e-01 4.91839498e-01 4.94605750e-01
 4.95665133e-01 4.98761266e-01 5.58818996e-01 5.26912332e-01
 2.58491397e-01 2.87801623e-01 6.28780901e-01 4.00636226e-01
 4.90530908e-01 3.25370818e-01 5.58579087e-01 4.50500727e-01
 5.26550353e-01 4.05127048e-01 3.54560971e-01 5.62575459e-01
 4.64046150e-01 4.01932627e-01 4.07820523e-01 5.91764092e-01
 2.92362869e-01 4.36760902e-01 4.33744907e-01 4.64919686e-01
 4.02111292e-01 4.82128620e-01 4.77736622e-01 4.75306839e-01
 4.86990124e-01 4.79628921e-01 4.87476766e-01 4.73848134e-01
 4.81950879e-01 4.86607790e-01 4.75508392e-01 4.70965236e-01
 4.81409729e-01 4.94864345e-01 4.76743490e-01 4.59449738e-01
 4.80659395e-01 4.66511607e-01 4.89942104e-01 4.73122835e-01
 4.75082606e-01 4.68205035e-01 5.02164960e-01 4.76000011e-01
 4.75367278e-01 4.78864282e-01 4.72517043e-01 4.80027527e-01
 4.86523092e-01 4.92400885e-01 4.77837771e-01 4.65594530e-01
 4.85519648e-01 4.79389727e-01 4.78411734e-01 4.83427197e-01
 4.86181587e-01 4.84379321e-01 4.75511134e-01 4.64606762e-01
 4.71136391e-01 4.85570192e-01 4.80923444e-01 4.90181029e-01
 4.76275861e-01 4.77073908e-01 4.76549715e-01 4.76962537e-01
 4.89054203e-01 4.81935024e-01 4.67445165e-01 4.83725727e-01
 4.84400332e-01 4.80790764e-01 4.84935403e-01 4.71987218e-01
 4.94078040e-01 4.99566823e-01 4.74081099e-01 4.96444881e-01
 4.95818943e-01 4.97936845e-01 4.88045394e-01 5.06994009e-01
 4.98371243e-01 4.83095437e-01 4.93930906e-01 4.86655742e-01
 4.98414338e-01 5.03627181e-01 4.99902129e-01 4.78828043e-01
 4.95999724e-01 5.05666733e-01 4.89562005e-01 5.00929415e-01
 5.05083323e-01 4.98385310e-01 4.99656558e-01 4.98181969e-01
 4.94241238e-01 4.96952683e-01 4.93205041e-01 4.99542832e-01
 5.03637969e-01 4.85674769e-01 4.96099353e-01 4.96114492e-01
 5.05215585e-01 4.98226762e-01 4.95186687e-01 4.94798362e-01
 4.92414266e-01 4.97957200e-01 4.94064152e-01 5.04784524e-01
 4.89451885e-01 4.98495102e-01 4.92127687e-01 4.96395528e-01
 4.95965481e-01 4.96228874e-01 4.91921812e-01 5.00223875e-01
 4.90832359e-01 4.94659573e-01 4.81363654e-01 4.97345120e-01
 4.88185406e-01 5.16817033e-01 5.15753865e-01 5.32162130e-01
 4.36077356e-01 4.35955882e-01 5.31909943e-01 5.10541081e-01
 4.60279614e-01 4.73973930e-01 5.04605353e-01 5.08027315e-01
 4.73971575e-01 4.60263252e-01 5.14625728e-01 5.29842556e-01
 5.00769317e-01 5.15216768e-01 4.92322326e-01 4.99103725e-01
 5.08893251e-01 4.60178584e-01 4.72686350e-01 5.58748364e-01
 5.18286169e-01 5.22272646e-01 4.86894131e-01 5.00895977e-01
 4.49409485e-01 4.61136281e-01 5.19459009e-01 4.97555494e-01
 5.02744138e-01 4.34134066e-01 4.58222806e-01 4.82987970e-01
 4.58758980e-01 4.99077588e-01 4.92997766e-01 3.99857283e-01
 6.64030910e-01 4.00733173e-01 2.42845803e-01 4.82101887e-01
 4.42802876e-01 5.66945553e-01 6.40176296e-01 3.32868040e-01
 7.53870010e-01 4.16749358e-01 1.91915572e-01 6.42364264e-01
 7.32259512e-01 3.76871675e-01 5.19584060e-01 7.31157064e-01
 6.81711793e-01 3.66750211e-01 5.55197120e-01 2.01551169e-01
 6.05549455e-01 5.04427969e-01 3.30714613e-01 4.25627410e-01
 7.06625223e-01 2.16701031e-01 4.77773935e-01 5.77007949e-01
 2.73352206e-01 5.30029178e-01 2.13855326e-01 7.24800944e-01
 7.33157456e-01 4.33824629e-01 6.12496018e-01 5.13682842e-01
 4.48306262e-01 8.94444346e-01 2.90831983e-01 4.89258170e-01
 5.37374258e-01 5.30518651e-01 4.87901062e-01 5.29965103e-01
 5.07624030e-01 5.10437071e-01 5.33751667e-01 4.76344019e-01
 4.96184945e-01 5.23358107e-01 5.24283290e-01 5.22466183e-01
 4.88346875e-01 5.01989782e-01 5.17086685e-01 5.06176233e-01
 5.11886001e-01 5.16886830e-01 5.12851238e-01 5.25493562e-01
 5.19600749e-01 5.14748573e-01 5.21962523e-01 5.07464528e-01
 4.91778523e-01 5.62559128e-01 5.11284411e-01 5.22212327e-01
 4.89733249e-01 5.24912417e-01 5.27502835e-01 5.25182009e-01
 5.44341803e-01 5.07883787e-01 5.28980732e-01 5.19110620e-01
 4.93898302e-01 4.87377495e-01 5.07343948e-01 5.06617606e-01
 4.62199807e-01 4.94618058e-01 5.05621552e-01 4.41558808e-01
 5.10598123e-01 4.70721304e-01 4.73939717e-01 4.81120914e-01
 4.63951766e-01 4.87642944e-01 4.46040541e-01 5.00213563e-01
 4.96491671e-01 5.05347311e-01 5.19920886e-01 5.03623545e-01
 4.54106927e-01 5.09385824e-01 4.51080620e-01 4.48197454e-01
 4.96087283e-01 4.99568909e-01 4.81677264e-01 4.81773674e-01
 4.33236003e-01 4.87917960e-01 4.61419493e-01 4.93861169e-01
 4.72848505e-01 4.96391088e-01 4.92601037e-01 4.47215855e-01
 4.81730312e-01 5.01345992e-01 5.21750033e-01 6.54626727e-01
 9.11667109e-01 5.85373819e-01 6.05334163e-01 3.19537640e-01
 7.03485727e-01 1.47826016e-01 4.85310733e-01 1.68657035e-01
 4.66829568e-01 3.65555853e-01 6.12416804e-01 6.05441451e-01
 6.84586525e-01 4.45963949e-01 7.34379292e-01 6.44841850e-01
 4.11936492e-01 3.50437880e-01 4.51575160e-01 7.90468335e-01
 7.45699942e-01 3.56464922e-01 6.38121843e-01 6.71336949e-01
 6.54344618e-01 1.44910932e-01 6.03714466e-01 3.98957700e-01
 7.75543690e-01 3.06556135e-01 4.64741111e-01 7.35329568e-01
 7.76724577e-01 7.61107683e-01 3.91250968e-01 5.46897769e-01
 6.92083120e-01 2.44984150e-01 3.63584459e-01 7.18503356e-01
 2.84911573e-01 2.51349509e-01 6.94879413e-01 1.53926492e-01
 4.94443148e-01 3.82663816e-01 4.23940688e-01 8.80588889e-01
 1.43221289e-01 1.99370652e-01 7.92550564e-01 1.32072777e-01
 7.04797447e-01 9.06652629e-01 6.62540913e-01 5.61807871e-01
 6.33506060e-01 2.50798076e-01 4.55835819e-01 2.55499899e-01
 5.18621922e-01 6.57694876e-01 5.20556927e-01 3.61541152e-01
 2.19012231e-01 2.60602415e-01 2.73075163e-01 8.88509870e-01
 4.48536277e-01 2.60938436e-01 5.15008092e-01 4.01113898e-01], shape=(664,), dtype=float32)
rounded label:tf.Tensor(
[1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1.
 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.
 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1.
 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1.
 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.
 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0.
 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1.
 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1.
 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.
 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0.
 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1.
 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1.
 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.], shape=(664,), dtype=float32)
predicted label rank:[2 1 1 1 1 2 1 2 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2
 2 2 1 2 1 2 1 1 2 2 2 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 1 1 1
 1 2 1 1 2 1 1 1 1 2 2 2 1 1 1 2 2 2 2 1 1 2 1 2 1 2 2 2 1 2 2 1 1 1 1 2 1
 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2
 1 2 2 1 1 2 2 2 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1
 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 1 1 1 1 2
 1 1 1 2 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 2 1 2 2 1 1
 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 2 2 2 1 1 2 2
 1 1 2 2 1 1 2 2 2 2 1 1 2 1 1 2 2 2 1 2 1 1 2 1 2 1 1 1 1 1 1 1 2 1 1 1 1
 2 2 1 2 1 1 2 2 1 2 2 2 1 2 1 2 2 1 1 2 1 1 2 1 2 1 2 2 1 2 2 1 2 1 1 2 2
 1 2 2 2 2 1 1 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 1 1 2
 2 1 1 2 1 2 1 1 1 1 1 1 2 1 2 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2
 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 1 1 1 2 2 1 2 2 2 1 2 1 2 1 1 2 2 2 1 2 2
 1 1 2 1 1 2 1 1 1 1 2 1 1 2 1 2 2 2 2 2 1 1 1 2 2 2 1 1 1 1 2 1 1 2 1]
mse:tf.Tensor(0.258293, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/bandec.smt2-0033_000.smt2
true label:[1, 1, 1]
true label rank:[1 1 1]
predicted label:tf.Tensor([0.49284267 0.5077138  0.493376  ], shape=(3,), dtype=float32)
rounded label:tf.Tensor([0. 1. 0.], shape=(3,), dtype=float32)
predicted label rank:[1 2 1]
mse:tf.Tensor(0.25207403, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0140_000.smt2
true label:[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0]
true label rank:[1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 2 2 1 1 2 2 1 2 2
 1 1 2 2 1 1 2 2 1 1 2 2 1 1 2 2 1]
predicted label:tf.Tensor(
[0.52168095 0.48520714 0.4916765  0.4698428  0.43828484 0.5306736
 0.4118482  0.5036791  0.40398607 0.49489272 0.44687152 0.4845174
 0.48361963 0.4847722  0.47547033 0.45899105 0.54694456 0.5085039
 0.4490962  0.46128657 0.49575564 0.49597484 0.49066257 0.49430996
 0.5154899  0.50974905 0.50239944 0.4955585  0.4994717  0.4932194
 0.49979594 0.49090034 0.49447927 0.4910671  0.48198825 0.430327
 0.49717596 0.56364596 0.50279975 0.509578   0.50385606 0.49951756
 0.53615534 0.47510067 0.48084557 0.50532264 0.5319948  0.5068544
 0.5322113  0.46887472 0.52245057 0.49143955 0.48433474 0.50529605], shape=(54,), dtype=float32)
rounded label:tf.Tensor(
[1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1.
 1. 0. 1. 0. 0. 1.], shape=(54,), dtype=float32)
predicted label rank:[2 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1
 2 2 2 2 1 2 1 1 2 2 2 2 1 2 1 1 2]
mse:tf.Tensor(0.25492874, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0028_000.smt2
true label:[0, 0, 1, 0, 1]
true label rank:[1 1 2 1 2]
predicted label:tf.Tensor([0.507409   0.5084215  0.48574165 0.5204114  0.47369674], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 0.], shape=(5,), dtype=float32)
predicted label rank:[2 2 1 2 1]
mse:tf.Tensor(0.26564822, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/xy10.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.81835306 0.32485393 0.34714252 0.21547839 0.14383048 0.76848876
 0.17042738], shape=(7,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 0. 0. 1. 0.], shape=(7,), dtype=float32)
predicted label rank:[2 1 1 1 1 2 1]
mse:tf.Tensor(0.22606835, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/sum3_000.smt2
true label:[1, 0]
true label rank:[2 1]
predicted label:tf.Tensor([0.4935469 0.5107132], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 2]
mse:tf.Tensor(0.25866136, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/bandec.smt2-0188_000.smt2
true label:[1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1]
true label rank:[2 1 1 2 2 2 2 2 1 1 2 2]
predicted label:tf.Tensor(
[0.49701983 0.5105513  0.5086693  0.4883613  0.50501585 0.4949379
 0.49142414 0.5238028  0.49939463 0.48728186 0.5021425  0.501263  ], shape=(12,), dtype=float32)
rounded label:tf.Tensor([0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1.], shape=(12,), dtype=float32)
predicted label rank:[1 2 2 1 2 1 1 2 1 1 2 2]
mse:tf.Tensor(0.25025997, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/diamond_1-1.c-1_000.smt2
true label:[1, 1]
true label rank:[1 1]
predicted label:tf.Tensor([0.4854586 0.5028161], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 2]
mse:tf.Tensor(0.25597233, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0270_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[1.5246946e-01 1.0000000e+00 1.7081828e-09 1.0000000e+00 9.8689026e-01
 7.9723441e-07 1.0000000e+00 5.0911659e-01 5.0093776e-01 4.7242019e-01
 4.4200563e-01 4.6270475e-01 4.4781384e-01 4.5086190e-01 4.6495813e-01
 4.8635262e-01 4.8280135e-01 4.9667200e-01 4.9028724e-01 4.8298278e-01
 4.8462787e-01 4.7019342e-01 4.9164924e-01 4.6686095e-01 4.9878550e-01
 4.9496409e-01 4.7436982e-01 4.8160824e-01 4.8922881e-01 4.9140877e-01
 4.9829710e-01 5.0459754e-01 4.9801388e-01 4.9708807e-01 4.8007941e-01
 4.8935869e-01 4.6961400e-01 4.8577794e-01 4.6804744e-01 5.1006556e-01
 4.9426544e-01 5.0052333e-01 5.0237584e-01 4.8304430e-01 4.8933652e-01
 4.9277148e-01 5.1422560e-01 4.8714012e-01 5.0137258e-01 4.8857638e-01
 4.9410751e-01 4.9920115e-01 4.7723281e-01 4.8402706e-01 4.8362097e-01
 4.9543211e-01 4.7460046e-01 5.0574493e-01 4.6093252e-01 5.0272650e-01
 4.8536354e-01 5.0677013e-01 4.7924581e-01 5.0523961e-01 4.9798882e-01
 4.6429378e-01 5.1515454e-01 4.9880269e-01 4.8996478e-01 4.9180987e-01
 5.0137496e-01 4.9961317e-01 5.2448124e-01 4.8089713e-01 4.7982311e-01
 5.0882202e-01 4.9471262e-01 4.7918653e-01 4.8076367e-01 4.7386956e-01
 4.6681964e-01 4.9878502e-01 5.0167269e-01 4.9961138e-01 5.0793236e-01
 4.9819675e-01 4.7295472e-01 4.2611033e-01 4.0584928e-01 4.9610412e-01
 5.0348359e-01 5.5775851e-01 4.9276063e-01 4.6240929e-01 3.9533159e-01
 6.1189020e-01 4.8662066e-01 4.9350527e-01 4.8324960e-01 5.5058342e-01
 5.6799018e-01 6.3846570e-01 4.6807039e-01 6.1894739e-01 5.0846821e-01
 4.2074129e-01 5.3816229e-01 4.7387853e-01 5.4272127e-01 7.7731502e-01
 4.5855135e-01 4.2827395e-01 3.8129941e-01 5.8714992e-01 5.0423819e-01
 5.0697702e-01 4.9007827e-01 4.9875584e-01 3.5332817e-01 5.7221329e-01
 4.5575890e-01 5.2917278e-01 4.2825264e-01 5.9586990e-01 6.1296272e-01
 6.2354434e-01 4.2234075e-01 5.0298738e-01 3.8465255e-01 6.9036180e-01
 4.3120092e-01 4.2630988e-01 4.1525647e-01 4.4642782e-01 4.5083305e-01
 3.7862056e-01 4.8556113e-01 5.5086380e-01 3.4571224e-01 5.1438600e-01
 4.1887707e-01 4.2756474e-01 4.7344321e-01 6.5573281e-01 3.5434562e-01
 4.5421380e-01 6.0322702e-01 5.5311352e-01 3.5121328e-01 6.0947394e-01
 6.4102978e-01 5.0981379e-01 4.7037110e-01 5.4791558e-01 4.0407547e-01
 4.8827025e-01 5.0581402e-01 4.0097564e-01 4.2490938e-01 6.0020655e-01
 4.2480454e-01 4.4593632e-01 5.8917171e-01 4.7791153e-01 5.6576461e-01
 5.6168467e-01 4.2442295e-01 5.2202243e-01 4.8517394e-01 3.8063371e-01
 3.7687966e-01 4.2881650e-01 3.5173449e-01 5.1797062e-01 4.6460205e-01
 4.0705779e-01 4.5110369e-01 4.4765052e-01 5.2575624e-01 3.1635258e-01
 4.1373104e-01 5.1642203e-01 4.4970715e-01 4.5359540e-01 6.6200608e-01
 5.2261436e-01 5.6958878e-01 6.4535296e-01 4.7907948e-01 5.4794693e-01
 6.1963421e-01 5.7451355e-01 5.8656603e-01 4.0412617e-01 5.3037852e-01
 2.9331714e-01 4.1402191e-01 6.5825665e-01 5.4134446e-01 4.7636154e-01
 5.5688292e-01 3.1951088e-01 3.0193397e-01 3.2487720e-01 3.6432722e-01
 5.8208323e-01 6.5243030e-01 4.6026278e-01 3.5464853e-01 5.6400186e-01
 4.5115861e-01 3.6890244e-01 4.6176115e-01 4.3949208e-01 5.1672471e-01
 6.7422128e-01 6.6786557e-01 4.2050719e-01 6.1570668e-01 4.9765587e-01
 5.0961190e-01 6.2650442e-01 5.0251621e-01 4.6221286e-01 5.1204836e-01
 4.8502979e-01 3.1721312e-01 4.2551041e-01 5.5371362e-01 4.9590024e-01
 2.7550161e-01 4.3536830e-01 3.4727275e-01 3.4938949e-01 5.3721941e-01
 7.4864483e-01 5.9176773e-01 6.9493687e-01 2.7110288e-01 3.7041140e-01
 3.6202949e-01 3.8151869e-01 4.6821174e-01 5.5745661e-01 5.9383643e-01
 5.3549469e-01 5.6301641e-01 4.2439979e-01 4.5699298e-01 6.6298997e-01
 4.4765040e-01 3.5296476e-01 4.1820842e-01 5.8652735e-01 4.9990192e-01
 3.7584636e-01 3.3944684e-01 6.4535677e-01 3.7581578e-01 5.0862932e-01
 4.9857050e-01 6.0534561e-01 5.5953586e-01 5.1335841e-01 4.6704468e-01
 5.1548415e-01 5.6493074e-01 4.8904705e-01 5.1609838e-01 6.2036425e-01
 4.0441597e-01 5.6298047e-01 5.3833294e-01 5.0061828e-01 4.9513596e-01
 3.3079401e-01 3.7707171e-01 3.2661015e-01 4.5572317e-01 5.6101972e-01
 4.9440980e-01 4.2922786e-01 4.1358152e-01 3.5628980e-01 5.4547167e-01
 4.0789825e-01 6.7415613e-01 5.0216669e-01 5.0729305e-01 6.3710141e-01
 4.7188187e-01 4.0280962e-01 3.8109961e-01 6.2989616e-01 7.8187764e-01
 4.4730794e-01 6.1097312e-01 5.8140320e-01 5.3229302e-01 4.3686163e-01
 3.3563769e-01 6.5814298e-01 5.4961139e-01 2.4872831e-01 3.7213784e-01
 2.7857906e-01 5.0549972e-01 5.4169685e-01 4.0352318e-01 3.7069726e-01
 5.5018932e-01 3.6914128e-01 5.2419257e-01 3.7413424e-01 4.5041695e-01
 5.7768750e-01 5.6347609e-01 4.2997235e-01 4.2151040e-01 5.2293986e-01
 6.0158235e-01 4.5546305e-01 3.5586733e-01 5.7164323e-01 4.7479576e-01
 5.4406291e-01 4.0722811e-01 4.9058560e-01 4.9035388e-01 6.3430345e-01
 5.1867139e-01 4.5204929e-01 6.2649065e-01 4.0239978e-01 5.3867561e-01
 4.9294123e-01 3.6600813e-01 4.8100856e-01 7.0412707e-01 3.6614409e-01
 3.9233649e-01 4.5006812e-01 4.4056687e-01 3.0987644e-01 4.2282128e-01
 4.4933966e-01 3.7439865e-01 4.9962166e-01 4.3239683e-01 4.4870049e-01
 5.3937387e-01 5.8403563e-01 5.0974143e-01 5.5681109e-01 4.0168732e-01
 4.5323741e-01 4.7435164e-01 3.8363206e-01 5.4130954e-01 4.4216239e-01
 5.1684684e-01 3.6078948e-01 5.7573271e-01 4.4577202e-01 3.6666936e-01
 4.8320457e-01 5.5601573e-01 4.7441342e-01 3.4040785e-01 5.8355016e-01
 4.1097477e-01 4.8507032e-01 5.2175695e-01 4.3452567e-01 4.5380780e-01
 5.8305836e-01 5.7020444e-01 4.7917134e-01 4.2077574e-01 5.3253925e-01
 4.6046004e-01 4.4597641e-01 5.3953844e-01 6.9628096e-01 4.0801421e-01
 4.8635381e-01 6.3846350e-01 4.2976087e-01 5.0273800e-01 5.4579669e-01
 5.2093357e-01 5.5013853e-01 5.5406451e-01 5.2561241e-01 4.2463753e-01
 4.9904594e-01 5.6089318e-01 2.6189429e-01 5.1699233e-01 5.4410815e-01
 5.0025040e-01 5.9702575e-01 6.9078553e-01 5.8922380e-01 5.8651918e-01
 5.8206993e-01 5.5144495e-01 4.9107316e-01 7.0207453e-01 5.1073998e-01
 5.2952397e-01 6.0601795e-01 4.1752753e-01 3.7717730e-01 4.7275922e-01
 4.5522618e-01 4.3641666e-01 4.5708698e-01 4.8378521e-01 4.9033809e-01
 4.1876951e-01 4.9636829e-01 5.4873294e-01 4.6341842e-01 6.0715920e-01
 6.2378460e-01 4.3842804e-01 4.5071948e-01 6.2760377e-01 5.2983415e-01
 5.7037848e-01 3.8384232e-01 4.3758395e-01 4.6649262e-01 4.3701422e-01
 4.9425095e-01 5.1645702e-01 5.6301153e-01 5.7661015e-01 5.4068923e-01
 3.8871157e-01 5.1926798e-01 6.2019485e-01 5.6298977e-01 4.6025193e-01
 6.0182762e-01 4.9960801e-01 3.2233039e-01 4.9535650e-01 4.9510312e-01
 5.7291692e-01 5.0615340e-01 4.8846519e-01 4.9451265e-01 4.5550004e-01
 5.7343525e-01 5.9443992e-01 4.9690193e-01 4.7195977e-01 5.7564116e-01
 4.8817253e-01 6.5970302e-01 4.5081830e-01 5.6920594e-01 5.0579417e-01
 4.6669841e-01 5.0498509e-01 6.0182196e-01 5.2738792e-01 3.1133866e-01
 4.7193578e-01 5.4334581e-01 5.6911570e-01 5.9492242e-01 5.6679583e-01
 4.6023017e-01 5.7132238e-01 5.7752699e-01 4.2863065e-01 5.0301850e-01
 3.5578716e-01 4.9855548e-01 5.2301669e-01 4.4965023e-01 6.1448467e-01
 3.5912907e-01 2.8469861e-01 5.9236127e-01 5.4380035e-01 3.9809570e-01
 4.8878607e-01 7.0046276e-01 6.9161803e-01 5.2372861e-01 4.5245582e-01
 3.4195870e-01 4.6983367e-01 4.4768584e-01 4.0236959e-01 5.1839417e-01
 5.8643365e-01 3.5730940e-01 4.5756745e-01 4.9885711e-01 4.2050722e-01
 5.0996780e-01 4.3513691e-01 5.2796239e-01 5.2321601e-01 4.8026317e-01
 5.0307024e-01 4.8415306e-01 4.8704863e-01 5.2635533e-01], shape=(514,), dtype=float32)
rounded label:tf.Tensor(
[0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.
 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1.
 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.
 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1.
 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1.
 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0.
 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1.
 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1.
 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0.
 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0.
 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1.
 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.
 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0.
 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.
 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1.
 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.
 0. 1. 0. 1. 1. 0. 1. 0. 0. 1.], shape=(514,), dtype=float32)
predicted label rank:[1 2 1 2 2 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 2 1 2 2 1 1 1 2 1 2 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1 1 2 1 2 1
 1 2 1 1 1 1 1 1 2 1 2 1 1 1 1 1 2 2 1 1 1 2 1 1 1 2 2 2 1 2 2 1 2 1 2 2 1
 1 1 2 2 2 1 1 1 2 1 2 1 2 2 2 1 2 1 2 1 1 1 1 1 1 1 2 1 2 1 1 1 2 1 1 2 2
 1 2 2 2 1 2 1 1 2 1 1 2 1 1 2 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 2 1 1 2
 2 2 2 1 2 2 2 2 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2 1 1 1 1 2 2 2 1 2 1 2 2
 2 1 2 1 1 1 2 1 1 1 1 1 2 2 2 2 1 1 1 1 1 2 2 2 2 1 1 2 1 1 1 2 1 1 1 2 1
 2 1 2 2 2 1 2 2 1 2 2 1 2 2 2 1 1 1 1 1 2 1 1 1 1 2 1 2 2 2 2 1 1 1 2 2 1
 2 2 2 1 1 2 2 1 1 1 2 2 1 1 2 1 2 1 1 2 2 1 1 2 2 1 1 2 1 2 1 1 1 2 2 1 2
 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 2 1 2 1 2 1 1 1 2 1 1 2
 1 1 2 1 1 2 2 1 1 2 1 1 2 2 1 1 2 1 2 2 2 2 2 2 1 1 2 1 2 2 2 2 2 2 2 2 2
 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 2 2 2 1 1 1 1 1 2 2 2 2 1 2 2 2
 1 2 1 1 1 1 2 2 1 1 1 2 2 1 1 2 1 2 1 2 2 1 2 2 2 1 1 2 2 2 2 1 2 2 1 2 1
 1 2 1 2 1 1 2 2 1 1 2 2 2 1 1 1 1 1 2 2 1 1 1 1 2 1 2 2 1 2 1 1 2]
mse:tf.Tensor(0.25336033, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/SYNAPSE_5_e2_1525_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.4104601  0.48514375 0.37996587 0.79404193 0.18670467 0.9112921
 0.10274184 0.8448669  0.00926757 0.43585217 0.04216364 0.09154329
 0.24834356 0.02765074 0.24365395 0.12489644 0.9847177  0.57095665
 0.0879252  0.23316592 0.01692382 0.0252445  0.01719949 0.9179851
 0.95474327 0.92885494 0.01031637 0.747247   0.12523603 0.04059818
 0.1176641  0.5104996  0.48345518 0.5201563  0.5111954  0.4844256
 0.47634348 0.49683112 0.50143814 0.5061343  0.49589607 0.50291985
 0.5143781  0.5000775  0.52166957 0.50448245 0.49604315 0.52129954
 0.5318423  0.4762304  0.49352297 0.5082171  0.49574596 0.5217564
 0.48660365 0.5031294  0.5073124  0.5449467  0.5040921  0.47717163
 0.50339514 0.4870313  0.4878773  0.4930732  0.51236385 0.5028228
 0.49563748 0.5103427  0.49184218 0.49674177 0.49810442 0.49372256
 0.5057894  0.50026244 0.4896039  0.48777854 0.48822972 0.49524936
 0.48727626 0.4929748  0.47973981 0.4851923  0.48445433 0.5036102
 0.49662465 0.4854241  0.49215758 0.49696174 0.48927334 0.5128379
 0.50856555 0.4996808  0.49343517 0.50049603 0.4967721  0.5135724
 0.49200693 0.4947368  0.5045525  0.46326172 0.51582736 0.6296348
 0.43127602 0.6041153  0.46801004 0.44782174 0.5864622  0.53100944
 0.52170986 0.7397865  0.39413556 0.470681   0.5072214  0.5633243
 0.4982286  0.45325974 0.35411394 0.5935714  0.345733   0.6392787
 0.4406619  0.47746146 0.48776332 0.48900005 0.48966095 0.63476527
 0.33267868 0.42441165 0.42312753 0.62140495 0.49015108 0.51111776
 0.46520475 0.62124366 0.5097163  0.53901154 0.45455277 0.5942293
 0.2743147  0.67367476 0.47290018 0.56297493 0.5035448  0.80141217
 0.3087322  0.40671656 0.6175098  0.59360284 0.22919366 0.36970073
 0.65644985 0.5288696  0.44731352 0.48094502 0.34188414 0.455281
 0.48742476 0.36849505 0.32463259 0.3194111  0.49689677 0.48602983
 0.44927594 0.4771908  0.5203609  0.50900835 0.44937187 0.49092966
 0.45968652 0.4661382  0.39602733 0.4543029  0.43597457 0.49265718
 0.49025375 0.50112444 0.4139068  0.40829426 0.44375113 0.41478267
 0.4760937  0.4782514  0.44643453], shape=(183,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1.
 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.
 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1.
 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1.
 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.], shape=(183,), dtype=float32)
predicted label rank:[1 1 1 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 2 2 2 1 2 1 1 1 2 1 2 2 1 1
 1 2 2 1 2 2 2 2 2 1 2 2 1 1 2 1 2 1 2 2 2 2 1 2 1 1 1 2 2 1 2 1 1 1 1 2 2
 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 2 1 1 2 1 2 1 1 2 1 2 2 1 2 1 1 2 2 2 2 1
 1 2 2 1 1 1 2 1 2 1 1 1 1 1 2 1 1 1 2 1 2 1 2 2 2 1 2 1 2 1 2 2 2 1 1 2 2
 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1]
mse:tf.Tensor(0.24662103, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0031_000.smt2
true label:[1, 1, 1]
true label rank:[1 1 1]
predicted label:tf.Tensor([0.51608914 0.51087826 0.49972966], shape=(3,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0.], shape=(3,), dtype=float32)
predicted label rank:[2 2 1]
mse:tf.Tensor(0.24122673, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/loop__while_after_while_if_000.smt2
true label:[0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1]
true label rank:[1 1 1 2 1 1 2 1 2 2 1 2 1 2]
predicted label:tf.Tensor(
[0.49486783 0.50286645 0.48323873 0.5126035  0.46449366 0.5128971
 0.57926035 0.5300053  0.4207305  0.5054503  0.41771322 0.4561834
 0.50459    0.4423443 ], shape=(14,), dtype=float32)
rounded label:tf.Tensor([0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0.], shape=(14,), dtype=float32)
predicted label rank:[1 2 1 2 1 2 2 2 1 2 1 1 2 1]
mse:tf.Tensor(0.2515381, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/four1.smt2-0033_000.smt2
true label:[1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]
true label rank:[2 1 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2]
predicted label:tf.Tensor(
[0.5006619  0.5020979  0.4993537  0.49100354 0.5095011  0.48824826
 0.48900548 0.50146174 0.49359357 0.4992718  0.48823622 0.4974995
 0.4925763  0.5007838  0.49796897 0.48531303 0.4861417  0.48415267
 0.48220932 0.4760011 ], shape=(20,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float32)
predicted label rank:[2 2 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1]
mse:tf.Tensor(0.24961805, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/bandec.smt2-0148_000.smt2
true label:[0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1]
true label rank:[1 2 2 2 1 1 1 1 1 2 2 1 2 1 2 2 2 1 1 1 1 1 2]
predicted label:tf.Tensor(
[0.48893487 0.5109718  0.488202   0.48044208 0.50369537 0.4774571
 0.48451084 0.49014357 0.48851985 0.48420206 0.50285685 0.5061343
 0.501778   0.5465699  0.50232714 0.514014   0.49871394 0.4998543
 0.49665588 0.48658934 0.514603   0.51342976 0.4877207 ], shape=(23,), dtype=float32)
rounded label:tf.Tensor([0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0.], shape=(23,), dtype=float32)
predicted label rank:[1 2 1 1 2 1 1 1 1 1 2 2 2 2 2 2 1 1 1 1 2 2 1]
mse:tf.Tensor(0.25134915, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/04.c_000.smt2
true label:[0, 0]
true label rank:[1 1]
predicted label:tf.Tensor([0.50718373 0.50492054], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.25609004, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/minepump_spec1_product58_true-unreach-call.cil.c.flat_000.smt2
true label:[1, 1, 1]
true label rank:[1 1 1]
predicted label:tf.Tensor([0.90374476 1.         0.9563221 ], shape=(3,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)
predicted label rank:[1 1 1]
mse:tf.Tensor(0.0037242777, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/amebsa.smt2-0078_000.smt2
true label:[1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]
true label rank:[2 1 1 2 2 2 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2
 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 2 1 1 2]
predicted label:tf.Tensor(
[0.51035726 0.5017489  0.50421965 0.5121966  0.49305338 0.51726544
 0.50376564 0.506411   0.4965496  0.51956683 0.4791801  0.47507334
 0.4548522  0.508688   0.49564818 0.47430992 0.47283915 0.50344956
 0.46420264 0.4637735  0.4505366  0.45656732 0.47632357 0.49451405
 0.52286834 0.517643   0.46929517 0.45849487 0.484687   0.48775575
 0.47732413 0.48623374 0.4826169  0.5525956  0.46984372 0.44859517
 0.48528817 0.48852885 0.47509485 0.47279075 0.4706335  0.49786007
 0.5768898  0.47035617 0.51380813 0.51676244 0.54862803 0.5069252
 0.56635886 0.46764043 0.5215899  0.5173964  0.484656   0.573397
 0.54185236 0.580033   0.5019556  0.59114164 0.4848365  0.51361936
 0.5286779  0.49629092 0.45166397 0.5020105  0.5752006  0.49952865
 0.5234551  0.56793314 0.43829733 0.4536327  0.49020922 0.48478886
 0.49269104 0.47495145 0.49868485 0.49701232 0.48681372 0.4893773
 0.47945532 0.4764282  0.4933287  0.4810951  0.47158003 0.484889
 0.499876   0.50376856 0.47979972 0.46667805 0.49376622 0.493158
 0.4920948  0.4990933  0.46962705 0.48139852 0.48408872 0.46653435
 0.48412913 0.49033582 0.47443792 0.46322775 0.46419787 0.47977555
 0.4972511  0.481972   0.4853304  0.50433904 0.47070134 0.48401186
 0.48609346 0.4797444  0.45277405 0.49332836 0.46510965 0.45060155
 0.510911   0.4762571  0.48266554 0.4789092  0.48623776 0.4753374
 0.5066471  0.48170978 0.46065784 0.47740427 0.44769445 0.46942967
 0.47330528 0.4705631  0.4722128  0.47306648 0.47197342 0.47021544
 0.46736202 0.4859962  0.5457147  0.4692381  0.45082226 0.48613837
 0.43278426 0.5309608  0.44886145 0.4837784  0.5513819  0.5099837
 0.4360348  0.46669444 0.49120793 0.4780295  0.4663719  0.46896294
 0.50400865 0.45805916 0.4583797  0.5038386  0.5109974  0.4895043
 0.50467473 0.47893217 0.47819778], shape=(159,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1.
 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0.], shape=(159,), dtype=float32)
predicted label rank:[2 2 2 2 1 2 2 2 1 2 1 1 1 2 1 1 1 2 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1
 1 1 1 1 1 2 1 2 2 2 2 2 1 2 2 1 2 2 2 2 2 1 2 2 1 1 2 2 1 2 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 2 2 1 1 1 1
 1 1 2 1 1 2 2 1 2 1 1]
mse:tf.Tensor(0.24492815, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/MOESI_2_e3_1523_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1
 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[9.9989986e-01 9.9537516e-01 7.7064037e-03 9.5413065e-01 4.1969487e-01
 9.7482634e-01 1.9562244e-04 2.9326391e-01 1.9838875e-08 2.3707151e-03
 6.4169217e-07 5.0595673e-07 4.6320069e-06 8.1500149e-09 8.7943673e-04
 9.9329233e-01 1.0000000e+00 9.9546206e-01 7.9461932e-04 2.1320581e-04
 1.2473013e-10 4.5198114e-08 2.8617592e-13 9.8965108e-01 9.9980861e-01
 1.0000000e+00 2.7532927e-09 9.9922884e-01 5.0873012e-05 3.3303189e-07
 1.4792889e-02 1.6242805e-01 2.5540762e-06 9.9316669e-01 2.9805303e-04
 8.5551974e-09 9.9870420e-01 9.8508185e-01 9.9979591e-01 2.9864907e-04
 9.9943972e-01 8.6649656e-03 9.3538713e-01 5.5448771e-02 2.0775199e-04
 9.9769032e-01 9.3647110e-01 9.9996090e-01 9.5437098e-01 2.4049473e-06
 1.2624088e-01 1.4331937e-04 2.1652192e-01 6.4128327e-01 9.9999768e-01
 5.2386266e-01 5.0519472e-01 5.5288756e-01 4.4447076e-01 4.9887356e-01
 4.5917377e-01 4.7930241e-01 4.8834491e-01 4.8524421e-01 4.8613527e-01
 5.3448820e-01 5.4298306e-01 4.9081832e-01 4.4394407e-01 4.8020267e-01
 5.9852433e-01 5.0746149e-01 5.3712577e-01 4.6831778e-01 5.1216131e-01
 5.7623369e-01 5.5555826e-01 4.0183794e-01 4.6885970e-01 4.5966446e-01
 4.2453694e-01 4.2686278e-01 4.6484259e-01 4.9402830e-01 5.3479743e-01
 4.5832106e-01 4.7388697e-01 4.7949353e-01 4.8988378e-01 5.0312418e-01
 5.1789331e-01 5.0068951e-01 5.3848934e-01 5.0144494e-01 4.7373328e-01
 5.0301427e-01 5.1544887e-01 5.0028545e-01 4.8085776e-01 5.2009624e-01
 5.2486277e-01 5.0022882e-01 4.7948936e-01 5.1990634e-01 4.9755326e-01
 4.9250165e-01 5.1603955e-01 4.9377990e-01 5.3571075e-01 5.1625788e-01
 4.8828653e-01 4.7662279e-01 4.7886530e-01 4.8955762e-01 4.9879599e-01
 4.8820999e-01 4.7743759e-01 5.0357533e-01 5.0598812e-01 4.9691311e-01
 4.8641720e-01 4.9097529e-01 4.8774180e-01 5.1978153e-01 4.9728277e-01
 4.7724375e-01 4.8382634e-01 4.8637781e-01 4.8324600e-01 9.6930492e-01
 4.3392655e-01 5.5352426e-01 3.6833131e-01 6.6877520e-01 7.0715010e-01
 5.1309216e-01 3.7967652e-01 7.2178882e-01 2.5285965e-01 8.9519531e-01
 2.2070196e-01 4.7565061e-01 4.7852713e-01 4.8670641e-01 4.7697094e-01
 4.8558357e-01 4.8597130e-01 4.8765922e-01 4.8681629e-01 4.8977301e-01
 5.0030226e-01 4.8347521e-01 4.7958609e-01 5.0378686e-01 4.8368546e-01
 5.0507706e-01 4.9925092e-01 4.9755535e-01 4.9574348e-01 5.1317716e-01
 5.0637597e-01 5.0329524e-01 5.0376743e-01 5.1465613e-01 4.9919152e-01
 4.9515760e-01 4.8503914e-01 4.8579377e-01 4.8913240e-01 4.9816093e-01
 4.8655945e-01 4.9657530e-01 4.8343477e-01 4.9396673e-01 4.8941052e-01
 4.7924134e-01 4.7911131e-01 4.7021559e-01 4.9788231e-01 4.7142100e-01
 4.5936263e-01 5.1089263e-01 5.0798643e-01 4.8643285e-01 4.8853698e-01
 4.8354089e-01 5.0547040e-01 5.0491923e-01 4.6351397e-01 4.6685016e-01
 4.9588203e-01 4.8880595e-01 5.0020546e-01 4.4495234e-01 4.8211005e-01
 4.5387998e-01 4.6733385e-01 5.6058073e-01 5.1817113e-01 5.1097518e-01
 5.1235408e-01 4.8126829e-01 4.9171767e-01 4.5364687e-01 4.1619498e-01
 4.7075230e-01 5.2670270e-01 4.8024091e-01 4.7523421e-01 4.8062292e-01
 4.9369782e-01 4.6762964e-01 4.7918519e-01 4.7224784e-01 4.8850584e-01
 4.9151486e-01 4.8223379e-01 4.8374936e-01 5.0228602e-01 4.7731960e-01
 4.7825894e-01 4.5650637e-01 4.8660776e-01 4.7568363e-01 4.7686228e-01
 4.5315757e-01 4.7432649e-01 4.4440472e-01 5.1487952e-01 4.7282520e-01
 4.7680962e-01 4.8412579e-01 4.4781068e-01 4.7973382e-01 4.6798322e-01
 4.9803948e-01 4.5433670e-01 4.9762309e-01 4.4751248e-01 4.7945046e-01
 4.6635297e-01 4.6555361e-01 4.5814809e-01 4.8119339e-01 4.8971683e-01
 5.4590380e-01 5.0374550e-01 4.4174531e-01 4.6896556e-01 6.1796844e-01
 4.7148952e-01 4.4911513e-01 4.6443897e-01 4.9621373e-01 5.0226486e-01
 4.9185172e-01 4.6979308e-01 4.9477676e-01 4.9331042e-01 4.8462802e-01
 4.6099576e-01 5.6175214e-01 5.3354037e-01 5.1842177e-01 4.9047428e-01
 5.6126022e-01 4.7161964e-01 4.2784458e-01 5.1658756e-01 5.0770670e-01
 4.4705731e-01 4.6275449e-01 4.9731490e-01 4.8085669e-01 4.6131825e-01
 4.3696886e-01 4.6713063e-01 4.6856210e-01 4.7860897e-01 4.9342212e-01
 4.3181184e-01 4.6301475e-01 4.8451585e-01 4.8042533e-01 5.0338584e-01
 4.6044055e-01 5.4359710e-01 4.5993182e-01 5.2166086e-01 4.7168380e-01
 4.3105116e-01 4.3467167e-01 4.6853536e-01 4.9487767e-01 4.9265209e-01
 4.9028185e-01 5.0052661e-01 4.7805113e-01 4.9798954e-01 5.0659376e-01
 4.7611052e-01 5.2708834e-01 4.9960846e-01 4.8316392e-01 4.9181286e-01
 4.9208051e-01 4.8454559e-01 5.0431359e-01 4.9949065e-01 4.9655870e-01
 5.2197134e-01 4.7520530e-01 4.8986286e-01 4.7465253e-01 4.7739869e-01
 4.9911931e-01 4.8818642e-01 4.9792400e-01 4.9534720e-01 5.0918812e-01
 5.1286942e-01 5.0955290e-01 5.1606494e-01 5.0566393e-01 4.7812405e-01
 4.8981702e-01 4.9134955e-01 5.1335150e-01 5.2779037e-01 5.4116052e-01
 4.8050633e-01 5.2170813e-01 5.3139168e-01 5.0015539e-01 5.2082115e-01
 5.1059014e-01 4.9833411e-01 5.1271480e-01 5.1602435e-01 4.8571932e-01
 5.0984055e-01 5.0990653e-01 5.1266092e-01 4.6754038e-01 4.7853604e-01
 4.7699133e-01 5.3812021e-01 4.8161715e-01 4.7663614e-01 4.6315980e-01
 4.6360052e-01 4.6929574e-01 4.7517127e-01 4.7764030e-01 4.7219214e-01
 4.6625912e-01 4.8040605e-01 4.6174240e-01 4.6377170e-01 4.6671981e-01
 4.7699502e-01 4.7452548e-01 4.7219247e-01 4.4729978e-01 4.8355743e-01
 4.7861254e-01 4.6225077e-01 4.5870548e-01 4.8260424e-01 4.9266651e-01
 4.7753391e-01 4.8484805e-01 4.7993729e-01 4.5064956e-01 4.8225579e-01
 4.6679878e-01 4.7222471e-01 4.8707086e-01 4.9241790e-01 4.7752148e-01
 4.6510088e-01 4.7623658e-01 4.9794647e-01 4.9172258e-01 4.5867616e-01
 4.7895783e-01 4.9609584e-01 4.7239351e-01 4.9642062e-01 4.8210540e-01
 4.9989003e-01 4.6746713e-01 4.5543116e-01 4.6692830e-01 4.6622926e-01
 4.7713056e-01 4.8075297e-01 4.6591684e-01 4.8361632e-01 4.7833231e-01
 4.9006787e-01 4.9027467e-01 5.0594044e-01 5.0213528e-01 4.8908609e-01
 5.0720608e-01 4.8542482e-01 4.5614159e-01 5.3637987e-01 5.0809932e-01
 4.7564569e-01 5.1775563e-01 5.0932235e-01 4.7995445e-01 5.0794446e-01
 4.5004264e-01 5.3167003e-01 4.8059785e-01 4.8072109e-01 4.9513125e-01
 5.1344585e-01 4.9577019e-01 5.0090450e-01 4.8159590e-01 5.1588577e-01
 5.5758280e-01 5.2130497e-01 4.8573384e-01 5.0833714e-01 5.1558596e-01
 5.0857681e-01 4.9988464e-01 4.8460081e-01 4.9062434e-01 4.8709953e-01
 5.0063944e-01 5.3543210e-01 5.1266265e-01 5.0311387e-01 5.0824517e-01
 4.6687111e-01 6.9842917e-01 9.3339401e-01 6.1410213e-01 1.6168275e-01
 7.0935845e-01 7.3997676e-01 1.8105417e-01 4.8015815e-01 8.1390125e-01
 8.8260275e-01 5.6450671e-01 3.2580644e-01 6.6860855e-01 1.3771448e-01
 5.3900516e-01 9.5006621e-01 3.9817512e-01 1.5050232e-01 6.3073981e-01
 8.0033267e-01 9.7071588e-01 1.2800765e-01 6.0293835e-01 4.5949537e-01
 7.5772142e-01 8.7068498e-01 8.9796954e-01 5.7495910e-01 3.1130522e-02
 5.0630414e-01 6.4721793e-02 3.2442564e-01 8.2559574e-01 4.9490422e-01
 2.9369581e-01 7.7442956e-01 7.8170466e-01 2.9744267e-01 5.1189190e-01
 5.4344296e-02 1.5536156e-01 7.2780800e-01 4.6218148e-01 5.3669757e-01
 4.9959657e-01 4.4018769e-01 5.2235138e-01 5.0884926e-01 4.4192553e-01
 4.4205153e-01 5.5650735e-01 5.1507878e-01 4.5320091e-01 4.6744210e-01
 4.7474626e-01 4.8199445e-01 4.8752758e-01 4.7019979e-01 5.1264840e-01
 5.6545693e-01 4.0105289e-01 4.9493462e-01 5.0133765e-01 4.2752951e-01
 5.1883394e-01 4.4340077e-01 5.6740427e-01 4.1484320e-01 5.2696669e-01
 5.2479976e-01 4.8069090e-01 4.6869129e-01 5.2157700e-01 4.6001589e-01
 4.5703828e-01 5.0637209e-01 4.7237423e-01 4.9046496e-01 5.0176394e-01
 4.8961827e-01 5.0994045e-01 5.0827765e-01 5.0628275e-01 5.0951427e-01
 5.1869023e-01 5.1223075e-01 5.2951443e-01 4.9829152e-01 5.0714976e-01
 5.0008899e-01 5.1953107e-01 4.8857683e-01 5.2095526e-01 5.2226388e-01
 5.2140790e-01 5.1212198e-01 4.9672237e-01 5.0311971e-01 4.9996302e-01
 5.1654327e-01 5.3056937e-01 4.9075606e-01 5.2669609e-01 4.8614293e-01
 5.2448016e-01 5.4403931e-01 5.1313859e-01 5.1952344e-01 5.1382703e-01
 5.2837068e-01 5.0247335e-01 5.2871615e-01 4.9891472e-01 5.1199132e-01
 5.1359600e-01 5.1070297e-01 5.2475506e-01 5.1723784e-01 4.8883235e-01
 5.2866405e-01 5.2701378e-01 5.2602535e-01 4.8863208e-01 5.2528697e-01
 5.4110074e-01 5.0665420e-01 5.1002491e-01 5.2404499e-01 5.2297062e-01
 5.1610982e-01 4.9543446e-01 5.2120787e-01 5.1811433e-01 5.2950311e-01
 5.1429963e-01 5.2048969e-01 5.3219551e-01 5.2165282e-01 5.0651723e-01
 5.2673233e-01 4.8249179e-01 5.0485182e-01 4.9926013e-01 4.8165864e-01
 5.2449208e-01 4.9291968e-01 4.9325901e-01 5.0598222e-01 5.2383369e-01
 5.3497934e-01 5.2617520e-01 5.3143752e-01 4.8648256e-01 4.7755471e-01
 4.6233264e-01 5.2639204e-01 4.7826082e-01 4.9124148e-01 5.0341213e-01
 5.0662982e-01 4.9323469e-01 5.0078070e-01 4.6347827e-01 5.2964121e-01
 4.9899843e-01 4.9816674e-01 4.7929427e-01 5.0458407e-01 5.0667179e-01
 5.0096703e-01 4.7291419e-01 5.0664884e-01 4.7563428e-01 5.0982410e-01
 5.3055906e-01 4.7946373e-01 4.7484204e-01 5.1101476e-01 5.0936615e-01
 4.9539414e-01 5.0107610e-01 4.8067942e-01 4.8936713e-01 4.8966992e-01
 4.8424119e-01 4.6441188e-01 5.1757312e-01 4.8970026e-01 4.4653925e-01
 4.9957001e-01 5.2557331e-01 4.7919789e-01 5.1765746e-01 5.2101761e-01
 4.4342953e-01 5.0193548e-01 5.2558714e-01 5.1166326e-01 5.2188909e-01
 4.7537383e-01 4.7610611e-01 5.1743644e-01 4.4870594e-01 5.0249189e-01
 4.9733153e-01 5.3049469e-01 4.9614745e-01 4.9947497e-01 5.2337646e-01
 4.8256424e-01 5.0627255e-01 4.8865190e-01 4.9319577e-01 5.3702098e-01
 5.0039291e-01 5.1647031e-01 5.1626897e-01 4.9469936e-01 5.3249407e-01
 5.0383228e-01 5.0788176e-01 4.9174494e-01 4.9897087e-01 5.0940114e-01
 5.0277805e-01 4.7583446e-01 5.0926602e-01 5.0576180e-01 4.7208238e-01
 5.2055299e-01 5.0393844e-01 4.5284429e-01 4.9917966e-01 4.9919438e-01], shape=(675,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.
 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.
 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1.
 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1.
 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.
 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1.
 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0.
 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0.
 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1.
 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1.
 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.
 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.
 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1.
 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0.
 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1.
 0. 0. 0.], shape=(675,), dtype=float32)
predicted label rank:[2 2 1 2 1 2 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 2 2 2 1 2 1 1 1 1 1 2 1 1 2
 2 2 1 2 1 2 1 1 2 2 2 2 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 2 2 1 1 1 2 2 2 1
 2 2 2 1 1 1 1 1 1 1 2 1 1 1 1 2 2 2 2 2 1 2 2 2 1 2 2 2 1 2 1 1 2 1 2 2 1
 1 1 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 1 2 1 2 1 2 2 2 1 2 1 2 1 1 1 1 1 1 1 1
 1 1 2 1 1 2 1 2 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1
 1 2 2 1 1 1 1 2 1 1 1 1 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 1 2 1 1 1 1
 1 1 2 2 2 1 2 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1
 2 1 1 2 1 2 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 2 2 2 1 2 2
 2 2 2 1 2 2 1 2 2 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 1
 1 2 2 1 2 2 1 2 1 2 1 1 1 2 1 2 1 2 2 2 1 2 2 2 1 1 1 1 2 2 2 2 2 1 2 2 2
 1 2 2 1 1 2 2 2 1 2 1 2 2 1 1 2 2 2 1 2 1 2 2 2 2 1 2 1 1 2 1 1 2 2 1 2 1
 1 2 1 2 1 1 2 2 1 1 2 2 1 1 1 1 1 1 2 2 1 1 2 1 2 1 2 1 2 2 1 1 2 1 1 2 1
 1 2 1 2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2 1 2 1 2 2 1 2 1 2 2 2 2 2 2 2 2 1 2
 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 1 2 1 1 2 1 1 2 2 2 2
 2 1 1 1 2 1 1 2 2 1 2 1 2 1 1 1 2 2 2 1 2 1 2 2 1 1 2 2 1 2 1 1 1 1 1 2 1
 1 1 2 1 2 2 1 2 2 2 2 1 1 2 1 2 1 2 1 1 2 1 2 1 1 2 2 2 2 1 2 2 2 1 1 2 2
 1 2 2 1 2 2 1 1 1]
mse:tf.Tensor(0.26683116, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/SYNAPSE_123_e8_953_e7_1465_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[9.42069232e-01 9.81354296e-01 1.03604615e-01 7.55797982e-01
 1.08271509e-01 5.42896032e-01 7.89514184e-03 5.97106636e-01
 8.30464387e-07 1.39589190e-01 1.94728374e-04 4.92897630e-03
 3.38588357e-02 2.29388475e-04 2.14910358e-01 2.78722644e-02
 9.99925256e-01 5.63951671e-01 6.83591962e-02 9.45872068e-03
 1.79169929e-05 2.10558628e-05 2.29790130e-05 1.65138543e-02
 8.07490706e-01 9.83442247e-01 1.01134086e-04 8.90519619e-01
 7.96854496e-04 6.22272491e-04 2.04061091e-01 7.30096519e-01
 2.07004214e-05 9.37408447e-01 2.86299288e-02 4.38784093e-01
 4.81695294e-01 5.49185932e-01 5.51256955e-01 5.41045427e-01
 5.41647673e-01 4.64819461e-01 5.16644955e-01 4.57179874e-01
 5.09557247e-01 4.93315160e-01 5.66994429e-01 4.73872691e-01
 5.67722738e-01 4.64122295e-01 4.99763221e-01 5.07903576e-01
 5.12796521e-01 4.78929162e-01 5.25704741e-01 5.54088771e-01
 5.11932135e-01 5.23437977e-01 4.04245496e-01 4.97997463e-01
 5.31078935e-01 4.76996183e-01 4.47887719e-01 5.05348861e-01
 5.74052036e-01 4.93601799e-01 5.40471613e-01 5.02010167e-01
 4.60700959e-01 4.80330020e-01 4.88992304e-01 4.76939499e-01
 5.02157271e-01 4.84307140e-01 4.99909312e-01 5.06864130e-01
 4.94047493e-01 4.88372833e-01 4.87782985e-01 5.01787007e-01
 4.71917272e-01 4.81090575e-01 5.04307568e-01 4.92602050e-01
 5.02763033e-01 4.94978130e-01 4.83423680e-01 5.15865266e-01
 4.95258242e-01 5.10930002e-01 5.08173943e-01 5.13908207e-01
 4.93421644e-01 4.84353006e-01 4.80490506e-01 5.19326031e-01
 4.93923128e-01 5.41949749e-01 4.68798935e-01 5.26623666e-01
 4.81405288e-01 5.30348837e-01 4.48788702e-01 4.69099402e-01
 4.83947664e-01 4.38770443e-01 3.96015912e-01 4.23103213e-01
 4.80829477e-01 5.45852244e-01 4.57295030e-01 4.12481159e-01
 4.75128710e-01 4.80008215e-01 4.98005331e-01 4.60907787e-01
 4.90283042e-01 4.90322560e-01 4.67961162e-01 4.93098676e-01
 4.25427347e-01 4.34638023e-01 4.79165465e-01 4.87093538e-01
 4.42920595e-01 4.87685680e-01 4.60583210e-01 4.70432997e-01
 4.70972776e-01 4.80914772e-01 4.81288105e-01 4.78639930e-01
 4.44259584e-01 4.67626572e-01 4.69459295e-01 4.43057120e-01
 4.49177831e-01 5.77125549e-01 3.52030098e-01 5.61015546e-01
 4.11524594e-01 5.42724013e-01 5.18176377e-01 6.79006159e-01
 3.37255448e-01 4.57074463e-01 7.57003427e-01 5.56964159e-01
 3.19049418e-01 5.16231775e-01 6.02147102e-01 4.24500555e-01
 3.26004177e-01 4.03224140e-01 4.23398703e-01 6.07524455e-01
 5.70778430e-01 3.45905900e-01 3.87354255e-01 3.66763622e-01
 4.53945547e-01 5.89617014e-01 5.25969982e-01 5.64666629e-01
 7.34519780e-01 6.01036966e-01 5.14306962e-01 4.00144219e-01
 5.88804662e-01 2.99052775e-01 2.19702214e-01 3.06642950e-01
 4.52403247e-01 4.03090924e-01 4.51749474e-01 5.63426793e-01
 4.59291101e-01 4.81785625e-01 5.52791953e-01 2.80418932e-01
 4.68513191e-01 5.69401443e-01 4.85468864e-01 4.03116643e-01
 6.53238416e-01 5.54077327e-01 4.79128927e-01 5.68948925e-01
 3.95529479e-01 6.18740916e-01 6.16192937e-01 5.30463815e-01
 5.64560294e-01 4.58268553e-01 4.15301204e-01 2.81474650e-01
 3.86434138e-01 7.03736007e-01 5.94044149e-01 5.61666071e-01
 5.26793420e-01 3.24243188e-01 3.43293369e-01 4.52400953e-01
 3.13218445e-01 5.54723859e-01 6.69735014e-01 5.87408543e-01
 3.12341928e-01 4.72980261e-01 3.92015994e-01 3.61122906e-01
 4.96401310e-01 5.30005038e-01 6.31394029e-01 5.81478894e-01
 6.78972363e-01 4.13649142e-01 4.98690784e-01 5.74254811e-01
 4.06565607e-01 5.60364366e-01 5.17414510e-01 3.47033262e-01
 5.76938033e-01 4.61134344e-01 1.99497849e-01 4.68761086e-01
 4.96881604e-01 4.84424919e-01 5.06016433e-01 4.82983142e-01
 4.88165081e-01 4.75994736e-01 4.98533934e-01 5.11941910e-01
 5.02878070e-01 5.24225891e-01 4.77003366e-01 5.09472668e-01
 4.87581104e-01 4.90015775e-01 5.05024195e-01 4.83028829e-01
 5.27057409e-01 4.97786701e-01 4.81267750e-01 5.09199977e-01
 4.97705013e-01 5.08063674e-01 4.76518095e-01 5.13319790e-01
 4.86781299e-01 5.09082377e-01 4.87299919e-01 4.73407328e-01
 4.58245724e-01 4.73072857e-01 4.94460911e-01 4.93673295e-01
 4.89628732e-01 4.68580246e-01 4.86264944e-01 4.70880777e-01
 4.66647565e-01 4.73044962e-01 4.90257353e-01 4.74261314e-01
 4.58623737e-01 4.83348131e-01 4.95890439e-01 4.86865163e-01
 5.06793678e-01 4.96022940e-01 4.82583970e-01 4.92899925e-01
 4.88745540e-01 4.95265901e-01 4.84583765e-01 4.75848377e-01
 4.74705309e-01], shape=(281,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0.
 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1.
 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1.
 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0.
 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1.
 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1.
 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1.
 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(281,), dtype=float32)
predicted label rank:[2 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 2 2 1 2 1 1 1 2 1 2 1 1 1
 2 2 2 2 1 2 1 2 1 2 1 2 1 1 2 2 1 2 2 2 2 1 1 2 1 1 2 2 1 2 2 1 1 1 1 2 1
 1 2 1 1 1 2 1 1 2 1 2 1 1 2 1 2 2 2 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 2 2 1 1 2 2
 1 2 2 1 1 1 1 2 2 1 1 1 1 2 2 2 2 2 2 1 2 1 1 1 1 1 1 2 1 1 2 1 1 2 1 1 2
 2 1 2 1 2 2 2 2 1 1 1 1 2 2 2 2 1 1 1 1 2 2 2 1 1 1 1 1 2 2 2 2 1 1 2 1 2
 2 1 2 1 1 1 1 1 2 1 1 1 1 2 2 2 1 2 1 1 2 1 2 1 1 2 1 2 1 2 1 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.24359779, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/SYNAPSE_2_e8_1118_e7_1043_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.46753973 0.3682659  0.4462386  0.44183186 0.49925753 0.5325798
 0.4058972  0.579859   0.13727286 0.3338823  0.26074085 0.27161217
 0.3970092  0.1598078  0.33192143 0.7130412  0.6362113  0.4706539
 0.25029168 0.44014066 0.46746317 0.3696891  0.14594778 0.6139556
 0.78518206 0.69785947 0.18739852 0.70971024 0.31460834 0.19175649
 0.37642747 0.48983628 0.495319   0.51212835 0.49582657 0.47204474
 0.49464953 0.48400286 0.46349916 0.5050433  0.4997946  0.5020516
 0.49452734 0.51096684 0.51995957 0.54012257 0.5417377  0.48596036
 0.5290498  0.49054083 0.52615845 0.51921993 0.47760844 0.53124046
 0.47573906 0.5496289  0.5013217  0.51607746 0.50283295 0.513858
 0.51942515 0.49626654 0.49059227 0.49808836 0.49689114 0.4988202
 0.5081917  0.48481655 0.49090877 0.4818684  0.50685316 0.51270944
 0.52475804 0.4893383  0.48406982 0.489466   0.48680043 0.4922698
 0.491395   0.4967042  0.48248732 0.49816608 0.4933341  0.5044828
 0.49066144 0.48867977 0.47622594 0.5008809  0.483181   0.5060213
 0.4976121  0.49823678 0.63971555 0.3651089  0.26554626 0.371206
 0.3294537  0.6781502  0.39629006 0.47591624 0.5156208  0.67702264
 0.42819998 0.56929564 0.6110633  0.43905404 0.3904912  0.38427523
 0.4098161  0.6393469  0.47657394 0.47823066 0.42749798 0.5521207
 0.4910707  0.5063666  0.42484197 0.5216563  0.42386085 0.5356233
 0.49501866 0.55535054 0.42090398 0.6429082  0.49122956 0.70195144
 0.2686222  0.462515   0.38331634 0.80882776 0.5274538  0.60986644
 0.40428174 0.56565773 0.6334827  0.5217073  0.39837736 0.57336324
 0.46762466 0.49062455 0.44532856 0.5144674  0.529391   0.5058837
 0.42237753 0.45431125 0.52497125 0.4580933  0.43532532 0.4809351
 0.4969794  0.3789729  0.48538524 0.46672717 0.43406427 0.50929886
 0.4713487  0.4414905  0.45997012 0.45161018], shape=(160,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1.
 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0.
 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.
 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.], shape=(160,), dtype=float32)
predicted label rank:[1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1
 1 1 2 1 2 1 2 2 2 2 1 2 1 2 2 1 2 1 2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 2 2 2 1
 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 1 2 2 1 2 2 1 1 1 1 2 1
 1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 2 2 2 1 2 2 2 1 2 1 1 1 2 2 2 1 1 2 1
 1 1 1 1 1 1 1 2 1 1 1 1]
mse:tf.Tensor(0.24115284, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/02.c_000.smt2
true label:[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1]
true label rank:[1 1 2 2 2 2 1 1 2 2 2 2 1 1 2 2 2 2]
predicted label:tf.Tensor(
[0.4903003  0.50283295 0.47377154 0.46805194 0.43463442 0.50958127
 0.48578218 0.4827338  0.41963014 0.48416358 0.46251056 0.4766169
 0.51147264 0.5051494  0.50553733 0.5104852  0.5109938  0.50897384], shape=(18,), dtype=float32)
rounded label:tf.Tensor([0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.], shape=(18,), dtype=float32)
predicted label rank:[1 2 1 1 1 2 1 1 1 1 1 1 2 2 2 2 2 2]
mse:tf.Tensor(0.26273102, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/minepump_spec5_product59_true-unreach-call.cil.c.flat_000.smt2
true label:[1, 1, 1, 1]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([1.0000000e+00 1.0000000e+00 1.9723177e-04 1.0000000e+00], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1.], shape=(4,), dtype=float32)
predicted label rank:[2 2 1 2]
mse:tf.Tensor(0.2499014, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/spline-fixed.smt2-0001_000.smt2
true label:[1, 1]
true label rank:[1 1]
predicted label:tf.Tensor([0.50341815 0.49210125], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 0.], shape=(2,), dtype=float32)
predicted label rank:[2 1]
mse:tf.Tensor(0.2522773, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/minepump_spec5_product55_true-unreach-call.cil.c.flat_000.smt2
true label:[1, 1, 1, 1]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([1.000000e+00 1.000000e+00 9.383612e-06 1.000000e+00], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1.], shape=(4,), dtype=float32)
predicted label rank:[2 2 1 2]
mse:tf.Tensor(0.24999532, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/svd-some-loop.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[9.8695993e-01 1.0000000e+00 9.9643016e-01 9.9887288e-01 9.8424137e-01
 2.5406709e-06 3.7449067e-07 1.0000000e+00 1.2157190e-37 6.6968209e-10
 1.0164715e-17 3.9153812e-25], shape=(12,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0.], shape=(12,), dtype=float32)
predicted label rank:[2 2 2 2 2 1 1 2 1 1 1 1]
mse:tf.Tensor(0.49445343, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/nested-while_merged_safe.c-1_000.smt2
true label:[1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 2 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.51988786 0.5033628  0.48907286 0.51620513 0.48496923 0.4913332
 0.4908009  0.504016   0.47306257 0.49830517 0.47109887 0.46830225
 0.5121654  0.49223155 0.52185047 0.52245617 0.56117344 0.48542213
 0.42729047 0.47226715 0.47261387 0.47895023 0.44269338 0.4789491
 0.5237037 ], shape=(25,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 1.], shape=(25,), dtype=float32)
predicted label rank:[2 2 1 2 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 1 1 1 1 2]
mse:tf.Tensor(0.24335466, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/bandec.smt2-0159_000.smt2
true label:[1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1]
true label rank:[2 1 1 2 2 1 2 2 2 1 1 2 2]
predicted label:tf.Tensor(
[0.4909187  0.50675327 0.5036766  0.50055414 0.49139678 0.55026114
 0.5052804  0.4795861  0.48993856 0.48916587 0.47292054 0.4828958
 0.4891199 ], shape=(13,), dtype=float32)
rounded label:tf.Tensor([0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0.], shape=(13,), dtype=float32)
predicted label rank:[1 2 2 2 1 2 2 1 1 1 1 1 1]
mse:tf.Tensor(0.2575105, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/SYNAPSE_6_e3_1666_e5_1558_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.4104601  0.48514375 0.37996587 0.79404193 0.18670467 0.9112921
 0.10274184 0.83348954 0.00968513 0.42255652 0.04065615 0.09292209
 0.24834356 0.02765074 0.24365395 0.12489644 0.9847177  0.57095665
 0.0879252  0.23316592 0.01692382 0.0252445  0.01719949 0.9179851
 0.95474327 0.92885494 0.01031637 0.747247   0.13259363 0.04125282
 0.1176641  0.5104996  0.48345518 0.5201563  0.5111954  0.4844256
 0.47634348 0.49683112 0.50143814 0.5061343  0.49589607 0.50291985
 0.5143781  0.5000775  0.52166957 0.50448245 0.49604315 0.52129954
 0.5318423  0.4762304  0.49352297 0.5082171  0.49574596 0.5217564
 0.48660365 0.5031294  0.5073124  0.5449467  0.5040921  0.47717163
 0.50339514 0.4870313  0.4878773  0.4930732  0.51236385 0.5028228
 0.49563748 0.5103427  0.49184218 0.49674177 0.49810442 0.49372256
 0.5057894  0.50026244 0.4896039  0.48777854 0.48822972 0.49524936
 0.48727626 0.4929748  0.47973981 0.4851923  0.48445433 0.5036102
 0.49662465 0.4854241  0.49215758 0.49696174 0.48927334 0.5128379
 0.50856555 0.4996808  0.49343517 0.50049603 0.4967721  0.5135724
 0.49579236 0.49611822 0.5045525  0.46326172 0.51073855 0.63157004
 0.43127602 0.6041153  0.46801004 0.44782174 0.5864622  0.53100944
 0.52170986 0.7397865  0.39413556 0.470681   0.5072214  0.5633243
 0.4982286  0.45325974 0.35411394 0.5935714  0.345733   0.6392787
 0.4406619  0.47746146 0.48776332 0.48900005 0.48966095 0.63476527
 0.33267868 0.42441165 0.42312753 0.62140495 0.49015108 0.51111776
 0.46520475 0.62124366 0.5097163  0.53901154 0.45455277 0.5942293
 0.2743147  0.67367476 0.47290018 0.56297493 0.5035448  0.80141217
 0.3087322  0.40671656 0.6175098  0.59360284 0.22919366 0.36970073
 0.65644985 0.5288696  0.44731352 0.48094502 0.34188414 0.455281
 0.48742476 0.36849505 0.32463259 0.3194111  0.49689677 0.48602983
 0.44927594 0.4771908  0.5203609  0.50900835 0.44937187 0.49092966
 0.45968652 0.4661382  0.39602733 0.4543029  0.43597457 0.49265718
 0.49025375 0.50112444 0.4139068  0.40829426 0.44375113 0.41478267
 0.4760937  0.4782514  0.44643453], shape=(183,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1.
 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.
 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1.
 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1.
 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.], shape=(183,), dtype=float32)
predicted label rank:[1 1 1 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 2 2 2 1 2 1 1 1 2 1 2 2 1 1
 1 2 2 1 2 2 2 2 2 1 2 2 1 1 2 1 2 1 2 2 2 2 1 2 1 1 1 2 2 1 2 1 1 1 1 2 2
 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 2 1 1 2 1 2 1 1 2 1 2 2 1 2 1 1 2 2 2 2 1
 1 2 2 1 1 1 2 1 2 1 1 1 1 1 2 1 1 1 2 1 2 1 2 2 2 1 2 1 2 1 2 2 2 1 1 2 2
 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1]
mse:tf.Tensor(0.24647845, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/loop__barthe2_000.smt2
true label:[1, 0, 1, 1, 1]
true label rank:[2 1 2 2 2]
predicted label:tf.Tensor([0.49250424 0.5345093  0.48331693 0.5199853  0.46699917], shape=(5,), dtype=float32)
rounded label:tf.Tensor([0. 1. 0. 1. 0.], shape=(5,), dtype=float32)
predicted label rank:[1 2 1 2 1]
mse:tf.Tensor(0.26494354, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/s_multipl_11_000.smt2
true label:[0, 0, 1, 0, 0]
true label rank:[1 1 2 1 1]
predicted label:tf.Tensor([0.5084386  0.49348396 0.5122282  0.5043463  0.50082475], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 0. 1. 1. 1.], shape=(5,), dtype=float32)
predicted label rank:[2 1 2 2 2]
mse:tf.Tensor(0.24902964, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0102_000.smt2
true label:[1, 1]
true label rank:[1 1]
predicted label:tf.Tensor([0.5097085  0.49469763], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 0.], shape=(2,), dtype=float32)
predicted label rank:[2 1]
mse:tf.Tensor(0.2478581, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/apache-get-tag.i.v+nlh-reducer.c-1_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.48152977 0.48589116 0.54746515 0.5235708  0.4740037  0.53332365
 0.37515122 0.5106604 ], shape=(8,), dtype=float32)
rounded label:tf.Tensor([0. 0. 1. 1. 0. 1. 0. 1.], shape=(8,), dtype=float32)
predicted label rank:[1 1 2 2 1 2 1 2]
mse:tf.Tensor(0.261155, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/four1.smt2-0044_000.smt2
true label:[1, 0, 1, 1, 1, 1]
true label rank:[2 1 2 2 2 2]
predicted label:tf.Tensor([0.499424   0.4996933  0.5028814  0.49404642 0.4931744  0.49223158], shape=(6,), dtype=float32)
rounded label:tf.Tensor([0. 0. 1. 0. 0. 0.], shape=(6,), dtype=float32)
predicted label rank:[1 1 2 1 1 1]
mse:tf.Tensor(0.25301442, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/SpamAssassin-loop.i.v+cfa-reducer.c-1_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.6428646  0.5684827  0.55473614 0.6321013  0.3373788  0.54029316
 0.49823463 0.5406797  0.40525177 0.46297625], shape=(10,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 0. 1. 0. 1. 0. 0.], shape=(10,), dtype=float32)
predicted label rank:[2 2 2 2 1 2 1 2 1 1]
mse:tf.Tensor(0.24026231, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/minepump_spec4_product57_true-unreach-call.cil.c.flat_000.smt2
true label:[1, 1, 1]
true label rank:[1 1 1]
predicted label:tf.Tensor([0.9985602 1.        0.9669608], shape=(3,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)
predicted label rank:[1 1 1]
mse:tf.Tensor(0.0003645542, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/s3_srvr_8.cil.c-1_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1
 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 2 2 1 1 1 1
 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 1 2 2 2 2 2 1 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 2 2 1 2 2 2 1 1 1 1 1 1
 1 1 2 2 1 1 1 2 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2
 2 2 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 2 2 1
 1 2 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 2 2 2 2 2 2 1 1
 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1
 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 2 2]
predicted label:tf.Tensor(
[5.12782753e-01 4.97820437e-01 4.91841972e-01 5.09750426e-01
 4.48134273e-01 5.03017068e-01 5.02684057e-01 5.28637528e-01
 4.04518157e-01 5.36983848e-01 4.39099908e-01 4.73671943e-01
 4.90048170e-01 4.76063967e-01 4.66495365e-01 4.83152598e-01
 5.09126961e-01 5.11612475e-01 4.73556250e-01 4.38832551e-01
 4.22012568e-01 4.41582292e-01 4.93846744e-01 1.26887321e-01
 9.96172428e-01 9.99966025e-01 3.65376472e-04 8.71852160e-01
 3.94883752e-03 2.15085447e-02 1.02862954e-01 5.49170554e-01
 1.89209404e-05 8.41785908e-01 9.64208007e-01 7.12596666e-05
 9.54273224e-01 9.91227984e-01 9.92136955e-01 8.34174156e-02
 9.94096875e-01 3.00664604e-02 9.99942958e-01 2.89342701e-02
 1.24149323e-02 7.48272479e-01 5.08203745e-01 4.95866835e-01
 6.27999544e-01 4.19766903e-01 5.31308234e-01 4.98650104e-01
 4.79420781e-01 5.75163901e-01 4.90855962e-01 6.48761034e-01
 5.02669752e-01 7.04886794e-01 4.73360449e-01 5.29539466e-01
 5.40825546e-01 4.78975087e-01 4.37888294e-01 5.30635893e-01
 5.64468563e-01 5.71159422e-01 5.18741667e-01 5.88993132e-01
 4.19110835e-01 4.36927885e-01 5.16687930e-01 4.93723333e-01
 5.44765711e-01 4.98418391e-01 5.01270950e-01 5.06191909e-01
 4.79885757e-01 4.84087676e-01 4.89875138e-01 4.99324977e-01
 4.69246775e-01 4.96711701e-01 4.73836660e-01 5.06436706e-01
 5.11795163e-01 5.25248349e-01 4.99538660e-01 5.08461714e-01
 5.01446605e-01 5.10887802e-01 4.90799338e-01 4.99902219e-01
 4.91065055e-01 4.86606717e-01 4.60747331e-01 5.01079559e-01
 4.76646185e-01 4.63097751e-01 4.67788607e-01 4.62659061e-01
 4.48838085e-01 4.71236169e-01 4.82683808e-01 4.67647374e-01
 4.55087423e-01 4.82428581e-01 4.53390002e-01 4.69304860e-01
 4.67623353e-01 4.69531298e-01 4.36176896e-01 4.41079408e-01
 4.76799041e-01 4.54486758e-01 4.79351163e-01 4.64333385e-01
 4.90743130e-01 5.00379741e-01 5.03331602e-01 4.99518514e-01
 4.84536827e-01 4.69040990e-01 4.95311648e-01 5.06248474e-01
 5.12044787e-01 4.89714652e-01 5.09305477e-01 5.10464668e-01
 4.78844285e-01 5.44624925e-01 5.09421170e-01 4.98871952e-01
 4.71359015e-01 5.27083039e-01 5.19614875e-01 5.13757586e-01
 4.95598435e-01 4.95095283e-01 4.65699673e-01 5.15033722e-01
 5.02471268e-01 4.64325726e-01 4.99961674e-01 5.04531562e-01
 4.57246453e-01 4.88514096e-01 5.02747774e-01 4.90238756e-01
 4.93514478e-01 4.88276601e-01 5.05046904e-01 4.88701671e-01
 4.84334290e-01 4.70571876e-01 4.66587245e-01 4.74179775e-01
 4.49002683e-01 4.83716547e-01 4.86611277e-01 4.43121523e-01
 4.78951901e-01 5.09579897e-01 4.96858150e-01 4.82012093e-01
 4.67028558e-01 5.45884967e-01 4.87123579e-01 5.36262810e-01
 4.94991511e-01 4.66301799e-01 4.09897268e-01 4.34765041e-01
 4.68405336e-01 5.01695514e-01 4.47929204e-01 4.92798299e-01
 4.97975677e-01 4.88851935e-01 5.49501777e-01 4.30594772e-01
 4.93122727e-01 4.87021387e-01 4.95567650e-01 5.13172209e-01
 5.45421243e-01 4.72290337e-01 5.07796228e-01 4.82234359e-01
 4.58959788e-01 4.87716466e-01 5.49185157e-01 4.86241490e-01
 5.28530955e-01 4.90090758e-01 4.88747835e-01 3.63899142e-01
 4.40200269e-01 5.21000862e-01 4.91027981e-01 4.86818850e-01
 4.99866962e-01 4.72322255e-01 4.36382711e-01 4.43887979e-01
 3.62538993e-01 4.80015934e-01 5.51954091e-01 5.10240734e-01
 4.17061329e-01 4.74949151e-01 4.45055336e-01 4.77902472e-01
 4.69100803e-01 4.54803467e-01 4.58473682e-01 4.70451653e-01
 4.72511917e-01 4.65021104e-01 4.59838241e-01 4.77260053e-01
 4.71766829e-01 4.59957480e-01 4.56830204e-01 4.49916989e-01
 4.50848848e-01 4.56559956e-01 4.41237956e-01 4.51722771e-01
 4.53625023e-01 4.60657269e-01 4.60906684e-01 4.62391347e-01
 4.31531161e-01 4.62284744e-01 4.68263328e-01 4.84447241e-01
 4.78113592e-01 4.94201660e-01 4.56713468e-01 4.62911814e-01
 4.69766259e-01 4.45184737e-01 4.67818916e-01 4.93360519e-01
 4.73850965e-01 4.59799260e-01 4.61598009e-01 4.47748065e-01
 4.69407797e-01 4.82965022e-01 4.72687453e-01 4.63850349e-01
 4.73244816e-01 4.93527591e-01 4.71808404e-01 4.58042085e-01
 4.38389301e-01 4.89500105e-01 4.69938278e-01 4.74548668e-01
 5.03693104e-01 5.11358321e-01 4.94799495e-01 4.91090596e-01
 5.05334496e-01 4.83066559e-01 4.98036116e-01 5.03104687e-01
 5.08410335e-01 4.89578009e-01 4.93493438e-01 4.66671646e-01
 4.84408140e-01 4.87242609e-01 4.89082932e-01 4.85708982e-01
 4.62129891e-01 4.91068602e-01 5.05267382e-01 5.02592981e-01
 4.89850223e-01 4.55484211e-01 4.90395337e-01 4.72123265e-01
 5.07164657e-01 4.51171786e-01 4.78042513e-01 4.97069895e-01
 4.58444983e-01 4.76076096e-01 4.84441131e-01 4.65570569e-01
 4.75960046e-01 4.71967816e-01 4.63799566e-01 4.86590296e-01
 5.06058812e-01 4.81240571e-01 4.95305151e-01 4.66869354e-01
 4.48634356e-01 5.09763300e-01 4.65546310e-01 4.31456685e-01
 4.54908520e-01 4.15066630e-01 4.91668463e-01 5.40155888e-01
 4.48123813e-01 5.15831470e-01 5.08304000e-01 4.47949708e-01
 4.48399484e-01 4.47888017e-01 4.19193029e-01 4.68746811e-01
 4.39938575e-01 4.73507255e-01 4.54045683e-01 5.21707654e-01
 4.81549233e-01 4.62218046e-01 4.40608382e-01 5.16701460e-01
 4.36879098e-01 5.01057982e-01 4.76454198e-01], shape=(327,), dtype=float32)
rounded label:tf.Tensor(
[1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0.
 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.
 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1.
 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.
 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.], shape=(327,), dtype=float32)
predicted label rank:[2 1 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 2 1 1 1 1 1 1 2 2 1 2 1 1 1 2 1 2 2 1 2
 2 2 1 2 1 2 1 1 2 2 1 2 1 2 1 1 2 1 2 2 2 1 2 2 1 1 2 2 2 2 2 1 1 2 1 2 1
 2 2 1 1 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 2 1 1 1 1 2 2 1 2 2 1 2 2 1 1 2 2 2 1 1 1 2 2 1 1 2 1 1 2 1
 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 2 2
 1 2 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 2 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1
 2 1 1 1 1 2 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 1 2 1]
mse:tf.Tensor(0.25777298, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/underapprox_2-2.c-1_000.smt2
true label:[1, 0]
true label rank:[2 1]
predicted label:tf.Tensor([0.5080205  0.50665337], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.24937072, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/013b-horn_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.48590937 0.5004894  0.49093813 0.49532706 0.4307195  0.52126366
 0.49523234 0.5267205 ], shape=(8,), dtype=float32)
rounded label:tf.Tensor([0. 1. 0. 0. 0. 1. 0. 1.], shape=(8,), dtype=float32)
predicted label rank:[1 2 1 1 1 2 1 2]
mse:tf.Tensor(0.24411142, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/bandec.smt2-0260_000.smt2
true label:[1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1]
true label rank:[2 2 2 2 2 2 1 1 2 2 1 2 2 2 1 1 2 2]
predicted label:tf.Tensor(
[0.50523025 0.49854597 0.4972222  0.4956509  0.50868803 0.49486423
 0.4841094  0.49956104 0.45839196 0.49647835 0.47318506 0.48721567
 0.49667236 0.48301208 0.484118   0.5358839  0.5225898  0.496765  ], shape=(18,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.], shape=(18,), dtype=float32)
predicted label rank:[2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 2 1]
mse:tf.Tensor(0.25227377, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/bandec.smt2-0178_000.smt2
true label:[1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1]
true label rank:[2 2 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 2 1 2 2 2 1 1 1 1 1 2 2]
predicted label:tf.Tensor(
[0.50474745 0.504      0.50792336 0.49603477 0.49090937 0.4923078
 0.47903472 0.5001106  0.49774396 0.4915107  0.47840458 0.4953204
 0.4900708  0.5071805  0.50650597 0.4939964  0.4756103  0.49196497
 0.4766905  0.506887   0.5051716  0.48945743 0.47515118 0.4999786
 0.5014164  0.49504963 0.48340636 0.51262045 0.50056624 0.48347217], shape=(30,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0.
 1. 0. 0. 1. 1. 0.], shape=(30,), dtype=float32)
predicted label rank:[2 2 2 1 1 1 1 2 1 1 1 1 1 2 2 1 1 1 1 2 2 1 1 1 2 1 1 2 2 1]
mse:tf.Tensor(0.2521075, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0278_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[2 2 2 ... 2 2 2]
predicted label:tf.Tensor([0.50503755 0.50201607 0.5025067  ... 0.79015875 0.67218715 0.1106993 ], shape=(1042,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. ... 1. 1. 0.], shape=(1042,), dtype=float32)
predicted label rank:[2 2 2 ... 2 2 1]
mse:tf.Tensor(0.27122185, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/four1.smt2-0046_000.smt2
true label:[1, 0, 1, 1, 1, 1]
true label rank:[2 1 2 2 2 2]
predicted label:tf.Tensor([0.5007102  0.4996933  0.5028814  0.49404642 0.4931744  0.49223158], shape=(6,), dtype=float32)
rounded label:tf.Tensor([1. 0. 1. 0. 0. 0.], shape=(6,), dtype=float32)
predicted label rank:[2 1 2 1 1 1]
mse:tf.Tensor(0.25280008, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/destroy_test_dangling_unsafe.c_000.smt2
true label:[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 2 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 2 1 2 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2
 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.50205564 0.5354566  0.5114786  0.5237543  0.49544686 0.5323548
 0.5057969  0.51777613 0.49132532 0.528945   0.5262561  0.5281553
 0.5171128  0.5142763  0.5119371  0.51962364 0.5226894  0.52595985
 0.4948951  0.49408242 0.50868446 0.5156104  0.5133241  0.5116865
 0.51665926 0.5083479  0.54276484 0.513501   0.506408   0.492229
 0.5240865  0.5177247  0.5341177  0.51494133 0.5185288  0.49210116
 0.53044546 0.5202716  0.49976546 0.49658385 0.5145278  0.5174214
 0.51939994 0.5107087  0.51775265 0.50248086 0.5249169  0.5173802
 0.54007304 0.51678973 0.521511   0.51728165 0.50054187 0.52037764
 0.5150777  0.5208686  0.5081586  0.5497891  0.53093284 0.5202098
 0.5115671  0.5097449  0.5282347  0.5057191  0.5130409  0.5108237
 0.519528   0.51208144 0.52135116 0.5220389  0.55086875 0.511711
 0.5241467  0.505123   0.5010931  0.5207725  0.4969588  0.5030043
 0.51141554 0.51112986 0.5018669  0.5280605  0.5253184  0.5242823
 0.49409506 0.4843746  0.46134233 0.4861851  0.47294548 0.47018462
 0.48138422 0.47963458 0.45578915 0.47688168 0.47346473 0.4596542
 0.4841287  0.44507033 0.46235254 0.45981863 0.46705595 0.4859869
 0.4800622  0.48324826 0.46704036 0.47686735 0.45058763 0.47409064
 0.455105   0.48537022 0.44159505 0.46806648 0.4438401  0.4572994
 0.4662674  0.47246477 0.48344344 0.47560984 0.4655183  0.4754557
 0.47360867 0.4441082  0.48882806 0.47791564 0.45221096 0.49275166
 0.46691138 0.4753149  0.47637028 0.4905977  0.45757893 0.48832467
 0.4516324  0.4488443  0.46442    0.4593958  0.46754533 0.45353505
 0.47474748 0.46830118 0.46447852 0.4784816  0.47609854 0.47830585
 0.4636643  0.4820442  0.46661937 0.45043284 0.4703431  0.47482222
 0.47372618 0.4424092  0.46392867 0.4452696  0.4903239  0.4566303
 0.46768028 0.4629     0.46902478 0.47601563 0.45702744 0.46601406
 0.4847527  0.4884178  0.4639268  0.47831836 0.4962656  0.46779147
 0.4492075  0.4732548  0.47889683 0.47434795 0.47634673 0.5028598
 0.47149673 0.46644926 0.46743733 0.4520363  0.4751295  0.46987176
 0.45813635 0.4525277  0.50456667 0.46133864 0.44894058 0.47908694
 0.46025395 0.46191156 0.47609237 0.46648535 0.4795879  0.5204748
 0.44096732 0.45966646 0.4429205  0.47870335 0.4561894  0.4518975
 0.47657105 0.46551725 0.4737069  0.48408306 0.47205684 0.4835266
 0.46025938 0.4779062  0.48169902 0.45474967 0.4841311  0.49553818
 0.48661405 0.47699064 0.48770514 0.4935085  0.4869878  0.48692533
 0.49998742 0.49673522 0.50802916 0.47235212 0.4740543  0.4938168
 0.4758196  0.5059461  0.4821721  0.48164818 0.4820237  0.4836105
 0.49408534 0.5012162  0.48581547 0.4705522  0.45866138 0.4630804
 0.4890898  0.52133274 0.47812206 0.51246804 0.4634118  0.49035487
 0.47210664 0.47439492 0.48111463 0.48441148 0.48685443 0.4851293
 0.4979206  0.4758546  0.48553237 0.49506664 0.48863932 0.49296734
 0.4833838  0.5182195  0.5043013  0.4632578  0.48329684 0.47786883
 0.48632315 0.49598458 0.46385524 0.49696237 0.46832633 0.49282986
 0.48819625 0.49216032 0.49872893 0.4957588  0.49092802 0.48274896
 0.48271462 0.4875586  0.48994744 0.4867918  0.4665525  0.4877124
 0.48802823 0.48595917 0.48131442 0.4761072  0.48992264 0.4903925
 0.49262908 0.49124488 0.49605423 0.4818753  0.5102653  0.47813845
 0.52701324 0.49767724 0.48349696 0.49938366 0.48351383 0.48565623
 0.51073056 0.48522002 0.49823523 0.4847282  0.4841011  0.47525603
 0.47351038 0.49850336 0.50108695 0.47623166 0.48839238 0.49384487
 0.48616502 0.51579607 0.46921733 0.4745127  0.500978   0.4808883
 0.4898507  0.4742483  0.48322308 0.4892221  0.47764325 0.4825466
 0.5049091  0.4949495  0.50516254 0.47665992 0.46763983 0.49294832
 0.48276386 0.4968238  0.4810527  0.47645488 0.4930451  0.49678236
 0.4781149  0.4591689  0.4985023  0.46939322 0.48125604 0.4896708
 0.46572638 0.48157516 0.49974856 0.48973733 0.47473803 0.49150965
 0.51248485 0.47311696 0.47650304 0.47260836 0.45809498 0.5060833
 0.47745597 0.4779368  0.47446936 0.49855396 0.46216908 0.4825155
 0.47967726 0.4794951  0.46724993 0.49134478 0.48796415 0.49866217
 0.4692263  0.479263   0.4871279  0.49323726 0.48416615 0.49170086
 0.46431485 0.46718708 0.48103714 0.48362052 0.5130636  0.4858542
 0.4872167  0.49385038 0.50113094 0.4682675  0.47701192 0.47099844
 0.46169007 0.48103353 0.48906404 0.4705172  0.49939588 0.4791162
 0.48058924 0.4864373  0.45955807 0.49788126 0.5006026  0.4582324
 0.45368078 0.46249726 0.46907312 0.46923426 0.4867942  0.46128795
 0.47705787 0.4803001  0.5074627  0.48552507 0.46007818 0.46647012
 0.4488487  0.5049604  0.48382396 0.4758627  0.45228094 0.4705695
 0.46536094 0.4729061  0.4585424  0.45573193 0.4971109  0.4608187
 0.45749092 0.47653437 0.5202692  0.48256794 0.48399442 0.5028537
 0.48032844 0.4789617  0.48214847 0.5076584  0.47596467 0.46484762
 0.48430046 0.49621272 0.48729503 0.4787662  0.50300366 0.48637903
 0.46141872 0.46263477 0.4951089  0.4879062  0.5040115  0.48830548
 0.5013388  0.4913701  0.4443946  0.49696478 0.4971805  0.4954996
 0.47229475 0.4834237  0.47079852 0.49894345 0.4815899  0.4553806
 0.4978855  0.4808492  0.50414306 0.49181256 0.5026333  0.47829038
 0.4648084  0.49222457 0.45731646 0.48053947 0.5057576  0.4777922
 0.48306355 0.4401611  0.4828813  0.4645613  0.44783893 0.45617402
 0.48431262 0.48069924 0.44871235 0.48758176 0.5010555  0.45520768
 0.48763514 0.48079023 0.44673786 0.4957342  0.4877139  0.48613262
 0.46898678 0.45635325 0.48809317 0.48973078 0.4479111  0.48940477
 0.45702076 0.5060611  0.4481785  0.47409686 0.4752632  0.4589979
 0.49515077 0.48486128 0.47540367 0.4924923  0.49388003 0.50298584
 0.5002924  0.46938813 0.48074535 0.46559167 0.5095949  0.48573095
 0.46858674 0.4518193  0.46798813 0.46584356 0.47124937 0.47233567
 0.48775566 0.47145274 0.45811903 0.46969527 0.48866916 0.446648
 0.45283175 0.46491796 0.48075894 0.4638741  0.5064609  0.48121142
 0.47197217 0.48072928 0.5057266  0.48790154 0.49911958 0.48084304
 0.49405003 0.49430138 0.4992315  0.4837894  0.4871923  0.491125
 0.49614474 0.49301156 0.4925138  0.49225968 0.49659052 0.493554
 0.49286723 0.49526027 0.49526656 0.48448953 0.48880112 0.48983338
 0.49455023 0.48680028 0.48945135 0.48892397 0.4907596  0.48410666
 0.4973378  0.48938346 0.48597336 0.47554848 0.49063432 0.48854148
 0.4930954  0.49752975 0.48706546 0.48842704 0.48011613 0.4843503
 0.48879015 0.4842141  0.48436025 0.48516944 0.4797007  0.49967405
 0.4890594  0.48525834 0.49117732 0.49306694 0.4814239  0.48675343
 0.4859785  0.4991456  0.48609084 0.4909963  0.4909669  0.49608693
 0.4928401  0.49184352 0.5053619  0.48688495 0.48305342 0.48663598
 0.49434346 0.4884242  0.4888697  0.49210858 0.48887506 0.49364078
 0.4874366  0.4748705  0.48528817 0.49586767 0.49174994 0.4812797
 0.49397075 0.4892706  0.4888544  0.49257004 0.4993938  0.48774257
 0.4841253  0.48017806 0.4950718  0.49860734 0.49763444 0.5001904
 0.48673713 0.497478   0.48706642 0.48401055 0.48770335 0.49039385
 0.48500314 0.47821265 0.48877466 0.486261   0.49982744 0.5011341
 0.49298114 0.49061817 0.4964255  0.49171528 0.49256733 0.48399246
 0.490872   0.49057034 0.48519894 0.4971209  0.4791969  0.48574588
 0.4902832  0.49615613 0.48549396 0.47897556 0.48664433 0.4957839
 0.49131566 0.49666867 0.4864633  0.48749536 0.48698482 0.48792285
 0.48856473 0.49883223 0.4928682  0.49121922 0.4922167  0.48745072
 0.48560384 0.49906185 0.4863932  0.4860833  0.48101285 0.48479742
 0.48164704 0.4974141  0.4786841  0.4833107  0.48360306 0.49122903
 0.49079219 0.49132794 0.48201147 0.4889137  0.5024204  0.49194887
 0.48471504 0.49318695 0.4909492  0.49297366 0.49903113 0.49304613
 0.48387328 0.48914003 0.4801287  0.50263953 0.49561468 0.4876971
 0.47746608 0.48942736 0.48141593 0.49305823 0.48502555 0.4712645
 0.48672813 0.4816837  0.48982203 0.4882888  0.48363674 0.49279407
 0.4870064  0.4889229  0.4975105  0.49507913 0.498689   0.48826432
 0.49139822 0.49014103 0.48527956 0.4883353  0.48143032 0.4952036
 0.49166852 0.49155438 0.48736718 0.49956864 0.49597144 0.49080127
 0.48172522 0.48710883 0.49020132 0.48088413 0.49465945 0.49341908
 0.49283406 0.4697254  0.47474837 0.47159228 0.45666188 0.46746415
 0.4734218  0.47237977 0.47069526 0.46509105 0.48442748 0.48330954
 0.4700455  0.47403544 0.4620001  0.46569937 0.48175213 0.48558214
 0.47521824 0.48239964 0.4812704  0.46561623 0.4541787  0.49868435
 0.50770235 0.48431376 0.49114317 0.5018169  0.4877319  0.4910267
 0.48631924 0.48421535 0.5077667  0.48695356 0.49417922 0.4914637
 0.49336764 0.5083797  0.50509197 0.4954228  0.50091404 0.49789396
 0.47278276 0.49229878 0.4813591  0.48024178 0.48771653 0.49853012
 0.4998314  0.48741528 0.5016033  0.5015512  0.4946144  0.5140531
 0.5125745  0.510675   0.5095901  0.50478363 0.5295258  0.5146648
 0.50020903 0.50860304 0.50192964 0.5091381  0.50583404 0.4979938
 0.50407666 0.5015121  0.51735663 0.50009483 0.49666235 0.5111796
 0.5159294  0.48992985 0.50581425 0.49693358 0.5041644  0.50335544
 0.5027023  0.5081967  0.51132196 0.49613336 0.5057165  0.50698066
 0.50557154 0.51177466 0.5191264  0.51130766 0.5033868  0.5088656
 0.50333196 0.50112176 0.5054544  0.4603166  0.46043494 0.45519626
 0.46798417 0.44866323 0.44838068 0.44849467 0.46333584 0.45153642
 0.4514933  0.45460257 0.4624696  0.46361315 0.46065858 0.45361522
 0.4460765  0.44862267 0.44792196 0.46199483 0.46137804 0.45432588
 0.45938122 0.45829096 0.45643988 0.448199   0.45527548 0.47099993
 0.44362348 0.45637915 0.45138755 0.45964924 0.45455384 0.46466866
 0.4406466  0.4584129  0.46129176 0.438737   0.45340297 0.448704
 0.45956612 0.44230935 0.4590454  0.46966833 0.46094018 0.4476058
 0.4477476  0.46388555], shape=(860,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1.
 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(860,), dtype=float32)
predicted label rank:[2 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 1 2
 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 1 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1
 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1
 1 2 1 1 1 1 1 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 2 1
 1 1 1 1 1 1 2 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 2 1 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 1 2 1 1 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 2
 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 2 1 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.23922724, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/PRODUCER_CONSUMER_3_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 1 1 1 2 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1
 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[9.31263685e-01 1.43909335e-01 1.06164634e-01 9.67588425e-01
 7.00403631e-01 9.60917830e-01 1.05704963e-02 9.24619913e-01
 9.39694615e-08 6.39384985e-02 1.11734867e-03 7.42137432e-04
 7.96360135e-01 3.47882509e-04 5.46136379e-01 7.23011434e-01
 9.93101776e-01 6.43889904e-01 1.28170252e-02 5.81699610e-02
 1.50883116e-05 1.07447537e-04 8.19887930e-07 3.92008811e-01
 3.37407827e-01 8.61266136e-01 1.41739845e-04 5.49083292e-01
 3.58178616e-01 4.99383837e-01 4.06027138e-01 4.89358485e-01
 2.31410384e-01 5.19674778e-01 3.60058278e-01 3.33269298e-01
 5.75737834e-01 6.93886817e-01 6.38247371e-01 4.96768564e-01
 6.09868765e-01 4.57229555e-01 7.49885678e-01 4.75760341e-01
 3.69108230e-01 6.62175000e-01 6.94291770e-01 4.69384223e-01
 6.59047902e-01 2.41315752e-01 6.67417347e-01 4.58073646e-01
 4.52947706e-01 4.68067735e-01 6.44913316e-01 7.14976311e-01
 6.28289998e-01 4.81446207e-01 4.88695920e-01 5.03717601e-01
 4.81098622e-01 4.94225174e-01 4.86037672e-01 4.94583040e-01
 4.87699807e-01 4.93938088e-01 4.85728890e-01 4.94049519e-01
 5.01764894e-01 4.99334574e-01 5.00210583e-01 4.93634403e-01
 4.93303418e-01 5.15321195e-01 5.06233454e-01 4.92532551e-01
 5.02763689e-01 4.95404452e-01 4.93212044e-01 5.69567919e-01
 4.48672503e-01 5.24453640e-01 4.64082122e-01 4.65890229e-01
 5.19671679e-01 5.01285434e-01 4.75132048e-01 5.72611630e-01
 4.24274892e-01 4.44635332e-01 4.43222374e-01 6.04712069e-01
 4.89239901e-01 5.06651700e-01 4.70688850e-01 4.68590617e-01
 2.71544337e-01 6.24268532e-01 3.25914085e-01 5.68078816e-01
 3.40190768e-01 7.26348341e-01 6.37510598e-01 6.26719773e-01
 2.98973709e-01 6.13978565e-01 3.84829909e-01 8.48542452e-01
 4.84699070e-01 4.81101900e-01 4.78809357e-01 4.74132478e-01
 4.94000614e-01 4.57085311e-01 4.45193708e-01 4.38464046e-01
 4.49388057e-01 4.79233533e-01 4.84991640e-01 4.59773242e-01
 4.88030285e-01 4.97598976e-01 4.53445792e-01 4.58480448e-01
 4.79048938e-01 4.73061979e-01 4.52691823e-01 4.71048087e-01
 4.87464458e-01 4.58279759e-01 5.09348691e-01 4.58401948e-01
 4.82413411e-01 4.81539518e-01 4.65365261e-01 4.57642883e-01
 4.75827456e-01 4.69722122e-01 4.77292091e-01 4.74190474e-01
 4.92463470e-01 4.70129400e-01 4.85472381e-01 4.76271540e-01
 4.75454211e-01 4.67880964e-01 2.46789277e-01 3.54178250e-02
 7.55286217e-02 6.25994802e-03 1.12161845e-01 5.80697238e-01
 5.21677732e-02 8.01332235e-01 5.16898811e-01 2.67106593e-02
 3.02609265e-01 8.59365165e-02 4.28115547e-01 1.98208839e-01
 7.35646129e-01 7.08999634e-02 8.95805240e-01 5.34976959e-01
 5.91646969e-01 9.80195224e-01 1.00823551e-01 7.56929219e-01], shape=(168,), dtype=float32)
rounded label:tf.Tensor(
[1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0.
 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1.], shape=(168,), dtype=float32)
predicted label rank:[2 1 1 2 2 2 1 2 1 1 1 1 2 1 2 2 2 2 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 2 1 1 2
 2 2 1 2 1 2 1 1 2 2 1 2 1 2 1 1 1 2 2 2 1 1 2 1 1 1 1 1 1 1 1 2 1 2 1 1 2
 2 1 2 1 1 2 1 2 1 1 2 2 1 2 1 1 1 2 1 2 1 1 1 2 1 2 1 2 2 2 1 2 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 1 2 2 1 1 1 1 1 2 1 2 2 2 2 1 2]
mse:tf.Tensor(0.28142303, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/chc-lia-lin-0018_000.smt2
true label:[1, 0]
true label rank:[2 1]
predicted label:tf.Tensor([0.49757054 0.50582695], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 2]
mse:tf.Tensor(0.25414813, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/loop__loop2_000.smt2
true label:[1, 1, 0, 1, 1]
true label rank:[2 2 1 2 2]
predicted label:tf.Tensor([0.49038687 0.52705425 0.4862777  0.51784533 0.4674416 ], shape=(5,), dtype=float32)
rounded label:tf.Tensor([0. 1. 0. 1. 0.], shape=(5,), dtype=float32)
predicted label rank:[1 2 1 2 1]
mse:tf.Tensor(0.24718817, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-hybrid-direction-layer-graph/test_data/dillig33.c_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[9.7526586e-01 5.6113356e-01 4.4433188e-01 9.4104874e-01 2.5181359e-01
 9.9946272e-01 1.5091056e-01 8.1775379e-01 3.9128787e-07 2.2634798e-01], shape=(10,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 0. 1. 0. 1. 0. 0.], shape=(10,), dtype=float32)
predicted label rank:[2 2 1 2 1 2 1 2 1 1]
mse:tf.Tensor(0.41540822, shape=(), dtype=float32)
-------
mean(mse_list):0.2683789
