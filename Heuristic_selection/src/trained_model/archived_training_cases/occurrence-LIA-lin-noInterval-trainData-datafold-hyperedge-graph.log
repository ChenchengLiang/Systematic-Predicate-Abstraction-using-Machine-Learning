best_valid_epoch:23.0
train loss:nan
valid loss:3.5883176
test loss list:tf.Tensor(1.9183613, shape=(), dtype=float32)
mean test loss:1.9183613
mean loss list:tf.Tensor(2.1175888, shape=(), dtype=float32)
mean mean loss:2.1175888
accuracy list:[<tf.Tensor: shape=(), dtype=float64, numpy=0.8443432694785671>]
mean accuracy:0.8443432694785671
-------
true label:[2, 5, 2, 2, 2]
true label rank:[1 2 1 1 1]
predicted label:tf.Tensor([0.9439886 1.3215206 1.3215048 1.3215206 1.3212686], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(3.2055478, shape=(), dtype=float32)
-------
true label:[3, 2, 2, 1, 2, 1]
true label rank:[3 2 2 1 2 1]
predicted label:tf.Tensor([1.0689929 1.3215206 1.1562428 0.7599909 1.0922232 0.709445 ], shape=(6,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1.], shape=(6,), dtype=float32)
predicted label rank:[1 1 1 1 1 1]
mse:tf.Tensor(0.9778557, shape=(), dtype=float32)
-------
true label:[3, 2, 3, 3, 1, 3, 0, 0]
true label rank:[4 3 4 4 2 4 1 1]
predicted label:tf.Tensor(
[1.3215206 1.3215206 1.3215196 1.3215206 1.3069115 1.2376013 1.3215206
 1.321512 ], shape=(8,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1.], shape=(8,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1]
mse:tf.Tensor(1.9506589, shape=(), dtype=float32)
-------
true label:[0, 0, 2, 2, 2, 1, 3, 2]
true label rank:[1 1 3 3 3 2 4 3]
predicted label:tf.Tensor(
[1.2738521 1.1294811 1.3215206 1.1074569 1.3215206 1.3215206 1.3215206
 1.3215146], shape=(8,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1.], shape=(8,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.9995924, shape=(), dtype=float32)
-------
true label:[0, 2, 1, 2, 1]
true label rank:[1 3 2 3 2]
predicted label:tf.Tensor([0.9439886 1.3215206 1.3215048 1.3215203 1.3212686], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.40367246, shape=(), dtype=float32)
-------
true label:[0, 0, 0, 0, 0, 1, 4, 2, 3, 2, 2, 2, 1, 2, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 2 5 3 4 3 3 3 2 3 1 1 1 1 1]
predicted label:tf.Tensor(
[0.9707009  1.3215206  1.3215206  1.3215206  1.3215203  1.0628376
 1.3215206  1.3215187  1.3215177  1.2553582  0.65737903 0.9325587
 1.3214827  0.8246911  1.2732255  1.1032917  0.739613   0.8974088
 0.6980293 ], shape=(19,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(19,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(1.4759469, shape=(), dtype=float32)
-------
true label:[1, 0, 1, 1, 2, 1, 2, 1]
true label rank:[2 1 2 2 3 2 3 2]
predicted label:tf.Tensor(
[0.7486409  1.3215206  1.3200712  0.86410636 1.3212826  0.98790985
 1.3215206  1.2286232 ], shape=(8,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1.], shape=(8,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.3629896, shape=(), dtype=float32)
-------
true label:[2, 0, 0, 0, 1, 1, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0]
true label rank:[3 1 1 1 2 2 3 1 1 1 1 1 3 1 1 1 1 1]
predicted label:tf.Tensor(
[0.8367018  0.6273851  0.27009213 0.46731126 0.28279763 0.10205398
 1.0722635  0.45227903 1.0826612  0.49087518 0.38287038 0.72297615
 0.6993965  0.12390229 0.48323983 0.745701   0.55734235 0.15157014], shape=(18,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0.], shape=(18,), dtype=float32)
predicted label rank:[2 2 1 1 1 1 2 1 2 1 1 2 2 1 1 2 2 1]
mse:tf.Tensor(0.51870304, shape=(), dtype=float32)
-------
true label:[2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0]
true label rank:[2 1 1 2 2 2 1 1 1 1 2 1 1 1 2 1 1 1]
predicted label:tf.Tensor(
[0.74540824 0.718824   0.27677917 0.5347285  1.3170376  0.1588512
 1.2718005  0.23611861 0.20876196 0.15359148 0.4521765  0.14268869
 1.0971613  0.12390229 0.8322945  0.4391666  0.3391363  0.23407862], shape=(18,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.], shape=(18,), dtype=float32)
predicted label rank:[2 2 1 2 2 1 2 1 1 1 1 1 2 1 2 1 1 1]
mse:tf.Tensor(0.84846914, shape=(), dtype=float32)
-------
true label:[0, 1, 0, 0, 3, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1]
true label rank:[1 2 1 1 4 3 1 1 1 1 2 2 1 1 1 1 1 2 2 1 1 1 1 2 2]
predicted label:tf.Tensor(
[0.75918174 0.95536643 0.43681377 0.57514524 0.28279763 1.2697453
 0.746074   0.19604594 0.30275863 0.15359148 0.3806308  0.19546333
 0.2478956  0.17694467 0.56551707 0.52327293 0.27627105 0.1113943
 0.2831776  0.60636103 0.22833699 1.084614   0.97573775 0.20672917
 1.3215206 ], shape=(25,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0.
 1.], shape=(25,), dtype=float32)
predicted label rank:[2 2 1 2 1 2 2 1 1 1 1 1 1 1 2 2 1 1 1 2 1 2 2 1 2]
mse:tf.Tensor(0.64418817, shape=(), dtype=float32)
-------
true label:[1, 1, 0, 3, 0, 2, 1, 0, 3, 3, 2, 0, 0, 0, 1, 1, 2, 0, 0, 0, 1, 1, 0, 2]
true label rank:[2 2 1 4 1 3 2 1 4 4 3 1 1 1 2 2 3 1 1 1 2 2 1 3]
predicted label:tf.Tensor(
[0.9546955  0.39854074 0.01960926 1.1560628  0.41484743 0.14164516
 0.55413485 0.18954086 0.86012256 0.72889304 0.3280342  0.7785375
 0.06999448 0.25359836 0.48323983 0.236449   0.19975069 0.20476884
 0.23255655 0.46952266 0.33950534 1.2908874  1.2095158  0.20672917], shape=(24,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.], shape=(24,), dtype=float32)
predicted label rank:[2 1 1 2 1 1 2 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 2 1]
mse:tf.Tensor(1.2683096, shape=(), dtype=float32)
-------
true label:[0, 4, 4, 3]
true label rank:[1 3 3 2]
predicted label:tf.Tensor([0.9049775 1.3215206 1.2787035 1.3215206], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)
predicted label rank:[1 1 1 1]
mse:tf.Tensor(4.553996, shape=(), dtype=float32)
-------
true label:[1, 1, 1, 1]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([0.73256433 0.67357934 1.3215206  1.3215206 ], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)
predicted label rank:[1 1 1 1]
mse:tf.Tensor(0.09620581, shape=(), dtype=float32)
-------
true label:[1, 1, 1, 1]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([0.6745243 0.6674086 1.3215206 1.3215206], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)
predicted label rank:[1 1 1 1]
mse:tf.Tensor(0.1058256, shape=(), dtype=float32)
-------
true label:[1, 1, 1, 1]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([0.6745243 0.6674086 1.3215206 1.3215206], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)
predicted label rank:[1 1 1 1]
mse:tf.Tensor(0.1058256, shape=(), dtype=float32)
-------
true label:[1, 2, 1, 2, 2, 2, 2, 0, 2, 3, 5, 1]
true label rank:[2 3 2 3 3 3 3 1 3 4 5 2]
predicted label:tf.Tensor(
[1.0585816 0.9648476 1.1377313 0.7851693 1.0922327 1.0388932 0.9205604
 1.3182058 1.2049866 1.2679946 1.27773   1.3214192], shape=(12,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(12,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(2.0675726, shape=(), dtype=float32)
-------
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[-4.11596447e-02  1.32152057e+00  1.47139025e+00  1.32152057e+00
  4.14847434e-01  5.73123097e-01  7.54594207e-01  1.83366835e-01
  6.33179903e-01  4.83297050e-01 -1.86045170e-02 -1.10919327e-02
  3.02589685e-02 -9.24466550e-03  5.04853576e-02  1.09425336e-02
  1.67303085e-02  2.49346942e-02 -2.14488655e-02  2.95757502e-02
  1.10098720e-03  6.19953275e-02 -3.60193849e-03 -7.31259584e-04
  2.26705223e-02  4.99494076e-02  9.33335721e-03 -6.02865219e-03
 -6.03774786e-02  1.70339644e-03  3.44077051e-02  3.21853012e-02
  2.33944654e-02 -4.97008860e-03  4.65634614e-02  8.26862454e-03
  6.69048727e-02  1.34211391e-01 -7.48937353e-02 -1.26715198e-01
  5.18187582e-02  8.48304033e-02  3.24906111e-02 -4.41233069e-02
  1.10223696e-01  1.11418247e-01  6.00666255e-02  6.35903329e-02
 -3.67715955e-04  2.13513821e-02  3.56290191e-02  7.90971965e-02
  1.35280460e-01  8.00919831e-02  3.94284427e-02  1.41693920e-01
  3.33128870e-02  3.50075960e-03  5.59807271e-02  8.35825056e-02
  1.23652995e-01  5.13425916e-02  9.17602628e-02  9.07690227e-02
  7.04904795e-02  7.94704854e-02  2.05221772e-01  3.07383955e-01
  4.62377965e-01  1.26826465e-01  8.68539810e-02  6.31680191e-01
  5.38781434e-02  1.33215129e-01  5.79034984e-02  1.13780499e-01
  2.80445844e-01  1.08251587e-01  2.26066858e-02  4.21375155e-01
  3.24908644e-02  6.85752779e-02  2.18999594e-01  2.81613708e-01
  1.68378532e-01 -5.99944592e-03  1.85240805e-02  1.15776598e-01
  5.81009090e-02  5.77673465e-02  9.64121372e-02  6.18756264e-02
  6.67358339e-02  1.96238756e-01  1.32152057e+00  3.90015244e-01
  1.01113725e+00  4.75060642e-01  2.61028647e-01  9.48361307e-02
  2.93730527e-01  1.53154820e-01  8.80896002e-02  8.59389007e-02
  2.57560462e-02  2.57845372e-02  1.05119944e-01  1.86384767e-02
  3.75590920e-02  9.68942046e-03  2.97837257e-02  4.87167984e-02
 -4.18436229e-02 -2.97356024e-02 -5.66671789e-03  9.67889875e-02
  6.85994625e-02  8.43038410e-02  7.56832957e-03  6.75250590e-02
  1.96701288e-02  1.74170107e-01  1.40226722e-01  7.32873678e-02
  1.32318169e-01  2.44973242e-01  2.35273063e-01  2.64156312e-01
  2.46137917e-01  9.34225470e-02  4.56229895e-02  6.36089295e-02
  8.07784200e-02  6.15896881e-01 -3.32808495e-03  2.37358212e-01
  1.31708056e-01  3.06460559e-02  1.68514311e-01  1.37834936e-01
  3.90005410e-02  5.87157458e-02  3.86606455e-02  4.83241528e-02
  2.84572095e-02  3.17979604e-02  2.32433617e-01  5.13598770e-02
  1.01446301e-01  3.97067219e-02  1.49686188e-02  1.38974726e-01
  3.40964943e-02  7.10575432e-02  1.10565722e-01  3.71145189e-01
  3.56690198e-01  5.09162605e-01  1.76497102e-01], shape=(159,), dtype=float32)
rounded label:tf.Tensor(
[-0.  1.  1.  1.  0.  1.  1.  0.  1.  0. -0. -0.  0. -0.  0.  0.  0.  0.
 -0.  0.  0.  0. -0. -0.  0.  0.  0. -0. -0.  0.  0.  0.  0. -0.  0.  0.
  0.  0. -0. -0.  0.  0.  0. -0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.
  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0. -0. -0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  1. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.], shape=(159,), dtype=float32)
predicted label rank:[1 2 2 2 1 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 1]
mse:tf.Tensor(0.09029493, shape=(), dtype=float32)
-------
true label:[1, 1, 0, 1, 1]
true label rank:[2 2 1 2 2]
predicted label:tf.Tensor([0.62644845 0.560363   0.27677917 1.1501138  1.265779  ], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 1.], shape=(5,), dtype=float32)
predicted label rank:[2 2 1 2 2]
mse:tf.Tensor(0.10052017, shape=(), dtype=float32)
-------
true label:[4, 2, 2, 2, 2, 2, 2, 3, 3]
true label rank:[3 1 1 1 1 1 1 2 2]
predicted label:tf.Tensor(
[1.0585816  0.9648486  1.1377316  0.78520995 1.0922315  1.1093183
 0.92624694 1.3212261  1.3215206 ], shape=(9,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(9,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(2.2609534, shape=(), dtype=float32)
-------
true label:[1, 2, 1, 2, 1, 2, 1, 2]
true label rank:[1 2 1 2 1 2 1 2]
predicted label:tf.Tensor(
[0.85113037 1.2791059  0.312237   0.6014632  1.1959238  1.2358191
 1.136174   0.09531362], shape=(8,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 1. 1. 1. 0.], shape=(8,), dtype=float32)
predicted label rank:[2 2 1 2 2 2 2 1]
mse:tf.Tensor(0.9049382, shape=(), dtype=float32)
-------
true label:[2, 1, 3, 2, 1, 3]
true label rank:[2 1 3 2 1 3]
predicted label:tf.Tensor([0.970831   0.6361644  1.3215206  0.9186787  0.63245845 1.3215206 ], shape=(6,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1.], shape=(6,), dtype=float32)
predicted label rank:[1 1 1 1 1 1]
mse:tf.Tensor(1.3550825, shape=(), dtype=float32)
-------
true label:[0, 1]
true label rank:[1 2]
predicted label:tf.Tensor([0.7486409 1.3215206], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.33191934, shape=(), dtype=float32)
-------
true label:[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[ 0.47778308  0.4909727   0.10792421  0.30324972  0.04788068  0.07107206
 -0.03372209  0.02826436  0.04608579  0.03149399 -0.00799801  0.0338967
  0.09436962 -0.02107338  0.27771467  0.09052244  0.06155555  0.2250539
  0.07407983  0.35463452  0.03441371  0.32293183  0.06796297  0.07946092
  0.03294103  0.12329984  0.18569708], shape=(27,), dtype=float32)
rounded label:tf.Tensor(
[ 0.  0.  0.  0.  0.  0. -0.  0.  0.  0. -0.  0.  0. -0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.], shape=(27,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.038968038, shape=(), dtype=float32)
-------
true label:[1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 2 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[ 0.45897847  0.38062626  0.06363523  0.0601991   0.18338436  0.08770171
  1.068126    0.9790209   0.94273895  0.28271362  0.02933486  0.5361275
  1.0624442   0.95516473  0.79490846  0.5416644   0.11666025  0.3044087
  0.3812762   0.6951821   0.49918061  0.9311519   0.97573775  0.44822538
  0.33051705  0.11302198  0.2802795   0.53243047  0.84516597  0.48791915
  0.3775447   0.5091363  -0.04475409  0.2586482   0.00756735  0.7320928
  0.41996723  1.0789819   0.7249697   0.4080673   0.51145655  0.74881876
  0.25942662  1.1393852   0.9217525   0.32052952  0.15473565  0.23564541
  0.06608455  0.4582191   0.01103711  0.478849    0.51605195  0.23726892], shape=(54,), dtype=float32)
rounded label:tf.Tensor(
[ 0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.  1.  1.  0.  0.
  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1. -0.  0.  0.  1.
  0.  1.  1.  0.  1.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.], shape=(54,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 2 2 2 1 1 2 2 2 2 2 1 1 1 2 1 2 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1
 2 2 1 2 2 1 2 2 1 1 1 1 1 1 1 2 1]
mse:tf.Tensor(0.30871245, shape=(), dtype=float32)
-------
true label:[0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 0, 2, 0, 1]
true label rank:[1 1 2 1 1 1 1 1 1 3 3 3 2 2 1 3 1 2]
predicted label:tf.Tensor(
[0.6365981  0.5414575  0.43681377 0.0916343  0.15338293 0.00750971
 0.03837575 0.00827585 0.20876196 0.9230558  0.21479857 1.1135142
 0.9376783  0.12390229 0.48323983 0.57014626 0.19975069 0.2773104 ], shape=(18,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0.], shape=(18,), dtype=float32)
predicted label rank:[2 2 1 1 1 1 1 1 1 2 1 2 2 1 1 2 1 1]
mse:tf.Tensor(0.54649657, shape=(), dtype=float32)
-------
true label:[1, 1, 1, 1]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([1.0971248  1.051409   0.91730696 1.2163506 ], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)
predicted label rank:[1 1 1 1]
mse:tf.Tensor(0.016430454, shape=(), dtype=float32)
-------
true label:[2, 0, 2, 3, 0, 2, 2, 0, 2]
true label rank:[2 1 2 3 1 2 2 1 2]
predicted label:tf.Tensor(
[ 1.3207493   0.5414575   1.3215113   0.08336796  0.00925893  0.11205153
  0.746074    0.24834618 -0.02432606], shape=(9,), dtype=float32)
rounded label:tf.Tensor([ 1.  1.  1.  0.  0.  0.  1.  0. -0.], shape=(9,), dtype=float32)
predicted label rank:[2 2 2 1 1 1 2 1 1]
mse:tf.Tensor(2.1131094, shape=(), dtype=float32)
-------
true label:[11, 12, 27, 14, 39, 1, 1]
true label rank:[2 3 5 4 6 1 1]
predicted label:tf.Tensor(
[0.62644845 1.3213053  0.2222977  1.0457561  1.2048461  0.17412591
 1.1863277 ], shape=(7,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 1. 0. 1.], shape=(7,), dtype=float32)
predicted label rank:[2 2 1 2 2 1 2]
mse:tf.Tensor(362.2419, shape=(), dtype=float32)
-------
true label:[1, 1]
true label rank:[1 1]
predicted label:tf.Tensor([0.8234038 0.6988424], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.060941063, shape=(), dtype=float32)
-------
true label:[1, 1]
true label rank:[1 1]
predicted label:tf.Tensor([0.8234038  0.86681825], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.024461802, shape=(), dtype=float32)
-------
true label:[0, 0, 0, 2, 2, 2, 2]
true label rank:[1 1 1 2 2 2 2]
predicted label:tf.Tensor([0.5876888 1.1726787 1.2761426 1.3215206 1.2288964 1.3134987 1.3215206], shape=(7,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1.], shape=(7,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1]
mse:tf.Tensor(0.7622352, shape=(), dtype=float32)
-------
true label:[1, 1, 1, 2]
true label rank:[1 1 1 2]
predicted label:tf.Tensor([1.3215206 1.3215206 1.1903136 1.3215206], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)
predicted label rank:[1 1 1 1]
mse:tf.Tensor(0.17582613, shape=(), dtype=float32)
-------
true label:[1, 0, 1, 1, 1]
true label rank:[2 1 2 2 2]
predicted label:tf.Tensor([1.3215144 1.3215206 1.2691236 1.3215146 1.3045187], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.4236638, shape=(), dtype=float32)
-------
true label:[1, 2]
true label rank:[1 2]
predicted label:tf.Tensor([0.9413393 1.2335188], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.29546723, shape=(), dtype=float32)
-------
true label:[1, 0, 0, 1, 1]
true label rank:[2 1 1 2 2]
predicted label:tf.Tensor([1.3215206 1.2439337 1.1345334 1.3209851 1.3214846], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.6288592, shape=(), dtype=float32)
-------
true label:[2, 1, 2, 1]
true label rank:[2 1 2 1]
predicted label:tf.Tensor([0.62644845 0.7039338  0.04590747 0.8862125 ], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1.], shape=(4,), dtype=float32)
predicted label rank:[2 2 1 2]
mse:tf.Tensor(1.451431, shape=(), dtype=float32)
-------
true label:[1, 1, 2, 1, 2, 1, 2, 2, 5]
true label rank:[1 1 2 1 2 1 2 2 3]
predicted label:tf.Tensor(
[1.058567  0.964786  1.3215196 1.3215206 1.3215206 1.1204629 1.0984316
 0.4216519 1.3215206], shape=(9,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 0. 1.], shape=(9,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 1 2]
mse:tf.Tensor(1.9864941, shape=(), dtype=float32)
-------
true label:[1, 1, 1, 1, 0, 0, 1, 1, 2]
true label rank:[2 2 2 2 1 1 2 2 3]
predicted label:tf.Tensor(
[1.0585816 0.964847  1.3215206 1.3215206 1.3215206 1.1077361 1.0986152
 0.4204868 1.3215206], shape=(9,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 0. 1.], shape=(9,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 1 2]
mse:tf.Tensor(0.4434232, shape=(), dtype=float32)
-------
true label:[4, 2, 2, 3, 4, 3, 3, 4]
true label rank:[3 1 1 2 3 2 2 3]
predicted label:tf.Tensor(
[1.0585394  0.96469206 1.1373365  0.78334814 0.29521054 1.3215206
 1.3215206  1.3215206 ], shape=(8,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 0. 1. 1. 1.], shape=(8,), dtype=float32)
predicted label rank:[2 2 2 2 1 2 2 2]
mse:tf.Tensor(5.239511, shape=(), dtype=float32)
-------
true label:[3, 1, 2, 2, 1, 0, 1, 1, 2]
true label rank:[4 2 3 3 2 1 2 2 3]
predicted label:tf.Tensor(
[1.0585723  0.9648021  1.13768    0.78461015 1.0897968  1.0221097
 1.3215206  1.3215206  1.3215206 ], shape=(9,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(9,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.8567784, shape=(), dtype=float32)
-------
true label:[0, 0, 0, 0, 0, 1, 4, 2, 3, 2, 2, 2, 1, 2, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 2 5 3 4 3 3 3 2 3 1 1 1 1 1 1]
predicted label:tf.Tensor(
[1.0673225  1.3215206  1.3215206  1.3215206  1.3215206  1.0658393
 1.3215206  1.3215206  1.3215206  1.2338912  0.6573791  0.93255883
 1.3214827  0.8246911  1.7652695  1.2761202  1.1611338  0.42216223
 0.7933081  1.3199644 ], shape=(20,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 0. 1. 1.], shape=(20,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 1 2 2]
mse:tf.Tensor(1.6118749, shape=(), dtype=float32)
-------
true label:[0, 2, 0, 0, 0, 2, 2, 0, 0, 2, 4, 4, 2]
true label rank:[1 2 1 1 1 2 2 1 1 2 3 3 2]
predicted label:tf.Tensor(
[0.70001054 0.7432919  0.3428515  0.7815349  1.0331795  1.8560131
 1.0956073  0.35523552 0.6176703  0.59308255 1.0305004  1.1925547
 1.2932754 ], shape=(13,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 1. 2. 1. 0. 1. 1. 1. 1. 1.], shape=(13,), dtype=float32)
predicted label rank:[2 2 1 2 2 3 2 1 2 2 2 2 2]
mse:tf.Tensor(1.876158, shape=(), dtype=float32)
-------
true label:[1, 2, 2, 2, 2, 4, 4, 2, 2]
true label rank:[1 2 2 2 2 3 3 2 2]
predicted label:tf.Tensor(
[1.0585816  0.96484846 1.1377313  0.78519744 1.0922318  1.2371132
 1.3215206  1.3215206  1.3215206 ], shape=(9,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(9,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(2.205192, shape=(), dtype=float32)
-------
true label:[2, 1, 2, 1, 2, 2, 1, 1, 3, 2, 2, 1, 2, 3, 3, 3, 2, 3, 2, 2, 2, 1, 1, 1, 2, 1, 2]
true label rank:[2 1 2 1 2 2 1 1 3 2 2 1 2 3 3 3 2 3 2 2 2 1 1 1 2 1 2]
predicted label:tf.Tensor(
[1.2760735  1.1280992  1.3215206  1.3215206  1.2745471  1.2321925
 1.10203    0.1738297  0.8637311  1.0896478  0.8062227  1.3215206
 1.1368856  1.0962307  1.144978   0.66943586 0.5423402  0.31666696
 0.17430645 0.10897702 0.09070963 1.3215206  1.3215206  0.41476017
 0.18651587 0.51456255 0.39395517], shape=(27,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0.
 0. 1. 0.], shape=(27,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 1 1 1 1 2 2 1 1 2 1]
mse:tf.Tensor(1.8373461, shape=(), dtype=float32)
-------
true label:[2, 1, 2, 3, 1, 2, 0, 0, 0, 1]
true label rank:[3 2 3 4 2 3 1 1 1 2]
predicted label:tf.Tensor(
[ 1.0585816   0.9648476   1.1377313   0.78515977  1.0922322   1.3215206
  1.1484413   1.3215206   1.3215206  -0.06611276], shape=(10,), dtype=float32)
rounded label:tf.Tensor([ 1.  1.  1.  1.  1.  1.  1.  1.  1. -0.], shape=(10,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 2 2 1]
mse:tf.Tensor(1.2953717, shape=(), dtype=float32)
-------
true label:[2, 0, 0, 4, 2, 2, 4, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1]
true label rank:[3 1 1 4 3 3 4 1 1 3 3 1 1 1 3 1 1 1 1 3 1 1 1 1 3 1 1 1 1 2 2]
predicted label:tf.Tensor(
[0.74540824 0.66977304 1.0206141  1.314693   1.0331795  0.9963152
 1.0907648  0.31123278 1.2511594  0.569145   0.87078065 0.31345123
 1.0510998  0.10334671 0.69733125 0.24347457 0.6319843  0.03613639
 0.3298239  1.7173159  0.11472805 0.8023177  1.1497679  0.13800535
 2.147415   0.02806267 0.2753395  0.02032189 0.2573598  0.64891165
 0.32521114], shape=(31,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 2. 0. 1. 1. 0.
 2. 0. 0. 0. 0. 1. 0.], shape=(31,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 1 2 2 2 1 2 1 2 1 2 1 1 3 1 2 2 1 3 1 1 1 1 2 1]
mse:tf.Tensor(1.031177, shape=(), dtype=float32)
-------
true label:[0, 1, 0, 0, 3, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1]
true label rank:[1 2 1 1 4 3 1 1 1 1 2 2 1 1 1 1 1 2 2 1 1 1 1 2 2]
predicted label:tf.Tensor(
[0.75918174 0.95536643 0.43681377 0.57514524 0.28279763 1.2697453
 0.746074   0.19604594 0.30275863 0.15359148 0.3806308  0.19546333
 0.2478956  0.17694467 0.56551707 0.52327293 0.27627105 0.1113943
 0.2831776  0.60636103 0.22833699 1.084614   0.97573775 0.20672917
 1.3215206 ], shape=(25,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0.
 1.], shape=(25,), dtype=float32)
predicted label rank:[2 2 1 2 1 2 2 1 1 1 1 1 1 1 2 2 1 1 1 2 1 2 2 1 2]
mse:tf.Tensor(0.64418817, shape=(), dtype=float32)
-------
true label:[2, 2, 1, 2, 2, 2, 2, 0, 2, 3, 5, 1]
true label rank:[3 3 2 3 3 3 3 1 3 4 5 2]
predicted label:tf.Tensor(
[1.0585816  0.9648481  1.1377313  0.78514785 1.092232   0.7796244
 0.75991714 1.1641455  1.3215206  1.2645252  1.2603121  1.3213654 ], shape=(12,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(12,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(2.1849825, shape=(), dtype=float32)
-------
true label:[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1
 1 1 1 1]
predicted label:tf.Tensor(
[ 1.3215206e+00  3.9117664e-01  2.0010018e-01  1.3215206e+00
  5.7448596e-02 -1.8049720e-01  9.2156500e-01  1.3215206e+00
 -1.3601780e-04  9.7432834e-01  4.6160668e-03  1.2758365e+00
  7.6334074e-02  9.8512858e-01  8.9389950e-02  9.8945385e-01
  2.5625646e-02  2.1760160e-01 -1.3039589e-02  1.3206141e+00
  3.6093891e-03  1.3215206e+00  4.7119856e-03  4.4298035e-01
  1.5625507e-02  9.9602300e-01  1.6555077e-01  3.1854928e-02
  1.8783769e-01  3.9197230e-01  4.4501349e-02  2.6844916e-01
  6.0256231e-01  1.0080309e+00 -1.2192480e-02 -1.0098654e-01
  5.4526079e-01  4.5930815e-01 -2.2328563e-02  7.8501445e-01
  6.2069058e-02], shape=(41,), dtype=float32)
rounded label:tf.Tensor(
[ 1.  0.  0.  1.  0. -0.  1.  1. -0.  1.  0.  1.  0.  1.  0.  1.  0.  0.
 -0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1. -0. -0.
  1.  0. -0.  1.  0.], shape=(41,), dtype=float32)
predicted label rank:[2 1 1 2 1 1 2 2 1 2 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 2 1 1 1 1 1 1 2 2 1 1 2
 1 1 2 1]
mse:tf.Tensor(0.47684777, shape=(), dtype=float32)
-------
true label:[2, 2, 4, 4, 3, 4, 5, 5, 3, 2, 2, 5]
true label rank:[1 1 3 3 2 3 4 4 2 1 1 4]
predicted label:tf.Tensor(
[1.0585816  0.9648486  1.1377316  0.78520995 1.0922315  1.1093156
 0.92701274 0.9420089  0.90016407 1.3215203  1.3215206  1.2777882 ], shape=(12,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(12,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(7.0601883, shape=(), dtype=float32)
-------
true label:[0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 2, 2, 0, 1, 1, 2, 0, 0, 0, 0, 1, 0, 2, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 2, 1, 2, 2, 0, 1, 1, 2, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 2, 2, 0, 1, 1, 2, 0, 0, 0, 0, 1, 1, 0, 0, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1]
true label rank:[1 2 2 2 2 1 1 1 2 1 1 2 2 2 2 2 3 3 1 2 2 3 1 1 1 1 2 1 3 2 2 2 1 2 1 2 1
 1 2 2 1 2 2 2 2 1 1 1 2 1 1 2 2 2 3 2 3 3 1 2 2 3 1 1 1 2 1 2 1 2 2 2 2 1
 1 1 2 1 1 2 2 2 2 2 3 3 1 2 2 3 1 1 1 1 2 2 1 1 3 3 1 1 2 3 1 1 1 1 1 2 1
 1 2 2 1 1 1 1 1 1 2 2 1 1 3 3 1 1 2 3 1 1 1 1 2 2 1 1 2 2 1 1 2 2 1 1 1 1
 1 2 2 1 1 2 2 1 1 2 1 1 1 2 2 1 1 2 2 1 1 2 2 1 1 1 1 1 1 2 2 1 1 2 2 1 1
 2 1 2 1 1 1 2 2 1 1 2 2 1 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 1 2 2 1 1 1 1 1 2
 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 1 1 2 2 1 1 2 1 2 1 1 1 2 2 1 1 2 2 1 2 2 1
 1 1 1 1 1 2 2 1 1 2 2 1 1 2 1 2 1 1 1 2 2 1 1 2 2 1 1 2 1 2 1 1 1 1 2 2 1
 1 2 2 1 2 2 1 1 1 1 1 2 2 1 1 2 2 1 1 2 1 2 1 1 1 2]
predicted label:tf.Tensor(
[ 6.52713418e-01  5.60362995e-01  2.76779175e-01  4.79108930e-01
  4.40919340e-01  3.50554734e-01  4.50577557e-01  1.80084258e-01
  3.17964733e-01  6.02350831e-01  3.55230212e-01  2.55675673e-01
  1.78733081e-01  1.02581143e-01  3.93449545e-01  3.38354886e-01
  3.39136302e-01  2.34078616e-01  4.48846996e-01  3.26398194e-01
  3.39505345e-01  4.94994819e-01  9.75737751e-01  2.06729174e-01
  2.35892832e-01  1.89388543e-01  1.62443042e-01  3.69599938e-01
  8.27152371e-01  4.87919152e-01  3.77544701e-01  5.09136319e-01
  2.79108256e-01  9.99541134e-02  4.10369635e-01  6.37244105e-01
  2.95798600e-01  4.71601248e-01  1.77749127e-01  3.96680832e-02
  1.04346228e+00  2.51791149e-01  3.08338553e-02  9.32160556e-01
  7.99371600e-01  8.80562842e-01  6.31081104e-01  1.79718554e-01
  5.16379774e-02  2.46951163e-01  4.61723953e-02  3.11650783e-01
  5.24667561e-01  1.89729786e+00  5.06723940e-01  1.71748805e+00
 -4.98852953e-02 -2.21454054e-02  1.89176130e+00  4.05068398e-02
 -3.57658342e-02 -8.59089196e-03  1.06650338e-01 -6.04075193e-03
  9.96436924e-02  9.28922445e-02  1.35650307e-01  7.53377080e-02
  2.56527960e-02  2.70991325e-02  4.90707695e-01  8.96330535e-01
  5.71571141e-02  3.24331224e-02 -3.46296430e-02  5.30924261e-01
 -2.16124058e-02  2.97985673e-01 -9.21405852e-03  3.61470610e-01
 -2.44070590e-03  1.29648536e-01  4.62641656e-01  2.16775298e-01
  8.93566310e-01  8.81929696e-03  5.33662140e-01  8.13376129e-01
  1.03396225e+00  4.07260358e-02  9.73979890e-01  8.09301555e-01
  8.36081505e-02  7.86837041e-01  7.51131028e-02  1.11129403e+00
  1.18493700e+00  1.02854681e+00  1.09537220e+00  6.08455241e-01
  9.32045519e-01  1.08360124e+00  1.10030246e+00  7.63515532e-01
  1.07124805e+00  8.48703027e-01  1.05631322e-01  1.10818219e+00
  9.65195000e-01  5.41995466e-02  5.29953718e-01  2.93083847e-01
  6.32889271e-01  2.96673924e-02  7.13849247e-01  2.42315292e-01
  1.62013978e-01  4.84258413e-01 -1.07501447e-03  4.76409942e-02
 -3.77290100e-02  1.08279124e-01  7.05458939e-01  8.41155648e-02
  2.46803463e-02 -8.88071880e-02  1.51290387e-01 -8.06148350e-03
  4.00152802e-03  9.29289013e-02  6.56313747e-02  2.17203856e-01
  3.21495980e-02 -1.27539784e-02  8.63350183e-02  1.77713335e-02
  1.34645104e-01  4.31356728e-02  1.33962840e-01  5.05046904e-01
  2.26405859e-01 -4.83088866e-02  1.40108615e-01  6.13020062e-02
  1.89652652e-01  7.21098632e-02  1.09333813e-01  1.62564218e-02
  1.04370475e-01  1.39735639e-02  5.60430586e-02  2.36436397e-01
  3.42984110e-01  1.64405555e-01  1.32809043e-01  1.68085903e-01
  5.28210998e-01  4.65350807e-01  3.32682967e-01  3.32371145e-02
  1.66401416e-02  8.75245482e-02  3.90998572e-02  3.25752944e-01
  2.08763063e-01  1.12802401e-01  9.57009494e-01  2.36414433e-01
  7.41362274e-02  2.29082704e-02  2.31490403e-01  5.34690499e-01
  1.87904507e-01  1.68389857e-01  6.23020530e-02  1.32606357e-01
  5.72642088e-02  2.23672390e-02 -4.32457849e-02  3.60826999e-02
  4.08926308e-01  1.29175830e+00 -7.26907700e-02  6.63993359e-01
  7.64675200e-01  4.90794480e-02  3.74723434e-01  1.25448287e-01
  3.12222242e-02  1.56682730e-02 -4.91607562e-02  5.46270609e-02
 -2.57720053e-03 -1.62723958e-02  5.68301529e-02  1.09330714e-02
  8.23764265e-01  3.21513653e-01  4.50784713e-02  9.95816886e-02
  5.98710299e-01  5.28641343e-01  2.85834402e-01  9.37163055e-01
  1.10639870e-01  2.60699064e-01  6.79969043e-02  6.22142434e-01
  1.68646097e-01  5.51579416e-01  4.16015267e-01  1.24416679e-01
  6.05258942e-01  1.91425860e-01  1.40928626e-01  2.89085269e-01
  7.41340369e-02  1.97698265e-01  2.45279372e-02  1.06848866e-01
  4.00555432e-02  6.30153865e-02  1.88301653e-01  9.13094729e-02
  6.93704784e-01  4.59011793e-02  2.74638623e-01  2.22482681e-01
  3.51206601e-01  4.13409412e-01  3.71898293e-01  2.11040467e-01
  7.48958588e-02  9.85470414e-03  5.17144978e-01  2.72375494e-01
  2.61624336e-01  2.01362759e-01  2.10691184e-01  2.70775437e-01
  2.84413993e-03  6.13348663e-01  9.15513039e-02  1.25788498e+00
  1.16106153e+00 -2.64162049e-02 -3.57250720e-02  1.89537406e-02
  1.83695912e-01  2.55742311e-01  5.52701771e-01  3.87256324e-01
  2.00351059e-01  2.91298419e-01  4.12918687e-01  3.74092400e-01
  5.28903961e-01  7.54344583e-01  3.87085021e-01  3.50025296e-01
  4.26562250e-01  7.57786930e-01  4.47432518e-01  8.62698376e-01
  2.96220183e-04  1.11427331e+00  1.21952802e-01  2.63506800e-01
  9.49695557e-02  7.98788369e-02  3.37791145e-02  1.05784822e+00
  7.02464283e-01  2.44975865e-01  2.08059222e-01  5.58922768e-01
  2.07853675e-01  4.71932113e-01  1.57800674e-01  1.09367204e+00
  7.63908476e-02  3.95069957e-01  4.86028194e-01 -4.34413552e-02
  7.42101669e-01  6.80809200e-01  1.25772268e-01  2.98040181e-01
  6.82557225e-01  1.20562464e-01  8.44616741e-02  3.42866272e-01
  8.73826683e-01  2.56256402e-01  6.32454634e-01  2.46743709e-01
  3.75560343e-01  1.02395058e-01  3.21026564e-01  5.48095405e-02
  1.49621308e-01  2.48674780e-01  4.46875870e-01  1.32571220e-01
  1.17062807e-01  2.42911577e-01  2.53428578e-01  1.87174141e-01
 -4.21881229e-02  1.92187965e-01  5.74451387e-02  2.61811793e-01
  2.89275497e-01  7.75816441e-01  4.34364378e-01  2.42821127e-01
  3.48726869e-01  1.77403331e-01  1.54844463e-01  3.02829564e-01
  1.49029166e-01  1.22078001e-01], shape=(322,), dtype=float32)
rounded label:tf.Tensor(
[ 1.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.
  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.  0.  1.  2.
  1.  2. -0. -0.  2.  0. -0. -0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  1.
  0.  0. -0.  1. -0.  0. -0.  0. -0.  0.  0.  0.  1.  0.  1.  1.  1.  0.
  1.  1.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  0.  1.  0.  1.  0.  1.  0.  0.  0. -0.  0. -0.  0.  1.  0.  0. -0.
  0. -0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  1.  0. -0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0. -0.  0.
  0.  1. -0.  1.  1.  0.  0.  0.  0.  0. -0.  0. -0. -0.  0.  0.  1.  0.
  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1. -0. -0.  0.  0.  0.  1.  0.
  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  0.
  0.  1.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0. -0.  1.  1.  0.  0.
  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0. -0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.], shape=(322,), dtype=float32)
predicted label rank:[2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 2 1 1 1 2 1
 1 1 1 2 1 1 2 2 2 2 1 1 1 1 1 2 3 2 3 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 2 1 1 1 1 1 1 1 1 2 1 2 2 2 1 2 2 1 2 1 2 2 2 2 2 2 2 2 2 2 2 1 2 2 1 2
 1 2 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 1 1 1 1 1 1 1
 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 2 1 1 1 1 1 2 2 1
 1 1 2 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.51340103, shape=(), dtype=float32)
-------
true label:[3, 3, 2, 3, 4, 3, 0, 1, 1, 1, 3, 3, 2, 3, 4, 3, 0, 0, 1, 4, 2, 1, 5, 3, 3, 0, 1, 4, 2, 1, 5, 3, 3, 0, 1, 4, 2, 1, 5, 3, 3, 0, 1, 3, 2, 1, 3, 3, 3, 0, 1, 3, 2, 1, 3, 3, 3, 0, 1, 3, 2, 1, 3, 2, 2, 0, 1, 2, 2, 1, 2, 2, 2, 0, 1, 2, 2, 1, 2, 2, 2, 0, 1, 2, 2, 1, 2, 2, 2, 0, 1, 1, 2, 1, 2, 2, 2, 0, 1, 1, 2, 1, 2, 2, 2, 0, 1, 1, 2, 1, 1, 1, 2, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[4 4 3 4 5 4 1 2 2 2 4 4 3 4 5 4 1 1 2 5 3 2 6 4 4 1 2 5 3 2 6 4 4 1 2 5 3
 2 6 4 4 1 2 4 3 2 4 4 4 1 2 4 3 2 4 4 4 1 2 4 3 2 4 3 3 1 2 3 3 2 3 3 3 1
 2 3 3 2 3 3 3 1 2 3 3 2 3 3 3 1 2 2 3 2 3 3 3 1 2 2 3 2 3 3 3 1 2 2 3 2 2
 2 3 1 2 1 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 1
 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 1 2 2 2 2 2
 1 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[ 1.01492620e+00  1.01028681e+00  1.13773155e+00  7.85209954e-01
  1.09223151e+00  9.93001997e-01  9.27014053e-01  3.04208517e-01
  4.52900648e-01  4.34551299e-01  4.69538093e-01  3.49130303e-01
  9.07852590e-01  1.09573817e+00  8.91296566e-01  6.87767327e-01
  8.16116154e-01  2.34078616e-01  1.73915207e-01  5.22266030e-01
  6.71462774e-01  7.15453565e-01  6.72778845e-01  1.09410667e+00
  5.48339188e-01  1.13021985e-01  9.76604521e-01  2.27559000e-01
  1.01459980e+00  4.36012805e-01  6.58865750e-01  8.77847493e-01
  1.08053923e+00  2.58648187e-01  7.21332878e-02  1.01720667e+00
  1.00472498e+00  1.10815978e+00  2.27771044e-01  1.03749490e+00
  7.56027520e-01  1.39433414e-01  3.32615077e-02  4.91542578e-01
  2.08573675e+00  1.07995725e+00  1.69979191e+00  1.71153736e+00
  4.35174108e-02  8.26563537e-01  1.80359989e-01  1.63532305e+00
  1.79346824e+00  1.17983556e+00  1.60350752e+00  2.10568213e+00
  8.82750601e-02 -4.25910056e-02  1.13603786e-01  6.85966253e-01
  3.59827459e-01  6.51690245e-01  6.93682075e-01  7.86797523e-01
  1.04899049e+00  9.03294086e-02  7.86157548e-02  7.89510190e-01
  7.94128835e-01  5.02890170e-01  9.33723748e-01  6.80367351e-01
  9.53049362e-01  9.20376182e-02  6.59004331e-01  4.13323879e-01
  4.42800701e-01  3.23871374e-01  7.36387432e-01  4.43833649e-01
  6.54263854e-01  4.30866182e-02  2.66793817e-01  6.88639224e-01
  8.59190047e-01  6.40430868e-01  8.99534881e-01  8.30990851e-01
  1.14481997e+00 -3.02736908e-02  6.65339053e-01  7.88422287e-01
  6.47737026e-01  3.82054746e-01  7.33876348e-01  6.78042233e-01
  8.74877274e-01  5.25045991e-01  2.07623601e-01  1.99885875e-01
  6.34671092e-01  9.04696167e-01  1.03117990e+00  9.90565717e-01
  1.19804883e+00  3.02745998e-01  1.02630407e-01  1.10806775e+00
  9.16352451e-01  9.09874499e-01  7.31698334e-01  1.00370264e+00
  9.01053131e-01 -7.17949867e-03  7.08769619e-01  5.20689070e-01
  5.11328399e-01  5.58827758e-01  8.72350633e-01  9.10534680e-01
  6.32981300e-01  1.47615314e-01  3.24741721e-01  3.48850667e-01
  2.27506399e-01  5.96357286e-01  5.96926749e-01  4.91366625e-01
  9.62170899e-01  1.32656753e-01  7.55243242e-01  3.35270882e-01
  1.47630125e-01  7.80618668e-01  6.94241226e-01  9.83129561e-01
  7.62666881e-01  1.04238585e-01  4.93412673e-01  3.85521591e-01
  3.17503840e-01  8.98136437e-01  7.39504874e-01  4.66785252e-01
  3.76099944e-01  1.05295643e-01  3.10341924e-01  9.62671489e-02
  3.43870759e-01  6.55458927e-01  4.97988522e-01  2.44240701e-01
  3.22309822e-01  1.47506893e-01  3.13851804e-01  3.35925996e-01
  3.14791083e-01  8.68498027e-01  4.22265410e-01  3.69978368e-01
  3.66393536e-01  1.48572445e-01  7.13145554e-01  3.95131171e-01
  3.63257498e-01  3.40502471e-01  2.81080216e-01  3.29258353e-01
  3.57881367e-01  1.30100012e-01  3.60373199e-01  2.95100212e-01
  2.74419487e-01  5.67560613e-01  1.62973493e-01  2.93110847e-01
  6.35058165e-01  7.25159049e-03  3.99531603e-01  1.93959385e-01
  4.38109934e-01  6.68096483e-01  3.53357702e-01  4.27206099e-01
  5.49674511e-01  1.41064763e-01  2.16759413e-01 -2.82656699e-02
  3.31098706e-01  2.08825678e-01  5.46943545e-01  3.70491445e-01
  4.78404880e-01  7.68617988e-02  3.54519188e-01  6.28295898e-01
  7.00275481e-01  6.61723733e-01  4.94672298e-01  4.47516561e-01
  5.98661661e-01  4.20386046e-02  5.89529514e-01  4.08363402e-01
  7.18222439e-01  4.34314311e-01  3.75480711e-01  4.65969026e-01
  3.79362643e-01 -3.58830392e-03  1.47491843e-01  4.66937721e-01
  8.80281508e-01  6.48877919e-01  6.60138488e-01  6.61963761e-01
  6.44259691e-01  2.01885819e-01  3.35647583e-01  1.93346083e-01
  5.79881966e-02  3.57385129e-02  1.03743359e-01  1.99229270e-02
  2.24043876e-02 -4.75096703e-03  3.65543813e-02  6.04604632e-02
  1.02932274e-01  1.15663737e-01  1.19815588e-01  1.32874578e-01
  2.54006088e-02  8.89069438e-02  4.81102169e-02  2.47233003e-01
  1.30089790e-01  2.15568841e-02  4.46856022e-02 -2.21717358e-02
  6.65874630e-02  8.78372043e-02 -6.48066401e-03  2.17990965e-01
  5.16537428e-02  1.10385433e-01  8.62063468e-03  2.82969624e-02
  2.83294767e-02 -7.63943344e-02  4.72399741e-02  2.36470699e-01
  4.70842421e-02  1.19947374e-01  6.40837103e-02  4.68164384e-02
  1.82312578e-01  6.61663711e-03  6.67349547e-02  8.81826431e-02
  5.35844266e-02  8.02754611e-02  7.77340084e-02  1.93206817e-02
  1.03463531e-01  1.86522305e-02  2.81344205e-02  6.35515153e-02
  5.75209409e-02 -7.88886845e-03  9.20799524e-02  4.73828167e-02
  1.15128204e-01  2.57797837e-01 -7.27415085e-03  1.03626803e-01
  7.78532326e-02  6.92799687e-03 -3.15288752e-02  1.17547557e-01
  4.04870212e-02  2.18274444e-02 -1.44526735e-02  4.79384065e-02
  1.13747120e-02  2.33463079e-01  1.17671236e-01  5.09096831e-02
  9.31083262e-02  2.16900617e-01  3.11514735e-02  5.42262942e-02
  4.05501872e-02  6.38657957e-02 -7.80246407e-03  1.60901695e-01
  2.08721757e-02  3.07024688e-01  2.79014558e-02  6.68119937e-02
  6.06852025e-02  1.21444643e-01  7.33077526e-02  1.34883910e-01
  8.24692845e-02  6.88703060e-02  3.21324915e-02  4.45006639e-02
 -2.28555873e-02  1.75015926e-02  3.94827873e-02  9.13790762e-02
  1.05734661e-01  2.95290589e-01 -4.59875837e-02 -1.73500106e-02
  1.03649944e-02  1.01689816e-01  7.97899216e-02  1.24873638e-01
  1.20495975e-01 -1.38277188e-02  4.29888070e-02  5.69804013e-02
  1.14423692e-01  2.61190534e-02 -5.27748913e-02  6.12505376e-02
  5.41059673e-03  9.16191936e-03 -4.95109037e-02  4.41363901e-02
  9.44994390e-02  1.22850448e-01  8.18321258e-02  1.30986512e-01
  3.96792442e-02  2.16693074e-01  8.80228579e-02  4.55055833e-02
  5.60768992e-02  6.47200942e-02  4.95108217e-02  4.46551293e-02
  1.06334269e-01  1.26339823e-01  1.94664299e-03  4.62825000e-02
  1.88897282e-01  2.58078426e-02  6.10604882e-03  6.07800186e-02
  1.05614588e-01  1.44436091e-01  6.19401038e-03 -2.95552015e-02
  8.75438154e-02  5.10383248e-02 -2.99331620e-02  5.18420041e-02
  5.28290570e-02  9.74507630e-03 -4.63445634e-02 -5.03931046e-02
  1.38802558e-01  7.12781847e-02  8.36864263e-02  5.79032451e-02
  9.15208161e-02  1.50949955e-02  6.93875104e-02  6.44461662e-02
  1.34574622e-02  4.10642922e-02  3.97808701e-02  8.28029215e-02
  5.59940934e-04  9.56424177e-02  1.98292434e-02 -4.44025099e-02
 -9.04667675e-02  3.03302258e-02 -2.99992412e-02  1.75803661e-01
 -3.08796763e-03  7.48576820e-02  3.45339775e-02  7.20415115e-02
  8.31601620e-02  2.22296566e-02  9.34210420e-03  5.91889918e-02
  5.14242351e-02  6.25924617e-02  4.17642742e-02  2.87207961e-03
 -1.56108961e-02  3.89653444e-03  2.78958678e-03 -1.12409964e-02
 -2.79486999e-02  1.94875062e-01 -2.60431170e-02 -7.45888352e-02
  4.06951308e-02  3.64011526e-02  4.44013923e-02  1.34830922e-01
 -2.68048272e-02 -1.66264027e-02  1.13426596e-02  2.66536027e-02
  6.46201521e-02 -2.08107680e-02  1.79800987e-02  3.27895880e-02
  1.76870108e-01  7.63875395e-02  1.07674301e-03  8.29285979e-02
  5.33095151e-02  6.10779524e-02  4.26648557e-02  8.31132084e-02
  3.24655324e-02  9.96493250e-02 -2.06349567e-02  7.60875493e-02
  5.01164049e-02  6.55983388e-02  4.43034023e-02 -1.28338709e-02
  4.31344062e-02  1.60140991e-02  4.44106758e-03  5.43237776e-02
  1.00337759e-01  6.45171106e-03  3.71839851e-02  3.11610848e-02
  6.26264662e-02  6.07745349e-03  1.31186694e-02  4.17395532e-02
  7.03978390e-02 -6.73366264e-02  3.63096744e-02  2.91379392e-02
  4.48870808e-02  3.28482538e-02  8.45725834e-03 -8.93256813e-03
  5.68363369e-02 -2.11113468e-02 -2.29270011e-02 -1.58877671e-02
 -7.25934654e-03 -4.07377481e-02 -3.63267362e-02  3.96821797e-02
  2.90064961e-02 -1.47706270e-03  6.04441911e-02  2.45676488e-02
  5.00779152e-02 -2.69875303e-02  3.46252471e-02  2.09476769e-01
  9.92557704e-02 -1.60318017e-02  1.61446780e-02  3.52298915e-02
  1.46187842e-02 -3.26150656e-03  4.88813818e-02 -2.78977305e-02
  1.06492639e-02  5.84920645e-02  3.61472070e-02  5.68084419e-03
  3.42269987e-02 -1.85108855e-02 -4.81640771e-02  1.06937826e-01
 -6.03942573e-03  1.58647627e-01  1.92567110e-02 -4.20642272e-02
  2.19222605e-02  1.08615071e-01 -3.71818244e-03 -1.49875879e-03
  1.26382142e-01  5.00278175e-02  8.88103098e-02  2.09209323e-03
  3.13827842e-02 -1.67663470e-02  4.90438491e-02  1.06473863e-02
  6.56243861e-02 -2.53001451e-02  6.29826635e-02  3.84321362e-02
  1.29751861e-02  4.77465391e-02 -7.03218579e-03], shape=(507,), dtype=float32)
rounded label:tf.Tensor(
[ 1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.
  0.  1.  1.  1.  1.  1.  1.  0.  1.  0.  1.  0.  1.  1.  1.  0.  0.  1.
  1.  1.  0.  1.  1.  0.  0.  0.  2.  1.  2.  2.  0.  1.  0.  2.  2.  1.
  2.  2.  0. -0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.  1.  1.
  1.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1. -0.
  1.  1.  1.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.  1.  1.  0.  0.  1.
  1.  1.  1.  1.  1. -0.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  1.
  1.  0.  1.  0.  1.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.
  0.  1.  0.  0.  1.  0.  0. -0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  0. -0.  0.  0.  1.  1.  1.  1.
  1.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0. -0.  0.  0. -0.  0.  0.  0.  0.  0.  0. -0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.
  0.  0.  0.  0. -0.  0.  0.  0. -0.  0.  0.  0. -0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0. -0.  0.  0.  0.  0.  0. -0. -0.  0.  0.  0.  0.  0. -0.  0.  0.
  0.  0. -0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0. -0.  0.
  0.  0. -0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0. -0. -0.  0. -0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
 -0.  0.  0. -0. -0.  0. -0. -0.  0.  0.  0.  0. -0. -0.  0.  0.  0. -0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0. -0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.
  0. -0.  0. -0. -0. -0. -0. -0. -0.  0.  0. -0.  0.  0.  0. -0.  0.  0.
  0. -0.  0.  0.  0. -0.  0. -0.  0.  0.  0.  0.  0. -0. -0.  0. -0.  0.
  0. -0.  0.  0. -0. -0.  0.  0.  0.  0.  0. -0.  0.  0.  0. -0.  0.  0.
  0.  0. -0.], shape=(507,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 1 1 1 1 1 2 2 2 2 2 1 1 2 2 2 2 2 2 1 2 1 2 1 2 2 2 1 1 2 2
 2 1 2 2 1 1 1 3 2 3 3 1 2 1 3 3 2 3 3 1 1 1 2 1 2 2 2 2 1 1 2 2 2 2 2 2 1
 2 1 1 1 2 1 2 1 1 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2 1 1 2 2 2 2 2 1 1 2 2 2 2
 2 2 1 2 2 2 2 2 2 2 1 1 1 1 2 2 1 2 1 2 1 1 2 2 2 2 1 1 1 1 2 2 1 1 1 1 1
 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 2 1 1 2
 1 1 1 1 1 2 1 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.6114343, shape=(), dtype=float32)
-------
true label:[5, 2, 4, 5, 2, 0, 1, 1, 1, 5, 2, 4, 5, 2, 0, 0, 1, 2, 2, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 4, 1, 1, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 3, 2, 0, 1, 2, 2, 2, 3, 2, 0, 1, 2, 2, 1, 3, 2, 0, 1, 2, 2, 1, 2, 2, 0, 1, 2, 2, 1, 2, 2, 0, 1, 2, 2, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[6 3 5 6 3 1 2 2 2 6 3 5 6 3 1 1 2 3 3 2 2 1 1 2 2 2 2 2 1 1 2 5 2 2 2 3 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 4 3 1 2 3 3 3 4 3 1 2 3 3 2 4 3 1 2 3 3 2
 3 3 1 2 3 3 2 3 3 1 2 3 3 2 3 2 1 2 2 2 2 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[ 9.71648157e-01  9.64848578e-01  1.13561583e+00  7.84631193e-01
  9.87445652e-01  1.12238789e+00  8.98598850e-01  2.31089503e-01
  6.65931702e-01  7.80429602e-01  6.38307273e-01  3.80804121e-01
  9.31139052e-01  9.48371470e-01  8.91251504e-01  1.16149640e+00
  1.16037712e-01  5.75624168e-01  4.50485528e-01  5.52087665e-01
  5.37445426e-01  6.36100888e-01  3.58942807e-01  3.99275959e-01
  8.00940514e-01  4.20336485e-01  1.02863169e+00  6.64714634e-01
  4.18965638e-01  1.16891813e+00  3.06692570e-01  1.23561025e+00
  1.19394302e+00  1.05200195e+00  9.38990295e-01  1.01720667e+00
  5.74853837e-01  3.12666804e-01  9.09547269e-01  4.37978983e-01
  6.60920739e-01  2.39247382e-01  1.52567923e-01  3.34362358e-01
  2.20321059e-01  1.48862362e-01  2.41119385e-01  2.53608555e-01
  8.79174024e-02  1.10436231e-01 -2.43406296e-02  7.41931736e-01
  6.75334692e-01  4.45171595e-01  3.57822597e-01  6.02545738e-01
  3.00473660e-01  3.99148524e-01  2.09282458e-01  3.09403986e-01
  3.94025981e-01  2.94215530e-01  4.44594085e-01  4.56459939e-01
  2.26602077e-01  8.54221731e-02  1.10168964e-01  4.65092301e-01
  2.26717770e-01  1.64936393e-01  6.10431850e-01  1.04796946e-01
  8.25447142e-02  3.56730849e-01  1.10078669e+00  2.96569973e-01
  6.37765348e-01  9.22412872e-02 -2.56079361e-02  3.70300889e-01
  7.60438442e-01  1.55143678e-01  2.51311958e-01  4.82551396e-01
  9.77438867e-01 -2.96270922e-02 -5.01182675e-03  6.94060206e-01
  1.04850006e+00  1.19065428e+00  1.27146745e+00  7.03918040e-01
 -3.03964689e-02  9.45173562e-01  1.06431651e+00  1.07146859e+00
  1.11651921e+00  1.07674241e+00  1.05401587e+00  4.34932530e-01
  6.49292350e-01  9.89095271e-01  1.07466030e+00  1.17513585e+00
  1.15248036e+00  1.02876759e+00 -3.85209695e-02  6.46807551e-01
  1.07441139e+00  9.43364441e-01  6.78480506e-01  1.01860547e+00
  1.10895038e+00 -4.46607471e-02  6.78322673e-01  9.20384586e-01
  8.36814165e-01  8.25844705e-01  9.97641742e-01  9.96016920e-01
  2.15790957e-01  5.91081738e-01  9.26796257e-01  1.10542059e+00
  5.60223699e-01  9.40290272e-01  5.55820644e-01  5.10006964e-01
  4.54779267e-01  4.10741746e-01  1.03253651e+00  3.61625671e-01
  5.66519856e-01  5.64068556e-01  1.50375515e-02  4.25033152e-01
  5.60812712e-01  3.15990508e-01  4.26513970e-01  5.44887125e-01
  3.33855927e-01  1.61757916e-01  1.27453208e-01  2.62150317e-01
  2.80609310e-01  2.36106277e-01  3.19949150e-01  2.33532876e-01
  4.57610488e-02  4.56634909e-02  6.00295067e-02  3.03016633e-01
  2.32808352e-01  2.60876834e-01 -9.87637043e-03  6.37666583e-02
  1.12741366e-01  5.30451894e-01  3.76506567e-01  1.03072882e-01
  2.15936571e-01  1.77887529e-02  1.91074491e-01  1.41552776e-01
  2.28962332e-01  3.07842374e-01  2.70171374e-01  3.03407222e-01
  1.22790068e-01  1.41219199e-01  3.48054051e-01  1.65391952e-01
  3.13147813e-01  2.92731941e-01  1.95242912e-01  4.02998269e-01
 -3.30069512e-02  2.50030160e-02  5.80371022e-01  4.14827317e-02
  2.19290555e-01  3.34648103e-01  1.68601632e-01  1.44125938e-01
  9.25828815e-02  3.61093342e-01  4.07562554e-01  8.30849558e-02
  1.78668201e-01  2.72819906e-01 -4.72772121e-03  1.85639083e-01
  3.92245501e-02 -3.99599969e-03  1.74352407e-01  7.75769353e-02
  7.75218457e-02 -8.66908133e-02  4.60049212e-02  3.71533781e-02
  1.06787547e-01  6.37826025e-02  1.75504208e-01 -6.09800220e-04
  1.21607512e-01  1.87661797e-02  2.03440011e-01 -3.56158316e-02
 -2.94592902e-02  4.27450091e-02  1.44350231e-01  1.94410354e-01
  3.42269689e-02 -1.10453218e-02 -7.50929341e-02  1.07754618e-02
 -4.73742858e-02  1.77248865e-02 -7.04639405e-02  4.63194847e-02
  1.42847747e-02  7.81848282e-02  1.32606477e-01  7.00047165e-02
  3.05762291e-02 -4.67357039e-03 -3.30318511e-02  9.46067870e-02
  1.47171736e-01  5.29367477e-02  9.40648466e-02  7.53109604e-02
 -3.08166444e-03  3.96500677e-02  9.38950032e-02  4.34749901e-01
  1.34245247e-01  2.44306922e-02  9.85468179e-02  7.80636817e-02
  5.22249490e-02 -1.39797479e-02  6.88001513e-02  2.81811118e-01
  7.26723075e-02 -2.88159698e-02  1.69693083e-02  2.68815905e-02
  9.55431163e-02  7.18753040e-02  9.98114645e-02  7.04746842e-02
  2.76447982e-02  1.23511612e-01 -8.00308585e-03  3.34358513e-02
  7.36245811e-02  2.38780528e-02  6.13245517e-02 -3.85101140e-03
 -3.32836583e-02  1.28953159e-03  8.50252062e-02  3.75090241e-02
  1.00181505e-01  7.77936876e-02  8.54991674e-02  1.82285726e-01
  7.37910271e-02 -2.07123458e-02  1.03417888e-01  9.79526490e-02
  7.94273019e-02  7.73043483e-02  5.26861101e-02  4.93835211e-02
  5.49232960e-03 -4.05142754e-02  1.01989508e-02  4.86893356e-02
  1.21674985e-02  4.55636233e-02 -2.84395143e-02  9.11172777e-02
 -6.45954907e-03 -1.00220591e-02  8.00950229e-02  6.68089390e-02
 -2.63563320e-02  3.67194116e-02  1.08197585e-01  5.59738874e-02
  6.99886978e-02  2.83847541e-01  1.97406352e-01  1.97532058e-01
  4.76359427e-02  9.14425999e-02  1.05207518e-01  3.22869569e-02
  3.75602841e-02  7.73631930e-02  1.36848688e-01  2.61670351e-02
  1.08314499e-01  1.35641992e-02  3.14545929e-02  4.69658375e-02
 -4.58721370e-02  1.46289766e-01  2.70408690e-02  8.79519731e-02
 -5.88009506e-02  1.45289660e-01 -4.23531309e-02  1.28976047e-01
  6.65486306e-02 -3.21926177e-03  1.77906901e-02  9.86863375e-02
 -6.11246526e-02  4.52699959e-02  8.61719847e-02 -1.17154419e-02
 -3.63753363e-02  5.02356738e-02  1.93499774e-02  5.85244745e-02
  5.36511838e-02  4.60833013e-02 -7.08045512e-02  1.56858265e-02
  2.85847932e-02  5.16354442e-02  2.76546180e-02 -2.85060406e-02
  4.70948219e-02  1.22506440e-01  1.89774781e-02  5.63136637e-02
  1.29626811e-01  3.53907049e-02  6.53781146e-02  2.21776813e-02
 -3.28377336e-02  3.71579081e-02 -1.13072693e-02  1.61144346e-01
  1.06261820e-02 -1.79461166e-02 -2.80788243e-02  4.52980399e-03
  8.56214166e-02  2.74273455e-02 -8.63495469e-02 -1.16276816e-02
  1.11133069e-01  4.46217507e-02 -4.47883010e-02  1.24409527e-01
  5.96309900e-02  5.26662171e-03  3.19257379e-02  1.32863551e-01
  1.42206609e-01  5.39107472e-02  1.30755544e-01  3.42815071e-02
  4.83988971e-02  5.92625886e-02  6.28291667e-02  4.22312915e-02
  2.36356556e-02  1.87425166e-02  4.31962162e-02  8.20656568e-02
  7.19066113e-02  4.21122462e-02  3.07686031e-02  1.63596928e-01
 -2.54904926e-02  2.75871456e-02 -1.38659999e-02  1.89812064e-01
  2.26908773e-02  7.03658015e-02  6.19496703e-02  3.65018994e-02
  1.00516275e-01  4.93307710e-02  2.56013274e-02  6.19853884e-02
  1.21118456e-01  4.69403416e-02  3.53090316e-02  1.44389689e-01
  3.51516157e-02  9.47935581e-02  1.31799698e-01  4.76769209e-02
 -3.20523232e-02 -8.50278884e-03 -1.57458037e-02 -2.00343430e-02
  2.72024274e-02  3.21429074e-02 -1.39708668e-02  5.54706454e-02
  4.69490886e-03 -7.47317523e-02  4.63030338e-02  4.10905182e-02
  7.43365735e-02 -4.97167856e-02  1.18531793e-01  1.54353678e-03
  2.88298756e-01 -2.72158310e-02  9.47517902e-02  6.73265606e-02
  5.29752970e-02 -3.42996493e-02 -4.02261987e-02  4.55675125e-02
  7.76843727e-03  1.90180689e-02  1.41140670e-01  4.40190583e-02
  1.15379110e-01  7.57480264e-02  2.10215151e-03 -2.83396840e-02
  9.81093943e-03  3.37778479e-02  2.71568149e-02  2.18208432e-02
  2.11892724e-02 -9.63584334e-03  2.35923231e-02 -5.03175557e-02
 -7.94591010e-03  1.48096979e-02  2.07130462e-02 -4.05018181e-02
  1.79478824e-02  8.26962590e-02  1.51521415e-02 -1.05257928e-02
  1.27213895e-01 -5.53978533e-02 -1.77624673e-02 -1.97978318e-03
  3.87028307e-02  4.05894071e-02  1.09706074e-02  1.50149167e-02
  6.90219253e-02  3.99174988e-02  3.62471491e-02  3.35649252e-02
  4.56542671e-02  2.39579231e-02  8.20729584e-02  6.54722303e-02
  1.40361637e-02 -4.70483452e-02  1.96251571e-02 -4.04132903e-03
  8.94448608e-02  1.17627233e-02 -2.06921026e-02 -6.13291338e-02
  1.12931430e-02  4.43083048e-03  1.57137096e-01 -3.36631685e-02
 -4.63347584e-02  5.88790625e-02  1.37172639e-02 -6.77493960e-03
  4.23242599e-02 -1.43168196e-02 -1.31557599e-01 -8.34696889e-02
 -7.32109472e-02  1.13690048e-02 -1.15580484e-02 -5.40902615e-02
  3.76792252e-03  2.72034705e-02  1.61868095e-01  8.12832415e-02
  1.90881699e-01 -2.93144211e-02  5.41395694e-02  1.30349398e-03
 -8.58695060e-03 -5.08734286e-02 -4.34702635e-03  6.00524247e-03
  9.03732181e-02  8.88663828e-02  6.29338771e-02  1.11509562e-02
  1.10264421e-02 -3.73581052e-03  8.02052021e-03  9.13295448e-02
  2.19443321e-01  1.93028897e-01 -1.87985748e-02  2.19704807e-02
  2.41488218e-02  9.41184908e-02], shape=(514,), dtype=float32)
rounded label:tf.Tensor(
[ 1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.  0.  1.
  0.  1.  1.  1.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.  1.  1.
  1.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  1.  1.  0.
  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.
  0.  0.  1.  0.  1.  0. -0.  0.  1.  0.  0.  0.  1. -0. -0.  1.  1.  1.
  1.  1. -0.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1. -0.  1.
  1.  1.  1.  1.  1. -0.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  1.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  1.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0. -0.  0.  0.  0. -0.
  0.  0.  0.  0.  0. -0.  0.  0.  0. -0. -0.  0.  0.  0.  0. -0. -0.  0.
 -0.  0. -0.  0.  0.  0.  0.  0.  0. -0. -0.  0.  0.  0.  0.  0. -0.  0.
  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.
  0.  0. -0.  0.  0.  0.  0. -0. -0.  0.  0.  0.  0.  0.  0.  0.  0. -0.
  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0. -0.  0. -0. -0.  0.  0.
 -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0. -0.  0.  0.  0. -0.  0. -0.  0.  0. -0.  0.  0. -0.  0.  0. -0.
 -0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.
  0.  0. -0.  0. -0.  0.  0. -0. -0.  0.  0.  0. -0. -0.  0.  0. -0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0. -0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0. -0. -0. -0. -0.  0.  0. -0.  0.  0. -0.  0.  0.  0. -0.
  0.  0.  0. -0.  0.  0.  0. -0. -0.  0.  0.  0.  0.  0.  0.  0.  0. -0.
  0.  0.  0.  0.  0. -0.  0. -0. -0.  0.  0. -0.  0.  0.  0. -0.  0. -0.
 -0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0. -0.
  0.  0. -0. -0.  0.  0.  0. -0. -0.  0.  0. -0.  0. -0. -0. -0. -0.  0.
 -0. -0.  0.  0.  0.  0.  0. -0.  0.  0. -0. -0. -0.  0.  0.  0.  0.  0.
  0. -0.  0.  0.  0.  0. -0.  0.  0.  0.], shape=(514,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2 1 2 1 2 2 2 1 1 2 1 2 2 1 2 1 2 2 2 2 2 2
 1 2 1 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1
 2 1 2 1 1 1 2 1 1 1 2 1 1 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2
 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.32808957, shape=(), dtype=float32)
-------
true label:[0, 1, 0, 0, 0]
true label rank:[1 2 1 1 1]
predicted label:tf.Tensor([0.45897847 1.3153627  1.1529114  1.3215206  0.7853498 ], shape=(5,), dtype=float32)
rounded label:tf.Tensor([0. 1. 1. 1. 1.], shape=(5,), dtype=float32)
predicted label rank:[1 2 2 2 2]
mse:tf.Tensor(0.8005021, shape=(), dtype=float32)
-------
true label:[2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[3 1 1 3 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 4 1 1 4 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 1 1 5 1 1 1 1 1 1 2 1 2 1
 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 6 1 1 1 1 1 1 2 1 2 1 2
 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 7 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[ 7.00010538e-01  9.59471643e-01  3.73307407e-01  8.31251085e-01
  3.73634577e-01  3.50554734e-01  4.50577557e-01  2.53166765e-01
  2.79241532e-01  6.79518342e-01  2.86086768e-01  1.52414769e-01
  1.47052914e-01  2.76342481e-02  1.22084677e-01  3.92122984e-01
  1.23595566e-01  3.34988475e-01  1.39635503e-01  2.99691916e-01
  2.93007642e-02  2.37704158e-01  2.50071049e-01  3.35490614e-01
  7.31392056e-02  1.37056172e-01  2.30091274e-01  6.04293793e-02
  5.38260698e-01  3.58400315e-01  1.04454651e-01  5.52254468e-02
 -2.05671787e-02  5.94174713e-02  4.25322056e-02 -5.01380861e-03
 -5.77478707e-02  2.91606933e-02  1.37546062e-01 -6.44343942e-02
  3.62160206e-01  1.33838296e-01  5.53214252e-02 -5.02449125e-02
  1.08191460e-01  9.52181220e-02  1.10665724e-01  2.10719556e-02
  1.75039321e-02  2.21710205e-02  5.93555927e-01  7.27268010e-02
  2.86402971e-01  1.53488517e-01  9.85834748e-02  8.92840028e-02
  7.65677154e-01  4.54721749e-02  1.06736273e-01 -8.83804262e-03
  7.57319331e-02  7.52004385e-02  7.73131549e-02  3.46957594e-02
  5.39326966e-02  4.79985923e-02  3.99984419e-02  8.85584950e-03
  3.25496644e-02  4.76758033e-02 -3.30825746e-02  6.60748899e-01
  2.57374048e-01  2.26635963e-01  3.14577579e-01  7.55429417e-02
  1.07596904e-01  7.46490806e-02  3.83317709e-01  2.36786991e-01
  5.39475232e-02  6.47099465e-02  3.81132901e-01  4.57298309e-02
 -4.73777056e-02  1.32152057e+00  5.86197078e-01  1.32152057e+00
  1.19028521e+00 -2.64814347e-02  2.27417886e-01  8.86765420e-02
  1.40259415e-01  1.20375574e-01  6.39634579e-02  1.25138551e-01
  9.61681753e-02  7.32831806e-02  2.48195648e-01  9.48786885e-02
  1.65936828e-01  6.05403483e-02  9.93297398e-02  3.10565978e-02
  1.13802522e-01  4.11303341e-02  9.95329916e-02  7.40500689e-02
  4.83328998e-02 -2.73883119e-02  1.28641725e-04  6.96885288e-02
  9.19089913e-02 -1.48860812e-01  2.45947003e-01  1.45456165e-01
  4.80712950e-02  6.15911186e-02  1.84973776e-02  1.96230859e-02
 -5.41832298e-02  8.92271996e-02  1.05842695e-01  1.13154590e-01
  5.50310761e-02  8.58054161e-02  8.68847817e-02  3.35463881e-03
  9.84700620e-02  3.03249359e-02  2.30021715e-01  8.31231177e-02
  1.32538795e-01  1.06180489e-01  1.23443335e-01  3.77064288e-01
  1.79220945e-01  3.41233015e-02  1.14845335e-01  5.78323603e-02
  7.25126714e-02  3.99746448e-02  3.23026180e-02  7.63990432e-02
  2.75469720e-02  3.57216001e-02  4.35682058e-01  3.80588323e-02
  1.80240065e-01  3.61090153e-02  1.18080378e-02  1.97544396e-01
  6.98219687e-02  7.39844590e-02  3.16061378e-02  2.66253948e-04
  3.14713567e-02  1.68151528e-01  1.74408019e-01  4.45552766e-02
  5.20979762e-02  3.40633839e-02  2.70924747e-01  1.91223204e-01
  4.07083780e-02  9.37978029e-02  4.64981347e-02  4.40908819e-02
  2.47600675e-02  1.34224743e-01  1.77593738e-01  6.04441613e-02
  9.56659913e-02  7.49022514e-02  3.56926620e-02  9.77547318e-02
  9.27694887e-02  4.45501506e-02  2.75496036e-01  1.22554153e-02
  2.19717771e-02 -1.70028135e-02 -1.30801946e-02  2.47575045e-02
  6.78263903e-02  8.21959525e-02  1.57279998e-01  3.72879952e-02
 -3.77959907e-02  6.54378235e-02  9.03697014e-02  3.36109400e-02
  1.90306425e-01  4.82302457e-02  2.00426340e-01  1.65019929e-03
  5.15397191e-02  5.66138923e-02  5.45527488e-02  4.50635850e-02
  4.49694544e-02  5.62476814e-02  1.68693155e-01  2.41949975e-01
  2.04324543e-01  3.78100276e-02  5.61649948e-02  1.30037963e-03
  1.32152057e+00  2.14961916e-01  1.32152057e+00  6.86920345e-01
 -6.54320419e-03  2.23053962e-01  2.22268850e-02  6.96568936e-02
  7.48869777e-02  3.16681862e-02 -7.82383233e-03  6.57763481e-02
  4.68175709e-02  3.83866131e-02  5.36249876e-02  5.66853136e-02
  8.27483535e-02  1.71496779e-01  1.84717864e-01  8.33420306e-02
  7.95935988e-02  4.47450578e-02  2.30240077e-02 -3.67936492e-03
  1.05576515e-01  5.45900762e-02  4.26575840e-02  2.06072628e-02
  7.91524649e-02  2.24099457e-02  6.13719821e-02  3.68026644e-02
  4.46758419e-02  1.89017057e-02 -1.27958581e-02  4.23145056e-01
  1.78000271e-01 -4.72488999e-03 -4.51900065e-03  5.58294952e-02
  7.01178014e-02  6.97152615e-02  9.65091884e-02  4.85009849e-02
  7.92329013e-03  8.59746486e-02  1.68418139e-02  1.14061981e-02
  2.94703990e-02  4.03810591e-02  7.55462497e-02  1.08651698e-01
  1.18071169e-01  4.80440408e-02  6.33883774e-02 -6.79576397e-03
  3.42569798e-02  1.11822796e+00 -1.16525441e-02  2.63640583e-02
  2.75944054e-01 -6.46859109e-02  8.37839395e-02  8.70345533e-03
  7.96692371e-02 -8.20079446e-02  5.77762723e-03  4.56716716e-02
 -8.31256062e-03  1.88513547e-02  3.88033986e-02  1.03211284e-01
  3.68628353e-02  5.59178293e-02 -4.38660905e-02  5.26447594e-02
  2.06068546e-01  8.88476372e-02  9.05746222e-03  1.04831219e-01
  6.98248446e-02  5.29631078e-02  8.88848454e-02  3.21389735e-03
 -1.74030915e-01  1.11676440e-01 -5.41488826e-03 -1.37916356e-02
  2.92177051e-02  9.42994952e-02  1.06596321e-01 -4.19200733e-02
  6.10533357e-03  6.33210093e-02  5.33241034e-03  4.80320305e-02
  5.61117828e-02  8.85730237e-02  3.61281186e-02  3.73073518e-02
 -8.05316865e-03  1.63496614e-01  9.72280502e-02  2.58983016e-01
 -2.01021627e-01 -4.80467528e-02  1.07996762e-02  5.88663816e-02
  9.62495804e-03 -1.56789199e-02  1.36834532e-02  1.86626107e-01
 -9.83373225e-02  2.34293282e-01  4.74126339e-02  6.36668503e-02
  1.20709926e-01  1.05109021e-01  1.13929659e-01 -4.43831086e-04
  4.62371111e-03  1.40312374e-01  1.62189335e-01  1.47577226e-02
  5.07746637e-02  5.97125441e-02  3.90936732e-02  2.82529145e-01
  1.78805888e-02  5.87409884e-02  1.31470799e-01  4.30377424e-02
  5.98661155e-02  1.89512134e-01  7.76603818e-04 -4.36625779e-02
  8.84680003e-02  2.35029906e-02 -2.68346071e-03  6.58465028e-02
  4.10603136e-02  9.60378349e-03  2.13883072e-02  7.31728226e-02
  7.89283663e-02  2.15020776e-02 -2.71928310e-03  1.28062797e+00
  7.90800333e-01  1.32152057e+00  6.42357528e-01  1.55912399e-01
  6.69192821e-02  4.70189750e-03 -4.06627208e-02 -4.57942039e-02
  8.03560466e-02  3.50861400e-02  1.49948120e-01  2.53369808e-02
  8.57081860e-02  8.56891274e-03  4.60444391e-02  2.54511982e-02
  7.73872733e-02  4.14375216e-02  4.42059338e-03  3.83122712e-02
  2.17040032e-01  1.58908516e-02  1.11750460e+00 -5.60103059e-02
 -8.14523473e-02  8.28580558e-03 -2.08214223e-02  1.35895610e-02
  3.24004292e-02  7.64576942e-02  9.84314680e-02  1.30659163e-01
  4.13416922e-02  6.71342015e-04 -9.32544470e-03  3.73312086e-02
  1.70892775e-02  1.33039206e-02  4.72194850e-02  2.79270262e-02
  2.54891068e-02  2.31308937e-02  2.40447521e-02  4.49717492e-02
  9.12062973e-02 -3.24049592e-03  7.26203620e-03  1.81716830e-02
  1.18753910e-02  1.21647269e-02 -7.29411840e-03 -2.25766450e-02
  4.94438857e-02 -1.05515495e-02  3.38123739e-03  1.71571821e-02
  3.96529138e-02  1.84653401e-02  6.39876872e-02 -7.14191049e-03
  1.87228948e-01  1.70706928e-01 -5.47967628e-02  2.28792429e-01
  2.45592743e-02  1.46366894e-01 -9.61867645e-02 -5.10980189e-03
  6.68269545e-02 -8.89413804e-03 -2.90859193e-02  1.24436617e-01
  1.13825053e-02  1.30282074e-01  2.52470791e-01 -1.00469187e-01
 -4.77667674e-02  4.02781814e-02 -1.28551304e-01 -1.84500515e-02
  5.59008271e-02  4.46897149e-02  3.22334766e-02  2.55918801e-02
 -8.24010372e-03  4.50758636e-03 -1.40729055e-01 -1.43668711e-01
  1.65170133e-01  1.99002028e-02  3.70193869e-02  1.46485060e-01
 -7.64664859e-02  6.87469393e-02  4.33740616e-02  7.01923668e-02
  3.74526232e-02  4.64073569e-02 -3.23539972e-03  3.49238962e-02
  2.03305483e-03  6.06808215e-02  2.43114829e-02 -9.82020795e-03
  1.04345232e-02 -9.82941762e-02  3.47238779e-03  1.53605193e-02
  3.41902524e-02  9.63446051e-02  8.85913819e-02  7.66556561e-02
 -4.28238511e-02 -6.33160770e-03 -4.15751413e-02 -4.36640307e-02
  6.73554242e-02  9.80379134e-02  4.31209654e-02  4.03900445e-03
  6.09830320e-02  6.77095056e-02  3.72798443e-02  1.48769468e-02
  6.87586367e-02  1.84607118e-01 -4.32274416e-02  5.06958663e-02
  1.26109570e-02  4.35266644e-02 -8.80220532e-03 -3.72445583e-03
 -2.06862390e-03  5.81476539e-02  3.98133397e-02  1.08588636e-02
  1.08569428e-01  6.36042953e-02  8.02379400e-02  5.20758778e-02
  1.06049910e-01 -7.02734143e-02  1.90833241e-01  3.38540524e-02
  1.52693242e-01 -1.61780268e-02  1.07508570e-01  2.63098627e-02
  1.93271190e-02 -1.47313774e-02  4.04331535e-02 -2.38166973e-02
 -1.35695189e-02 -1.22828037e-02 -1.78640336e-02  2.88426846e-01
  1.39253855e-01  7.36372471e-02 -8.22944045e-02  9.68200713e-02
 -1.54965669e-01  5.81761748e-02  4.41592485e-02  1.45741552e-02
  3.29799056e-02  1.28873229e-01 -4.71281484e-02  4.95881736e-02
  5.46064228e-02  9.21404660e-02  1.59754276e-01  5.32339692e-01
  5.93456805e-01  1.00884840e-01  8.71813297e-03  4.74541932e-02
  1.46277094e+00 -7.85071403e-03  3.03050578e-01  4.27083492e-01
  1.23987079e-01  9.20096219e-01  7.30472058e-02  1.05721688e+00
  2.82724619e-01  2.88192540e-01  2.09784120e-01  3.93240452e-01
  3.30212712e-03  2.24076003e-01 -3.02203745e-02  2.78599560e-03
  3.85277420e-02  6.64850324e-02  7.49873519e-02 -3.52806151e-02
  2.37267315e-02 -4.15541530e-02 -4.22746018e-02  2.89195776e-03
 -9.34671760e-02  2.97289342e-02 -4.02720273e-03  2.40441710e-02
 -9.67743546e-02 -1.23163015e-02  2.82108188e-02 -1.16435565e-01
  2.89502144e-02  1.03063717e-01  9.26617384e-02 -9.99896452e-02
  1.78940511e+00  1.01479387e+00 -1.07580051e-02  4.47258949e-02
  3.72692347e-02 -8.66072625e-03 -2.65523791e-04 -3.89555097e-03
  4.85530496e-03 -9.46254283e-03  7.62201846e-03  5.93390167e-02
  9.96394902e-02  5.68355471e-02 -1.60125643e-02  1.32276565e-02
 -1.99587643e-03 -3.45324129e-02 -8.43713433e-02  3.32342982e-02
  3.50172818e-02  1.71950310e-01 -9.85587239e-02  3.92259806e-02
 -4.67114449e-02  4.92669940e-02 -6.30258024e-02 -6.04381859e-02
  6.72836900e-02 -1.11085549e-02  2.86914617e-01  1.29452348e-02
  2.06000507e-01  4.96862084e-02  2.86595583e-01 -2.86193416e-02
  1.15882084e-01  8.49422812e-02  6.82327598e-02  2.80564129e-01
  5.57686239e-02  5.37190586e-02  6.02751672e-02  2.64525712e-01
 -4.39710841e-02 -2.00648531e-02 -5.15557379e-02  4.09888029e-02
 -1.64908171e-03  4.87926006e-02 -2.01430842e-02  5.66921681e-02
  2.39510834e-02  8.33473951e-02  9.06016380e-02 -5.14791310e-02
  5.35481125e-02  5.77160865e-02  5.08970022e-02  6.50077313e-02
  7.26224035e-02  9.76762772e-02  1.32588148e-02  4.18060422e-02
  5.20963967e-03 -1.86235681e-02 -4.69982997e-02  5.64928800e-02
 -1.87977254e-02  1.01267844e-01  8.97321105e-03 -9.09483433e-03
 -6.55080378e-02  1.35589600e-01 -9.12965238e-02 -8.30647722e-02
 -1.18786603e-01  9.99169201e-02  6.49421513e-02  2.69582272e-02
 -1.78006142e-02  2.36527920e-02 -1.30268037e-02 -2.93581933e-02
 -3.12887058e-02 -1.61938369e-02 -6.92684054e-02  1.24271780e-01
  6.20586127e-02  1.52392685e-02  5.40223718e-02  7.58920312e-02
  4.16845083e-02 -9.69942659e-03  3.68071049e-02 -5.04130274e-02
 -2.12882534e-02  3.14208269e-02  5.79443574e-03  4.23638523e-02
 -9.98250395e-03 -2.09207833e-03  2.92481184e-02 -7.53953308e-03
  1.16821587e-01 -3.98146734e-02  2.33175009e-02  2.38800496e-02
  2.13460803e-01 -1.73006952e-03  9.29740965e-02  5.75726181e-02
 -3.09047103e-03 -2.13104635e-02  7.16145933e-02 -1.50823593e-02
  2.31879950e-03 -8.16764683e-03 -4.24901769e-02  2.46697813e-02
 -1.01574883e-02 -1.04330927e-02  1.64230168e-02  6.05806708e-04
  3.30483615e-02 -2.08298787e-02 -2.97235474e-02  7.98217654e-02
  1.16209686e-03 -4.87540886e-02 -2.67944634e-02 -9.62745249e-02
 -1.48477703e-02 -5.10894954e-02  3.79444659e-03 -5.88262752e-02
  8.42466950e-04  1.67166293e-02  4.29229438e-03 -1.42773688e-02
  8.56632590e-02 -3.71783972e-05  1.92008018e-02  6.53750002e-02
  3.71576697e-02  6.19981736e-02  3.82710099e-02  3.25020850e-02
  4.37924862e-02  2.44243145e-02  1.01335496e-02  8.72103721e-02
 -4.84411269e-02  2.60776430e-02  3.16960365e-02 -2.09521949e-02
  3.56152803e-02  8.43459666e-02 -4.64275479e-03  3.29677016e-02
 -5.85357845e-03  3.23667079e-02 -5.70645630e-02  3.85847688e-02
  8.08288157e-03  1.12551600e-02 -3.04032266e-02 -4.94512916e-03
  5.12748957e-03 -2.67904252e-02 -3.25290188e-02  9.19477344e-02
 -2.58614123e-03 -2.17662454e-02  6.24485612e-02  5.95297813e-02
  4.12999094e-02  1.01641729e-01  9.11053419e-02  1.43837929e-02
 -5.42695671e-02  6.91033900e-02  3.33250761e-02  9.25812125e-03
  4.18801904e-02  3.34581584e-02 -1.71993673e-03  5.77444881e-02
 -3.11924517e-02 -4.00410593e-03  7.67258853e-02  1.64880902e-02
 -6.66668862e-02  4.34581488e-02  2.91066170e-02  1.21706426e-02
 -2.86081284e-02  2.87185609e-03  4.96420264e-03  1.68970227e-03
  5.37221134e-03  4.38798815e-02 -6.84501231e-03  3.72010469e-03
 -7.13256299e-02  2.45802402e-02 -2.64268517e-02  3.67975533e-02
 -7.25999475e-04  9.81586576e-02  5.81562072e-02 -1.45816430e-02
 -6.43625855e-04  9.51078534e-03  4.03448939e-02 -7.19768554e-03
  1.17121190e-02  7.87444413e-02 -1.62524730e-02  3.02354544e-02
  8.11288357e-02 -1.01842731e-02  1.63698196e-03 -4.72955406e-03
 -1.33906752e-02 -8.85820091e-02 -2.54298300e-02  3.98327708e-02
  2.09914446e-02  5.94416857e-02 -2.15360373e-02 -5.29563501e-02
 -4.27437425e-02  6.11979365e-02 -5.95271587e-04  4.91199493e-02
  1.77679509e-02 -5.21411002e-03  9.71591324e-02 -9.01188329e-02
 -1.84367597e-03  4.35933769e-02  3.14664245e-02  1.94655359e-02
 -5.09580970e-03 -4.18212116e-02  2.40443945e-01  4.36174423e-02
 -2.83497497e-02 -5.45723364e-02  7.90757239e-02  6.64666891e-02
 -3.64913195e-02 -6.67409301e-02  4.22286540e-02 -4.00968790e-02
  1.64339691e-02 -4.39900607e-02  4.12627161e-02 -1.59676895e-02
 -1.71246380e-02 -9.36115533e-03  3.05149853e-02 -5.51666319e-02
  2.96729803e-03 -6.79676980e-03  3.31352800e-02 -4.15517390e-03
 -1.30607784e-02 -1.42040253e-02  4.92378026e-02  3.14093530e-02
  4.56382185e-02  3.43214273e-01 -6.72103465e-03 -8.75808001e-02
  1.38469875e-01 -1.46616101e-02  9.57578421e-03  1.89673603e-02
 -1.22423336e-01  8.72054100e-02 -3.11285257e-05  5.15336394e-02
 -7.35144317e-03  9.62969661e-03 -1.57514811e-02  1.32963657e-02
  2.60240585e-02  2.62714922e-03 -9.31154191e-03  3.10972929e-02], shape=(860,), dtype=float32)
rounded label:tf.Tensor(
[ 1.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0. -0.  0.  0. -0.
 -0.  0.  0. -0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.
  0.  0.  1.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  1.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  1.  1.  1.  1. -0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0. -0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0. -0. -0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1. -0.  0.  0.  0.
  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0. -0. -0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  1. -0.  0.  0. -0.
  0.  0.  0. -0.  0.  0. -0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.
  0.  0.  0.  0. -0.  0. -0. -0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.
  0.  0. -0.  0.  0.  0. -0. -0.  0.  0.  0. -0.  0.  0. -0.  0.  0.  0.
  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0. -0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0. -0.  1.  1.  1.  1.  0.
  0.  0. -0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  1. -0. -0.  0. -0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0. -0.  0.  0.  0.  0. -0. -0.  0. -0.  0.  0.  0.  0.
  0. -0.  0.  0. -0.  0.  0.  0. -0. -0.  0. -0. -0.  0.  0.  0.  0. -0.
 -0.  0. -0. -0.  0.  0.  0.  0. -0.  0. -0. -0.  0.  0.  0.  0. -0.  0.
  0.  0.  0.  0. -0.  0.  0.  0.  0. -0.  0. -0.  0.  0.  0.  0.  0.  0.
 -0. -0. -0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.
 -0. -0. -0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0. -0.  0.  0.
  0. -0.  0. -0. -0. -0. -0.  0.  0.  0. -0.  0. -0.  0.  0.  0.  0.  0.
 -0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1. -0.  0.  0.  0.  1.  0.  1.
  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0. -0.  0. -0. -0.  0. -0.  0.
 -0.  0. -0. -0.  0. -0.  0.  0.  0. -0.  2.  1. -0.  0.  0. -0. -0. -0.
  0. -0.  0.  0.  0.  0. -0.  0. -0. -0. -0.  0.  0.  0. -0.  0. -0.  0.
 -0. -0.  0. -0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.
 -0. -0. -0.  0. -0.  0. -0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.
  0.  0.  0. -0. -0.  0. -0.  0.  0. -0. -0.  0. -0. -0. -0.  0.  0.  0.
 -0.  0. -0. -0. -0. -0. -0.  0.  0.  0.  0.  0.  0. -0.  0. -0. -0.  0.
  0.  0. -0. -0.  0. -0.  0. -0.  0.  0.  0. -0.  0.  0. -0. -0.  0. -0.
  0. -0. -0.  0. -0. -0.  0.  0.  0. -0. -0.  0.  0. -0. -0. -0. -0. -0.
  0. -0.  0.  0.  0. -0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
 -0.  0.  0. -0.  0.  0. -0.  0. -0.  0. -0.  0.  0.  0. -0. -0.  0. -0.
 -0.  0. -0. -0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0. -0.  0.
 -0. -0.  0.  0. -0.  0.  0.  0. -0.  0.  0.  0.  0.  0. -0.  0. -0.  0.
 -0.  0. -0.  0.  0. -0. -0.  0.  0. -0.  0.  0. -0.  0.  0. -0.  0. -0.
 -0. -0. -0.  0.  0.  0. -0. -0. -0.  0. -0.  0.  0. -0.  0. -0. -0.  0.
  0.  0. -0. -0.  0.  0. -0. -0.  0.  0. -0. -0.  0. -0.  0. -0.  0. -0.
 -0. -0.  0. -0.  0. -0.  0. -0. -0. -0.  0.  0.  0.  0. -0. -0.  0. -0.
  0.  0. -0.  0. -0.  0. -0.  0. -0.  0.  0.  0. -0.  0.], shape=(860,), dtype=float32)
predicted label rank:[2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 3 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.16980806, shape=(), dtype=float32)
-------
true label:[3, 3, 4, 3, 3, 0, 2, 2, 2, 5, 2, 2]
true label rank:[3 3 4 3 3 1 2 2 2 5 2 2]
predicted label:tf.Tensor(
[ 1.0585816e+00  9.6484846e-01  1.1377313e+00  7.8519976e-01
  1.0922315e+00 -5.5003166e-04  1.3215206e+00  1.3215206e+00
  1.3215206e+00  1.2487710e+00  5.9238386e-01  1.3215206e+00], shape=(12,), dtype=float32)
rounded label:tf.Tensor([ 1.  1.  1.  1.  1. -0.  1.  1.  1.  1.  1.  1.], shape=(12,), dtype=float32)
predicted label rank:[2 2 2 2 2 1 2 2 2 2 2 2]
mse:tf.Tensor(3.545241, shape=(), dtype=float32)
-------
true label:[2, 3, 2, 2, 1, 2, 3, 2]
true label rank:[2 3 2 2 1 2 3 2]
predicted label:tf.Tensor(
[1.0585806  0.9648389  1.137727   0.7850283  1.0912316  1.3215206
 1.3214762  0.32856834], shape=(8,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 0.], shape=(8,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 1]
mse:tf.Tensor(1.6659508, shape=(), dtype=float32)
-------
true label:[1, 1, 1]
true label rank:[1 1 1]
predicted label:tf.Tensor([0.5651037 1.2432332 1.2672122], shape=(3,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)
predicted label rank:[1 1 1]
mse:tf.Tensor(0.106566496, shape=(), dtype=float32)
-------
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2
 2 1 1 1]
predicted label:tf.Tensor(
[ 1.0574126   0.9617464   1.1067019   0.7690545   1.056606    1.086307
  0.80514735  0.31326774  0.34785938  0.34838417  0.20746058  0.24768156
  0.07911626  0.2679982   0.20886302  0.42079604  0.13010293  0.23083836
  0.12659556  0.2759278   0.02412292  0.19044375  0.06748374  0.37129086
  0.30665857  0.3539528   0.34318048  0.07715979  0.11949569  0.29243234
  0.50019443  0.20883611  0.28101176  0.01310195  0.02541292  0.00386159
 -0.05788596 -0.0085792   0.12590179 -0.05009819  0.37873214  0.14471114
  0.06153056 -0.02032109  0.1128096   0.07417679  0.10925412 -0.00213555
  0.01519418  0.02348253  0.6712005   0.06802902  0.27209115  0.18584183
  0.12324062  0.13292566  0.65044117  0.01715617  0.10987356  0.07574159
  0.07796788  0.01986556  0.08440916  0.07533509  0.04062195  0.05750382
  0.06759048  0.0796295   0.02093646  0.08065483  0.04144764  0.64402515
  0.20609608  0.24520868  0.43628603  0.07433888  0.03092521  0.07070091], shape=(78,), dtype=float32)
rounded label:tf.Tensor(
[ 1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.
 -0. -0.  0. -0.  0.  0.  0. -0.  0.  0.  0. -0.  0.  0.  1.  0.  0.  0.
  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.
  0.  0.  0.  0.  0.  0.], shape=(78,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 1 1 1]
mse:tf.Tensor(0.15323968, shape=(), dtype=float32)
-------
true label:[0, 2, 2, 2, 2]
true label rank:[1 2 2 2 2]
predicted label:tf.Tensor([1.3214142  1.3096638  0.76520246 1.1862979  1.2889066 ], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.98303795, shape=(), dtype=float32)
-------
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[ 1.3215206   1.0942361   1.3215206   0.5347285   0.13075396  0.11411627
  0.08962007  0.00827585  0.05050255  0.02165207 -0.01523941 -0.01389963
  0.02265047 -0.02107338  0.04861     0.00410256 -0.03504456  0.03123337
  0.12225941  0.06517772], shape=(20,), dtype=float32)
rounded label:tf.Tensor(
[ 1.  1.  1.  1.  0.  0.  0.  0.  0.  0. -0. -0.  0. -0.  0.  0. -0.  0.
  0.  0.], shape=(20,), dtype=float32)
predicted label rank:[2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.25212604, shape=(), dtype=float32)
-------
true label:[0, 0, 0, 1, 0, 0, 0, 1]
true label rank:[1 1 1 2 1 1 1 2]
predicted label:tf.Tensor(
[0.5651037  0.46912593 0.11384107 0.46731126 1.0529449  0.62247306
 1.3215194  1.2648258 ], shape=(8,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 0. 1. 1. 1. 1.], shape=(8,), dtype=float32)
predicted label rank:[2 1 1 1 2 2 2 2]
mse:tf.Tensor(0.5186063, shape=(), dtype=float32)
-------
true label:[8, 2, 5, 4, 4, 3, 2, 2, 3, 2, 2, 3, 2, 2]
true label rank:[5 1 4 3 3 2 1 1 2 1 1 2 1 1]
predicted label:tf.Tensor(
[1.3068554  0.6674085  1.2756917  0.8861919  1.2837288  1.042022
 1.0186651  0.583451   1.2188561  0.3738755  0.41153294 0.9820358
 0.9880931  1.2012196 ], shape=(14,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.], shape=(14,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 2 2 1 1 2 2 2]
mse:tf.Tensor(7.0282755, shape=(), dtype=float32)
-------
true label:[17, 16, 17, 19, 8, 11, 14, 9, 12, 17, 7, 15, 12, 5, 7]
true label rank:[10  9 10 11  3  5  7  4  6 10  2  8  6  1  2]
predicted label:tf.Tensor(
[1.3215139  1.3144813  1.1298931  1.2881811  0.2786776  0.4159419
 1.2503455  0.8671638  0.7995882  0.67333716 0.32588455 0.44610238
 1.2180831  0.60756826 1.0202916 ], shape=(15,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1.], shape=(15,), dtype=float32)
predicted label rank:[2 2 2 2 1 1 2 2 2 2 1 1 2 2 2]
mse:tf.Tensor(149.80367, shape=(), dtype=float32)
-------
true label:[104, 51]
true label rank:[2 1]
predicted label:tf.Tensor([1.3215194 1.3202963], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(6505.4717, shape=(), dtype=float32)
-------
true label:[1, 0]
true label rank:[2 1]
predicted label:tf.Tensor([0.6562419 1.3136735], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.92195386, shape=(), dtype=float32)
-------
true label:[2, 2, 1, 1, 1, 1]
true label rank:[2 2 1 1 1 1]
predicted label:tf.Tensor([0.9946789 1.2438095 1.2655284 1.3215206 1.3204565 0.8500765], shape=(6,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1.], shape=(6,), dtype=float32)
predicted label rank:[1 1 1 1 1 1]
mse:tf.Tensor(0.3135908, shape=(), dtype=float32)
-------
true label:[1, 2, 0]
true label rank:[2 3 1]
predicted label:tf.Tensor([0.9069975 1.3213449 1.3213644], shape=(3,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)
predicted label rank:[1 1 1]
mse:tf.Tensor(0.73840874, shape=(), dtype=float32)
-------
true label:[2, 1, 2, 1]
true label rank:[2 1 2 1]
predicted label:tf.Tensor([0.62644845 0.7039338  0.04590747 0.8862125 ], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1.], shape=(4,), dtype=float32)
predicted label rank:[2 2 1 2]
mse:tf.Tensor(1.451431, shape=(), dtype=float32)
-------
true label:[2, 2, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 2 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.5729401  0.6273851  0.01069945 0.15681812 0.04788068 0.4711491
 0.5348828  0.45013815 0.5085658  0.4345513 ], shape=(10,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 0. 0. 0. 1. 0. 1. 0.], shape=(10,), dtype=float32)
predicted label rank:[2 2 1 1 1 1 2 1 2 1]
mse:tf.Tensor(0.510575, shape=(), dtype=float32)
-------
true label:[1, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0]
true label rank:[2 1 1 1 1 3 3 3 3 1 1 1]
predicted label:tf.Tensor(
[0.70001054 0.083188   0.01404783 0.23268464 0.6539396  0.4159419
 0.9542785  0.59143364 0.2834412  0.5216293  0.7469994  0.24184325], shape=(12,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0.], shape=(12,), dtype=float32)
predicted label rank:[2 1 1 1 2 1 2 2 1 2 2 1]
mse:tf.Tensor(0.8334076, shape=(), dtype=float32)
-------
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 ... 1 1 1]
predicted label:tf.Tensor([1.0585816  0.9648486  1.1377316  ... 0.12224504 0.15066782 0.18502617], shape=(1420,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(1420,), dtype=float32)
predicted label rank:[2 2 2 ... 1 1 1]
mse:tf.Tensor(0.044341903, shape=(), dtype=float32)
-------
true label:[1, 0, 2, 3, 2, 1, 2, 0, 0, 2, 2, 3, 1, 0, 1, 0, 2, 2, 1, 1, 2, 3, 1, 2, 1, 0, 2, 3, 0, 0, 1, 0, 2, 2, 1, 2, 1, 2, 1, 0, 2, 5, 0, 1, 2, 2, 2, 1, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 1, 1, 1, 2, 1, 1, 0, 0, 0, 1, 0, 2, 2, 1, 1, 0, 2, 2, 2, 1, 2, 1, 0, 2, 5, 0, 1, 2]
true label rank:[2 1 3 4 3 2 3 1 1 3 3 4 2 1 2 1 3 3 2 2 3 4 2 3 2 1 3 4 1 1 2 1 3 3 2 3 2
 3 2 1 3 5 1 2 3 3 3 2 3 1 1 1 1 1 1 2 3 1 1 1 1 2 2 2 2 3 2 2 1 1 1 2 1 3
 3 2 2 1 3 3 3 2 3 2 1 3 5 1 2 3]
predicted label:tf.Tensor(
[ 1.3215206   1.0465357   1.1377316   0.46731126  1.1957023   1.10936
  1.1857095   0.26519236  0.76873195  0.90133137  0.11446965  0.31244078
  0.47864962  1.0941544   0.2433533   0.33650413  0.15230295  0.26121658
  0.16750214  1.3215206   0.6714684   0.6743006   0.5768798   1.039104
  0.09427771  0.41046053  0.28147718  0.33146933  0.74133027  0.28676933
  0.9176001   0.04526365  0.095333    0.06724109  0.01841836 -0.04748937
  0.8106918   0.87234336  0.12692383  0.9421678   0.4674514   0.38710237
  0.2760663   0.15775132  0.4643249   0.03715713  0.08072655  0.01070046
 -0.01931839  0.12763822  0.66550833  0.2158601   0.59762615  0.3939737
  0.2070015   0.18145478  0.77521944  0.10175957  0.1256513   0.29810232
  0.16947335  0.20044884  0.499304    0.09073314  0.04382198  0.03712092
  0.09099996  0.09073314  0.03712092  0.11120874  0.03672823  0.3319318
  0.64389634  0.36519787  0.18538177  0.08111764  0.2286669   0.56370586
  0.7180214   0.3543676   0.15116143  0.16546953  0.39502293  0.22273618
  0.09997362  0.04444058  0.44608194  0.10833931 -0.14780305  0.19290403], shape=(90,), dtype=float32)
rounded label:tf.Tensor(
[ 1.  1.  1.  0.  1.  1.  1.  0.  1.  1.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  1.  1.  1.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0. -0.
  1.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  1.  0.  1.  0.
  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.], shape=(90,), dtype=float32)
predicted label rank:[2 2 2 1 2 2 2 1 2 2 1 1 1 2 1 1 1 1 1 2 2 2 2 2 1 1 1 1 2 1 2 1 1 1 1 1 2
 2 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1
 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(1.8606447, shape=(), dtype=float32)
-------
true label:[0, 0, 0, 4, 2, 3, 3, 3, 2, 0, 1, 2, 1, 3, 2, 3, 2]
true label rank:[1 1 1 5 3 4 4 4 3 1 2 3 2 4 3 4 3]
predicted label:tf.Tensor(
[1.3215206  0.9712489  1.3215206  1.3215206  1.2690496  1.0854917
 1.3215125  1.2933266  1.3203883  0.6166657  0.9037177  1.2430146
 0.5122867  0.92350286 0.8576741  1.0731304  0.79383856], shape=(17,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(17,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(1.9992238, shape=(), dtype=float32)
-------
true label:[2, 0, 1, 2, 1, 4, 3, 2, 2, 2]
true label rank:[3 1 2 3 2 5 4 3 3 3]
predicted label:tf.Tensor(
[1.3215206  0.9712489  0.35919195 1.3215203  0.16966012 1.2123435
 1.2395878  1.2933266  1.3207979  0.74183816], shape=(10,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 0. 1. 1. 1. 1. 1.], shape=(10,), dtype=float32)
predicted label rank:[2 2 1 2 1 2 2 2 2 2]
mse:tf.Tensor(1.6377846, shape=(), dtype=float32)
-------
true label:[3, 3, 2, 3, 3, 2]
true label rank:[2 2 1 2 2 1]
predicted label:tf.Tensor([1.0089757 1.3215141 1.3211303 0.7038224 1.3214595 1.1029532], shape=(6,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1.], shape=(6,), dtype=float32)
predicted label rank:[1 1 1 1 1 1]
mse:tf.Tensor(2.6894963, shape=(), dtype=float32)
-------
true label:[0, 2, 1, 2, 3, 0, 1]
true label rank:[1 3 2 3 4 1 2]
predicted label:tf.Tensor([0.5876888 1.1726787 1.2311997 1.0502627 1.2311792 1.1009438 1.2434201], shape=(7,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1.], shape=(7,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1]
mse:tf.Tensor(0.9121929, shape=(), dtype=float32)
-------
true label:[1, 0, 2]
true label rank:[2 1 3]
predicted label:tf.Tensor([1.0585816 0.9648486 1.3215206], shape=(3,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)
predicted label rank:[1 1 1]
mse:tf.Tensor(0.46489963, shape=(), dtype=float32)
-------
true label:[1, 0, 0, 2, 1, 0, 0, 2, 1, 0, 0, 0]
true label rank:[2 1 1 3 2 1 1 3 2 1 1 1]
predicted label:tf.Tensor(
[1.0153606  0.9616086  1.3215206  0.77501607 1.0922315  1.08845
 1.3215206  0.25986838 0.2834412  0.38987958 1.3215206  0.29930866], shape=(12,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0.], shape=(12,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 1 1 1 2 1]
mse:tf.Tensor(1.0534248, shape=(), dtype=float32)
-------
true label:[0, 2, 1, 2, 2]
true label rank:[1 3 2 3 3]
predicted label:tf.Tensor([1.0585816 1.3215206 1.1377316 0.7852093 1.0922315], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.7799319, shape=(), dtype=float32)
-------
true label:[0, 1, 0, 2]
true label rank:[1 2 1 3]
predicted label:tf.Tensor([1.0585816 0.9648486 1.1377316 1.3215206], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)
predicted label rank:[1 1 1 1]
mse:tf.Tensor(0.7191495, shape=(), dtype=float32)
-------
true label:[1, 2]
true label rank:[1 2]
predicted label:tf.Tensor([1.0585797 1.3215206], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.23188296, shape=(), dtype=float32)
-------
true label:[0, 2, 1]
true label rank:[1 3 2]
predicted label:tf.Tensor([1.0585816 1.3215206 1.1377316], shape=(3,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)
predicted label rank:[1 1 1]
mse:tf.Tensor(0.53329974, shape=(), dtype=float32)
-------
true label:[0, 2, 1]
true label rank:[1 3 2]
predicted label:tf.Tensor([1.0585816 1.3215206 1.1377316], shape=(3,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)
predicted label rank:[1 1 1]
mse:tf.Tensor(0.53329974, shape=(), dtype=float32)
-------
true label:[0, 1, 0, 0]
true label rank:[1 2 1 1]
predicted label:tf.Tensor([1.0585816  1.3215206  1.1377316  0.78520995], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)
predicted label rank:[1 1 1 1]
mse:tf.Tensor(0.78373957, shape=(), dtype=float32)
-------
true label:[0, 0, 0, 1]
true label rank:[1 1 1 2]
predicted label:tf.Tensor([1.0585816 0.9648486 1.1377316 1.3215206], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)
predicted label rank:[1 1 1 1]
mse:tf.Tensor(0.8623341, shape=(), dtype=float32)
-------
true label:[0, 1, 0]
true label rank:[1 2 1]
predicted label:tf.Tensor([1.0585816 1.3215206 1.1377316], shape=(3,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)
predicted label rank:[1 1 1]
mse:tf.Tensor(0.8394678, shape=(), dtype=float32)
-------
true label:[1, 1]
true label rank:[1 1]
predicted label:tf.Tensor([1.1555519 1.2438095], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.041819725, shape=(), dtype=float32)
-------
true label:[1]
true label rank:[1]
predicted label:tf.Tensor([1.3131049], shape=(1,), dtype=float32)
rounded label:tf.Tensor([1.], shape=(1,), dtype=float32)
predicted label rank:[1]
mse:tf.Tensor(0.09803466, shape=(), dtype=float32)
-------
true label:[2, 1, 2, 1, 1, 0, 1, 0, 1]
true label rank:[3 2 3 2 2 1 2 1 2]
predicted label:tf.Tensor(
[1.0585778  0.9648338  1.1377106  0.78477836 1.0912316  0.9869446
 1.3215206  1.3214934  1.3215206 ], shape=(9,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(9,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.5125394, shape=(), dtype=float32)
-------
true label:[1, 0, 0, 1, 0, 0, 1]
true label rank:[2 1 1 2 1 1 2]
predicted label:tf.Tensor([1.3215206 1.3215206 1.0185888 1.3194382 0.2786776 0.8389242 1.313755 ], shape=(7,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 0. 1. 1.], shape=(7,), dtype=float32)
predicted label rank:[2 2 2 2 1 2 2]
mse:tf.Tensor(0.55275047, shape=(), dtype=float32)
-------
true label:[2, 2, 3, 1, 1, 0, 1, 0, 1]
true label rank:[3 3 4 2 2 1 2 1 2]
predicted label:tf.Tensor(
[1.0585816  0.9648439  1.1377285  0.78500766 1.0922196  0.78476644
 0.9882037  1.3215103  1.3215206 ], shape=(9,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(9,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.88292897, shape=(), dtype=float32)
-------
true label:[1, 0, 1, 0]
true label rank:[2 1 2 1]
predicted label:tf.Tensor([ 1.275492    0.5751291  -0.13001603  1.3178737 ], shape=(4,), dtype=float32)
rounded label:tf.Tensor([ 1.  1. -0.  1.], shape=(4,), dtype=float32)
predicted label rank:[2 2 1 2]
mse:tf.Tensor(0.8550992, shape=(), dtype=float32)
-------
true label:[0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 2, 1, 1, 0, 0, 2, 2, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0]
true label rank:[1 2 1 2 1 2 2 2 2 1 1 1 3 2 2 1 1 3 3 2 1 2 2 1 1 1 2 2 1 1 1 1 1 1 1 1 1
 1 1 1 2 1 2 1 1 2 1 1 1]
predicted label:tf.Tensor(
[ 1.3215206   1.0465357   1.1356039   0.86531925  1.1833425   0.36098802
  1.2331748   0.16887477  0.7814493   0.20770317  0.23939952  0.15767336
  1.3215206   0.30057538  0.58060974  0.7229908   0.6371185   0.26280177
  0.40172988  0.14127511  0.05197279  0.36627027  0.20140794  0.24142265
  0.26473895  0.28952724  0.29870695  0.30471873  0.19330871  0.29774097
  1.0340867   0.2624455   0.6355052   0.2914809   0.36039555  0.03261192
  0.5396746   0.49090803  0.1242871  -0.07300961  0.4791183   0.13167775
  0.05493167  0.75903714  0.2537479   0.38545328  0.10868365 -0.00693105
 -0.0085596 ], shape=(49,), dtype=float32)
rounded label:tf.Tensor(
[ 1.  1.  1.  1.  1.  0.  1.  0.  1.  0.  0.  0.  1.  0.  1.  1.  1.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.
  1.  0.  0. -0.  0.  0.  0.  1.  0.  0.  0. -0. -0.], shape=(49,), dtype=float32)
predicted label rank:[2 2 2 2 2 1 2 1 2 1 1 1 2 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 2
 1 1 1 1 1 1 2 1 1 1 1 1]
mse:tf.Tensor(0.42908996, shape=(), dtype=float32)
-------
true label:[1, 0, 0, 1, 1, 0, 0, 1, 2, 0, 1, 0, 0, 1, 2, 0, 1, 0, 0, 2, 1, 0, 0, 1, 1, 0, 0, 1, 2, 1, 0, 0, 1, 3, 0, 1, 0, 0, 1, 3, 0, 0, 1, 0, 0, 1, 3, 0, 1, 0, 0, 2, 1, 0, 0, 1, 2, 1, 0, 0, 1, 2, 2, 1, 0, 0, 1, 2, 2]
true label rank:[2 1 1 2 2 1 1 2 3 1 2 1 1 2 3 1 2 1 1 3 2 1 1 2 2 1 1 2 3 2 1 1 2 4 1 2 1
 1 2 4 1 1 2 1 1 2 4 1 2 1 1 3 2 1 1 2 3 2 1 1 2 3 3 2 1 1 2 3 3]
predicted label:tf.Tensor(
[ 1.0048783   0.5414575   0.2765675   0.64840007  1.2326474   0.62247306
  0.5348828   0.75520295  0.96771497  0.2811911   0.4521765   0.03204536
  0.9376783   0.7202951   0.48323983  0.17622548  0.3391363   0.23407862
  0.448847    0.6951821   0.53320867  0.67065233  0.3589428   0.596361
  0.5926539   0.15256622  1.0286317   0.976029    0.6740318   0.83633214
  0.6772425   0.9175587   0.5385117   0.7536415   0.29130134 -0.06963864
  1.1907265   1.4613235   2.1279113  -0.04606408  0.38725418  1.4923387
  0.3286045   0.5627935   2.9305828   0.75044394  2.2851653   1.0456226
  0.38188267  0.11857772  0.24482387  0.52969956  0.6709829   0.20010626
  0.21306902  0.97023505  0.8328633   0.98436445  0.11102857 -0.02250686
  0.6726023   0.86373943  0.4691953   0.34824648  0.22925091 -0.04830218
  0.47777563  0.42724615  0.97794694], shape=(69,), dtype=float32)
rounded label:tf.Tensor(
[ 1.  1.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.
  0.  1.  1.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.  0. -0.
  1.  1.  2. -0.  0.  1.  0.  1.  3.  1.  2.  1.  0.  0.  0.  1.  1.  0.
  0.  1.  1.  1.  0. -0.  1.  1.  0.  0.  0. -0.  0.  0.  1.], shape=(69,), dtype=float32)
predicted label rank:[2 2 1 2 2 2 2 2 2 1 1 1 2 2 1 1 1 1 1 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2 1 1 2
 2 3 1 1 2 1 2 4 2 3 2 1 1 1 2 2 1 1 2 2 2 1 1 2 2 1 1 1 1 1 1 2]
mse:tf.Tensor(0.8680531, shape=(), dtype=float32)
-------
true label:[2, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[3 1 1 3 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 4 1 1 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 1 1 5 1 1 1 1 1 2 1 2
 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 6 1 1 1 1 1 2 1 2 1
 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 7 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[ 7.00010538e-01  9.60081637e-01  3.73307407e-01  7.95482934e-01
  3.73634577e-01  2.84933299e-01  4.50577557e-01  2.53166765e-01
  2.79241532e-01  6.34120226e-01  1.06126800e-01  2.71687239e-01
  1.47052914e-01  8.84302557e-02  2.68233597e-01  3.45915169e-01
  1.15104541e-01  1.98084921e-01  1.21914208e-01  2.61778772e-01
  3.37285697e-02  2.25033313e-01  2.54001051e-01  4.06809211e-01
  2.06963688e-01  4.51784730e-02  2.30091274e-01  6.04293793e-02
  5.38260698e-01  3.58400315e-01  1.04454651e-01  5.52254468e-02
 -2.05671787e-02  5.94174713e-02  4.15811092e-02 -5.01380861e-03
 -5.94115928e-02  3.20295393e-02  1.33172870e-01 -6.26203492e-02
  3.66081655e-01  1.35617524e-01  5.53928912e-02 -7.17675239e-02
  1.11445397e-01  7.34116882e-02  1.11401916e-01  4.50679809e-02
  1.31813884e-02  2.97560394e-02  4.73158062e-01  1.20410919e-01
  2.86402971e-01  1.39097035e-01  5.68524748e-02  2.21243948e-02
  9.52047288e-01  3.56431156e-02  1.09357849e-01  6.21028394e-02
  3.64705920e-03  1.23014599e-02  4.14594263e-02  3.49076539e-02
  1.19611442e-01 -1.79160237e-02 -5.88903800e-02  1.68937057e-01
  3.78672034e-02  9.33377743e-02  1.25000387e-01  1.83344096e-01
  2.77280271e-01  2.16101795e-01  1.87772334e-01  7.28691667e-02
  1.03608057e-01  7.88489580e-02  3.23484570e-01  2.31951654e-01
  8.19870234e-02  5.80142140e-02  3.60952139e-01  4.65824753e-02
 -5.44873029e-02  1.30998641e-02  1.51501983e-01  1.32152057e+00
  3.84891629e-01  1.32152057e+00  1.32152057e+00  9.81884301e-02
  5.54940999e-02  1.11014187e-01  7.85359442e-02  1.25138551e-01
  5.76986521e-02  7.30175674e-02  2.48195648e-01  9.51764584e-02
  1.65936828e-01  6.05403483e-02  9.93297398e-02  3.10565978e-02
  1.48731112e-01  4.11303341e-02  9.95329916e-02  4.90168780e-02
  4.83328998e-02 -2.73883119e-02  1.28641725e-04  6.96885288e-02
  9.19089913e-02 -1.48860812e-01  2.45947003e-01  1.45456165e-01
  4.80712950e-02  6.15911186e-02  1.84973776e-02  1.58465207e-02
 -5.41832298e-02  8.92271996e-02  1.44553125e-01  1.07687250e-01
  5.18745035e-02  9.45266038e-02  8.95093679e-02 -2.06074789e-02
  8.40387940e-02  5.39606661e-02  7.90362358e-02  7.14455396e-02
  7.56609887e-02  1.01481870e-01  1.24223858e-01  3.63581032e-01
  1.86802834e-01  2.82086581e-02  1.13035902e-01  5.58404624e-02
  6.70581162e-02  4.16147113e-02  3.18517238e-02  6.95530325e-02
  2.55571008e-02  3.37874740e-02  2.44925350e-01  4.01990414e-02
  7.85989612e-02  3.17054093e-02 -1.43276155e-03  1.94405973e-01
  1.09146237e-02  5.91955334e-02  1.11307949e-02  7.78883547e-02
  3.12609822e-02  1.68352991e-01  1.75299436e-01  4.25538868e-02
  5.23367673e-02  3.43385488e-02  2.33119458e-01  1.79620296e-01
  4.08027619e-02  8.65758061e-02  4.83621806e-02  4.43839431e-02
  7.05833733e-02  1.67522222e-01  1.68593049e-01  1.89838856e-02
  6.91324919e-02  8.01852345e-02  2.97729820e-02  7.64898807e-02
  1.00562736e-01  2.10536271e-02  1.94413066e-01  1.62174404e-02
  5.90565801e-03  3.52018327e-02  3.70490849e-02  5.91987520e-02
  8.37476403e-02  7.61407316e-02  1.54692948e-01  3.16945612e-02
 -2.85925418e-02  5.33572882e-02  5.65931499e-02  2.87396014e-02
  2.45680183e-01  4.31163013e-02  2.69003689e-01 -5.32408059e-03
  7.38938004e-02  3.31917554e-02  6.10759109e-02  5.02575040e-02
  4.49934602e-02  1.39338970e-02  1.68341666e-01  7.50322789e-02
  4.57408428e-02  2.22438574e-02  6.51418567e-02 -1.11887977e-02
 -1.33889914e-02  6.03830814e-02  1.32152057e+00  2.09299266e-01
  9.96533930e-01  1.13578796e+00  1.14495084e-01  9.10566896e-02
  6.38586134e-02  3.55152041e-02  5.21996617e-03  6.74601793e-02
  4.68175709e-02  6.15027994e-02  5.36249876e-02  5.66853136e-02
  8.27483535e-02  1.71496779e-01  1.84717864e-01  8.33420306e-02
  7.95935988e-02  4.44158465e-02  5.68877161e-03 -5.90346754e-03
  1.09684154e-01  5.76405376e-02  4.23223525e-02  1.37956142e-02
  7.89682120e-02  2.21813172e-02  6.27085418e-02  3.60844731e-02
  4.60761338e-02  1.70422494e-02 -1.31329894e-02  1.69855505e-02
  1.31652594e-01 -1.09166205e-02 -4.20551226e-02  4.72818017e-02
  7.57907331e-02  8.97141248e-02  4.18040752e-02  7.39254355e-02
  7.20962882e-03  8.59746486e-02  2.43890285e-02  1.14061981e-02
  3.03133577e-02  4.03810591e-02  7.55462497e-02  1.08651698e-01
  1.27543509e-01  4.80126739e-02  6.18313551e-02 -6.47145063e-02
  3.39916795e-02  1.10305142e+00 -2.31067836e-02  2.63389349e-02
  5.40332347e-02 -4.16997075e-02  8.59755427e-02  7.69017637e-03
  7.48715997e-02 -4.22484726e-02  6.17729127e-03  5.36843985e-02
 -8.91721249e-03  4.88093495e-03  3.17054987e-02  1.01726830e-01
  3.71135026e-02  6.01826608e-02 -3.66677269e-02  4.98390496e-02
  2.06068546e-01  8.88476372e-02  1.74370855e-02  1.02010936e-01
  8.10090601e-02  4.94386256e-02  8.79103839e-02  5.73551655e-03
 -1.05986096e-01  1.11313358e-01 -5.62517345e-03 -1.24601871e-02
  9.31014121e-03  9.80042219e-02  1.04196757e-01 -3.23664099e-02
  7.58430362e-03  5.81212789e-02  1.30488425e-02  5.65502495e-02
  5.89881241e-02  6.78421408e-02  3.79012674e-02  3.38378549e-02
  2.57097185e-03  1.50097787e-01  8.27773064e-02  2.02520639e-01
 -1.44311368e-01 -3.98197994e-02  1.07996762e-02  4.53130901e-02
 -3.29648554e-02 -1.96437165e-02  1.39778703e-02  1.49369955e-01
 -9.32303369e-02  2.11808085e-01  4.56261039e-02  6.68140799e-02
  7.39328861e-02  1.12869114e-01  1.06384575e-01  1.65177882e-03
  9.18942690e-03  1.37586683e-01  1.63558483e-01  1.95018500e-02
  3.14676315e-02  5.04276305e-02  4.95878756e-02  3.27654123e-01
  2.72938311e-02  5.70789576e-02  1.39829010e-01  2.83512771e-02
  3.89679670e-02  5.66574335e-02  2.00495124e-02 -1.71717852e-02
  9.84091163e-02  3.24096829e-02  8.41194391e-03  6.75219148e-02
  5.85973859e-02  2.28786767e-02  1.68369561e-02  5.18757701e-02
  5.44054806e-02  6.02139980e-02  1.28237903e-03 -2.01308355e-02
  7.66055286e-02  1.32152057e+00  2.15116918e-01  9.10123587e-02
  1.13578796e+00  4.75154221e-02 -4.06627208e-02 -4.57942039e-02
  5.52130789e-02  3.50861400e-02  2.25339621e-01  1.98623240e-02
  6.75348341e-02  8.21639597e-03  5.28500676e-02 -8.09216499e-03
  7.85904676e-02  3.81121635e-02  1.05353147e-02  3.36059481e-02
  1.60533220e-01  3.10152620e-02  1.15907049e+00 -6.38897717e-02
 -8.02858546e-02  8.71339440e-03 -1.89647898e-02  1.13596469e-02
  1.19660646e-02  7.64576942e-02  9.84314680e-02  1.30659163e-01
  1.48241699e-01  8.29605162e-02 -9.32544470e-03  3.73312086e-02
  1.70892775e-02  1.33039206e-02  4.72194850e-02  2.79270262e-02
  2.82214433e-02  1.67475343e-02  2.40447521e-02  4.49717492e-02
  9.12062973e-02 -8.27895850e-03  7.26203620e-03  1.97666734e-02
  1.18753910e-02  1.21647269e-02 -7.29411840e-03 -2.25766450e-02
  5.32625318e-02 -1.29518136e-02 -2.51199305e-03  2.67498046e-02
  4.45646942e-02  1.73286945e-02  6.15219176e-02  7.77029991e-03
  1.42402977e-01  1.53127789e-01 -5.25526032e-02  2.31342465e-01
  2.68134326e-02  1.44666135e-01 -9.39687937e-02 -4.85691428e-03
  6.62443936e-02 -5.26733696e-03 -4.51344997e-02  1.21751100e-01
  1.30945295e-02  1.39474541e-01  2.45443285e-01 -8.71787667e-02
 -7.87445158e-02  3.34095210e-02 -7.01290369e-02 -2.05694139e-02
  5.18339872e-02  3.46885920e-02  3.58940214e-02  1.37916505e-02
 -6.77061826e-03  6.60994649e-03 -1.38191804e-01 -1.37197733e-01
  1.59763545e-01  1.68601125e-02  3.48171592e-02  1.47535920e-01
 -6.29363731e-02  6.18443191e-02  5.07774204e-02  6.35351986e-02
  3.84767652e-02  4.70718890e-02 -1.74181163e-03  6.50761873e-02
  3.93453538e-02  5.38258851e-02 -2.74938345e-03 -6.19174540e-03
  2.16425657e-02 -6.68946579e-02 -6.38365746e-03  1.22261643e-02
  4.74427491e-02  8.94490927e-02  8.48742723e-02  7.58328140e-02
 -4.40894589e-02 -5.63520193e-03 -1.84510201e-01  7.06057250e-02
  5.42053580e-02  3.85737568e-02  3.98079157e-02  1.04253292e-02
 -4.31665778e-02  6.52985871e-02  2.96494663e-02  3.03098410e-02
  4.65863645e-02  6.54803663e-02 -6.78417683e-02  7.44323730e-02
  8.56304169e-03  5.43009788e-02 -8.71616602e-03 -6.08476996e-03
  2.11411715e-02  3.97630632e-02 -1.56930089e-02  2.03065574e-02
  1.29924238e-01  9.96345878e-02  8.65702033e-02  2.07971334e-02
  8.84148329e-02 -3.46814543e-02  1.53868049e-01  8.94173980e-03
  1.37743860e-01  6.82695210e-03  8.43458772e-02  2.67838389e-02
  2.27694213e-03  6.06577992e-02 -1.15653425e-02 -3.03455293e-02
  7.40000606e-03  4.76924330e-02  1.35211945e-02 -1.40214786e-02
  1.19911730e-01  7.65237510e-02 -8.14928338e-02  5.99473268e-02
 -1.50649726e-01  5.79969138e-02  4.41592485e-02  1.63984150e-02
  3.53511572e-02  1.27799004e-01 -4.04831097e-02  4.59020436e-02
  5.15458435e-02  9.07965600e-02  1.53598189e-01  3.87598425e-02
 -1.14908740e-02  2.18188882e-01  1.22737789e+00  1.54587328e-02
  1.64111465e-01 -7.85071403e-03  3.03050578e-01  4.27083492e-01
  1.23987079e-01  9.20096219e-01  7.30472058e-02  1.05721688e+00
  2.82724619e-01  2.88192540e-01  2.09784120e-01  3.93240452e-01
  3.30212712e-03  3.67134988e-01 -3.02203745e-02 -1.30383149e-02
  3.85277420e-02  6.64850324e-02  7.49873519e-02 -3.52806151e-02
  2.37267315e-02 -4.15541530e-02 -4.22746018e-02  2.89195776e-03
 -9.34671760e-02  2.97289342e-02 -4.02720273e-03  2.40441710e-02
 -9.67743546e-02 -1.23163015e-02  2.82108188e-02 -1.16435565e-01
  3.19545120e-02  1.05919495e-01  9.39325392e-02 -1.10818446e-01
  7.71892965e-01  9.93520766e-02 -2.21642852e-02  2.17287689e-02
  5.34556210e-02 -6.42690063e-03 -2.55576223e-02 -3.23840976e-02
  2.12020576e-02 -1.76893100e-02 -9.06874239e-03 -1.50931329e-02
  8.17216039e-02  5.12663275e-02 -1.80139020e-02  1.93105340e-02
 -6.80997968e-04 -3.45324129e-02 -8.43713433e-02  3.32342982e-02
  3.50172818e-02  1.71950310e-01 -9.85587239e-02  3.92259806e-02
 -4.67114449e-02 -3.40261310e-02  7.19836950e-02 -8.88798684e-02
  5.82510233e-02 -8.03134590e-03  2.09444553e-01  1.34406984e-02
  1.93696290e-01  4.22820002e-02  3.35230052e-01 -3.29973102e-02
  1.28591448e-01  9.64989960e-02  6.82327598e-02  1.79261893e-01
  2.85186321e-02  5.37190586e-02  6.02751672e-02  2.64525712e-01
 -4.39710841e-02 -2.00648531e-02 -5.15557379e-02  4.91271615e-02
 -6.38678670e-04  4.87926006e-02 -2.01430842e-02  5.66921681e-02
  2.39510834e-02  8.33473951e-02  9.06016380e-02 -5.14791310e-02
  5.35481125e-02  5.77160865e-02  5.08970022e-02  6.50077313e-02
  7.26224035e-02  9.76762772e-02  1.32588148e-02  4.24564034e-02
 -1.49306655e-03 -2.18965784e-02 -4.64486331e-02  5.32836467e-02
 -1.97729617e-02  1.01927653e-01  6.77657127e-03 -3.00556421e-03
 -5.03664762e-02  1.31092191e-01 -4.36325371e-02 -8.15500543e-02
 -1.17063135e-01  9.92582142e-02  6.31540716e-02  2.70792097e-02
 -1.91355795e-02  2.12277770e-02 -1.38139948e-02 -2.20703110e-02
 -2.92055458e-02 -1.74128190e-02 -1.39613822e-02  9.32495892e-02
  4.40972745e-02 -2.83695310e-02  2.51341313e-02  3.86300981e-02
  5.63857406e-02 -2.49818414e-02  3.86173129e-02 -4.30099741e-02
 -1.60290599e-02  3.71454060e-02 -3.61546874e-04  4.03629541e-02
 -1.00408196e-02 -1.74351633e-02 -9.65968519e-03  9.76364315e-03
  9.04129297e-02 -2.29984075e-02  1.04363889e-01  6.68987632e-03
  1.10348687e-01 -1.48155242e-02  1.32031143e-02  1.01650745e-01
  7.88207352e-03 -1.31173208e-02  2.67472118e-02 -7.43062794e-03
 -6.60109222e-02 -1.63126215e-02 -1.77434012e-02 -2.96611860e-02
 -5.11451662e-02 -8.47190619e-04  1.67020112e-02 -6.21366203e-02
 -5.70061952e-02  6.16841018e-03 -3.01022902e-02  1.84210390e-02
 -5.58893308e-02 -1.20886564e-02 -2.31932402e-02 -2.72027627e-02
 -4.79909331e-02 -2.14013383e-02 -1.56876817e-02 -1.31868795e-02
 -4.30381000e-02 -4.67021316e-02 -2.00222135e-02 -9.06021148e-03
  5.39416969e-02 -4.83481139e-02  1.13494098e-02  6.40647262e-02
  1.85675025e-02 -7.33228177e-02 -4.38425839e-02  7.46570975e-02
  1.33814603e-01  1.29658729e-02  6.82724565e-02  8.15052539e-02
 -3.04353163e-02  2.67684013e-02  2.76033580e-02  7.37988949e-03
  2.93421298e-02  7.28320926e-02  4.68192995e-03  4.77221310e-02
  8.43520463e-03  4.62574512e-02 -1.70229301e-02  4.08601463e-02
  1.64497942e-02  1.45873427e-03 -1.10320747e-02  5.38532436e-03
  1.54513270e-02 -9.67278332e-03 -8.71005654e-03  7.53307641e-02
  1.37106180e-02 -8.77082348e-05  5.43760061e-02  3.12630236e-02
  4.50442582e-02  6.33048415e-02  9.27669108e-02  1.07004046e-02
 -5.10309264e-02  1.11036226e-01  2.23553479e-02 -5.08303940e-03
  1.90528184e-02  9.65246558e-03 -1.95929557e-02  1.92841589e-02
 -2.28589326e-02  3.03715467e-03  4.01459038e-02 -7.72008300e-03
 -4.34151441e-02  4.82810587e-02  3.23484987e-02  1.19291395e-02
 -2.42087841e-02  5.28432429e-03  5.09251654e-03 -5.34559786e-03
  1.30147338e-02  4.80021089e-02 -4.27779555e-03  5.21139801e-03
 -7.27065057e-02  2.84436047e-02 -2.44291872e-02 -3.07126343e-03
 -7.63043016e-03  1.21322572e-02  6.81445897e-02 -2.59152427e-02
 -1.90871581e-02 -9.85619426e-03  2.13399529e-02 -2.63433382e-02
  2.20403075e-04  3.91515642e-02 -5.38280085e-02 -1.57610029e-02
  1.73297524e-03 -1.00098252e-02 -9.65937972e-03 -3.05786133e-02
 -2.34823972e-02 -6.29366487e-02 -4.06112373e-02  1.99672133e-02], shape=(796,), dtype=float32)
rounded label:tf.Tensor(
[ 1.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0. -0.  0.  0. -0.
 -0.  0.  0. -0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0. -0. -0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  1.  0.  1.
  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0. -0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.
  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0. -0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0. -0. -0.  0.  1.  0.  1.  1.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0. -0. -0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  1. -0.  0.  0. -0.
  0.  0.  0. -0.  0.  0. -0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.
  0.  0.  0.  0. -0.  0. -0. -0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0. -0. -0.  0.  0. -0. -0.  0.  0. -0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  1.  0.  0.
  1.  0. -0. -0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.
  1. -0. -0.  0. -0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0. -0.  0.  0.  0.  0. -0. -0.  0. -0. -0.  0.  0.  0.
  0.  0.  0.  0. -0.  0.  0.  0. -0. -0.  0. -0. -0.  0.  0.  0.  0. -0.
 -0.  0. -0. -0.  0.  0.  0.  0. -0.  0. -0. -0.  0.  0.  0.  0. -0.  0.
  0.  0.  0.  0. -0.  0.  0.  0. -0. -0.  0. -0. -0.  0.  0.  0.  0.  0.
 -0. -0. -0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0. -0.  0.  0.  0.
 -0. -0.  0.  0. -0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.
  0.  0. -0. -0.  0.  0.  0. -0.  0.  0. -0.  0. -0.  0.  0.  0.  0.  0.
 -0.  0.  0.  0.  0.  0. -0.  0.  1.  0.  0. -0.  0.  0.  0.  1.  0.  1.
  0.  0.  0.  0.  0.  0. -0. -0.  0.  0.  0. -0.  0. -0. -0.  0. -0.  0.
 -0.  0. -0. -0.  0. -0.  0.  0.  0. -0.  1.  0. -0.  0.  0. -0. -0. -0.
  0. -0. -0. -0.  0.  0. -0.  0. -0. -0. -0.  0.  0.  0. -0.  0. -0. -0.
  0. -0.  0. -0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.
 -0. -0. -0.  0. -0.  0. -0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.
  0.  0. -0. -0. -0.  0. -0.  0.  0. -0. -0.  0. -0. -0. -0.  0.  0.  0.
 -0.  0. -0. -0. -0. -0. -0.  0.  0. -0.  0.  0.  0. -0.  0. -0. -0.  0.
 -0.  0. -0. -0. -0.  0.  0. -0.  0.  0.  0. -0.  0.  0.  0. -0.  0. -0.
 -0. -0. -0. -0. -0. -0.  0. -0. -0.  0. -0.  0. -0. -0. -0. -0. -0. -0.
 -0. -0. -0. -0. -0. -0.  0. -0.  0.  0.  0. -0. -0.  0.  0.  0.  0.  0.
 -0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0. -0.  0.  0. -0.
 -0.  0.  0. -0.  0.  0.  0.  0.  0.  0. -0.  0.  0. -0.  0.  0. -0.  0.
 -0.  0.  0. -0. -0.  0.  0.  0. -0.  0.  0. -0.  0.  0. -0.  0. -0.  0.
 -0. -0. -0.  0.  0. -0. -0. -0.  0. -0.  0.  0. -0. -0.  0. -0. -0. -0.
 -0. -0. -0.  0.], shape=(796,), dtype=float32)
predicted label rank:[2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.14982584, shape=(), dtype=float32)
-------
true label:[2, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[3 1 1 3 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 4 1 1 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 1 1 5 1 1 1 1 1 2 1 2
 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 6 1 1 1 1 1 2 1 2 1
 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 7 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[ 7.00010538e-01  9.60081637e-01  3.73307407e-01  7.95486212e-01
  3.73634577e-01  2.84933299e-01  4.50577557e-01  2.53166765e-01
  2.79241532e-01  6.34120226e-01  1.06126800e-01  2.71687239e-01
  1.47052914e-01  8.84302557e-02  2.68233597e-01  3.45915169e-01
  1.15104541e-01  1.98084921e-01  1.21914208e-01  2.61778772e-01
  3.37285697e-02  2.25033313e-01  2.54001051e-01  4.06809211e-01
  2.06963688e-01  4.51784730e-02  2.30091274e-01  6.04293793e-02
  5.38260698e-01  3.58400315e-01  1.04454651e-01  5.52254468e-02
 -2.05671787e-02  5.94174713e-02  4.15811092e-02 -5.01380861e-03
 -5.94115928e-02  3.20295393e-02  1.33172870e-01 -6.26203492e-02
  3.66081655e-01  1.35617524e-01  5.53928912e-02 -7.17675239e-02
  1.11445397e-01  7.34116882e-02  1.11401916e-01  4.50679809e-02
  1.31813884e-02  2.97560394e-02  4.73158062e-01  1.20410919e-01
  2.86402971e-01  1.39097035e-01  5.68524748e-02  2.21243948e-02
  9.52047288e-01  3.56431156e-02  1.09357849e-01  6.21028394e-02
  3.64705920e-03  1.23014599e-02  4.14594263e-02  3.49076539e-02
  1.19611442e-01 -1.79160237e-02 -5.88903800e-02  1.68937057e-01
  3.78672034e-02  9.33377743e-02  1.25000387e-01  1.83344096e-01
  2.77280271e-01  2.16101795e-01  1.87772334e-01  7.28691667e-02
  1.03608057e-01  7.88489580e-02  3.23484570e-01  2.31951654e-01
  8.19870234e-02  5.80142140e-02  3.60952139e-01  4.65824753e-02
 -5.44873029e-02  1.30998641e-02  1.51501983e-01  1.32152057e+00
  3.84891629e-01  1.32152057e+00  1.32152057e+00  9.81884599e-02
  5.54940999e-02  1.11014187e-01  7.85359442e-02  1.25138551e-01
  5.76986521e-02  7.30175674e-02  2.48195648e-01  9.51764584e-02
  1.65936828e-01  6.05403483e-02  9.93297398e-02  3.10565978e-02
  1.48731112e-01  4.11303341e-02  9.95329916e-02  4.90168780e-02
  4.83328998e-02 -2.73883119e-02  1.28641725e-04  6.96885288e-02
  9.19089913e-02 -1.48860812e-01  2.45947003e-01  1.45456165e-01
  4.80712950e-02  6.15911186e-02  1.84973776e-02  1.58465207e-02
 -5.41832298e-02  8.92271996e-02  1.44553125e-01  1.07687250e-01
  5.18745035e-02  9.45266038e-02  8.95093679e-02 -2.06074789e-02
  8.40387940e-02  5.39606661e-02  7.90362358e-02  7.14455396e-02
  7.56609887e-02  1.01481870e-01  1.24223858e-01  3.63581032e-01
  1.86802834e-01  2.82086581e-02  1.13035902e-01  5.58404624e-02
  6.70581162e-02  4.16147113e-02  3.18517238e-02  6.95530325e-02
  2.55571008e-02  3.37874740e-02  2.44925350e-01  4.01990414e-02
  7.85989612e-02  3.17054093e-02 -1.43276155e-03  1.94405973e-01
  1.09146237e-02  5.91955334e-02  1.11307949e-02  7.78883547e-02
  3.12609822e-02  1.68352991e-01  1.75299436e-01  4.25538868e-02
  5.23367673e-02  3.43385488e-02  2.33119458e-01  1.79620296e-01
  4.08027619e-02  8.65758061e-02  4.83621806e-02  4.43839431e-02
  7.05833733e-02  1.67522222e-01  1.68593049e-01  1.89838856e-02
  6.91324919e-02  8.01852345e-02  2.97729820e-02  7.64898807e-02
  1.00562736e-01  2.10536271e-02  1.94413066e-01  1.62174404e-02
  5.90565801e-03  3.52018327e-02  3.70490849e-02  5.91987520e-02
  8.37476403e-02  7.61407316e-02  1.54692948e-01  3.16945612e-02
 -2.85925418e-02  5.33572882e-02  5.65931499e-02  2.87396014e-02
  2.45680183e-01  4.31163013e-02  2.69003689e-01 -5.32408059e-03
  7.38938004e-02  3.31917554e-02  6.10759109e-02  5.02575040e-02
  4.49934602e-02  1.39338970e-02  1.68341666e-01  7.50322789e-02
  4.57408428e-02  2.22438574e-02  6.51418567e-02 -1.11887977e-02
 -1.33889914e-02  6.03830814e-02  1.32152057e+00  2.09299266e-01
  9.96533930e-01  1.13578796e+00  1.14495084e-01  9.10566896e-02
  6.38586134e-02  3.55152041e-02  5.21996617e-03  6.74601793e-02
  4.68175709e-02  6.15027994e-02  5.36249876e-02  5.66853136e-02
  8.27483535e-02  1.71496779e-01  1.84717864e-01  8.33420306e-02
  7.95935988e-02  4.44158465e-02  5.68877161e-03 -5.90346754e-03
  1.09684154e-01  5.76405376e-02  4.23223525e-02  1.37956142e-02
  7.89682120e-02  2.21813172e-02  6.27085418e-02  3.60844731e-02
  4.60761338e-02  1.70422494e-02 -1.31329894e-02  1.69855505e-02
  1.31652594e-01 -1.09166205e-02 -4.20551226e-02  4.72818017e-02
  7.57907331e-02  8.97141248e-02  4.18040752e-02  7.39254355e-02
  7.20962882e-03  8.59746486e-02  2.43890285e-02  1.14061981e-02
  3.03133577e-02  4.03810591e-02  7.55462497e-02  1.08651698e-01
  1.27543509e-01  4.80126739e-02  6.18313551e-02 -6.47145063e-02
  3.39916795e-02  1.10305142e+00 -2.31067836e-02  2.63389349e-02
  5.40332347e-02 -4.16997075e-02  8.59755427e-02  7.69017637e-03
  7.48715997e-02 -4.22484726e-02  6.17729127e-03  5.36843985e-02
 -8.91721249e-03  4.88093495e-03  3.17054987e-02  1.01726830e-01
  3.71135026e-02  6.01826608e-02 -3.66677269e-02  4.98390496e-02
  2.06068546e-01  8.88476372e-02  1.74370855e-02  1.02010936e-01
  8.10090601e-02  4.94386256e-02  8.79103839e-02  5.73551655e-03
 -1.05986096e-01  1.11313358e-01 -5.62517345e-03 -1.24601871e-02
  9.31014121e-03  9.80042219e-02  1.04196757e-01 -3.23664099e-02
  7.58430362e-03  5.81212789e-02  1.30488425e-02  5.65502495e-02
  5.89881241e-02  6.78421408e-02  3.79012674e-02  3.38378549e-02
  2.57097185e-03  1.50097787e-01  8.27773064e-02  2.02520639e-01
 -1.44311368e-01 -3.98197994e-02  1.07996762e-02  4.53130901e-02
 -3.29648554e-02 -1.96437165e-02  1.39778703e-02  1.49369955e-01
 -9.32303369e-02  2.11808085e-01  4.56261039e-02  6.68140799e-02
  7.39328861e-02  1.12869114e-01  1.06384575e-01  1.65177882e-03
  9.18942690e-03  1.37586683e-01  1.63558483e-01  1.95018500e-02
  3.14676315e-02  5.04276305e-02  4.95878756e-02  3.27654123e-01
  2.72938311e-02  5.70789576e-02  1.39829010e-01  2.83512771e-02
  3.89679670e-02  5.66574335e-02  2.00495124e-02 -1.71717852e-02
  9.84091163e-02  3.24096829e-02  8.41194391e-03  6.75219148e-02
  5.85973859e-02  2.28786767e-02  1.68369561e-02  5.18757701e-02
  5.44054806e-02  6.02139980e-02  1.28237903e-03 -2.01308355e-02
  7.66055286e-02  1.32152057e+00  2.15116888e-01  9.10124183e-02
  1.13578796e+00  4.75154221e-02 -4.06627208e-02 -4.57942039e-02
  5.52130789e-02  3.50861400e-02  2.25339621e-01  1.98623240e-02
  6.75348341e-02  8.21639597e-03  5.28500676e-02 -8.09216499e-03
  7.85904676e-02  3.81121635e-02  1.05353147e-02  3.36059481e-02
  1.60533220e-01  3.10152620e-02  1.15907049e+00 -6.38897717e-02
 -8.02858546e-02  8.71339440e-03 -1.89647898e-02  1.13596469e-02
  1.19660646e-02  7.64576942e-02  9.84314680e-02  1.30659163e-01
  1.48241699e-01  8.29605162e-02 -9.32544470e-03  3.73312086e-02
  1.70892775e-02  1.33039206e-02  4.72194850e-02  2.79270262e-02
  2.82214433e-02  1.67475343e-02  2.40447521e-02  4.49717492e-02
  9.12062973e-02 -8.27895850e-03  7.26203620e-03  1.97666734e-02
  1.18753910e-02  1.21647269e-02 -7.29411840e-03 -2.25766450e-02
  5.32625318e-02 -1.29518136e-02 -2.51199305e-03  2.67498046e-02
  4.45646942e-02  1.73286945e-02  6.15219176e-02  7.77029991e-03
  1.42402977e-01  1.53127789e-01 -5.25526032e-02  2.31342465e-01
  2.68134326e-02  1.44666135e-01 -9.39687937e-02 -4.85691428e-03
  6.62443936e-02 -5.26733696e-03 -4.51344997e-02  1.21751100e-01
  1.30945295e-02  1.39474541e-01  2.45443285e-01 -8.71787667e-02
 -7.87445158e-02  3.34095210e-02 -7.01290369e-02 -2.05694139e-02
  5.18339872e-02  3.46885920e-02  3.58940214e-02  1.37916505e-02
 -6.77061826e-03  6.60994649e-03 -1.38191804e-01 -1.37197733e-01
  1.59763545e-01  1.68601125e-02  3.48171592e-02  1.47535920e-01
 -6.29363731e-02  6.18443191e-02  5.07774204e-02  6.35351986e-02
  3.84767652e-02  4.70718890e-02 -1.74181163e-03  6.50761873e-02
  3.93453538e-02  5.38258851e-02 -2.74938345e-03 -6.19174540e-03
  2.16425657e-02 -6.68946579e-02 -6.38365746e-03  1.22261643e-02
  4.74427491e-02  8.94490927e-02  8.48742723e-02  7.58328140e-02
 -4.40894589e-02 -5.63520193e-03 -1.84510201e-01  7.06057250e-02
  5.42053580e-02  3.85737568e-02  3.98079157e-02  1.04253292e-02
 -4.31665778e-02  6.52985871e-02  2.96494663e-02  3.03098410e-02
  4.65863645e-02  6.54803663e-02 -6.78417683e-02  7.44323730e-02
  8.56304169e-03  5.43009788e-02 -8.71616602e-03 -6.08476996e-03
  2.11411715e-02  3.97630632e-02 -1.56930089e-02  2.03065574e-02
  1.29924238e-01  9.96345878e-02  8.65702033e-02  2.07971334e-02
  8.84148329e-02 -3.46814543e-02  1.53868049e-01  8.94173980e-03
  1.37743860e-01  6.82695210e-03  8.43458772e-02  2.67838389e-02
  2.27694213e-03  6.06577992e-02 -1.15653425e-02 -3.03455293e-02
  7.40000606e-03  4.76924330e-02  1.35211945e-02 -1.40214786e-02
  1.19911730e-01  7.65237510e-02 -8.14928338e-02  5.99473268e-02
 -1.50649726e-01  5.79969138e-02  4.41592485e-02  1.63984150e-02
  3.53511572e-02  1.27799004e-01 -4.04831097e-02  4.59020436e-02
  5.15458435e-02  9.07965600e-02  1.53598189e-01  3.87598425e-02
 -1.14908740e-02  2.18188882e-01  1.22737789e+00  1.54587328e-02
  1.64111465e-01 -7.85071403e-03  3.03050578e-01  4.27083492e-01
  1.23987079e-01  9.20096219e-01  7.30472058e-02  1.05721688e+00
  2.82724619e-01  2.88192540e-01  2.09784120e-01  3.93240452e-01
  3.30212712e-03  3.67134988e-01 -3.02203745e-02 -1.30383149e-02
  3.85277420e-02  6.64850324e-02  7.49873519e-02 -3.52806151e-02
  2.37267315e-02 -4.15541530e-02 -4.22746018e-02  2.89195776e-03
 -9.34671760e-02  2.97289342e-02 -4.02720273e-03  2.40441710e-02
 -9.67743546e-02 -1.23163015e-02  2.82108188e-02 -1.16435565e-01
  3.19545120e-02  1.05919495e-01  9.39325392e-02 -1.10818446e-01
  7.71892965e-01  9.93520766e-02 -2.21642852e-02  2.17287689e-02
  5.34556210e-02 -6.42690063e-03 -2.55576223e-02 -3.23840976e-02
  2.12020576e-02 -1.76893100e-02 -9.06874239e-03 -1.50931329e-02
  8.17216039e-02  5.12663275e-02 -1.80139020e-02  1.93105340e-02
 -6.80997968e-04 -3.45324129e-02 -8.43713433e-02  3.32342982e-02
  3.50172818e-02  1.71950310e-01 -9.85587239e-02  3.92259806e-02
 -4.67114449e-02 -3.40261310e-02  7.19836950e-02 -8.88798684e-02
  5.82510233e-02 -8.03134590e-03  2.09444553e-01  1.34406984e-02
  1.93696290e-01  4.22820002e-02  3.35230052e-01 -3.29973102e-02
  1.28591448e-01  9.64989960e-02  6.82327598e-02  1.79261893e-01
  2.85186321e-02  5.37190586e-02  6.02751672e-02  2.64525712e-01
 -4.39710841e-02 -2.00648531e-02 -5.15557379e-02  4.91271615e-02
 -6.38678670e-04  4.87926006e-02 -2.01430842e-02  5.66921681e-02
  2.39510834e-02  8.33473951e-02  9.06016380e-02 -5.14791310e-02
  5.35481125e-02  5.77160865e-02  5.08970022e-02  6.50077313e-02
  7.26224035e-02  9.76762772e-02  1.32588148e-02  4.24564034e-02
 -1.49306655e-03 -2.18965784e-02 -4.64486331e-02  5.32836467e-02
 -1.97729617e-02  1.01927653e-01  6.77657127e-03 -3.00556421e-03
 -5.03664762e-02  1.31092191e-01 -4.36325371e-02 -8.15500543e-02
 -1.17063135e-01  9.92582142e-02  6.31540716e-02  2.70792097e-02
 -1.91355795e-02  2.12277770e-02 -1.38139948e-02 -2.20703110e-02
 -2.92055458e-02 -1.74128190e-02 -1.39613822e-02  9.32495892e-02
  4.40972745e-02 -2.83695310e-02  2.51341313e-02  3.86300981e-02
  5.63857406e-02 -2.49818414e-02  3.86173129e-02 -4.30099741e-02
 -1.60290599e-02  3.71454060e-02 -3.61546874e-04  4.03629541e-02
 -1.00408196e-02 -1.74351633e-02 -9.65968519e-03  9.76364315e-03
  9.04129297e-02 -2.29984075e-02  1.04363889e-01  6.68987632e-03
  1.10348687e-01 -1.48155242e-02  1.32031143e-02  1.01650745e-01
  7.88207352e-03 -1.31173208e-02  2.67472118e-02 -7.43062794e-03
 -6.60109222e-02 -1.63126215e-02 -1.77434012e-02 -2.96611860e-02
 -5.11451662e-02 -8.47190619e-04  1.67020112e-02 -6.21366203e-02
 -5.70061952e-02  6.16841018e-03 -3.01022902e-02  1.84210390e-02
 -5.58893308e-02 -1.20886564e-02 -2.31932402e-02 -2.72027627e-02
 -4.79909331e-02 -2.14013383e-02 -1.56876817e-02 -1.31868795e-02
 -4.30381000e-02 -4.67021316e-02 -2.00222135e-02 -9.06021148e-03
  5.39416969e-02 -4.83481139e-02  1.13494098e-02  6.40647262e-02
  1.85675025e-02 -7.33228177e-02 -4.38425839e-02  7.46570975e-02
  1.33814603e-01  1.29658729e-02  6.82724565e-02  8.15052539e-02
 -3.04353163e-02  2.67684013e-02  2.76033580e-02  7.37988949e-03
  2.93421298e-02  7.28320926e-02  4.68192995e-03  4.77221310e-02
  8.43520463e-03  4.62574512e-02 -1.70229301e-02  4.08601463e-02
  1.64497942e-02  1.45873427e-03 -1.10320747e-02  5.38532436e-03
  1.54513270e-02 -9.67278332e-03 -8.71005654e-03  7.53307641e-02
  1.37106180e-02 -8.77082348e-05  5.43760061e-02  3.12630236e-02
  4.50442582e-02  6.33048415e-02  9.27669108e-02  1.07004046e-02
 -5.10309264e-02  1.11036226e-01  2.23553479e-02 -5.08303940e-03
  1.90528184e-02  9.65246558e-03 -1.95929557e-02  1.92841589e-02
 -2.28589326e-02  3.03715467e-03  4.01459038e-02 -7.72008300e-03
 -4.34151441e-02  4.82810587e-02  3.23484987e-02  1.19291395e-02
 -2.42087841e-02  5.28432429e-03  5.09251654e-03 -5.34559786e-03
  1.30147338e-02  4.80021089e-02 -4.27779555e-03  5.21139801e-03
 -7.27065057e-02  2.84436047e-02 -2.44291872e-02 -3.07126343e-03
 -7.63043016e-03  1.21322572e-02  6.81445897e-02 -2.59152427e-02
 -1.90871581e-02 -9.85619426e-03  2.13399529e-02 -2.63433382e-02
  2.20403075e-04  3.91515642e-02 -5.38280085e-02 -1.57610029e-02
  1.73297524e-03 -1.00098252e-02 -9.65937972e-03 -3.05786133e-02
 -2.34823972e-02 -6.29366487e-02 -4.06112373e-02  1.99672133e-02], shape=(796,), dtype=float32)
rounded label:tf.Tensor(
[ 1.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0. -0.  0.  0. -0.
 -0.  0.  0. -0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0. -0. -0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  1.  0.  1.
  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0. -0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.
  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0. -0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0. -0. -0.  0.  1.  0.  1.  1.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0. -0. -0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  1. -0.  0.  0. -0.
  0.  0.  0. -0.  0.  0. -0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.
  0.  0.  0.  0. -0.  0. -0. -0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0. -0. -0.  0.  0. -0. -0.  0.  0. -0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  1.  0.  0.
  1.  0. -0. -0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.
  1. -0. -0.  0. -0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0. -0.  0.  0.  0.  0. -0. -0.  0. -0. -0.  0.  0.  0.
  0.  0.  0.  0. -0.  0.  0.  0. -0. -0.  0. -0. -0.  0.  0.  0.  0. -0.
 -0.  0. -0. -0.  0.  0.  0.  0. -0.  0. -0. -0.  0.  0.  0.  0. -0.  0.
  0.  0.  0.  0. -0.  0.  0.  0. -0. -0.  0. -0. -0.  0.  0.  0.  0.  0.
 -0. -0. -0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0. -0.  0.  0.  0.
 -0. -0.  0.  0. -0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.
  0.  0. -0. -0.  0.  0.  0. -0.  0.  0. -0.  0. -0.  0.  0.  0.  0.  0.
 -0.  0.  0.  0.  0.  0. -0.  0.  1.  0.  0. -0.  0.  0.  0.  1.  0.  1.
  0.  0.  0.  0.  0.  0. -0. -0.  0.  0.  0. -0.  0. -0. -0.  0. -0.  0.
 -0.  0. -0. -0.  0. -0.  0.  0.  0. -0.  1.  0. -0.  0.  0. -0. -0. -0.
  0. -0. -0. -0.  0.  0. -0.  0. -0. -0. -0.  0.  0.  0. -0.  0. -0. -0.
  0. -0.  0. -0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.
 -0. -0. -0.  0. -0.  0. -0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.
  0.  0. -0. -0. -0.  0. -0.  0.  0. -0. -0.  0. -0. -0. -0.  0.  0.  0.
 -0.  0. -0. -0. -0. -0. -0.  0.  0. -0.  0.  0.  0. -0.  0. -0. -0.  0.
 -0.  0. -0. -0. -0.  0.  0. -0.  0.  0.  0. -0.  0.  0.  0. -0.  0. -0.
 -0. -0. -0. -0. -0. -0.  0. -0. -0.  0. -0.  0. -0. -0. -0. -0. -0. -0.
 -0. -0. -0. -0. -0. -0.  0. -0.  0.  0.  0. -0. -0.  0.  0.  0.  0.  0.
 -0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0. -0.  0.  0. -0.
 -0.  0.  0. -0.  0.  0.  0.  0.  0.  0. -0.  0.  0. -0.  0.  0. -0.  0.
 -0.  0.  0. -0. -0.  0.  0.  0. -0.  0.  0. -0.  0.  0. -0.  0. -0.  0.
 -0. -0. -0.  0.  0. -0. -0. -0.  0. -0.  0.  0. -0. -0.  0. -0. -0. -0.
 -0. -0. -0.  0.], shape=(796,), dtype=float32)
predicted label rank:[2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.152041, shape=(), dtype=float32)
-------
true label:[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[ 1.05850101e+00  9.64848578e-01  6.00265086e-01  6.12268925e-01
  7.66958416e-01  7.51397848e-01  5.49411774e-01  2.71917760e-01
  2.20831603e-01  4.51620698e-01  3.23739856e-01  2.74121314e-01
  4.41308320e-03  2.76342481e-02  3.21173638e-01  3.28404665e-01
  9.03475881e-02  1.99805319e-01  2.31497437e-01  1.95358217e-01
  1.04009897e-01  2.55976647e-01  5.92487305e-02  2.17846245e-01
  7.62342453e-01  1.34152800e-01  3.21143895e-01  2.26389736e-01
  7.07685649e-02  3.58664334e-01  5.18852413e-01  2.52817720e-02
 -3.21237072e-02  1.15691423e-02  1.70460194e-02 -1.59827620e-02
  3.20698082e-01 -3.02632377e-02  1.04718804e-01 -1.19581744e-02
  5.91828644e-01  1.06439322e-01  7.99242109e-02  1.66982830e-01
  7.69809783e-02  9.46904719e-02  1.15895256e-01  6.44711554e-02
 -1.60313994e-02  7.95673132e-02  3.22789401e-01  1.76275313e-01
  4.08794165e-01  1.35788560e-01  3.32917869e-02  5.60148060e-03
  8.39209020e-01 -5.60176075e-02  1.05789229e-01 -3.18184346e-02
  7.19733536e-02  3.10882926e-04  7.16130883e-02  1.14427954e-02
  7.88186640e-02  3.63907665e-02  9.09999609e-02  8.72454345e-02
  6.88474625e-02  9.23839658e-02  6.59416467e-02  2.31431007e-01
  1.26803517e-01  1.17278829e-01  9.92422253e-02  8.64069909e-02
  1.35878175e-01  1.08700678e-01  2.27364063e-01  3.07503998e-01
  9.06196833e-02  9.46313292e-02  2.06518143e-01  4.57983911e-02
  1.78777874e-01 -1.50137022e-02 -2.65308768e-02  8.45866948e-02
  3.37752163e-01  7.90724158e-03  2.94623166e-01  6.41007423e-02
  1.60221487e-01  1.11014187e-01  6.35258555e-02  9.20442641e-02
  3.03093791e-02  5.92644662e-02  2.73802727e-01  9.74446237e-02
  1.67147875e-01  5.19078523e-02  9.95272845e-02  2.30948031e-02
  1.38233781e-01  3.35483849e-02  1.01903245e-01  2.08684057e-02
  3.48764360e-02 -4.69270349e-03  1.35058314e-02  6.20350093e-02
  9.95051265e-02 -3.08637321e-02  1.89575583e-01  1.54820323e-01
  5.95490336e-02  7.25788921e-02  1.75731331e-02  2.65717655e-02
 -4.97945994e-02  1.03137195e-01  1.47117436e-01  8.06756765e-02
  3.49651426e-02  8.91515613e-02  6.98942393e-02 -1.57898515e-02
  7.82720447e-02  3.63802314e-02  6.55109733e-02  7.14921057e-02
  5.33250272e-02  3.89624387e-02  5.42242229e-02  2.31147766e-01
  9.51730311e-02  3.30946743e-02  1.32006705e-01  7.31031448e-02
  7.57535100e-02  6.19523972e-02  6.03109449e-02  6.34159595e-02
  4.63098735e-02  2.38381624e-02  4.60156739e-01  4.25603092e-02
  7.22894520e-02  3.72439325e-02  9.27363336e-03  1.24622583e-01
  1.11872405e-02  7.34751523e-02  5.65243810e-02  4.85170037e-02
  3.17952782e-02  1.58790201e-01  2.98462629e-01  3.62691134e-02
  6.73649311e-02  4.04449254e-02  2.00742155e-01  1.11620620e-01
  3.94420624e-02  5.74156493e-02  4.85619903e-02  4.82050031e-02
  2.98750699e-02  1.31811023e-01  1.49746239e-01  5.77279627e-02
  1.05884194e-01  7.38032311e-02  2.94288248e-02  1.20174170e-01
  1.05641887e-01  6.58158958e-02  2.18655825e-01  6.60438091e-02
  7.81598240e-02  2.67317593e-02  1.39323145e-01  1.94565207e-02
  5.48811406e-02  9.66241956e-02  1.39683843e-01  5.07364869e-02
 -5.43321669e-03  4.31253165e-02 -1.24855861e-02  1.69347674e-02
  1.39382154e-01  7.88130164e-02  3.06982547e-01  4.81501222e-04
  5.80174029e-02  5.40234894e-02  3.86916995e-02  7.36564994e-02
  8.03721249e-02  1.64056420e-01  3.27198833e-01  1.53879344e-01
  4.70053911e-01  4.82176393e-02  4.44181412e-02  9.55674052e-03
 -7.49994144e-02  4.26172018e-02  1.22234136e-01  3.56357545e-02
  7.34961033e-03  3.88647377e-01  5.31762391e-02  6.74070716e-02
  1.03324458e-01  3.45493853e-02  4.56376672e-02  6.74601793e-02
  4.41712439e-02  5.93703240e-02  4.46533859e-02  4.29920554e-02
  7.86725581e-02  1.55867040e-01 -5.80531657e-02  9.34040993e-02
  7.72341788e-02  4.60256487e-02  3.39918733e-02  1.10315233e-02
  8.46837312e-02  4.03107703e-02  4.44572419e-02  5.06467819e-02
  7.40470588e-02  3.66104841e-02  3.83588225e-02  5.40159494e-02
  3.49920690e-02  2.48965025e-02 -1.00448653e-02 -3.85210216e-02
  3.00583929e-01 -1.85764506e-02 -9.11766440e-02  3.88678014e-02
  6.02694303e-02  8.15003514e-02  3.70105505e-02  1.35644376e-01
 -4.50232625e-03  1.34511501e-01 -1.14551708e-02 -8.52905214e-03
  6.32333159e-02  4.28880006e-02  7.79517442e-02  1.04479939e-01
  1.39360070e-01  7.73605853e-02  9.62098092e-02  2.43187040e-01
  6.48788661e-02  3.91881108e-01  9.22507942e-02  2.97241807e-02
  3.99513543e-02 -3.16845328e-02  7.33521134e-02  6.06140494e-03
  9.68872607e-02 -3.63421068e-02  8.63060355e-04  3.83743197e-02
 -1.38194859e-02  1.88519061e-02  1.67308748e-02  7.40385354e-02
  3.14481258e-02  3.00066620e-02 -4.30888534e-02  5.73937595e-03
  1.22051001e-01  9.37881172e-02  2.10694671e-02  7.92035908e-02
  7.86508769e-02  5.83002120e-02  8.56114626e-02  2.98728049e-03
 -1.91535383e-01  1.11817166e-01 -1.54477209e-02 -1.74068138e-02
  7.84389079e-02  9.87308174e-02  1.10728279e-01 -3.39512900e-02
  1.26261413e-02  4.30586040e-02  2.68666148e-02  3.64615172e-02
  2.02260613e-02 -1.69315934e-03  2.86037475e-02  4.68796790e-02
 -9.91910696e-04  1.57790095e-01  6.90202117e-02  1.69828802e-01
 -1.44007295e-01 -4.81235012e-02  3.47964019e-02  1.10680312e-01
  2.97389030e-02 -4.25107181e-02 -1.55336037e-02  8.05827826e-02
 -8.24809521e-02  7.97240436e-02  2.91563720e-02  7.98692852e-02
  1.97353274e-01  1.22669458e-01  8.47018510e-02 -1.14566088e-03
  2.64191628e-02  1.03977785e-01  7.34123290e-02  2.61737406e-03
  5.24872988e-02  7.21029192e-02  3.58988941e-02  4.64498639e-01
 -7.55483210e-02  9.42591131e-02  1.82858348e-01  4.19420898e-02
  7.43219256e-02  3.87920290e-02  8.83008540e-03 -3.91122028e-02
  8.72701406e-02  2.74047405e-02 -2.03160942e-03  6.96334839e-02
  2.96328217e-02 -2.97775865e-03  1.68494731e-02  1.04419947e-01
  9.94856805e-02 -9.21279192e-04 -6.56367838e-03 -7.36312941e-02
 -2.24977970e-01  8.29009414e-02  2.95689851e-02  2.10870355e-02
  3.18513811e-02 -2.01774538e-02 -7.30041862e-02  2.83898860e-01
  4.74572033e-02  4.84383553e-02  1.39011145e-01  3.15783620e-02
  9.04989243e-02  4.81533557e-02  1.16480663e-01 -3.37043852e-02
 -2.03324854e-02  2.79694796e-05  7.31806755e-02  6.00036085e-02
  1.48212105e-01  3.74730080e-02  2.89966166e-02  1.31021887e-01
 -3.55236828e-02  1.36407167e-02  1.03193074e-02 -3.20224985e-02
  3.38463485e-02  4.94500697e-02  5.18432707e-02  5.27896136e-02
  6.82980269e-02 -5.30242920e-03  1.10494643e-02  8.81290436e-03
  4.82821465e-03  3.41643840e-02  4.09487486e-02  1.86876655e-02
  3.58151644e-02  2.74082571e-02  1.15337968e-02  9.37693864e-02
  3.64163518e-02  3.08688819e-01 -1.09124109e-02  1.34519637e-02
  4.45489585e-02  5.35637140e-03  2.44596601e-03  6.75074756e-03
  7.36267120e-02  2.13569701e-02  9.45800543e-03  5.01700342e-02
  7.62206763e-02  3.14816982e-02  3.65179032e-02  1.37887895e-02
  1.49079263e-01  1.25649780e-01  2.51936466e-02  4.44713086e-02
  4.91024554e-02  1.13727167e-01 -2.28274614e-02 -3.98071483e-02
  3.79412621e-02  4.06762362e-02 -1.51282996e-02  1.00105837e-01
  5.50254583e-02  8.19461495e-02  2.77940333e-02  3.70841026e-02
 -6.19479492e-02  6.62635267e-03 -4.96644974e-02 -2.12222338e-02
  5.00397980e-02  3.82363051e-02  7.44797289e-03  2.81583965e-02
  5.42710721e-03  7.43546635e-02  3.16746682e-02 -4.41015214e-02
 -7.05722719e-02 -2.90961415e-02  6.17081523e-02  1.16258085e-01
 -2.53325179e-02  1.90988630e-02  1.06105059e-02  3.50686908e-02
  6.83106184e-02  1.90422982e-02 -7.38816708e-03  5.36293834e-02
  1.11280531e-02  7.00592697e-02 -2.99482122e-02 -9.69462097e-03
  2.27522254e-02 -9.33134258e-02 -1.34967193e-02  2.73378789e-02
  3.77616733e-02  1.19471997e-02  2.34515369e-02  4.38012332e-02
 -3.78131717e-02  3.10525000e-02  8.71422887e-03 -1.24843493e-02
  5.46014458e-02  1.24058455e-01  4.32275087e-02 -2.37286091e-04
  9.96379852e-02  5.92187196e-02  3.32650989e-02  4.21976000e-02
  8.98713619e-02  2.10556716e-01  1.00184977e-02  3.95660400e-02
  1.53094977e-02  4.61570770e-02 -7.50486553e-03  4.93350625e-03
  1.16898119e-03  5.78781813e-02  2.77552277e-01 -3.35188061e-02
  8.13064426e-02  3.22455406e-01  1.12823203e-01  3.01229358e-02
  1.09418288e-01  9.51384902e-02  4.14560199e-01  3.53127718e-02
  8.84546936e-02  7.09219277e-03  9.08198059e-02  2.79769450e-02
  1.22711957e-02 -1.63326412e-02  2.31586605e-01 -2.15096027e-02
  1.98363215e-02  3.83148491e-02  8.85312259e-03  1.60212100e-01
 -9.46718752e-02  4.06290740e-02  3.42104673e-01 -6.95191324e-02
 -3.42243463e-02  1.78363174e-01  1.66452825e-02  1.30535215e-01
  1.37593001e-01  1.06879577e-01  8.00593197e-02  7.58466125e-03
  5.93052953e-02  2.54709631e-01  1.13602027e-01  2.31176615e-04
 -2.24547386e-02  6.52878582e-02  1.11511421e+00  2.61254460e-02
  7.04304427e-02  5.94615936e-03 -2.04564705e-02  2.78389961e-01
  4.88559157e-02  3.42322379e-01 -6.57663196e-02 -5.83783165e-02
 -5.34309521e-02  3.25881392e-02 -6.30327761e-02  7.33490735e-02
 -5.05531132e-02  2.95039594e-01 -2.47742683e-02  1.94585323e-02
  1.37263536e-02  4.34089303e-02  2.08914876e-01 -1.31656602e-02
 -8.30878615e-02 -3.33643556e-02 -1.41030848e-02 -1.10143870e-02
 -2.90383101e-02 -1.52447820e-03  1.02216005e+00  2.89520621e-02
 -6.02221712e-02 -8.67598653e-02 -3.04777175e-02 -2.65997648e-02
 -4.01756838e-02  4.59585041e-02  6.65993541e-02 -5.05506694e-02
  2.18257099e-01  4.29246128e-02 -3.01083103e-02  2.65333056e-02
  6.33712560e-02 -3.04481089e-02 -6.59006909e-02 -3.48890871e-02
  4.03420180e-02 -2.93496326e-02 -1.21393055e-02 -6.45460784e-02
  7.16272712e-01  4.08362001e-02 -3.61283794e-02 -5.25619090e-03
 -2.22317874e-03  2.26565838e-01  2.09900290e-02 -2.66727880e-02
  5.50491512e-02  1.58897877e-01 -5.01092523e-02  2.58583575e-02
 -1.02280080e-02  4.77477759e-02  1.74655020e-02 -4.55806032e-02
  8.14896673e-02 -3.43105942e-02  4.62624729e-02  2.48864293e-02
  1.20949149e-01  5.05374372e-02  3.97291422e-01  6.80169880e-01
  1.03646770e-01  5.20394892e-02  6.77623004e-02  2.59781063e-01
  3.75144333e-02  3.35275382e-02  4.94439304e-02  1.72497928e-01
  2.91311741e-03 -1.01312995e-04 -1.47354379e-02  2.29692757e-02
  2.50829518e-01  5.35729825e-02  1.17449984e-01 -2.16473639e-02
  6.70234114e-02  4.39535230e-02  4.78711426e-02 -3.24568152e-02
  1.49184018e-02], shape=(625,), dtype=float32)
rounded label:tf.Tensor(
[ 1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0. -0.  0.  0. -0.
  0. -0.  0. -0.  1.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.
  0.  0.  1. -0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0. -0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0. -0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.
  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0. -0.  0. -0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0. -0. -0.  0. -0. -0.  0.  0.  0.  0.  0.
 -0.  0. -0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.
  0.  0.  0. -0.  0.  0. -0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.
  0.  0.  0.  0. -0.  0. -0. -0.  0.  0.  0. -0.  0.  0.  0.  0.  0. -0.
  0.  0. -0.  0.  0.  0. -0. -0.  0.  0.  0. -0. -0.  0. -0.  0.  0.  0.
  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.
  0. -0.  0.  0. -0.  0.  0. -0.  0.  0.  0. -0. -0. -0. -0.  0.  0.  0.
  0. -0. -0.  0.  0.  0.  0.  0.  0.  0.  0. -0. -0.  0.  0.  0.  0.  0.
  0.  0. -0.  0.  0. -0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0. -0. -0.  0.  0. -0.  0.  0.  0.  0.  0.
 -0.  0. -0. -0.  0.  0.  0.  0.  0.  0.  0. -0. -0. -0.  0.  0. -0.  0.
  0.  0.  0.  0. -0.  0.  0.  0. -0. -0.  0. -0. -0.  0.  0.  0.  0.  0.
 -0.  0.  0. -0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
 -0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0. -0.  0. -0.  0.  0.  0.  0. -0.  0.  0. -0. -0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0. -0.  0.  1.  0.  0.  0. -0.  0.  0.  0. -0. -0.
 -0.  0. -0.  0. -0.  0. -0.  0.  0.  0.  0. -0. -0. -0. -0. -0. -0. -0.
  1.  0. -0. -0. -0. -0. -0.  0.  0. -0.  0.  0. -0.  0.  0. -0. -0. -0.
  0. -0. -0. -0.  1.  0. -0. -0. -0.  0.  0. -0.  0.  0. -0.  0. -0.  0.
  0. -0.  0. -0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.
  0. -0. -0.  0.  0.  0.  0. -0.  0.  0.  0. -0.  0.], shape=(625,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1
 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.030997323, shape=(), dtype=float32)
-------
true label:[2, 0, 2]
true label rank:[2 1 2]
predicted label:tf.Tensor([0.5876888  0.59575945 0.498659  ], shape=(3,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0.], shape=(3,), dtype=float32)
predicted label rank:[2 2 1]
mse:tf.Tensor(1.5345255, shape=(), dtype=float32)
-------
true label:[0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 2, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2]
true label rank:[1 1 2 1 3 1 1 1 1 1 1 1 1 1 2 1 3 1 1 1 1 1 1 1 1 1 1 1 1 2 1 3 3 1 4 5 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 3]
predicted label:tf.Tensor(
[ 0.85113037  0.8126134   0.7891376   0.5138264   0.6383963   1.1160073
  0.9255423   0.28680098  0.50170547  1.2026005   0.59561586  0.59117687
  0.09574555  1.139116    0.65205425  0.41136652  0.40601754  0.26922476
  0.17299968  0.35420036  0.12024796  0.29423812  1.3934655   0.0067316
  0.8009405   0.13241944  0.24020413  0.06418815  0.2144418   1.1689181
  1.5234523   0.17813519  1.3215206   1.1267817   1.2199337  -0.13593519
 -0.04133688  0.527102    0.36866277  0.27624476  1.0123255   0.1024271
  0.31132862  0.02955005  0.10290694  0.07426079  0.10083818  0.04471429
 -0.01109756  0.06193916  0.5986347   0.07652521  0.5447891   1.3215206 ], shape=(54,), dtype=float32)
rounded label:tf.Tensor(
[ 1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  2.  0.  1.  1.  1. -0.
 -0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0. -0.  0.  1.  0.  1.  1.], shape=(54,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 1 2 2 2 2 1 2 2 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 3 1 2 2 2 1 1
 2 1 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2]
mse:tf.Tensor(0.84376854, shape=(), dtype=float32)
-------
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 17, 1, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 8 2 2 1 1 1 1 1 1 4 1 1 1 1
 1 1 1 6 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 7 2 1
 1 1 1 1 1 4 1 1 1 1 1 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[ 5.72940111e-01  5.41457474e-01  8.93520772e-01  4.79098320e-01
  3.64298046e-01  2.35867828e-01  6.88761055e-01  2.18535006e-01
 -7.17614293e-02  2.96217978e-01 -1.02399096e-01  2.85837442e-01
  4.97926414e-01  1.07090816e-01  3.48727316e-01  5.64103425e-02
  9.03475881e-02  1.99805319e-01 -7.18453228e-02 -7.74649531e-02
 -1.88356116e-02  1.72816068e-01 -6.79277107e-02  1.26730704e+00
  5.25042862e-02  1.06012821e-03  1.16946697e-02  1.68895274e-02
  7.29956627e-02  2.97397375e-04  1.85361505e-02  4.00981903e-02
  2.28772461e-02 -5.50027117e-02  5.33518195e-02  3.68283391e-02
  5.41467518e-02  2.21958458e-02  3.70187163e-02 -1.43097043e-02
  2.63850778e-01 -4.75075096e-02 -9.92742926e-03 -3.60711664e-02
 -3.82258520e-02 -2.42852867e-02 -3.35605741e-02  6.35903329e-02
  4.69487309e-02  2.23662257e-02  2.85152346e-02  1.51715457e-01
  1.40985221e-01  1.01511151e-01 -5.59014007e-02 -3.29380855e-02
 -1.32324517e-01  5.85353374e-03  1.26250803e-01  1.29622400e-01
  9.46482271e-02  2.85739899e-02 -6.01370186e-02  1.62502289e-01
  1.00945562e-01  2.32830942e-02 -1.03474051e-01  1.69777423e-02
  3.14676464e-02 -7.87064433e-04 -6.79399893e-02  6.31680191e-01
  4.48555350e-02  1.04408249e-01 -1.15841702e-02  1.64869279e-01
  1.10187188e-01  2.12818176e-01  9.88142937e-02  3.51675153e-01
 -3.41381729e-02 -5.94542474e-02  2.39692360e-01  1.17172718e-01
  3.16762030e-01  7.70922005e-02 -2.19457522e-02  1.18404567e-01
  6.46085203e-01 -1.27096772e-02 -1.78779289e-02 -3.55312377e-02
 -1.57264844e-02  6.19085133e-03  5.15788943e-02  8.50002170e-02
  1.69091940e-01  7.73041993e-02  2.61225432e-01  1.37197465e-01
  1.67326391e-01  1.42844856e-01  9.12173092e-02  9.66092497e-02
  6.29301220e-02 -2.51739025e-02 -3.12557593e-02  1.86384767e-02
  7.40181506e-02  9.68942046e-03  4.31656390e-02  5.81550598e-02
  4.54346091e-02  1.45036459e-01 -2.41982564e-02 -1.60363764e-02
  1.86122656e-02 -1.35928988e-02 -4.25531864e-02  4.66407835e-02
  1.60555094e-02 -1.97956637e-02  1.48473829e-02 -8.52939263e-02
  1.33550912e-02  2.28435546e-02 -1.27307326e-02  2.26225555e-02
 -8.78454745e-03 -3.38605344e-02  1.53518170e-02  8.83933842e-01
 -1.54564530e-02  2.49156356e-02  2.35700607e-02 -4.70449552e-02
  4.87120152e-02  2.40635127e-02 -3.10230255e-03  5.08737564e-03
 -4.14718688e-03 -1.06304958e-02  3.57538462e-03 -2.96072662e-03
 -1.22176409e-02  1.07918441e-01  5.50833791e-02  4.13865745e-02
  8.64300579e-02 -3.38648260e-03  5.39864898e-02  1.16553456e-02
  1.81889534e-03  8.64479840e-02  5.93262613e-02  2.01858878e-02
 -1.85109451e-02  1.31811440e-01  1.48386955e+00  3.53494436e-02
  3.80549878e-02  5.11932969e-02  2.47062743e-02  6.28183931e-02
  4.68127131e-02  1.10929757e-01  3.23815793e-02  1.31441325e-01
  1.28695399e-01  1.38361573e-01  1.78055763e-01 -1.14275590e-02
  1.50973022e-01  2.46472180e-01 -2.60148719e-02  1.08081967e-01
  1.13228008e-01  1.86234146e-01  3.59122545e-01  8.25056285e-02
  2.68664211e-02  6.53589666e-02  8.54459107e-02 -8.21776837e-02
 -2.74645537e-02 -4.36722785e-02 -3.68991792e-02 -5.61636686e-03
  5.80522418e-03  2.20746100e-02  1.27397925e-02  6.11431003e-02
  5.43713868e-02  1.66223496e-02  5.39888591e-02  9.37595963e-03
  9.07010615e-01 -4.01765257e-02 -7.53962100e-02  1.67009801e-01
  3.05598736e-01  4.46322620e-01  4.99124825e-01  1.28099024e-02
  1.27854645e-01  3.51600736e-01  1.05035603e-01 -2.62638256e-02
 -2.18840837e-02 -3.94536778e-02 -4.59386706e-02 -3.11980620e-02
  1.30418688e-02  7.90568292e-02  1.93441510e-02 -1.82737410e-02
 -1.69575736e-02 -3.64825577e-02  6.98873699e-02  5.03246933e-02
 -2.58401260e-02 -9.04597342e-03 -3.71304303e-02 -6.06001914e-03
 -4.23377082e-02  3.60604525e-02  3.24080139e-02  5.63499779e-02
  3.07993442e-02  4.97889072e-02 -4.80020195e-02 -2.48734653e-03
 -2.40827128e-02 -3.59094143e-02 -8.69948417e-02  1.94963753e-01
  2.76401639e-03 -3.06653976e-03  6.64122403e-02 -2.08295360e-02
  1.75458640e-02  1.89649314e-02  2.43416429e-03  1.32282734e-01
  1.11692578e-01  2.53890306e-02 -1.39550120e-02  2.59681582e-01
  8.73646736e-02  7.22356141e-03  3.91507000e-02  4.85363752e-02
  5.48407435e-04 -1.29538476e-02 -6.77576885e-02 -2.68650129e-02
 -4.05226424e-02 -4.76710424e-02  1.32053196e-02  4.74122316e-02
  7.04620779e-02  7.97656924e-02  6.36779666e-02  4.81881201e-02
  6.19327575e-02  1.96778446e-01  1.05588198e-01 -4.30020913e-02
 -1.34897903e-02  4.32410091e-02  2.91860551e-02  7.03777194e-01
  2.22060144e-01 -5.10586202e-02  4.86373305e-02 -3.91735584e-02
 -7.37002194e-02 -2.43573859e-02 -3.69855314e-02 -8.89509469e-02
  7.50124305e-02 -2.24342942e-03 -1.98442787e-02  1.05111450e-02
  9.60661322e-02  1.29669428e-01  4.83025372e-01  1.17214590e-01
  7.07881302e-02 -2.66064331e-02 -7.37200528e-02  3.31445038e-02
  1.98726028e-01  6.75565302e-01  6.88628197e-01  3.14968884e-01
  4.72061336e-03  1.13560811e-01 -3.40199396e-02 -2.71695405e-02
 -2.34141648e-02  8.89641047e-03 -2.70963535e-02  3.36156726e-01
  3.05378735e-01  1.06527030e-01  2.29127616e-01  1.89836621e-01
  8.64487588e-02  1.55247986e-01  3.91121507e-02  2.00475514e-01
 -4.12349775e-02 -4.43026051e-02  2.22036839e-02  1.62942320e-01
  2.69362330e-01 -3.99148166e-02  6.03748858e-03  2.45503336e-01
  1.42381340e-02 -2.42901742e-02  2.16220766e-02 -9.80323553e-03
 -3.29562426e-02 -7.00735301e-03 -5.32248393e-02 -1.57227069e-02
  2.27014720e-03 -2.27278993e-02 -1.53939426e-02 -4.56493497e-02
 -3.48591134e-02], shape=(333,), dtype=float32)
rounded label:tf.Tensor(
[ 1.  1.  1.  0.  0.  0.  1.  0. -0.  0. -0.  0.  0.  0.  0.  0.  0.  0.
 -0. -0. -0.  0. -0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.
  0.  0.  0. -0.  0. -0. -0. -0. -0. -0. -0.  0.  0.  0.  0.  0.  0.  0.
 -0. -0. -0.  0.  0.  0.  0.  0. -0.  0.  0.  0. -0.  0.  0. -0. -0.  1.
  0.  0. -0.  0.  0.  0.  0.  0. -0. -0.  0.  0.  0.  0. -0.  0.  1. -0.
 -0. -0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0. -0.  0.
  0.  0.  0.  0.  0.  0. -0. -0.  0. -0. -0.  0.  0. -0.  0. -0.  0.  0.
 -0.  0. -0. -0.  0.  1. -0.  0.  0. -0.  0.  0. -0.  0. -0. -0.  0. -0.
 -0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0. -0.  0.  1.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0. -0.  0.  0.  0.  0.  0.
  0.  0.  0. -0. -0. -0. -0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  1. -0.
 -0.  0.  0.  0.  0.  0.  0.  0.  0. -0. -0. -0. -0. -0.  0.  0.  0. -0.
 -0. -0.  0.  0. -0. -0. -0. -0. -0.  0.  0.  0.  0.  0. -0. -0. -0. -0.
 -0.  0.  0. -0.  0. -0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.
  0. -0. -0. -0. -0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0. -0.  0.
  0.  1.  0. -0.  0. -0. -0. -0. -0. -0.  0. -0. -0.  0.  0.  0.  0.  0.
  0. -0. -0.  0.  0.  1.  1.  0.  0.  0. -0. -0. -0.  0. -0.  0.  0.  0.
  0.  0.  0.  0.  0.  0. -0. -0.  0.  0.  0. -0.  0.  0.  0. -0.  0. -0.
 -0. -0. -0. -0.  0. -0. -0. -0. -0.], shape=(333,), dtype=float32)
predicted label rank:[2 2 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(1.5984746, shape=(), dtype=float32)
-------
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 14, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 4, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 7 2 1 1 1 1 1 1 1 4 1 1 1 1
 1 1 1 7 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 7 2 1
 1 1 1 1 1 4 1 1 1 1 5 1 1 1 6 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[ 5.72940111e-01  5.41457474e-01  2.76567489e-01  5.45733392e-01
  4.98146534e-01  2.35867828e-01  3.44952524e-01  2.18535006e-01
  3.23407888e-01 -7.01317042e-02 -1.33222267e-02  2.85837442e-01
  4.97926414e-01  1.53760254e-01  3.48727316e-01  5.64103425e-02
  9.03475881e-02  1.99805319e-01 -3.49409431e-02 -4.23466191e-02
 -1.77264065e-02 -1.18074693e-01 -2.24310458e-02  5.13326645e+00
  5.25042862e-02  1.06012821e-03  1.16946697e-02  1.68895274e-02
  7.29956627e-02  2.97397375e-04  1.85361505e-02  5.72717190e-02
  2.28772461e-02 -5.50027117e-02 -2.13105232e-02  3.68283391e-02
  5.41467518e-02  2.21958458e-02  3.70187163e-02 -1.43097043e-02
  2.76828259e-02 -4.75075096e-02 -9.92742926e-03 -3.60711664e-02
 -3.82258520e-02 -2.42852867e-02 -4.53706309e-02  6.35903329e-02
  4.69487309e-02  2.23662257e-02  2.85152346e-02  1.51715457e-01
  1.40985221e-01  1.01511151e-01 -5.54187670e-02 -3.29381377e-02
 -1.44614577e-01  5.85353374e-03  1.26250803e-01  1.14125624e-01
  9.41166878e-02  2.85829008e-02 -6.01369888e-02  1.62502289e-01
  1.00945562e-01  4.11844254e-02 -1.13782905e-01  1.69777423e-02
  3.14676464e-02 -7.87064433e-04 -6.54760450e-02  6.31680191e-01
  4.48555350e-02  1.04408249e-01 -1.15841702e-02  1.64869279e-01
  1.10187188e-01  2.12818176e-01  9.88142937e-02  3.51675153e-01
 -3.41381729e-02 -5.94542474e-02  2.39692360e-01  1.17172718e-01
  3.16762030e-01  7.70922005e-02 -2.19457522e-02  1.18404567e-01
  6.46085203e-01 -1.27096772e-02 -1.78779289e-02 -3.55312377e-02
 -1.57264844e-02  6.19085133e-03  5.15788943e-02  8.50002170e-02
  1.69091940e-01  7.73041993e-02  2.61225432e-01  1.37197465e-01
  1.67326391e-01  1.42844856e-01  9.12173092e-02  9.66092497e-02
  6.29301220e-02 -2.51739025e-02 -3.12557593e-02  1.86384767e-02
  7.40181506e-02  9.68942046e-03  4.31656390e-02  5.81550598e-02
  4.54346091e-02  1.45036459e-01 -2.41982564e-02 -1.60363764e-02
  1.86122656e-02 -1.35928988e-02 -4.25531864e-02  2.15729177e-01
 -3.25739607e-02 -4.15798277e-02  1.85403615e-01  4.10448849e-01
 -4.14820015e-03  6.64784014e-02  1.87074244e-01 -2.58529559e-02
  9.99456048e-02 -3.44101116e-02  5.19241393e-03  1.65923059e-01
  6.14951998e-02 -1.58535317e-02 -6.03499189e-02  3.40910912e-01
  2.09317476e-01  1.40352249e-02 -4.71146703e-02  6.50681555e-03
 -3.28337476e-02  7.48962164e-04  2.70983577e-02 -2.96072662e-03
 -1.22176409e-02  1.07918441e-01  5.50833791e-02  4.13865745e-02
  4.59677577e-02 -3.38648260e-03  4.54523116e-02  1.66774839e-02
  2.40912735e-02  8.64479840e-02  1.94506466e-01  5.70006073e-02
 -1.85109451e-02  7.66886771e-02  1.82259679e-01  3.19470018e-02
  5.45275658e-02  5.22111654e-02  6.20879978e-02  4.91662025e-02
  4.46518809e-02  1.10929757e-01  3.23815793e-02  1.31441325e-01
  1.28695399e-01  1.38361573e-01  1.78055763e-01 -1.14275590e-02
  1.50973022e-01 -7.57119358e-02 -9.25662369e-02  1.89090729e-01
  1.13228008e-01  6.35244548e-02 -4.40521538e-02  8.25056285e-02
  2.68664211e-02  2.09051013e-01 -7.64961988e-02 -5.90590835e-02
 -5.15619069e-02 -2.59057879e-02 -4.42124605e-02  6.88339621e-02
  5.78552932e-02  2.20746100e-02  1.27397925e-02  6.11431003e-02
  5.43713868e-02  1.66223496e-02  5.39888591e-02  9.37595963e-03
 -6.75764680e-02 -3.54270637e-03  1.96149647e-02  1.67009801e-01
  6.93815053e-02  4.03546393e-02  3.02920938e-01  1.28099024e-02
  3.77748132e-01 -1.08450651e-04  9.34566557e-03 -2.72947848e-02
 -1.58398449e-02 -2.63584703e-02  7.95842260e-02 -4.72984090e-02
  1.30418688e-02  7.90568292e-02  1.93441510e-02 -1.82737410e-02
 -1.69575736e-02 -3.64825577e-02  6.98873699e-02 -9.97777060e-02
 -1.01608083e-01  5.71958721e-03 -6.06976449e-03  3.21636796e-02
 -4.23377082e-02  2.42909342e-02  3.24080139e-02  4.05001640e-02
 -9.06835347e-02 -6.46244138e-02 -9.03460532e-02 -4.04350311e-02
 -5.31397015e-02  2.80014426e-02  2.55002081e-03  1.41097248e-01
  2.76401639e-03 -3.06653976e-03  6.64122403e-02 -2.08295360e-02
  1.75458640e-02  1.89649314e-02 -3.73673737e-02 -3.28386128e-02
  8.17959070e-01  2.53890306e-02  2.97553569e-01  4.03020233e-02
  6.45460039e-02  7.22356141e-03  3.91507000e-02  6.68377727e-02
 -6.79010972e-02 -1.29538476e-02 -6.77576885e-02 -2.68650129e-02
 -4.05226424e-02  6.45491332e-02  1.32053196e-02  4.74122316e-02
  7.04620779e-02  7.97656924e-02  6.36779666e-02  4.81881201e-02
  6.19327575e-02  9.07059729e-01 -4.66822535e-02 -4.30020913e-02
 -1.34897903e-02  4.32410091e-02  5.36432862e-02  7.03777194e-01
  2.22060144e-01 -5.10586202e-02  6.95550889e-02  6.55636936e-02
 -7.37002194e-02 -2.43573859e-02 -3.69855314e-02 -8.89509469e-02
 -7.25419596e-02 -2.24342942e-03 -1.98442787e-02  1.77210599e-01
  9.60661322e-02  2.71783173e-01  4.83025372e-01  1.17214590e-01
  1.44659698e-01  4.96416688e-02 -3.56546268e-02 -5.33008128e-02
  1.98726028e-01  1.13153625e+00  6.88628197e-01  3.14968884e-01
  4.72061336e-03  1.13560811e-01 -1.77565217e-02 -1.99686885e-02
 -2.44559124e-02 -1.10562369e-02 -3.15559357e-02 -2.30082795e-02
  3.05378735e-01  1.06527030e-01  5.56176901e-02  1.29056960e-01
  8.64487588e-02  1.55247986e-01  1.98397487e-02  2.00475514e-01
 -3.63906473e-02 -5.46833128e-02 -3.30676511e-02  1.62942320e-01
  2.69362330e-01 -5.35452366e-03  6.03748858e-03  2.12295324e-01
  1.42381340e-02  2.22052038e-01 -4.94748354e-04 -6.55770302e-04
 -3.90102118e-02  1.75456554e-02 -3.35031301e-02], shape=(327,), dtype=float32)
rounded label:tf.Tensor(
[ 1.  1.  0.  1.  0.  0.  0.  0.  0. -0. -0.  0.  0.  0.  0.  0.  0.  0.
 -0. -0. -0. -0. -0.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0. -0.  0.
  0.  0.  0. -0.  0. -0. -0. -0. -0. -0. -0.  0.  0.  0.  0.  0.  0.  0.
 -0. -0. -0.  0.  0.  0.  0.  0. -0.  0.  0.  0. -0.  0.  0. -0. -0.  1.
  0.  0. -0.  0.  0.  0.  0.  0. -0. -0.  0.  0.  0.  0. -0.  0.  1. -0.
 -0. -0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0. -0.  0.
  0.  0.  0.  0.  0.  0. -0. -0.  0. -0. -0.  0. -0. -0.  0.  0. -0.  0.
  0. -0.  0. -0.  0.  0.  0. -0. -0.  0.  0.  0. -0.  0. -0.  0.  0. -0.
 -0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0. -0. -0.  0.  0.  0. -0.  0.
  0.  0. -0. -0. -0. -0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0. -0.
  0.  0.  0.  0.  0.  0.  0. -0.  0. -0. -0. -0.  0. -0.  0.  0.  0. -0.
 -0. -0.  0. -0. -0.  0. -0.  0. -0.  0.  0.  0. -0. -0. -0. -0. -0.  0.
  0.  0.  0. -0.  0. -0.  0.  0. -0. -0.  1.  0.  0.  0.  0.  0.  0.  0.
 -0. -0. -0. -0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  1. -0. -0. -0.  0.
  0.  1.  0. -0.  0.  0. -0. -0. -0. -0. -0. -0. -0.  0.  0.  0.  0.  0.
  0.  0. -0. -0.  0.  1.  1.  0.  0.  0. -0. -0. -0. -0. -0. -0.  0.  0.
  0.  0.  0.  0.  0.  0. -0. -0. -0.  0.  0. -0.  0.  0.  0.  0. -0. -0.
 -0.  0. -0.], shape=(327,), dtype=float32)
predicted label rank:[2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(1.5819297, shape=(), dtype=float32)
-------
true label:[0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 2, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]
true label rank:[1 2 1 2 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 3 4 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 1 1 2]
predicted label:tf.Tensor(
[ 0.85113037  0.8126134   0.43681377  0.6423627   1.0922756   1.1160073
  0.91952246  0.28680098  0.7889341   0.569145    0.22771338  0.57845736
  0.92818505  0.40081173  0.65205425  0.29714987  0.12038016  0.17692399
  0.27136508  0.35420036  0.12024796  0.29423812  0.20116031  0.2839291
  0.04962228  0.13241944  1.0286317   0.08256079  1.1379786   1.2321925
  0.8539037   1.3215206   1.2777941   0.04121736  0.01664542 -0.1420941
  0.10806662  0.02655292  0.3313344   0.02758437  0.46059448  0.11102147
  0.06284733 -0.04978003  0.09399757  0.06235565  0.8429233   0.06352223
 -0.01051492  1.3215206 ], shape=(50,), dtype=float32)
rounded label:tf.Tensor(
[ 1.  1.  0.  1.  1.  1.  1.  0.  1.  1.  0.  1.  1.  0.  1.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.  0. -0.
  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  1.  0. -0.  1.], shape=(50,), dtype=float32)
predicted label rank:[2 2 1 2 2 2 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 2 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 1 1 2]
mse:tf.Tensor(0.44570696, shape=(), dtype=float32)
-------
true label:[1, 4, 2, 1, 1, 1, 1, 2, 2]
true label rank:[1 3 2 1 1 1 1 2 2]
predicted label:tf.Tensor(
[0.8387462  0.6273851  0.27677917 1.3180199  1.3039792  0.96842307
 1.2318878  1.23477    1.2858422 ], shape=(9,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 1. 1. 1. 1. 1.], shape=(9,), dtype=float32)
predicted label rank:[2 2 1 2 2 2 2 2 2]
mse:tf.Tensor(1.7459923, shape=(), dtype=float32)
-------
true label:[4, 3, 2, 3, 2, 3]
true label rank:[3 2 1 2 1 2]
predicted label:tf.Tensor([1.3094463  1.193944   0.57229376 1.3115871  1.3108327  0.61507404], shape=(6,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1.], shape=(6,), dtype=float32)
predicted label rank:[1 1 1 1 1 1]
mse:tf.Tensor(3.5921373, shape=(), dtype=float32)
-------
true label:[2, 5, 1, 3, 4, 2, 1, 3]
true label rank:[2 5 1 3 4 2 1 3]
predicted label:tf.Tensor(
[1.3215206  1.3214183  0.47485846 0.6448689  1.3215206  0.74392635
 1.178473   0.4098782 ], shape=(8,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 1. 1. 1. 0.], shape=(8,), dtype=float32)
predicted label rank:[2 2 1 2 2 2 2 1]
mse:tf.Tensor(4.4134088, shape=(), dtype=float32)
-------
true label:[0, 2, 1, 0, 1]
true label rank:[1 3 2 1 2]
predicted label:tf.Tensor([0.62644845 0.560363   1.2941093  0.17951733 0.14938927], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 0. 0.], shape=(5,), dtype=float32)
predicted label rank:[2 2 2 1 1]
mse:tf.Tensor(0.6614516, shape=(), dtype=float32)
-------
true label:[1, 0, 1, 1, 1, 0, 0]
true label rank:[2 1 2 2 2 1 1]
predicted label:tf.Tensor(
[1.0584569  0.9646321  1.1364896  0.7828466  1.2979352  1.3215129
 0.47750497], shape=(7,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 0.], shape=(7,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 1]
mse:tf.Tensor(0.4375557, shape=(), dtype=float32)
-------
true label:[0, 0, 1, 0]
true label rank:[1 1 2 1]
predicted label:tf.Tensor([0.6586097  0.584717   0.29326397 0.4712314 ], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 0.], shape=(4,), dtype=float32)
predicted label rank:[2 2 1 1]
mse:tf.Tensor(0.37429887, shape=(), dtype=float32)
-------
true label:[0, 1]
true label rank:[1 2]
predicted label:tf.Tensor([0.6586097 0.6674086], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.27219188, shape=(), dtype=float32)
-------
true label:[0, 1, 0, 0, 0]
true label rank:[1 2 1 1 1]
predicted label:tf.Tensor([0.6586097  0.8959338  0.29326397 0.4712314  0.37363458], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 0. 0.], shape=(5,), dtype=float32)
predicted label rank:[2 2 1 1 1]
mse:tf.Tensor(0.1784524, shape=(), dtype=float32)
-------
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[ 4.45698261e-01  8.94157231e-01  2.32705772e-02  1.20926356e+00
  2.49275416e-02  8.96494925e-01  2.67907083e-01  3.25336218e-01
 -3.31068933e-02  2.16520727e-02 -1.52394101e-02  1.23191476e-01
  1.41745389e-01 -3.57040763e-02  4.86100018e-02  4.10255790e-03
  7.74874508e-01  5.13184816e-02  3.67056727e-02  1.68182522e-01
  2.98507035e-01  4.30731475e-01  3.88678133e-01  1.96271718e-01
  1.20556784e+00  2.69907296e-01  2.43865281e-01 -2.31554657e-02
  1.50818110e-01  5.66212118e-01  1.67847753e+00  1.32152057e+00
  1.01183772e+00  3.16111118e-01 -7.31630027e-02 -2.83099413e-01
 -7.93541968e-02  2.99118787e-01  1.20807737e-02  7.37488925e-01
  4.19786036e-01 -6.23629615e-02 -6.02100641e-02 -6.23629689e-02
  7.09433079e-01  1.07482865e-01  7.48835981e-01  5.05722582e-01
  1.25820786e-02  5.80365181e-01  6.49676025e-02  2.43675232e-01
  1.33108735e-01  2.73035347e-01  4.53472495e-01  6.69215083e-01
 -7.77599961e-02  6.98138028e-02 -6.26195520e-02  6.18102252e-02
 -5.08216843e-02  7.30501652e-01  4.34406698e-01 -6.45783693e-02
 -5.69924712e-02 -1.25032619e-01 -1.43807232e-02 -3.17516923e-02
  7.32632875e-02 -1.13936096e-01 -8.91628414e-02  2.76790351e-01
  4.52419966e-02 -2.81259716e-02  2.17041373e-01 -2.36691684e-02
 -4.76230457e-02 -6.24712408e-02  4.13294435e-02  1.18380398e-01
  8.40525091e-01  4.25143242e-02  1.34130120e-01 -2.77035013e-02
  1.31960034e-01 -3.52194458e-02 -9.12023187e-02  6.14185572e-01
  5.89257777e-02  1.04653978e+00  5.50267696e-02  4.60278451e-01
 -5.91617972e-02  1.68124139e-02  1.69805378e-01 -8.02060291e-02
  3.86263490e-01  8.79795849e-01  1.50399804e-02 -6.54704496e-02
 -2.72839963e-02 -1.84485614e-02  2.04701066e-01  4.83251274e-01
  2.58881748e-02 -2.40923539e-02 -3.51863280e-02 -2.77450681e-03
 -5.21877408e-02 -8.78829509e-02 -4.31944802e-02  1.32151484e+00
  9.93692577e-01 -1.31362155e-01  4.57467973e-01  1.09314039e-01
  1.39938325e-01  2.21249104e-01  2.39035696e-01  2.46018767e-02
 -1.19516999e-02  8.23345661e-01  7.16743827e-01  2.87482381e-01
 -5.92981726e-02 -5.17593175e-02 -6.32213727e-02  4.41250503e-02
  1.86881274e-02  6.77281618e-02 -2.31612548e-02 -1.07868671e-01
  2.02720702e-01  8.58431756e-01  4.51288521e-02 -3.27662230e-02
  1.91466123e-01 -5.97007200e-02 -3.91171873e-02  6.79311395e-01
 -1.07141420e-01 -1.45352110e-02 -1.16666704e-01 -1.13160640e-01
 -5.28903306e-02 -2.48160958e-02  4.02894557e-01  4.56495643e-01
  1.22968704e-01  1.04809952e+00 -3.39616835e-03  1.41608387e-01
  3.49953979e-01  3.30755413e-02  2.79828310e-01 -7.92901963e-03
  3.70299369e-02  4.86353934e-01  7.47419894e-02 -1.97055861e-02
 -6.21100143e-02 -1.72210768e-01  9.62633073e-01  5.27255595e-01
  5.70880115e-01 -2.03366816e-01 -5.56784719e-02 -3.42700705e-02
 -1.08707100e-01  1.67398363e-01  8.33275318e-01  1.32152057e+00
  4.01382327e-01  2.90759861e-01  1.24015391e-01  1.19713932e-01
 -7.73158222e-02 -4.80070710e-03 -1.94237083e-02 -7.26944953e-02
  3.79740000e-02  1.59907371e-01  1.21583402e-01  8.22820514e-02
 -9.09349099e-02  6.62001967e-03  3.64201069e-02 -4.17408198e-02
  6.86944425e-02  7.43021071e-02  1.02227235e+00  6.46475315e-01
  7.11733997e-02  5.42321056e-02 -1.23595387e-01  7.99878091e-02
  1.31389171e-01 -9.52051282e-02  3.07963997e-01  4.20474887e-01
  7.23535568e-02  1.60006464e-01  7.38698304e-01  1.93122745e-01
  5.00136614e-03  1.29376292e-01 -6.43208176e-02  4.61789966e-02
  5.92037082e-01  1.08533812e+00  1.92249089e-01 -5.74284568e-02
  1.27746701e-01  1.03175640e-04  6.53941631e-01  8.72142166e-02
  5.04899025e-02  1.82244867e-01  2.32979119e-01  8.62191916e-02
  5.16698062e-02  3.14160794e-01  1.63358152e-02  2.75751889e-01
 -2.19005048e-02  1.81170225e-01  2.66841948e-01  3.38613331e-01
  8.83945078e-02  9.94750559e-02  1.20520920e-01  1.37685061e-01
  1.36170149e-01  5.31246781e-01  5.18071055e-02  2.08098769e-01
  8.46924782e-02 -6.30916283e-02  4.02829349e-02  7.06245124e-01
  2.34502792e-01 -5.81359491e-02 -1.79558471e-02  1.04500723e+00
  1.16820049e+00  5.21250486e-01  4.47520673e-01  4.52306807e-01], shape=(248,), dtype=float32)
rounded label:tf.Tensor(
[ 0.  1.  0.  1.  0.  1.  0.  0. -0.  0. -0.  0.  0. -0.  0.  0.  1.  0.
  0.  0.  0.  0.  0.  0.  1.  0.  0. -0.  0.  1.  2.  1.  1.  0. -0. -0.
 -0.  0.  0.  1.  0. -0. -0. -0.  1.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. -0.  0. -0.  0. -0.  1.  0. -0. -0. -0. -0. -0.  0. -0. -0.  0.
  0. -0.  0. -0. -0. -0.  0.  0.  1.  0.  0. -0.  0. -0. -0.  1.  0.  1.
  0.  0. -0.  0.  0. -0.  0.  1.  0. -0. -0. -0.  0.  0.  0. -0. -0. -0.
 -0. -0. -0.  1.  1. -0.  0.  0.  0.  0.  0.  0. -0.  1.  1.  0. -0. -0.
 -0.  0.  0.  0. -0. -0.  0.  1.  0. -0.  0. -0. -0.  1. -0. -0. -0. -0.
 -0. -0.  0.  0.  0.  1. -0.  0.  0.  0.  0. -0.  0.  0.  0. -0. -0. -0.
  1.  1.  1. -0. -0. -0. -0.  0.  1.  1.  0.  0.  0.  0. -0. -0. -0. -0.
  0.  0.  0.  0. -0.  0.  0. -0.  0.  0.  1.  1.  0.  0. -0.  0.  0. -0.
  0.  0.  0.  0.  1.  0.  0.  0. -0.  0.  1.  1.  0. -0.  0.  0.  1.  0.
  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  1.
  0.  0.  0. -0.  0.  1.  0. -0. -0.  1.  1.  1.  0.  0.], shape=(248,), dtype=float32)
predicted label rank:[1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 3 2 2 1 1 1 1
 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 2 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1
 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 2 2 2 1 1]
mse:tf.Tensor(0.18685873, shape=(), dtype=float32)
-------
true label:[1, 0]
true label rank:[2 1]
predicted label:tf.Tensor([1.3215206 0.7316334], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.31933147, shape=(), dtype=float32)
-------
true label:[0, 1, 1]
true label rank:[1 2 2]
predicted label:tf.Tensor([1.321146  1.3215077 1.3202062], shape=(3,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)
predicted label rank:[1 1 1]
mse:tf.Tensor(0.650442, shape=(), dtype=float32)
-------
true label:[2, 2]
true label rank:[1 1]
predicted label:tf.Tensor([0.7162015 1.3199539], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(1.0553006, shape=(), dtype=float32)
-------
true label:[3, 3]
true label rank:[1 1]
predicted label:tf.Tensor([0.7162015 1.3199539], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(4.019145, shape=(), dtype=float32)
-------
true label:[2, 2, 4, 2, 3, 2, 3, 5, 3, 2, 2, 5]
true label rank:[1 1 3 1 2 1 2 4 2 1 1 4]
predicted label:tf.Tensor(
[1.0585816  0.9648486  1.1377316  0.78520995 1.0922315  1.1093159
 0.9270049  1.2345037  0.9099018  1.3215206  1.3215206  1.3215089 ], shape=(12,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(12,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(4.4463124, shape=(), dtype=float32)
-------
true label:[1, 0]
true label rank:[2 1]
predicted label:tf.Tensor([0.8938835 0.7032923], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.2529404, shape=(), dtype=float32)
-------
true label:[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2
 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[ 6.26448452e-01  6.69773042e-01  2.76779175e-01  4.79098320e-01
  3.64298046e-01  2.35867828e-01  3.44952524e-01  2.18535006e-01
  3.23407888e-01  2.96217978e-01  2.88566440e-01  2.85837442e-01
  4.97926414e-01  1.02306187e-01  3.48727316e-01  5.64103425e-02
  9.03475881e-02  1.99805319e-01  2.31497437e-01  1.95358217e-01
  1.96151793e-01  3.80037546e-01  7.16073662e-02 -9.94481891e-03
  3.84632349e-02  1.06012821e-03  2.53828168e-02  1.68895274e-02
  7.29956627e-02  1.80167407e-02  1.85361505e-02  1.73640847e-02
  2.28772461e-02  1.41745657e-02  1.28918737e-02  8.26862454e-03
  1.98435038e-02  1.68972909e-02  3.70187163e-02 -1.43097043e-02
  5.18187582e-02  1.19410306e-02  4.16503996e-02 -2.13953853e-03
 -1.65854245e-02 -2.48491019e-02 -1.28709167e-01  7.46954858e-01
  1.05813786e-01  9.89264250e-02  3.96941006e-02  1.26259416e-01
  3.07779074e-01  3.40839475e-01  3.62127364e-01  5.16594887e-01
  5.33361286e-02  2.20083296e-02  4.24004555e-01  1.51385367e-01
  9.24440920e-02  1.46557122e-01  3.00653279e-01  4.23339456e-02
  3.03946823e-01  1.32203221e-01  6.16417527e-02  1.40454143e-01
  4.30058837e-02  1.11208737e-01  1.38835043e-01  7.72971451e-01
  7.97004551e-02  1.05099350e-01  4.45403010e-02  2.83843815e-01
  1.26652271e-01  1.23493135e-01  1.70501143e-01  5.96925080e-01
  2.31711179e-01  1.06149837e-01  1.57198429e-01  9.41191763e-02
  2.09660709e-01  1.20712966e-01  7.45561272e-02  1.71920955e-01
  3.44563544e-01  1.47249281e-01  3.51825595e-01  5.08262992e-01
  2.19079494e-01  2.81555444e-01  2.56441534e-02  3.88916582e-02
  6.50348902e-01  4.20745313e-01  6.47134721e-01  2.35541761e-01
  4.20623720e-01  4.85465109e-01  5.48224032e-01  4.14664328e-01
  4.11970437e-01  3.03904474e-01  9.04251933e-02  4.73308682e-01
  3.16436946e-01  1.93167180e-01  3.13376904e-01 -3.47941890e-02
  2.86241263e-01  6.89759701e-02  2.33767331e-02  8.68489295e-02
  4.89391983e-02  1.31874084e-02  3.82532179e-02  8.75400007e-03
  3.70360613e-02  1.81501448e-01  4.42230552e-02  2.29249328e-01
  2.04001516e-02 -2.21103355e-02 -2.97578499e-02  4.73107249e-02
 -1.77943259e-02  3.14320028e-02  5.30073345e-01  2.76309550e-01
  1.00112408e-02  9.62420851e-02  4.80299592e-02  3.44639212e-01
  1.82174414e-01  2.54735351e-02  3.89124393e-01  1.33270383e-01
  6.43238962e-01  1.67624116e-01  8.94213319e-02  1.34852231e-01
  1.18599504e-01  7.65151680e-02  1.12593651e-01  4.10975516e-03
  5.83297312e-02  1.03715956e-02  1.09705031e-01  1.43255293e-03
  3.35855484e-02  1.61932558e-02  1.03034899e-01 -1.12167671e-02
 -4.36747074e-03  3.71785760e-02  1.99615538e-01  1.81368440e-02
  3.03342938e-02  7.13998377e-02  1.06266752e-01  4.06459123e-02
 -1.03454366e-02  2.46747017e-01  1.05806023e-01  7.82491267e-03
  1.42169297e-02  3.06111127e-02  5.07391989e-03  5.95697463e-02
  1.27446324e-01  8.43049437e-02  1.66110545e-02  1.62670463e-02
  2.09750623e-01  1.97715044e-01  3.18187773e-02  4.32764530e-01
  2.68664211e-02  6.53589666e-02 -1.14948303e-02  3.62650633e-01
  4.86920238e-01  9.38935131e-02  1.38847232e-01  1.68512106e-01
  2.13819563e-01  5.73351681e-02 -7.71242380e-03  4.27887797e-01
  3.79293084e-01  7.79175609e-02  2.82817930e-02  9.37595963e-03
  9.07010615e-01  3.88522208e-01  1.96149647e-02  1.67009801e-01
  3.05598736e-01  4.03546393e-02  3.02920938e-01  1.28099024e-02
  2.35945523e-01  4.75490540e-02  1.05035603e-01  6.49462581e-01
  1.79589927e-01 -6.30215332e-02  7.95842260e-02 -4.72984090e-02
  1.30418688e-02  7.90568292e-02  1.93441510e-02 -1.82737410e-02
 -1.69575736e-02 -3.64825577e-02  6.98873699e-02  3.83251011e-02
  4.12710905e-02  4.04424518e-02  4.07911092e-02  4.92265821e-02
  6.30776584e-03 -4.24978137e-03  1.84243768e-02  5.28477877e-02
  2.39452422e-02 -4.51163426e-02  1.35609508e-03  8.63295645e-02
  1.64747089e-02  1.40246004e-02  6.65407777e-02  1.78154558e-01
  8.14345181e-02  9.03755277e-02  1.62248999e-01  6.05962574e-02
  4.51842248e-02  6.38467968e-02  1.26699358e-02  1.17370152e+00
  9.88252819e-01  6.34244382e-02  1.44214392e-01  1.18851632e-01
  3.45260143e-01  2.21222430e-01  1.29378289e-01  1.42875642e-01
  1.04026943e-02  1.15035012e-01  4.18355316e-02  5.60788810e-03
  3.23974758e-01  9.69274700e-01  1.25824153e-01  1.98204756e-01
  3.14668000e-01  4.89666343e-01  2.27890670e-01  5.47788441e-02
  9.35245752e-02  1.26798964e+00  1.17037937e-01  3.56334746e-02
  3.95800918e-02 -5.00531495e-03  1.47655964e-01  1.04374290e+00
  6.57646298e-01 -1.61703527e-02  6.64718747e-02  3.60708475e-01
  1.58654094e-01  2.19033569e-01  9.02096927e-03  2.30231911e-01
  2.93942392e-02  3.29855680e-02  1.85424089e-03  3.02180648e-03
 -1.09008625e-02  3.10159713e-01  9.49587226e-02  8.82911682e-03
  1.79017127e-01 -5.38629293e-03  5.31183034e-02  2.67392099e-02
  1.12600818e-01  1.20687580e+00  8.59738469e-01  6.26609147e-01
  3.93141270e-01  4.73174453e-03  3.11942518e-01 -8.90498310e-02
  2.11652666e-02  1.97665960e-01  2.32656062e-01  2.29861140e-02
  2.62182057e-02  1.73145592e-01  1.98208958e-01  1.56752050e-01
  3.78503054e-02  1.01636395e-01  1.40189320e-01  4.60398614e-01
  1.08910143e-01  2.54531413e-01  1.40847981e-01  2.35708565e-01
  1.56841606e-01 -1.45764723e-02  1.45836473e-02  1.33628935e-01
 -1.37177631e-02  2.36912876e-01  8.22822571e-01  2.23212361e-01], shape=(324,), dtype=float32)
rounded label:tf.Tensor(
[ 1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0. -0.  0.  0.  0. -0. -0. -0. -0.  1.  0.  0.  0.  0.  0.  0.
  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.
  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.
  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.
 -0.  0. -0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0. -0.  0.  0.  0.  0.  0.
  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0. -0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  1.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0. -0.  0. -0.  0.  0.  0. -0.
 -0. -0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0. -0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0. -0.
  0.  1.  1. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.
  0. -0.  0.  0.  0.  1.  1.  1.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0. -0.  0.  1.  0.], shape=(324,), dtype=float32)
predicted label rank:[2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1
 1 1 1 1 1 1 2 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1]
mse:tf.Tensor(0.14294477, shape=(), dtype=float32)
-------
true label:[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2
 2 2 2 2 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1
 1 1 1 1 1 1]
predicted label:tf.Tensor(
[ 5.7294011e-01  5.4145747e-01  2.7009213e-01  4.8750836e-01
  4.4091934e-01  2.3586783e-01  3.4495252e-01  2.1853501e-01
  3.2340789e-01  2.9621798e-01  2.8856644e-01  1.2227386e-02
  5.1610485e-02 -9.2446655e-03  4.7751501e-02  2.7729571e-02
  1.6730309e-02  2.7419835e-02  2.1983862e-02  5.2174389e-02
  5.4649413e-03  4.6287194e-02  2.2105932e-02  7.9460919e-02
  3.2941028e-02  4.0268794e-02  5.0789177e-02  1.2422469e-01
  6.0609454e-01  1.8652320e-01  9.1760010e-01  4.5263648e-02
  9.5332995e-02  6.7241088e-02  5.7827950e-02 -2.3952506e-02
 -3.5969019e-03  8.5457325e-02  4.0860385e-01  3.0096596e-01
  7.4488789e-01  4.5056784e-01  2.1515745e-01  6.0787898e-01
  5.3638601e-01  5.5089325e-01  6.0465389e-01  5.1876551e-01
  3.4436017e-02  2.5920194e-01  4.4815853e-02  9.0750414e-01
  5.4552943e-01  9.6041471e-01  9.2554241e-01  1.2285454e+00
  8.7435544e-04 -3.5527907e-02  1.1945679e+00  9.7626492e-02
  8.3178982e-02  2.2377050e-01  2.4771020e-01  4.6503365e-02
  2.3771939e-01  8.7712720e-02  5.4363415e-02  1.8045515e-01
  7.1965802e-01  4.5779514e-01  1.0432539e+00  2.1271721e-01
  7.2505003e-01  4.8283294e-02  1.0383220e+00  1.0484462e+00
  4.0300208e-01  9.2085475e-01  5.5957288e-03  9.8718208e-01
 -6.5545231e-02 -1.0298342e-03  5.5308372e-02  5.4053634e-02
 -1.1965808e-01 -3.2693148e-04 -6.2264696e-02  5.0032139e-04
  6.9360897e-02  1.5996099e-03  1.9907033e-01  5.0405592e-02
  1.0944769e-02 -3.7385054e-02 -2.0920031e-02 -1.0253295e-02
  3.8510799e-02  5.8547962e-01  8.1635213e-01  2.4624255e-01
  3.8703603e-01  2.5156513e-01  2.1131331e-01  2.9515338e-01
  4.9019772e-01  1.7784178e-01  1.5546411e-01  6.8531281e-01
  3.2259220e-01  3.4536332e-02  6.1948419e-02  1.2197873e-01
  1.3880375e-01  6.9152296e-02  4.6549171e-01  1.1346157e+00
  4.0802473e-01], shape=(117,), dtype=float32)
rounded label:tf.Tensor(
[ 1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0. -0.
 -0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1.  0. -0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.
  1.  0.  1.  1.  0.  1.  0.  1. -0. -0.  0.  0. -0. -0. -0.  0.  0.  0.
  0.  0.  0. -0. -0. -0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.
  0.  0.  0.  0.  0.  0.  0.  1.  0.], shape=(117,), dtype=float32)
predicted label rank:[2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1
 1 1 1 2 1 1 2 2 2 2 2 1 1 1 2 2 2 2 2 1 1 2 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1
 2 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1
 1 1 1 1 2 1]
mse:tf.Tensor(0.26242527, shape=(), dtype=float32)
-------
true label:[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1]
predicted label:tf.Tensor(
[ 5.72940111e-01  5.60362995e-01  3.42851490e-01  4.79108930e-01
  3.64298046e-01  2.35867828e-01  3.44952524e-01  2.18535006e-01
  3.23407888e-01  2.96217978e-01  2.88566440e-01  2.85837442e-01
  4.97926414e-01  1.02306187e-01  3.48727316e-01  5.64103425e-02
  1.25523657e-02  2.49346942e-02 -2.30142847e-02  5.21743894e-02
  5.46494126e-03  4.62871939e-02  2.21059322e-02 -7.31259584e-04
  5.25042862e-02  1.06012821e-03  2.53828168e-02  1.68895274e-02
  7.29956627e-02  1.80167407e-02  1.85361505e-02  1.73640847e-02
  2.28772461e-02  1.66615576e-01  1.56102777e-01  2.62983352e-01
  9.36787426e-02  1.28616422e-01  6.53277040e-02  4.39950824e-03
  2.71563619e-01  1.13319665e-01  5.49834967e-02  1.49616599e-01
  2.15380818e-01  1.91642642e-01  1.15750813e+00  7.46954858e-01
  1.24175131e-01  1.71384096e-01  9.98157263e-03  1.67102069e-01
  3.07779074e-01  3.40839475e-01  3.62127364e-01  5.16594887e-01
  5.33361286e-02  2.20083296e-02  7.00253725e-01  1.88398004e-01
  1.05320692e-01  2.00448841e-01  4.99303997e-01  5.98870516e-02
  4.71242189e-01  1.49971992e-01  1.27356619e-01  1.09061420e-01
  1.28131270e-01  1.11208737e-01  1.12753451e-01  7.52444923e-01
  5.76803684e-02  1.32651478e-01  1.32968277e-01  6.05668843e-01
  2.28666902e-01  5.63705862e-01  1.24755234e-01  4.81150270e-01
  3.89837503e-01  1.86910093e-01  3.35858107e-01  5.83636522e-01
  1.50174588e-01 -3.43347266e-02  9.63375121e-02  8.53834897e-02
  1.02659717e-01  1.92904025e-01 -4.30509597e-02  4.16409194e-01
  4.48616296e-02  5.45145273e-02  1.35535449e-02  7.21663982e-02
  5.73151708e-01  5.38627952e-02  2.63734281e-01  8.64018053e-02
  9.66443568e-02 -8.29943120e-02  2.68171966e-01  5.50325334e-01
  6.45180345e-01  3.18731576e-01  8.10631365e-02  7.20950246e-01
 -1.82715058e-03  5.01893461e-01  1.00851083e+00  7.65096009e-01
  1.06060362e+00 -9.54899192e-03 -1.85571536e-02  2.33656615e-02
  2.00867355e-02  1.43590569e-02  1.35663003e-02 -3.49187851e-03
  1.60555094e-02 -1.97956637e-02 -8.58023763e-04 -1.52371824e-02
 -5.07432222e-03 -2.96705961e-03 -1.31268650e-02 -1.09931156e-02
  2.15212703e-02 -7.56785274e-04  3.91555727e-02  5.77531606e-02
  1.64413601e-02  1.47947043e-01  3.73490751e-02  6.35429561e-01
  2.99946994e-01  6.31440133e-02  5.61681271e-01  1.84327066e-01
  8.43510926e-02  1.23903960e-01  2.51983047e-01  2.87738949e-01
  4.34511453e-02  4.26851213e-02  1.11493140e-01  2.24793106e-02
  1.17481172e-01 -8.04786012e-02 -3.23008373e-02  6.78444207e-02
  1.48118764e-01  1.02469787e-01  9.76497233e-02  1.42982244e-01
  2.94511139e-01  1.74597710e-01  2.82809585e-02 -3.30837220e-02
  3.26323956e-02  7.21989721e-02  1.12244502e-01  1.30780846e-01
  5.47758639e-02  4.30012792e-02  8.69655907e-02  2.45721340e-02
 -1.90155581e-02  3.18571180e-02  9.73002613e-03 -5.03165126e-02
  6.14306927e-02  8.80246311e-02 -4.45179641e-03  3.22122127e-02
  5.54218888e-04  1.22512996e-01 -2.81122252e-02  4.82625216e-02
 -5.85479066e-02  6.54138327e-02 -3.73025239e-03  4.31173086e-01
  5.15250623e-01  8.65473449e-02  1.67778164e-01  9.46296751e-02
  7.88058043e-02  4.29086238e-02  1.40780568e-01], shape=(191,), dtype=float32)
rounded label:tf.Tensor(
[ 1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
 -0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.
  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0. -0.  0.  0.  0.  0.
 -0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0. -0.  0.  1.  1.  0.  0.  1.
 -0.  1.  1.  1.  1. -0. -0.  0.  0.  0.  0. -0.  0. -0. -0. -0. -0. -0.
 -0. -0.  0. -0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0. -0. -0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.
  0.  0.  0.  0.  0.  0. -0.  0.  0. -0.  0.  0. -0.  0.  0.  0. -0.  0.
 -0.  0. -0.  0.  1.  0.  0.  0.  0.  0.  0.], shape=(191,), dtype=float32)
predicted label rank:[2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 2 1 1 2 1 2 2
 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 1 1 1 1 1 1]
mse:tf.Tensor(0.18895951, shape=(), dtype=float32)
-------
true label:[1, 1, 1, 1, 0, 1, 0, 1, 1, 2, 2, 1, 0, 1, 1, 2, 2, 1, 0, 0, 0, 1, 2, 2, 1, 0, 1, 0, 0, 1, 1, 2, 2, 1, 0, 1, 2, 2, 1]
true label rank:[2 2 2 2 1 2 1 2 2 3 3 2 1 2 2 3 3 2 1 1 1 2 3 3 2 1 2 1 1 2 2 3 3 2 1 2 3
 3 2]
predicted label:tf.Tensor(
[1.0465696  0.96029705 1.053272   1.3215206  1.0783648  1.0614903
 1.0980144  0.21967092 0.20876196 0.15359148 0.23939952 0.19546333
 0.9969403  0.3042349  0.21596974 0.70323426 0.3031482  0.36192212
 0.16644415 0.1230908  0.33950534 1.084614   0.28365082 0.57602316
 0.2874556  0.10632198 0.15054551 0.36959994 1.0165846  0.7700143
 0.58490986 0.35048297 1.0876245  1.052002   0.29130134 0.12856692
 0.6622945  1.0192833  0.10322477], shape=(39,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0.], shape=(39,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 1 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 2 1 2 2 1 1 2
 2 1]
mse:tf.Tensor(0.86319506, shape=(), dtype=float32)
-------
true label:[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[3 1 1 ... 1 1 1]
predicted label:tf.Tensor([1.0304034 0.9552056 0.3733074 ... 1.2341087 1.2222381 1.2932796], shape=(1644,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. ... 1. 1. 1.], shape=(1644,), dtype=float32)
predicted label rank:[2 2 1 ... 2 2 2]
mse:tf.Tensor(0.13739279, shape=(), dtype=float32)
-------
true label:[2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[3 1 1 ... 1 1 1]
predicted label:tf.Tensor([1.0304034  0.9552056  0.3733074  ... 0.16968375 0.04724574 0.13154596], shape=(1114,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. ... 0. 0. 0.], shape=(1114,), dtype=float32)
predicted label rank:[2 2 1 ... 1 1 1]
mse:tf.Tensor(0.3490394, shape=(), dtype=float32)
-------
true label:[1, 0, 0, 1]
true label rank:[2 1 1 2]
predicted label:tf.Tensor([0.7486409 1.051368  1.2912273 1.0592325], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)
predicted label rank:[1 1 1 1]
mse:tf.Tensor(0.70983315, shape=(), dtype=float32)
-------
true label:[1, 0]
true label rank:[2 1]
predicted label:tf.Tensor([0.7486409  0.39266205], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 0.], shape=(2,), dtype=float32)
predicted label rank:[2 1]
mse:tf.Tensor(0.10868244, shape=(), dtype=float32)
-------
true label:[1, 0, 0, 0]
true label rank:[2 1 1 1]
predicted label:tf.Tensor([0.5876888  0.8794914  0.07515904 0.82674724], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1.], shape=(4,), dtype=float32)
predicted label rank:[2 2 1 2]
mse:tf.Tensor(0.4081664, shape=(), dtype=float32)
-------
true label:[6, 6]
true label rank:[1 1]
predicted label:tf.Tensor([1.2373149 0.123274 ], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 0.], shape=(2,), dtype=float32)
predicted label rank:[2 1]
mse:tf.Tensor(28.609539, shape=(), dtype=float32)
-------
mean(mse_list):56.09451
