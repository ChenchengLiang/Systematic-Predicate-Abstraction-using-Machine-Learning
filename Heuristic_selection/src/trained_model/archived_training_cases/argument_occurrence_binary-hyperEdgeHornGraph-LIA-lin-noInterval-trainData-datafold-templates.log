best_valid_epoch:37.0
train loss:0.0147204865
valid loss:0.07993954
test loss list:tf.Tensor(0.13287754, shape=(), dtype=float32)
mean test loss:0.13287754
mean loss list:tf.Tensor(0.18070275, shape=(), dtype=float32)
mean mean loss:0.18070275
accuracy list:[<tf.Tensor: shape=(), dtype=float64, numpy=0.8317744580876812>]
mean accuracy:0.8317744580876812
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/loop__barthe2_000.smt2
true label:[1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1]
predicted label:tf.Tensor([0.9951328  0.7716954  0.84095144 0.9997528  0.97225034], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.015642647, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/minepump_spec3_product49_true-unreach-call.cil.c.flat_000.smt2
true label:[0, 1, 0, 0, 1]
true label rank:[1 2 1 1 2]
predicted label:tf.Tensor([0.8261931  1.         0.9061196  0.7846638  0.98599035], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.4239083, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/four1.smt2-0033_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2]
predicted label:tf.Tensor(
[3.8039056e-09 1.5880677e-01 8.3759582e-01 7.3103333e-01 1.1731684e-03
 9.7054899e-02 1.8250942e-04 6.6119432e-04 4.1458011e-04 7.9259276e-04
 1.9113600e-02 1.1323435e-04 1.0763109e-03 3.0555487e-02 6.9874525e-04
 4.2304920e-05 3.7295222e-03 2.4542511e-03 5.2901894e-01 5.4370850e-02], shape=(20,), dtype=float32)
rounded label:tf.Tensor([0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.], shape=(20,), dtype=float32)
predicted label rank:[1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1]
mse:tf.Tensor(0.11939882, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/loop__loop_000.smt2
true label:[1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1]
predicted label:tf.Tensor([0.97753274 0.84826463 0.80520177 0.9999814  0.95761764], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.012654203, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/four1.smt2-0046_000.smt2
true label:[0, 0, 0, 0, 1, 1]
true label rank:[1 1 1 1 2 2]
predicted label:tf.Tensor([0.5404758  0.44286928 0.72233593 0.87373084 0.5169629  0.09538734], shape=(6,), dtype=float32)
rounded label:tf.Tensor([1. 0. 1. 1. 1. 0.], shape=(6,), dtype=float32)
predicted label rank:[2 1 2 2 2 1]
mse:tf.Tensor(0.47084513, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/s3_clnt_1.cil-1.c-1_000.smt2
true label:[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]
true label rank:[2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1]
predicted label:tf.Tensor(
[9.79454160e-01 7.41728456e-07 3.63912255e-01 4.08149213e-01
 3.67766619e-03 2.89246440e-03 4.77880239e-04 4.53165174e-03
 9.61093068e-01 8.91002893e-01 5.59481978e-03 6.08503819e-04
 2.27435085e-05 7.86978006e-03 1.33424997e-04 2.31666446e-01
 2.92405486e-03 2.66581774e-04 9.70155299e-02 4.40397322e-01
 2.29522586e-03 6.52005076e-01 3.71674448e-01 1.05676055e-02
 1.47664845e-02 7.72809982e-03 1.67734921e-02 1.11450255e-02
 1.32772624e-02 3.95932794e-03 8.34328413e-01 9.46880817e-01
 1.11347437e-03 3.82363796e-04 6.73383474e-04 3.49222864e-05
 5.26072108e-05 1.08629465e-03 7.06374645e-04 1.26948953e-03
 1.41644478e-03 1.18916505e-05 2.41379494e-05 4.17888165e-04
 4.54276800e-04 6.78062439e-04 8.68439674e-04 6.01798296e-04
 1.13850832e-03 3.74394377e-10 6.66062842e-05 5.35726547e-04
 1.10623240e-03 6.19053841e-04 5.52654266e-04 1.54575628e-06
 1.24237295e-05 7.42714155e-06 1.55326724e-03 9.99990761e-01
 5.60078621e-02 9.37515497e-03 1.26994848e-02 8.71931314e-02
 6.15938008e-02 3.88199091e-02 6.98209703e-02 3.29812765e-02
 1.03774965e-01 3.78206372e-02 2.50683427e-02 9.37574208e-02
 5.85810840e-02 7.75841773e-02 6.13540113e-02 4.66572046e-02
 2.46772468e-02 5.19487262e-03 7.65282214e-02 4.93032932e-02
 1.55552924e-02 2.65696645e-03 6.22532070e-02 5.19605279e-02
 4.52938378e-02 4.09925282e-02 3.23610008e-02 2.91349888e-02
 8.47921073e-02 1.40323043e-02 6.09070063e-03 2.39274204e-02
 3.10525298e-03 6.39814138e-03 1.56497061e-02 4.46939468e-03
 7.76150823e-03 5.17073274e-03 1.13698542e-02 1.52313709e-02
 1.94595456e-02 2.01931000e-02 9.58198309e-03 7.79870152e-03
 1.19388103e-02 8.34071636e-03 1.38556957e-03 1.20228827e-02
 1.68657303e-02 2.22966075e-03 5.22750616e-03 1.11527443e-02
 1.73544884e-02 2.08389759e-03 5.79592586e-03 7.82173872e-03
 1.35083497e-02 1.78342760e-02 1.07765794e-02 6.54704869e-02
 4.32091951e-03 2.28455663e-03 1.03574991e-02 5.01275063e-03
 1.91950500e-02 7.37017393e-03 1.37249529e-02 9.27183032e-03
 5.60572743e-03 7.20915198e-03 1.37193501e-02 4.54181135e-02
 1.31878257e-03 5.46382175e-08 4.83137369e-03 3.87114286e-03
 1.73747540e-04 5.84599376e-03 7.98329711e-03 1.68818235e-03
 9.19526815e-03 2.72077322e-03 5.19934297e-03 4.97123599e-03
 7.97295570e-03 1.54680610e-02 1.52181387e-02 4.75609303e-03
 4.15917039e-02 1.84306800e-02 1.81369781e-02 9.46682692e-03
 2.15008557e-02 1.46719217e-02 1.13260746e-02 8.52069259e-03
 1.59223974e-02 2.01117694e-02 5.15997410e-04 1.22577846e-02
 1.80062652e-02 8.17140937e-03 9.50118899e-03 1.33840442e-02
 1.32909119e-02 1.33770704e-03 5.63174486e-04 9.44349170e-03
 1.45109892e-02 8.42720270e-04 8.34448338e-01 1.02849603e-02
 1.39946342e-02 1.43186152e-02 2.32522190e-02 1.82545781e-02
 1.54233873e-02 7.35515356e-03 7.57079601e-01 5.13532758e-03
 8.11451674e-03 5.55750728e-03 3.85075808e-04 4.25571203e-03
 3.59448791e-03 3.02362442e-03 4.43723798e-03 2.30321169e-01
 2.52780318e-03 3.35261226e-03 5.70467114e-03 1.24057531e-02
 7.63970613e-03 1.92075968e-03 4.09316417e-05 7.98821449e-04
 4.90632653e-03 1.17649734e-02 3.72357368e-02 4.00736928e-03
 1.89066529e-02 2.75936723e-03 6.77728653e-03 1.16122067e-02
 4.44027781e-03 5.41764498e-03 1.73859298e-02 3.93873947e-08
 4.39882278e-04 2.83271074e-04 2.06232071e-04 5.84125519e-04
 2.45749950e-04 5.97749412e-01 7.05718994e-04 4.02241945e-04
 6.00665808e-04 8.81566448e-05 4.35858965e-04 1.29997730e-04
 3.31014395e-04 1.07142329e-03 2.64465809e-04 1.27136707e-04
 1.92135572e-04 1.08844812e-04 5.80988562e-05 1.46934181e-05
 6.81320525e-05 2.44875935e-07 6.63593937e-07 5.87403774e-04
 5.48452139e-04 8.80707667e-05 2.89916992e-04 2.85536051e-04
 5.12137121e-05 5.75384498e-03 3.42011452e-03 5.14477491e-03
 2.46551633e-03 7.67573714e-03 1.10415220e-02 9.80144739e-03
 3.00315022e-03 9.71230865e-03 2.31048465e-03 5.06916642e-03
 3.83535028e-03 6.12935424e-03 1.78217888e-03 3.19904089e-03
 4.66553465e-05 9.38531812e-05 4.93949652e-03 1.58071518e-04
 1.26126793e-06 8.66651535e-04 9.17252898e-03 8.27944279e-03
 8.81174207e-03 5.65218925e-03 2.80538201e-03 4.86463308e-03
 5.71990013e-03 3.29926610e-03 2.69639492e-02 1.76124871e-02
 6.10223711e-02 1.32955313e-02 4.85745072e-02 4.56261635e-03
 5.83105087e-02 1.86927915e-02 1.86819732e-02 1.98376179e-03
 1.26540661e-04 4.75604978e-08 9.62889194e-03 5.22567332e-02
 6.87941909e-03 1.32038593e-02 7.42882490e-04 8.04382563e-03
 3.80358100e-03 7.69549608e-03 1.13533139e-02 6.60562515e-03
 1.52973831e-02 9.68164206e-03 2.70351470e-02 9.15861130e-03
 1.47599876e-02 5.77884018e-02 7.56646752e-01 5.09697199e-02], shape=(296,), dtype=float32)
rounded label:tf.Tensor(
[1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0.], shape=(296,), dtype=float32)
predicted label rank:[2 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1]
mse:tf.Tensor(0.044999722, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/counter.correct.nts_000.smt2
true label:[1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1]
predicted label:tf.Tensor([0.10835093 0.8100195  0.37607923 0.9823628  0.81185955 0.94692516], shape=(6,), dtype=float32)
rounded label:tf.Tensor([0. 1. 0. 1. 1. 1.], shape=(6,), dtype=float32)
predicted label rank:[1 2 1 2 2 2]
mse:tf.Tensor(0.20982207, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/listcounter.correct.nts_000.smt2
true label:[1, 1, 0, 1, 1, 1, 1, 1, 0, 0]
true label rank:[2 2 1 2 2 2 2 2 1 1]
predicted label:tf.Tensor(
[0.9822464  0.9847154  0.74147713 0.9412945  0.9296214  0.66866577
 0.99374527 0.73546827 0.99746966 0.8311521 ], shape=(10,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(10,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.24242947, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0265_000.smt2
true label:[1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2
 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1
 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2
 2 2 1 2 1 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 1
 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 1 2 2 2 2 2
 1 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[9.99999285e-01 9.99998212e-01 1.00000000e+00 1.00000000e+00
 1.00000000e+00 9.99651551e-01 6.99892640e-01 8.42736244e-01
 9.41113234e-01 7.47392178e-01 9.99950171e-01 9.99811649e-01
 9.99841452e-01 1.00000000e+00 9.99993801e-01 9.50636864e-01
 2.33173370e-03 5.86861372e-03 9.52395082e-01 9.94237423e-01
 9.64184344e-01 9.59688365e-01 9.98298764e-01 1.00000000e+00
 9.63438988e-01 5.02480567e-02 9.31813121e-01 9.25770521e-01
 8.97571087e-01 9.15340185e-01 9.74141121e-01 9.85132158e-01
 9.85837579e-01 3.79389226e-01 9.76083934e-01 9.97841239e-01
 9.96025681e-01 9.94422436e-01 9.92767036e-01 9.96554732e-01
 9.81507778e-01 4.66336161e-01 9.99329090e-01 9.45367277e-01
 9.36350524e-01 9.14620459e-01 9.61453199e-01 9.88665462e-01
 9.32739615e-01 4.19446111e-01 9.97394323e-01 9.91645575e-01
 9.96355057e-01 9.82765973e-01 9.87033725e-01 9.89774704e-01
 9.93916154e-01 4.65455830e-01 9.95064974e-01 9.80960965e-01
 9.74947989e-01 9.10700679e-01 9.65196609e-01 9.74453688e-01
 7.22333193e-01 3.00945520e-01 9.88467515e-01 9.96403158e-01
 9.62900043e-01 8.88979495e-01 9.87383366e-01 9.91803885e-01
 9.92263913e-01 3.18997592e-01 9.20255542e-01 9.48104262e-01
 9.77477789e-01 7.72127151e-01 9.56579924e-01 9.82345641e-01
 9.75893438e-01 4.68495756e-01 8.59335899e-01 9.91461277e-01
 9.83607709e-01 9.86272633e-01 9.96578693e-01 9.95442152e-01
 9.97183323e-01 2.36450702e-01 9.99385476e-01 9.75166321e-01
 9.92862225e-01 9.79312539e-01 9.84964132e-01 9.92580056e-01
 9.95312154e-01 5.14948547e-01 9.69546735e-01 9.63396549e-01
 9.89343047e-01 9.82835650e-01 9.85385895e-01 9.93201375e-01
 9.87713397e-01 4.67188716e-01 9.45685863e-01 9.97063518e-01
 9.90418971e-01 9.90469575e-01 9.95822251e-01 9.89490271e-01
 9.91745472e-01 3.93087804e-01 9.92629528e-01 9.97810721e-01
 9.96966004e-01 9.96312439e-01 9.96820450e-01 9.99303639e-01
 9.98216510e-01 1.64285332e-01 9.99191403e-01 9.77919638e-01
 7.62554228e-01 9.51545715e-01 9.92098212e-01 9.93647933e-01
 9.89943385e-01 1.68773711e-01 9.89155054e-01 9.89758253e-01
 8.97732913e-01 9.76923943e-01 9.84906554e-01 9.89003181e-01
 9.87435579e-01 3.97710323e-01 9.92761850e-01 9.95909214e-01
 9.94762003e-01 9.97758389e-01 9.96403098e-01 9.98767972e-01
 9.98198509e-01 4.48974878e-01 9.98662829e-01 9.58376288e-01
 9.85327244e-01 9.91801620e-01 9.94692922e-01 9.94994164e-01
 9.82962787e-01 4.98172164e-01 9.98178899e-01 3.26047003e-01
 3.40937734e-01 7.11688757e-01 9.79185045e-01 9.82827723e-01
 9.56786990e-01 3.32879663e-01 9.95532274e-01 7.97309577e-01
 9.91119027e-01 9.84184861e-01 9.81167018e-01 9.92094755e-01
 9.79129553e-01 3.57963949e-01 9.94426668e-01 2.51433909e-01
 9.67573047e-01 9.85249758e-01 9.93606508e-01 9.94571626e-01
 9.84430075e-01 2.22914845e-01 9.96258497e-01 8.21242213e-01
 9.76915240e-01 9.88040030e-01 9.76943493e-01 9.87723708e-01
 9.80987310e-01 4.51284021e-01 9.94097471e-01 4.61545289e-01
 9.94721472e-01 9.59403574e-01 9.87964511e-01 9.89696264e-01
 9.78220344e-01 3.60642076e-01 9.92174149e-01 9.94829357e-01
 9.86670375e-01 9.81232285e-01 9.93828237e-01 9.96214211e-01
 9.94438469e-01 4.36211467e-01 9.87557530e-01 8.97848725e-01
 6.30219281e-01 7.33150721e-01 9.81985569e-01 9.74899530e-01
 8.89244020e-01 1.18896604e-01 9.92956221e-01 9.08510804e-01
 5.50391972e-01 7.03806639e-01 9.84976411e-01 9.79520917e-01
 1.58733785e-01 2.29455829e-02 9.31747198e-01 4.28922285e-05
 3.79777994e-05 1.60515308e-03 1.09019876e-03 4.52876091e-04
 1.01495258e-04 2.94194069e-05 7.91946659e-05 3.85382771e-03
 5.71042299e-03 9.37372446e-04 7.96803832e-03 4.39816713e-03
 2.14585662e-03 1.84974074e-03 7.36866832e-06 1.00442767e-03
 8.75543119e-05 1.22165680e-03 1.61425471e-02 2.23818421e-03
 1.32918358e-04 1.29804611e-02 5.28848469e-02 2.12034881e-02
 1.94147229e-03 1.22032464e-02 4.42851901e-01 2.23050416e-02
 2.48330832e-03 1.07961297e-02 6.71271682e-01 4.13385278e-05
 1.63793564e-04 3.02731991e-04 1.80020928e-03 1.12548470e-03
 1.82241201e-04 1.18216872e-03 1.92794204e-03 1.71402097e-03
 1.26506388e-02 1.08182430e-03 7.35997617e-01 5.10206819e-03
 1.10492110e-03 1.04161203e-02 6.83620572e-03 3.70562077e-04
 3.27944756e-04 8.36998224e-04 2.94913650e-02 5.08686900e-03
 1.95300579e-03 7.75694847e-04 3.10063362e-04 4.87998186e-05
 5.00711799e-03 5.09649515e-04 5.30800223e-03 3.24428082e-03
 3.85999680e-04 7.04312325e-03 3.51449847e-03 1.17678692e-05
 1.30712986e-04 1.62571669e-04 2.01234221e-03 1.52170658e-04
 1.36345625e-04 2.19672918e-04 1.89486146e-03 1.29401684e-04
 7.46548176e-04 5.33044338e-04 7.92586803e-03 4.73558903e-04
 1.30295753e-04 2.01499462e-03 2.08082795e-03 5.63693447e-06
 1.04478704e-05 4.92266463e-06 3.68403792e-02 6.02393920e-05
 1.00792131e-05 8.62543893e-05 1.48326159e-04 4.23786951e-05
 2.81154644e-05 2.31087208e-04 2.21049786e-03 2.40133886e-05
 1.81264131e-05 1.07242384e-04 1.79737806e-04 4.21960867e-05
 3.30650801e-05 1.08660352e-05 8.82532113e-05 4.79541231e-05
 9.86757368e-06 1.26928091e-04 1.07310671e-05 2.24141477e-05
 1.26128780e-05 2.37336026e-05 1.80840492e-04 4.89488502e-06
 2.88163410e-05 5.74082136e-04 1.25253201e-03 3.86067586e-06
 3.66002321e-04 2.76534138e-06 2.10833914e-05 3.84325067e-05
 3.34403893e-07 7.90553677e-05 7.03717960e-05 7.83004270e-06
 7.07689367e-07 5.06761990e-06 8.71860981e-03 2.19089416e-05
 4.26237904e-07 1.61440585e-05 1.88000886e-05 1.41261626e-06
 1.91303684e-06 4.67661539e-06 2.82278657e-03 6.11913492e-05
 8.55687449e-06 1.18257129e-04 6.52985364e-08 1.48338340e-05
 2.22444534e-04 1.29101363e-05 7.91370869e-04 8.87589704e-05
 1.18589214e-05 4.34655885e-05 4.67232468e-07 4.51737287e-06
 9.05137676e-06 3.41784562e-06 1.60306692e-03 6.27330905e-07
 1.82025906e-06 7.58881197e-06 8.38866981e-05 1.93427695e-06
 2.15344353e-05 1.58563660e-06 9.70363617e-04 4.95737877e-05
 1.90033479e-05 1.99288130e-04 2.11558981e-05 3.46398951e-06
 5.87546971e-08 1.23243435e-05 9.70211113e-06 5.57352869e-05
 1.31789920e-06 1.23848695e-05 1.92463398e-04 4.62376283e-06
 3.23054883e-06 1.93622600e-06 1.07794032e-04 9.97884490e-06
 1.84430644e-06 1.24028466e-05 5.84117750e-08 3.06930224e-06
 5.47803720e-05 7.32953631e-05 1.65435672e-03 5.09888523e-05
 6.89997614e-05 1.66726112e-03 8.26858832e-06 4.80264353e-05
 2.69373832e-05 4.97166293e-05 1.01858377e-03 7.35480944e-06
 3.89490779e-05 2.71320343e-04 1.33592330e-05 4.13566828e-04
 9.06243258e-06 8.24049221e-06 5.08069992e-04 5.45738021e-06
 4.75327988e-06 1.00255013e-03 3.59333649e-06 1.69977546e-03
 4.14708447e-05 1.81049109e-04 1.13496184e-03 4.83840704e-04
 2.72191573e-06 1.83105469e-04 1.53392553e-04 1.22139591e-05
 5.14134699e-05 2.67855103e-06 6.76989555e-04 1.35272741e-04
 1.16131796e-05 7.02172518e-04 9.23960033e-05 6.15506815e-06
 1.73479759e-06 9.76519550e-06 5.61330635e-05 5.94752710e-05
 1.15988132e-05 5.97360740e-05 1.92910433e-04 2.82635233e-06
 6.54121905e-05 1.38223171e-04 1.43557787e-04 2.85774513e-05
 4.88575133e-05 4.14222479e-04 6.47510342e-06 3.76448297e-05
 5.48832286e-05 2.30861187e-05 1.81028247e-03 2.30491161e-04
 1.11652498e-05 1.20913937e-04 4.60900774e-05 6.18305785e-05
 1.29789114e-04 2.57724114e-05 9.48461748e-05 5.08487225e-04
 2.14159489e-04 5.25975811e-05 3.75763193e-05 7.25152267e-06
 5.70599241e-06 2.48507763e-06 1.01935366e-04 6.66187334e-05
 2.60527554e-06 4.38498828e-05 1.45009499e-05 3.60907106e-05
 3.42384992e-05 4.17499323e-05 1.50841475e-03 2.19395915e-05
 1.13446098e-04 5.11944294e-04 5.52014626e-06 4.42200253e-05
 1.16039519e-06 2.81339162e-05 1.49808228e-02 3.93305163e-05
 2.38914326e-05 1.54495239e-04 3.60521153e-05 4.20706419e-05
 1.54248064e-05 3.49793481e-05 6.72787428e-04 2.43186951e-04
 1.75170917e-05 1.07562264e-04 7.80683149e-06 9.33909541e-05
 3.37823394e-07 8.42371637e-13 1.99826644e-07 2.42072344e-03
 1.79517263e-13 1.09315632e-04 2.84728662e-06], shape=(507,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1.
 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0.], shape=(507,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2
 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1
 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2
 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2
 2 2 2 2 2 1 2 1 1 2 2 2 2 1 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2
 1 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.027144784, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/bouncy_two_counters_equality_000.smt2
true label:[1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1]
predicted label:tf.Tensor([0.9484856  0.9450058  0.9825046  0.96355814 0.9648799 ], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.0017091237, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/dillig17.c_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.9723779  0.9604014  0.97907114 1.         0.82004607 0.99986815
 0.8977295  0.9996875  0.7172675 ], shape=(9,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(9,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.013949944, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/NetBSD_g_Ctoc.c_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.9995429  0.99778354 0.9813832  1.         0.99857366 0.78624725
 0.97934985 0.9424521  0.99265236 0.898186  ], shape=(10,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(10,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.0060202247, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/rotation_vc.correct.1.nts_000.smt2
true label:[0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1]
predicted label:tf.Tensor(
[9.04540181e-01 8.32677126e-01 7.28816450e-01 8.53722095e-01
 3.41173202e-01 8.96920085e-01 5.08209467e-01 5.82835173e-06
 1.67446703e-01 1.42454952e-01 5.83874404e-01 3.40804964e-01
 3.18258345e-01 5.43609142e-01 1.27399117e-01 5.06846011e-01
 3.89857888e-01 2.41872072e-02 5.14344523e-09 9.50809240e-01
 5.18767536e-02 2.00514495e-02 6.74432516e-03 1.40331686e-02
 4.25035417e-01 1.00515485e-02 3.14046741e-01 5.00864446e-01
 1.15927160e-02 4.27164674e-01 7.05510736e-01 7.28295743e-02
 1.48847163e-01 3.55863869e-02 8.56663883e-02 1.02346212e-01
 5.02955198e-01 1.86562538e-04 9.90868151e-01 3.46001923e-01
 8.16142559e-03 6.60598278e-04 7.72625029e-01 3.30777168e-02
 3.26479316e-01 3.73828262e-01 5.86969256e-02 9.66827810e-01
 9.08262253e-01 8.75727594e-01 9.89257693e-01 9.91100490e-01
 9.69403386e-01 4.32839334e-01 9.99982357e-01 4.46734875e-01
 2.94837356e-03 5.29510498e-01 1.49309486e-01 8.29028487e-02
 3.54311019e-01 2.83323377e-01 4.56498086e-01 8.18627715e-01
 8.39239359e-03 1.29520893e-04 8.31640601e-01 2.79217333e-01
 6.33725524e-03 4.87604737e-01 9.48250294e-04 9.70048904e-01
 8.41943026e-01 6.29723430e-01 6.41851008e-01 5.43877840e-01
 3.57061684e-01 4.45750356e-02 6.25611067e-01], shape=(79,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1.
 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1.
 1. 1. 1. 1. 0. 0. 1.], shape=(79,), dtype=float32)
predicted label rank:[2 2 2 2 1 2 2 1 1 1 2 1 1 2 1 2 1 1 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 2
 1 2 1 1 1 2 1 1 1 1 2 2 2 2 2 2 1 2 1 1 2 1 1 1 1 1 2 1 1 2 1 1 1 1 2 2 2
 2 2 1 1 2]
mse:tf.Tensor(0.3011463, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/28.c_000.smt2
true label:[1, 1, 1, 1, 0, 0, 1, 1, 0, 0]
true label rank:[2 2 2 2 1 1 2 2 1 1]
predicted label:tf.Tensor(
[0.74280393 0.75124156 0.6426569  0.45014238 0.78686523 0.77735245
 0.21799675 0.9797801  0.8115627  0.7014609 ], shape=(10,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 0. 1. 1. 0. 1. 1. 1.], shape=(10,), dtype=float32)
predicted label rank:[2 2 2 1 2 2 1 2 2 2]
mse:tf.Tensor(0.35441214, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0017_000.smt2
true label:[1, 1, 1, 1, 0, 0, 1, 1]
true label rank:[2 2 2 2 1 1 2 2]
predicted label:tf.Tensor(
[0.97195065 0.91128564 0.99995077 0.9997462  0.7264533  0.02074543
 0.9719924  0.86169446], shape=(8,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 0. 1. 1.], shape=(8,), dtype=float32)
predicted label rank:[2 2 2 2 2 1 2 2]
mse:tf.Tensor(0.06959184, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/spline-fixed.smt2-0003_000.smt2
true label:[0, 0, 1]
true label rank:[1 1 2]
predicted label:tf.Tensor([0.05656055 0.03245398 0.06776232], shape=(3,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)
predicted label rank:[1 1 1]
mse:tf.Tensor(0.2911065, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/013b-horn_000.smt2
true label:[1, 1, 1, 1, 1, 1, 0, 0]
true label rank:[2 2 2 2 2 2 1 1]
predicted label:tf.Tensor(
[0.9996493  0.9997209  0.9966364  0.99707764 0.67824435 0.06839219
 1.         1.        ], shape=(8,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 0. 1. 1.], shape=(8,), dtype=float32)
predicted label rank:[2 2 2 2 2 1 2 2]
mse:tf.Tensor(0.37142998, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0270_000.smt2
true label:[1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 2 2 2 2 1 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 1 1 2 2 2 2 2 1 1 2 2 2 2 2 1 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2
 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[9.99956369e-01 9.99976993e-01 1.00000000e+00 1.00000000e+00
 1.00000000e+00 9.85448837e-01 8.35386872e-01 7.90992558e-01
 9.94200766e-01 9.99364436e-01 9.99992967e-01 9.85305250e-01
 9.98883307e-01 1.00000000e+00 7.19821453e-03 4.01505828e-03
 8.26650858e-01 9.81218338e-01 9.52507257e-01 3.90196323e-01
 9.78087127e-01 3.63452554e-01 3.03224891e-01 9.75423217e-01
 6.80475473e-01 5.79139888e-01 8.13305855e-01 9.24254060e-01
 8.43951106e-03 7.98735023e-02 8.88852119e-01 9.74719524e-01
 9.81589258e-01 2.30209053e-01 8.86456430e-01 9.57842231e-01
 3.73100936e-01 9.90354300e-01 5.56647778e-04 1.01605058e-03
 1.01479888e-03 6.14569785e-07 9.85119459e-06 2.91976333e-03
 5.37058149e-05 9.25986751e-06 2.90435264e-06 3.70275666e-05
 1.86890364e-04 1.36257340e-05 3.85180116e-03 1.14945433e-05
 1.55711174e-03 3.02842259e-03 1.39346719e-03 1.57335401e-03
 6.19530678e-04 1.66035891e-02 3.76099348e-03 5.98821044e-03
 2.78055668e-04 1.16884708e-03 9.46491957e-04 6.08474016e-04
 2.88357437e-02 2.10154057e-03 1.37269497e-03 4.75734472e-04
 6.32870197e-03 2.30014324e-04 1.02847815e-03 6.46528602e-03
 4.21792269e-04 3.55529785e-03 5.48730241e-05 2.95013189e-04
 5.28812408e-04 1.44904434e-05 1.18692517e-02 1.76379085e-03
 4.49210405e-04 1.03705643e-04 1.50483847e-03 2.61813402e-04
 1.95664167e-03 2.41228938e-03 2.66807419e-05 9.85918045e-01
 1.00000000e+00 9.22146797e-01 9.30520773e-01 8.82730484e-01
 2.48253345e-02 9.38208401e-01 9.80118275e-01 9.86452162e-01
 9.82675314e-01 9.78103399e-01 9.75052834e-01 4.09528494e-01
 9.89062548e-01 9.80785072e-01 9.79699612e-01 9.91789162e-01
 9.11520481e-01 9.89526033e-01 1.18875772e-01 9.63281631e-01
 9.93198514e-01 9.96483445e-01 9.98213708e-01 9.84802365e-01
 9.97685075e-01 1.64428115e-01 9.83989239e-01 9.89371777e-01
 9.86712933e-01 9.84233797e-01 9.82983232e-01 9.90309596e-01
 5.07636786e-01 9.95901346e-01 9.95714426e-01 9.61176813e-01
 9.65033352e-01 9.69016075e-01 8.98619533e-01 2.35738337e-01
 9.72590208e-01 9.74705458e-01 9.55763996e-01 9.71742630e-01
 5.62517881e-01 9.91738796e-01 3.78812879e-01 9.85321224e-01
 9.16610479e-01 9.62337017e-01 9.05324340e-01 8.88442934e-01
 9.55009520e-01 4.27430749e-01 2.50251472e-01 1.44006938e-01
 3.06167006e-01 3.71165574e-02 5.55907786e-02 4.17193770e-03
 1.02764308e-01 7.89523125e-03 9.29951668e-03 6.10435009e-03
 1.22106969e-02 1.40774250e-03 7.00148940e-03 1.71587169e-02
 1.03208423e-03 3.79097462e-03 6.31272793e-04 1.20905638e-02
 8.45766068e-03 1.02353990e-02 3.65120471e-02 2.80976295e-04
 2.50956416e-02 5.06639481e-03 2.72647142e-02 6.72145188e-02
 3.21531892e-02 2.06776559e-02 1.87128782e-04 3.26188028e-01
 5.82287192e-01 8.23554516e-01 5.54400742e-01 4.86517578e-01
 2.77919561e-01 2.64793634e-04 1.05624914e-01 1.15534663e-03
 1.12414062e-02 9.82239842e-03 7.46175647e-03 1.69891119e-02
 2.33439207e-02 1.46149337e-01 4.40729856e-02 8.90214026e-01
 2.78343856e-02 4.43965197e-02 8.84670019e-02 1.13342792e-01
 7.76290894e-04 3.80653328e-05 1.77383423e-04 7.03811646e-04
 5.32746315e-04 2.78547406e-03 1.78855658e-03 3.57925892e-04
 1.24722719e-04 7.76884553e-05 1.70111656e-04 1.77025795e-04
 7.36504793e-04 1.22849800e-04 7.14674592e-03 1.23322010e-03
 2.19765306e-03 5.18620014e-04 4.42203879e-03 1.94699764e-02
 7.61643052e-03 7.01311231e-03 3.05494666e-03 2.19565630e-03
 2.06401944e-03 6.89253793e-05 3.07968259e-03 3.14059854e-03
 8.08268785e-04 7.21573830e-03 2.36451626e-04 3.06159258e-04
 4.15533781e-04 6.55144453e-04 1.53750181e-04 2.52604485e-04
 1.52140856e-04 7.48217106e-04 4.21686527e-05 3.14056873e-04
 6.22421503e-03 1.01681708e-05 9.27534711e-05 5.84840775e-04
 7.98336841e-05 2.46495008e-04 2.69114971e-04 2.84767151e-03
 9.96116432e-05 6.29736387e-05 5.34445047e-04 4.58478928e-04
 1.12165799e-04 1.09965375e-04 1.33949518e-03 3.49462032e-04
 8.01459173e-05 4.52280045e-04 8.59996799e-05 1.38312578e-04
 3.65896922e-05 1.62297487e-03 4.35023321e-05 2.91556120e-04
 7.39138413e-05 5.60492277e-04 7.95513391e-04 2.12624669e-03
 6.16043806e-03 7.68125057e-04 3.93189657e-05 8.59023858e-05
 3.33160162e-04 3.30211515e-05 8.78150458e-05 1.33353472e-03
 3.24597955e-03 6.26742840e-04 8.60095024e-04 1.30084157e-03
 1.79862976e-03 2.50756741e-04 1.08358264e-03 2.50548124e-04
 6.71017406e-05 1.56401384e-05 7.48521124e-05 3.68507935e-05
 9.55395735e-05 9.54139177e-05 4.04876555e-05 2.95162201e-04
 6.61313534e-04 5.32567501e-04 3.87489796e-04 5.98222017e-04
 2.72846222e-03 4.98592854e-04 1.26183033e-04 4.14791903e-05
 4.56392765e-04 3.34079086e-05 1.10522815e-04 5.08546829e-03
 7.45864672e-05 1.37906372e-05 7.74607470e-05 1.39385462e-04
 7.93328509e-05 2.20596790e-04 1.03157759e-03 6.82732889e-06
 2.92092562e-04 8.03879666e-05 3.97413969e-04 3.52799892e-04
 3.74320734e-05 1.61080956e-02 3.57983595e-06 5.93914992e-05
 1.21314788e-05 1.62363052e-04 5.71039345e-05 1.89930201e-04
 6.38067722e-04 4.34620870e-06 2.88790943e-05 1.44379019e-05
 1.72460568e-05 2.27729397e-05 5.49205333e-06 1.90231204e-03
 8.98853068e-06 1.28805637e-04 2.43043542e-05 5.76243037e-05
 1.22034166e-04 8.00579786e-04 1.22481585e-03 6.23597225e-06
 5.47257005e-05 2.22660242e-06 2.32700586e-06 1.83872617e-05
 3.66982522e-06 8.43885136e-05 2.09440313e-05 4.03344631e-04
 4.62725438e-05 7.73668289e-04 8.68052244e-04 7.42882490e-04
 8.08984041e-04 2.00691819e-03 2.39133835e-03 2.89022923e-04
 1.98695064e-03 1.19268894e-03 5.18501699e-02 1.72523558e-02
 2.21493840e-03 8.35508399e-06 1.97057693e-06 7.30521642e-05
 4.73320484e-04 3.62307219e-05 5.06818295e-04 9.18190708e-05
 2.06023455e-04 5.12244333e-06 1.86624493e-05 8.47647825e-05
 3.30090523e-04 1.12462044e-03 1.94767118e-03 8.70647546e-06
 4.55094269e-05 1.51975610e-05 2.09212303e-04 1.80721283e-04
 2.74956226e-04 1.20731593e-05 8.73655081e-04 2.93940306e-04
 1.51842833e-04 7.07745552e-04 3.91178182e-05 8.55088234e-04
 1.91014556e-06 1.74471352e-05 1.64356231e-06 2.92658806e-04
 3.33323915e-05 1.64756493e-05 5.45591116e-04 1.51959062e-03
 1.59054995e-04 4.83511612e-05 9.77811724e-05 1.36719955e-05
 1.67767630e-05 2.99215317e-04 8.84014639e-07 2.79873893e-06
 3.98159027e-04 5.42759895e-04 1.42651796e-03 6.84946775e-04
 3.57258320e-03 4.87476587e-04 1.87635422e-04 4.48942184e-04
 6.92635775e-04 4.61637974e-04 2.42432952e-03 2.87121534e-03
 3.70502472e-04 2.00152397e-04 2.47420321e-05 4.29719687e-04
 1.01757960e-05 6.34034222e-05 6.80357218e-04 1.57803297e-04
 2.49177217e-04 3.75753641e-03 6.14970922e-04 1.91683471e-02
 6.31302595e-04 8.99264216e-03 1.06161833e-03 5.18995523e-03
 2.63313777e-05 9.27358866e-04 5.24401665e-04 3.12685966e-04
 1.87226832e-02 8.75145197e-04 1.13472342e-03 4.27603722e-04
 1.07297301e-03 5.96806407e-03 9.21216607e-03 3.56430113e-02
 2.53160579e-06 2.04563141e-04 1.03104539e-05 8.71360302e-04
 6.50048256e-04 1.73747540e-04 2.96366215e-03 2.29746311e-05
 7.40249452e-05 1.14502167e-04 7.97637858e-06 7.85008451e-05
 4.44526595e-05 9.25183296e-04 7.35873471e-07 7.84735239e-05
 3.27140093e-04 1.43051147e-04 4.64469194e-04 1.35019422e-03
 2.09529698e-02 2.12877413e-08 3.76731157e-03 7.84456730e-04
 2.31078863e-02 1.48773193e-04 1.27136707e-04 5.54544628e-02
 1.31991506e-03 5.77750711e-07 3.03698125e-05 7.26193190e-04
 6.41352017e-05 2.26605443e-05 6.95139170e-04 2.65187025e-03
 4.21042751e-05 5.23077979e-05 1.42902136e-04 2.70126038e-05
 4.88109872e-05 1.03165468e-04 2.27808952e-04 3.20196152e-04
 5.69760799e-04 1.80983543e-03 2.73346901e-04 1.14869773e-02
 1.37129426e-03 6.29487634e-03 9.57337543e-05 4.06650033e-05
 2.91079283e-04 4.68399157e-05 1.38974190e-03 1.07744336e-03
 6.99986731e-06 2.29435827e-05 5.44688737e-06 2.72631787e-05
 1.63229306e-05 3.07482624e-05 2.22055987e-05 9.39749880e-05
 8.92797179e-05 7.69966300e-06 1.05422132e-05 4.19468488e-05
 1.34252241e-05 1.21501842e-04 2.05904245e-04 2.68136655e-18
 3.46461605e-33 2.02524855e-11 1.02730439e-04 2.66592581e-10
 1.63412094e-03 1.15021908e-06], shape=(514,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1.
 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1.
 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(514,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 1 2 1 1 2 2 2 2 2 1 1 2 2 2 1 2 2 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2
 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1
 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.023098331, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/inductive5_000.smt2
true label:[1, 1]
true label rank:[1 1]
predicted label:tf.Tensor([0.8093345  0.78904104], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.040428504, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/PRODUCER_CONSUMER_all_000.smt2
true label:[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 2 2 1 1 1 2
 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 1 2 2 1 1 1 2 1 2 1 1 2 2 1 1 1 1 2 1 1 2 1 1 2 1 2 1 1 2 2 1 1 1
 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 2 2 1 2 1 1 1
 1 1 1 1]
predicted label:tf.Tensor(
[5.68759263e-01 2.35611200e-02 1.60427779e-01 2.86612976e-05
 4.00538474e-01 2.24707097e-01 4.89864200e-01 5.86564660e-01
 6.64384861e-05 1.00000000e+00 4.03615147e-01 6.37237485e-12
 0.00000000e+00 2.25505744e-07 3.12615670e-31 2.93349922e-02
 2.29013860e-02 2.46703625e-04 8.75383615e-04 4.55861883e-18
 2.89863050e-02 1.82276203e-08 1.65170184e-19 9.95486140e-01
 6.37105874e-13 7.42021501e-02 1.99319392e-01 2.08953619e-02
 4.80013490e-02 1.28747821e-02 5.75720966e-02 1.35242343e-02
 3.00823450e-02 6.74569129e-32 1.94131434e-02 9.86734033e-03
 4.47390378e-02 3.28352749e-02 3.82694006e-02 3.82969588e-01
 9.60805595e-01 3.66179798e-08 1.61937486e-08 1.12959743e-03
 4.73893325e-09 7.58973002e-01 1.77153324e-05 4.38487828e-02
 3.65272224e-01 1.00000000e+00 8.53322468e-10 6.04716064e-08
 7.93008471e-22 9.31367993e-01 5.76397479e-02 9.74449515e-02
 1.16203308e-01 1.28025502e-01 6.41316175e-04 4.33522374e-09
 8.81385803e-03 7.76705146e-03 1.60684288e-02 2.18919903e-01
 1.63212329e-01 1.17537171e-01 1.85378432e-01 1.09505951e-02
 4.82792228e-01 6.11170053e-01 8.24150443e-03 4.22454894e-01
 4.24052715e-01 4.29617167e-01 4.42653596e-01 5.48854470e-03
 8.48898888e-01 7.80374289e-01 2.04100430e-01 1.22848958e-01
 4.64655161e-02 1.12048417e-01 1.45926714e-01 1.27257735e-01
 3.25196683e-02 1.20692611e-01 3.13135982e-03 3.15952301e-03
 2.48634517e-02 5.02380729e-03 5.04910946e-03 1.85492933e-02
 2.22751498e-03 5.55970669e-02 1.61974430e-02 1.72948837e-03
 9.30896401e-03 6.98629022e-03 9.38624501e-01 8.48828435e-01
 3.37584615e-02 2.68509090e-02 5.10036945e-04 1.89203024e-02
 2.00757384e-02 2.33052075e-02 2.15440989e-04 2.74297297e-02
 4.95105982e-04 2.33972967e-02 1.60194129e-01 1.15866065e-02
 1.86814964e-01 1.09773576e-02 7.15234280e-02 8.76446962e-02
 1.43286794e-01 1.97285414e-03 1.19176149e-01 3.22009444e-01
 5.28175235e-01 3.51308405e-01 5.07573068e-01 4.70940351e-01
 9.99316514e-01 9.99371707e-01 9.99148488e-01 9.96694446e-01
 9.99851823e-01 9.99788880e-01 9.74843144e-01 9.99877334e-01
 8.75292838e-01 4.86510843e-01 5.33761740e-01 3.29903692e-01
 9.47846532e-01 5.97999454e-01 5.62148511e-01 2.23096311e-02
 3.47802222e-01 5.65452278e-02 3.47339869e-01 6.04616702e-02
 6.98731542e-02 2.98854351e-01 2.94195056e-01 8.01438987e-02
 8.81095231e-02 1.38521194e-04 2.04080552e-01 1.58194512e-01
 3.98848653e-01 2.65494782e-06 1.89459056e-01 1.29364312e-01
 9.87706065e-01 2.96189845e-01 9.47574675e-02 1.86832666e-01
 2.13032544e-01 8.45559537e-02 1.46935791e-01 1.92311222e-06
 1.85551167e-01 2.48295516e-01 9.38617468e-01 1.84607506e-03
 1.71254514e-12 5.14786243e-02 9.48315263e-01 3.05716068e-01
 7.81665742e-02 9.13840592e-01 2.49672830e-05 3.56872052e-01
 1.92247927e-02 2.52645373e-01 6.73895359e-01 1.48051232e-01
 7.95317709e-01 2.88188457e-04 1.51668847e-01 3.37898731e-04
 2.17261910e-03 1.55330896e-02 2.26199627e-04 1.37099624e-03
 1.12661719e-03], shape=(189,), dtype=float32)
rounded label:tf.Tensor(
[1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(189,), dtype=float32)
predicted label rank:[2 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1
 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 1 2 1 2 2 2 2 2 2 2 2 2 1 2 1 2 2 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 1 2 1 1 1 1
 1 1 1 1]
mse:tf.Tensor(0.24195826, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/bouncy_one_counter_000.smt2
true label:[1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1]
predicted label:tf.Tensor([0.9467312  0.9386688  0.8537583  0.9168184  0.934018   0.98362243], shape=(6,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1.], shape=(6,), dtype=float32)
predicted label rank:[1 1 1 1 1 1]
mse:tf.Tensor(0.006587792, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/durationThm_1_e3_173_000.smt2
true label:[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[1.0000000e+00 4.2881191e-16 7.8030878e-01 9.1295373e-01 9.8623455e-01
 1.0000000e+00 8.1038177e-01 1.0000000e+00 6.4750016e-03 4.3606299e-01
 9.9791217e-01 9.3847013e-01 8.1299245e-02 6.4664042e-01 9.9998999e-01
 2.3469031e-03 4.9504608e-01 1.3660744e-01 3.6254057e-01 8.2740498e-01
 4.6947598e-04 5.5199295e-10], shape=(22,), dtype=float32)
rounded label:tf.Tensor([1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0.], shape=(22,), dtype=float32)
predicted label rank:[2 1 2 2 2 2 2 2 1 1 2 2 1 2 2 1 1 1 1 2 1 1]
mse:tf.Tensor(0.43831807, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/dillig33.c_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.97583747 0.9443196  0.9421622  0.99998224 0.89843243 0.9999809
 0.975706   0.9990237  1.         0.9999974 ], shape=(10,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(10,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.0017936466, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/metros_1_e8_725_e3_556_000.smt2
true label:[0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]
true label rank:[1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2
 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1
 2 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2]
predicted label:tf.Tensor(
[6.45214021e-02 4.63809073e-02 7.98523426e-03 4.69509959e-02
 1.30792618e-01 5.72202206e-02 9.98965025e-01 5.59528112e-01
 7.50065565e-01 2.21638978e-02 2.19973624e-02 2.82070041e-03
 5.79345226e-03 9.47988808e-01 4.64745700e-01 6.36023045e-01
 1.18256569e-01 8.43581557e-03 7.62786865e-02 7.37745762e-01
 5.90360165e-03 8.19050968e-02 2.44137049e-02 4.82258499e-02
 7.78281689e-03 1.71055377e-01 2.37343609e-02 1.21047229e-01
 1.24768615e-02 2.34004170e-01 3.30508918e-01 1.48850679e-01
 1.56695217e-01 5.72743654e-01 1.29935741e-02 1.52879953e-02
 1.07733011e-02 2.97010243e-02 9.45881009e-03 3.46242785e-02
 1.18921578e-01 4.98420000e-03 2.52297610e-01 3.29335630e-01
 5.29128313e-03 1.28589264e-08 1.91687346e-02 2.72813439e-03
 5.48909366e-01 5.99238276e-03 2.28807330e-03 1.63868070e-03
 2.06509233e-03 3.57872248e-03 3.18054259e-02 7.94051302e-05
 1.67116165e-01 1.99585885e-01 2.36744434e-01 2.68330067e-01
 1.70216560e-01 4.60180342e-02 1.27015442e-01 2.25006670e-01
 1.89162076e-01 1.42456740e-01 1.94056451e-01 1.17356956e-01
 2.52976060e-01 1.49350941e-01 1.07900649e-01 2.16993302e-01
 9.99968052e-01 9.98153865e-01 9.75166678e-01 8.74310732e-04
 3.62408161e-03 4.54038382e-04 5.04761934e-04 5.65895438e-03
 1.46021545e-02 1.67876482e-04 5.53399324e-04 9.53627229e-02
 7.00906813e-02 5.88994622e-02 4.24500406e-02 8.73917341e-02
 1.61678910e-01 8.59965384e-02 8.08444619e-02 1.72467470e-01
 4.97088730e-02 2.52916217e-01 1.38751596e-01 6.13453388e-02
 8.31528306e-02 6.72402084e-02 9.99937236e-01 1.00000000e+00
 1.00000000e+00 5.38659096e-03 2.10574269e-03 4.22060490e-04
 5.73104620e-03 7.52052069e-02 2.36942960e-05 2.07344979e-01
 5.55641949e-02 8.19334388e-03 4.60431874e-02 6.55537844e-03
 6.18133545e-02 3.54140997e-04 2.14682519e-02 2.91410089e-02
 3.14834416e-02 4.33691442e-02 3.04811299e-02 1.15847588e-02
 2.57428586e-02 6.22063875e-04 4.07508314e-02 2.68943012e-02
 5.57481945e-02 3.68952453e-02 1.00000000e+00 9.99997139e-01
 1.00000000e+00 3.31435331e-05 3.97728836e-05 2.44607527e-05
 3.63215695e-05 1.86811686e-02 3.82593274e-03 9.08523798e-03
 9.83178616e-04 1.14275038e-01 1.30767554e-01 8.36648345e-02
 1.21373564e-01 6.52682781e-03 1.40887231e-01 1.21801674e-01
 1.38764203e-01 2.10983664e-01 1.99678928e-01 1.33612752e-03
 1.11238599e-01 8.91202688e-03 1.81087077e-01 1.03906006e-01
 1.95851058e-01 1.49075538e-01 1.00000000e+00 1.00000000e+00
 1.00000000e+00 5.67238858e-05 1.05286344e-04 4.01824713e-04
 3.12042236e-03 3.40729952e-04 3.70860100e-04 4.82419318e-06
 1.05496436e-01 2.94774234e-01 5.61728477e-02 2.94983178e-01
 4.87512350e-03 3.02960575e-02 4.46170568e-04 2.44507402e-01
 3.82388771e-01 1.18442178e-01 3.08659375e-01 1.91130549e-01
 2.56683439e-01 2.69791484e-03 2.69427121e-01 3.52377974e-05
 5.99026680e-04 7.78904557e-03 2.81393528e-04 1.47601962e-03
 1.85820460e-03 2.99918652e-03 3.69031250e-01 3.74600947e-01
 2.01381892e-01 2.63088644e-01 2.49669850e-02 3.95998418e-01
 6.34050608e-01 2.58144677e-01 3.25333625e-01 3.91361415e-01
 2.86616385e-01 4.25780505e-01 2.31043369e-01 2.88420320e-02
 3.80542040e-01 4.77641821e-04 3.55398655e-03 3.18527222e-04
 2.22215056e-03 1.68156624e-03 6.72084093e-03 3.73185467e-05
 3.16574752e-01 2.74816513e-01 2.54902899e-01 3.40597510e-01
 8.44392180e-03 3.55724365e-01 5.31210005e-02 2.69933224e-01
 3.63265723e-01 1.17525041e-01 3.07102263e-01 2.25853980e-01
 2.69793332e-01 6.03672624e-01 3.47344518e-01 2.92095542e-03
 1.08693838e-02 2.82224417e-02 1.47944391e-02 2.58564949e-03
 9.29573178e-03 2.10898652e-05 3.23692471e-01 3.66272807e-01
 3.51840734e-01 1.59078777e-01 3.88047099e-02 2.71379113e-01
 2.23870277e-02 2.92741656e-01 2.64328957e-01 2.87255526e-01
 2.49281853e-01 3.69627774e-01 3.23394001e-01 1.01371109e-02
 2.29204655e-01 2.76991725e-03 1.74024701e-03 7.00771809e-04
 1.08195245e-02 9.96345282e-03 2.11292505e-03 2.86860466e-02
 3.57900441e-01 3.06028187e-01 3.10601354e-01 2.25952476e-01
 2.53046751e-02 2.81738937e-01 5.60728014e-02 3.37200344e-01
 2.28581607e-01 2.03287184e-01 2.26777226e-01 3.27416599e-01
 2.03286409e-01 8.08385015e-03 3.24453294e-01 2.26110220e-03
 1.71443820e-03 2.74920464e-03 2.29974091e-02 1.87325478e-03
 4.91201878e-03 9.66728621e-05 2.10439295e-01 1.87504083e-01
 2.56080091e-01 2.66994119e-01 2.69080400e-02 2.09078372e-01
 1.04539692e-02 2.00959384e-01 1.69709653e-01 2.05517769e-01
 1.65618688e-01 2.37617135e-01 1.87757820e-01 4.52640653e-03
 2.26488620e-01 9.95496302e-05 2.65997648e-03 3.51816416e-04
 6.46203756e-04 2.13432312e-03 4.62979078e-04 3.29800823e-05
 1.86634630e-01 1.55433476e-01 2.24659026e-01 2.68565893e-01
 1.91369653e-03 2.59882748e-01 3.00532579e-03 2.85139680e-01
 1.99210644e-01 1.80648386e-01 2.34486252e-01 1.83493525e-01
 2.07481712e-01 4.30950522e-03 2.89743066e-01 3.13901901e-03
 1.44085288e-02 1.47715211e-03 2.05636024e-03 7.83863664e-03
 1.00886822e-03 1.48713589e-04 2.93155789e-01 2.41474330e-01
 2.23000705e-01 2.91973442e-01 3.60676348e-02 3.30903023e-01
 5.64781725e-02 2.57425547e-01 1.92919612e-01 8.44916403e-02
 2.32998729e-01 3.41018289e-01 2.73647010e-01 8.28468800e-03
 3.88072908e-01 5.25045335e-01 4.46423599e-14 9.99940157e-01
 6.05067611e-03 7.32377089e-07 3.04266399e-12 1.66308041e-06
 5.83089786e-06 5.44368088e-01 3.14482331e-01 5.62530935e-01
 4.62341726e-01 5.97269535e-01 4.98760998e-01 4.74458039e-01
 7.52912462e-01 4.76641715e-01 7.53305912e-01 5.69177628e-01
 1.85693494e-07 6.91736318e-07 1.05261497e-05 1.39147043e-04
 1.84723106e-07 8.64774705e-08 8.89155507e-01 5.32760578e-06
 7.23252118e-01 2.50190496e-04 3.04368377e-01 3.14559281e-01
 3.38243246e-01 4.17367190e-01 2.97953606e-01 1.45938158e-01
 3.25743496e-01 1.81354225e-01 3.53883743e-01 3.50193083e-01
 2.03728676e-04 3.21399311e-05 3.06638976e-05 2.61315823e-01
 1.62546486e-01 9.59604979e-04 2.73814648e-01 4.75059460e-05
 1.29277349e-01 2.55970865e-01 1.29876107e-01 2.70724297e-04
 2.72747278e-01 9.96369541e-01 2.55008221e-01 2.79886484e-01
 2.68215418e-01 2.04698324e-01 2.64986873e-01 2.22665817e-01
 2.33921677e-01 2.06990153e-01 2.74782956e-01 2.03287512e-01
 1.86804882e-05 4.63983417e-03 2.98479497e-02 2.99894810e-03
 1.33214593e-02 1.16330981e-01 2.52038538e-02 1.14993453e-02
 6.42791390e-03 2.67746747e-02 3.10263038e-03 4.20156121e-03
 2.60456800e-02 1.58251822e-02 1.21867329e-01 9.40025747e-02
 2.44019330e-02 1.95497274e-03 1.06373727e-02 7.27751851e-03
 2.40415335e-04 3.94451618e-03 8.39787026e-06 3.50604981e-01
 3.08332622e-01 2.34519184e-01 2.47809052e-01 2.65227675e-01
 2.78809667e-02 9.75501239e-02 5.35977364e-01 6.94707334e-02
 6.38171017e-01 2.48507559e-02 2.60280102e-01 1.53822064e-01
 1.08999759e-01 3.72848630e-01 3.29665959e-01 2.55377799e-01
 8.85571599e-01 2.82276303e-01 2.12163866e-01 3.04341316e-04
 3.45421612e-01 2.79018760e-01 3.28528643e-01 3.52593869e-01
 3.79944324e-01 4.10334587e-01 3.83415043e-01 3.60132873e-01
 3.55135590e-01 3.33048403e-01 9.99998510e-01 2.66272366e-01
 2.65050411e-01 3.24774653e-01 3.19290876e-01 3.80183488e-01
 2.14329362e-03 8.93084895e-09 9.84777808e-01 4.82082367e-04
 3.07769567e-01 1.18995190e-01 1.31150275e-01 2.66766906e-01
 2.20536977e-01 1.78213418e-01 2.11740553e-01 2.59645283e-01
 1.66935802e-01 1.82996839e-01 9.84307885e-01 2.34779030e-01
 6.38663769e-03 1.93739146e-01 2.07574219e-01 2.18987644e-01
 2.08738923e-01 1.64279312e-01 2.10189432e-01 6.37263060e-04
 9.73465621e-01 2.52746046e-02 5.41648567e-02 1.26552403e-01
 3.70395184e-02 8.27247500e-02 1.83421373e-02 8.98365378e-02
 4.30061221e-02 7.84240663e-02 1.14057869e-01 9.80184019e-01
 1.61304832e-01 9.99999285e-01 6.62580132e-02 6.69010580e-02
 4.10959423e-02 7.15298057e-02 2.79279947e-02 2.83082724e-02
 4.83205914e-01 9.34309065e-01 8.02328050e-01 2.47043878e-01
 3.24561775e-01 2.93931991e-01 3.50142837e-01 3.52796108e-01
 2.83796966e-01 2.49081910e-01 3.47075701e-01 3.64986718e-01
 3.39280427e-01 3.84876192e-01 3.46707851e-01 2.69863844e-01
 3.72720182e-01 1.51925445e-01 3.88110578e-01 9.34030175e-01
 8.71952653e-01 4.02402908e-01 3.02466214e-01 9.58887577e-01
 2.92572379e-03 2.37446547e-01 2.03889251e-01 1.25102311e-01
 2.08609968e-01 2.47692972e-01 2.79882252e-01 1.38479799e-01
 1.03428274e-01 1.63569480e-01 2.90661395e-01 4.31829840e-01
 1.98579282e-01 3.40146959e-01 1.47524238e-01 2.24553913e-01
 2.08699614e-01 9.23940539e-02 9.73412395e-03 2.78397143e-01
 2.57457256e-01 9.67439890e-01 2.40460664e-01 5.90860844e-03
 4.39357758e-03 3.99887562e-04 8.28927796e-07 7.52310769e-10
 1.82188660e-01 3.35512996e-01 3.02475512e-01 3.44910234e-01
 3.49979609e-01 3.47653091e-01 4.71623629e-01 3.90051842e-01
 3.59965026e-01 2.88199604e-01 3.42675388e-01 3.79205048e-01
 2.13895291e-01 6.21971190e-01 7.40302503e-02 3.38060081e-01
 3.11214745e-01 3.15272480e-01 1.01451129e-01 6.83600783e-01
 3.48681122e-01 5.16233742e-02 1.13186240e-03 8.08154702e-01
 1.32759809e-02 6.79116201e-05 9.98948097e-01 9.07454789e-01
 9.98134971e-01 2.42380381e-01 1.38565987e-01 7.27445781e-01
 5.10203540e-01 1.31765008e-03 4.93779480e-02 5.34587502e-01
 5.00404179e-01 1.49635673e-01 5.11338830e-01 5.55833161e-01
 5.48686564e-01 9.41100717e-02 4.56346184e-01 5.70515335e-01
 3.98698777e-01 4.79853719e-01 3.37989151e-01 2.82734185e-01
 2.64132112e-01 2.81595170e-01 2.07550615e-01 1.73363715e-01
 2.91718066e-01 1.00305766e-01 3.27021480e-01 2.24183202e-01
 4.70989943e-03 2.60470808e-01 3.04378450e-01 2.86069274e-01
 1.80533528e-02 2.63888299e-01 1.62589461e-01 1.20783299e-01
 2.41819590e-01 2.26466209e-01 2.81546712e-01 1.30524635e-02
 1.29213065e-01 3.27005357e-01 2.58045614e-01 3.74564171e-01
 9.88155484e-01 9.59115028e-02 3.49423468e-01 3.91646028e-01
 3.94666642e-01 3.15730572e-01 3.95017207e-01 3.31446171e-01
 2.85317361e-01 2.84961998e-01 3.71794313e-01 3.43548059e-01
 3.96993905e-01 2.01023221e-02 1.68576837e-03 6.01466298e-02
 1.25211477e-03 3.93100023e-01 3.40437293e-01 2.06378102e-03
 4.79224324e-03 3.86666179e-01 4.48032677e-01 2.64150023e-01
 3.23645353e-01 4.43603396e-02 3.35048139e-02 1.06126070e-02
 9.99991179e-01 2.37825215e-02 8.96012187e-01 9.94050562e-01
 1.13758206e-01 8.83913040e-03 2.64396040e-05 1.21822653e-04
 4.89443243e-02 2.57400215e-01 9.76055861e-04 2.95895636e-02
 8.49665701e-02 1.65274888e-01 2.78079510e-03 1.63871050e-03
 9.96488333e-03 7.98523426e-03 1.50911242e-01 5.03287911e-01
 7.76916742e-04 9.24620032e-03 7.97539651e-02 4.76261973e-03
 2.08684206e-02 3.59565020e-03 7.24546726e-06 4.10305984e-05
 1.77198827e-01 1.45314336e-02 1.91742182e-03 1.00000000e+00
 5.79161048e-02 9.96501565e-01 9.99985158e-01 2.84867287e-02
 4.68473434e-02 5.87362945e-02 3.29613686e-04 1.96425617e-02
 2.95838207e-01 2.30644643e-02 2.09066629e-01 4.41184044e-02
 1.89697444e-02 2.85916626e-01 1.05809122e-01 6.51845336e-02
 8.64261866e-01 7.19569921e-02 9.74869728e-03 8.64100456e-03
 1.32003697e-05 4.11748886e-04 1.32858008e-01 2.43157506e-01
 1.08654171e-01 1.45230025e-01 9.63866115e-01 8.98349822e-01
 1.16163731e-01 5.14165342e-01 1.01700634e-01 5.94814658e-01
 8.73637915e-01 1.91742182e-03 8.51653993e-01 6.68185353e-01
 1.45562887e-02 1.65200830e-02 2.20964402e-01 2.81299353e-02
 5.96926391e-01 8.01345706e-02 8.96765888e-02 1.06155515e-01
 2.14014351e-02 1.09840631e-02 1.64758652e-01 8.86042416e-02
 7.69413114e-02 1.46854222e-02 9.23663378e-04 1.75760210e-01
 5.63746691e-03 3.04463208e-02 2.90133655e-02 2.99732089e-02
 1.36962533e-03 7.11455941e-03 7.22524524e-03 1.00627542e-03
 1.28432065e-01 3.77744436e-04 8.60768705e-13 1.56771167e-12
 9.99024153e-01 8.96601439e-01 9.99875367e-01 9.99997139e-01
 6.42460287e-01 1.59681141e-02 6.57675326e-01 6.67203128e-01
 8.02508473e-01 9.71868634e-03 1.80187821e-03 1.67848668e-08
 3.41834107e-06 1.37567520e-04 1.40666812e-09 3.35640857e-06
 9.94407845e-09 4.42802906e-04 1.37371391e-01 1.93101168e-03
 8.52903724e-02 3.51027265e-05 2.46190606e-08 7.87663817e-01
 9.41608669e-05 3.05939645e-01 9.02117789e-02 1.68943405e-03
 2.05096602e-03], shape=(777,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0.], shape=(777,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 2 2 2 1 1 1 1 2 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 1 2 1 1 1 1 1 2 1 2 1 2 1 1 2 1 2 2 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2
 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 2 1 1 2 2 2 1 1 2 2 1 1 2 2 1 2 2
 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 1 1 1 1 1 1 2 2 1 2 1 2 2 1 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 2 2 2 2 2 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1]
mse:tf.Tensor(0.133211, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/while_after_while_if_merged_safe.c-1_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2]
predicted label:tf.Tensor(
[0.99470115 0.9553549  0.95878035 0.49773434 0.870879   0.57210654
 0.9772936  0.67876554 0.98739195 0.58085    0.87834597 0.98808336
 0.99486107 0.9775318  0.53152615 0.82946444 0.84149754 0.8921187 ], shape=(18,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(18,), dtype=float32)
predicted label rank:[2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2]
mse:tf.Tensor(0.066544086, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/destroy_test_dangling_unsafe.c_000.smt2
true label:[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1
 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 2
 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[3.37564945e-03 7.06414878e-02 8.59439373e-04 1.00000000e+00
 9.32216644e-04 2.11828947e-03 9.66578722e-04 8.90954470e-06
 2.94655561e-04 1.71393156e-04 6.44579530e-03 1.10659603e-04
 7.77145374e-07 2.38043070e-03 5.62757254e-04 1.22687470e-05
 4.18325944e-05 1.43283606e-03 1.17277159e-05 6.00212458e-09
 5.00266560e-06 1.15066665e-10 1.73390502e-09 2.89446115e-03
 3.98158636e-06 4.78983166e-05 3.95825505e-03 1.79591775e-03
 1.88595057e-03 2.83092260e-04 2.32592225e-03 1.09368563e-03
 9.43511724e-04 1.64031982e-04 1.38085352e-05 2.14920163e-01
 1.98259936e-10 1.51032805e-02 3.48403519e-05 3.97429258e-01
 2.19216245e-09 2.83582239e-07 1.05840087e-07 9.73409300e-08
 6.66573357e-08 1.98662281e-04 1.71512365e-04 4.68432903e-04
 3.69933248e-03 1.03933562e-04 6.81142431e-09 1.10555702e-04
 7.33369598e-05 4.66827396e-06 3.19829583e-03 7.48592477e-09
 4.16148722e-01 8.59879918e-08 1.50211453e-02 1.79958188e-05
 3.24121118e-03 1.40905380e-04 6.71954258e-05 3.74853611e-04
 3.04565056e-05 1.09982895e-04 1.48922205e-04 7.53641129e-03
 5.43281567e-05 2.25186348e-04 1.60875625e-05 7.09884189e-05
 1.25801051e-07 5.27033210e-03 2.59119004e-01 1.53899193e-04
 1.68973207e-03 4.39733267e-04 4.53848202e-07 3.61150196e-05
 1.86184049e-03 3.88516508e-09 2.72899866e-04 6.27607107e-03
 7.87732005e-03 8.26449394e-02 8.56000185e-03 9.99631643e-01
 1.00000000e+00 3.91691625e-02 3.33055854e-03 1.18353069e-02
 6.35296106e-04 1.37102604e-03 9.44882631e-04 1.15192831e-02
 1.73762441e-03 8.72105360e-04 1.61764026e-03 1.04880333e-03
 1.65641308e-04 8.01354647e-04 1.09252334e-03 1.52170658e-04
 1.76396966e-03 9.83718038e-03 2.76599148e-05 3.12246919e-01
 5.11223972e-02 3.88885915e-01 6.79239631e-03 7.47538507e-01
 1.36217773e-02 1.65037215e-01 5.04514396e-01 5.39517403e-03
 2.26736069e-04 2.56323037e-05 1.34306610e-01 4.26061153e-02
 3.19953561e-02 3.49760056e-04 2.42935717e-02 1.86637044e-03
 5.42277098e-03 5.28866053e-03 8.72457027e-03 3.44148278e-03
 3.45084071e-03 1.11919913e-08 2.84936448e-08 8.63421974e-07
 8.55914768e-05 9.51606035e-02 2.24877954e-01 6.71680510e-01
 3.24849606e-01 1.28010243e-01 1.95760131e-05 2.15270787e-01
 5.06907701e-04 3.04576755e-03 9.68117165e-05 3.25305587e-06
 2.00688839e-04 2.67833471e-04 1.69736445e-02 1.05243622e-07
 9.85622108e-08 2.89121346e-07 3.78636687e-05 8.92579556e-04
 2.63387859e-02 3.71214642e-13 5.41971385e-01 5.17029803e-05
 1.15894077e-08 4.08917556e-13 8.69929790e-04 1.73226774e-01
 2.06348250e-05 3.96187289e-07 5.43683767e-04 1.85194582e-09
 1.48660811e-05 7.83932209e-03 2.59339809e-03 2.01605186e-08
 1.71738863e-03 5.20720278e-05 4.53263521e-04 1.75386667e-03
 1.98408361e-05 4.62490320e-03 1.63316727e-04 4.43100929e-04
 3.12247648e-05 7.98010826e-03 2.39747763e-03 2.11528231e-06
 2.03934312e-03 7.46041536e-04 6.17235899e-04 5.98460436e-04
 8.50498676e-04 2.54033506e-02 1.84577703e-03 2.36647129e-02
 4.86358404e-02 8.17864835e-02 1.25851685e-09 4.78503956e-08
 3.91113758e-03 9.65934992e-02 3.39925289e-04 5.99294901e-04
 5.16235828e-04 3.44753265e-04 4.91946936e-04 4.19402122e-03
 3.14742327e-04 8.00038761e-05 1.12274289e-03 2.41458416e-04
 1.73343420e-02 9.68605280e-04 1.79440677e-02 1.87575817e-04
 7.77280331e-02 9.38177109e-04 9.99878764e-01 1.00000000e+00
 9.60695744e-03 3.55720520e-02 3.62500548e-03 7.82191753e-04
 1.96146965e-03 6.14792109e-04 2.51916945e-02 2.09379196e-03
 5.68598509e-04 5.93838632e-01 5.68133255e-05 2.21014440e-01
 1.55337095e-01 5.81969380e-01 1.64747804e-01 1.61390245e-01
 1.20577216e-01 1.83446195e-06 5.02830744e-03 2.00381875e-03
 2.33610272e-02 1.87724829e-04 8.22581351e-05 3.92549753e-01
 1.48683786e-04 1.77890062e-04 2.39968300e-04 4.81024981e-01
 1.49831176e-03 7.63550124e-05 3.71846557e-03 1.33782625e-04
 5.98057568e-06 2.46969357e-05 2.31629965e-05 1.98764592e-05
 1.23218706e-04 5.06550074e-04 3.55584998e-05 1.97410583e-04
 4.19348478e-04 1.11678243e-03 2.51601637e-06 1.47902966e-03
 1.54727832e-06 1.23241316e-05 4.34875656e-05 3.76707940e-05
 1.30891800e-04 2.77798008e-05 4.37883682e-05 1.73070930e-06
 2.59697437e-03 5.58871670e-06 1.30340457e-03 1.05777079e-04
 1.51336193e-04 1.11275315e-02 2.10851431e-01 3.35058648e-05
 1.58250958e-01 2.27299424e-08 5.39826572e-10 6.41185034e-05
 1.02722684e-08 3.65607411e-05 1.49241927e-07 2.25332784e-08
 1.11590695e-10 1.27757460e-06 2.89965210e-05 2.17583121e-07
 1.54414811e-05 4.98097643e-06 3.75658274e-04 3.39362873e-06
 2.02364814e-09 2.84435401e-07 3.94912277e-05 9.47447774e-08
 6.34998977e-02 7.37839937e-03 5.59807773e-08 2.34995059e-05
 2.03461173e-06 5.92877086e-07 1.60574913e-04 9.05001629e-11
 5.00127890e-11 1.25189694e-13 2.16603013e-07 6.97456182e-09
 8.16256562e-10 3.45926843e-10 2.82257795e-04 1.72963738e-03
 1.63099170e-03 5.93045354e-02 9.56224128e-11 1.48996412e-06
 3.72623950e-01 3.94558609e-02 1.72990561e-03 1.56564474e-01
 8.47072079e-06 1.64240674e-07 1.70676321e-05 5.59449911e-01
 6.05932534e-01 3.73748839e-02 1.19233429e-02 1.59730862e-09
 2.65595327e-06 1.15924642e-07 7.13825226e-04 2.66051292e-03
 7.85973668e-03 5.73754013e-02 1.71810389e-04 2.67068981e-06
 3.28928232e-04 9.14037228e-04 1.56375427e-05 1.76021535e-06
 4.32613815e-05 5.29513727e-06 1.36435032e-04 1.74671412e-04
 2.07266548e-05 1.69038773e-04 6.63119499e-05 8.72880220e-04
 3.11440199e-05 6.41778111e-03 9.50239919e-05 4.80863346e-05
 3.39746293e-06 5.28216362e-04 2.83122063e-04 2.48799026e-02
 5.49755314e-05 1.06005146e-07 4.56865422e-07 9.97240126e-01
 1.39302641e-01 9.99987483e-01 1.00000000e+00 1.55538321e-03
 1.28629506e-02 6.84864347e-07 1.94664517e-05 5.35043478e-02
 1.35260522e-02 2.69850969e-01 3.90216410e-02 3.87519598e-04
 2.53440559e-01 3.61472368e-04 5.85091829e-01 7.85470009e-04
 4.15706575e-01 3.56286764e-04 1.23773038e-01 7.46738911e-03
 1.32423639e-03 5.65033138e-01 9.91926427e-05 2.71182762e-05
 6.40239972e-10 3.11881304e-04 9.12693532e-10 4.53054905e-04
 1.43694878e-03 1.77592039e-04 1.20517612e-03 1.03890896e-02
 3.85368148e-05 2.01580897e-05 2.41103768e-03 1.17797543e-04
 1.59382034e-06 7.24134622e-07 4.41020165e-05 1.46719103e-07
 9.73370916e-05 1.73744559e-03 1.20800734e-03 5.70848584e-03
 7.29441643e-04 2.21133232e-04 8.70996009e-05 3.75658274e-04
 1.12357736e-03 2.72870064e-04 2.33387198e-07 1.39799681e-07
 3.86370357e-06 4.63575125e-04 6.61230087e-03 1.46090984e-04
 1.54588236e-07 2.36608684e-02 3.03590987e-05 8.13145995e-09
 4.37119305e-02 1.07021799e-06 4.56145608e-06 7.08650231e-01
 1.72491310e-09 6.50515437e-01 3.19610582e-09 7.74812222e-01
 1.18405551e-01 6.16275012e-01 9.25357044e-02 7.32726336e-01
 3.31885904e-01 9.16697979e-01 2.35739946e-02 2.31418014e-03
 7.91281462e-04 1.60749920e-08 5.65651415e-10 2.20518708e-02
 5.56451482e-11 3.33254635e-02 7.04368949e-03 7.00102377e-15
 8.45601899e-05 7.29550375e-05 1.13388300e-02 1.14269211e-18
 9.76680240e-05 2.67055875e-05 9.68489622e-10 3.52255313e-07
 5.09530306e-04 9.09784436e-03 7.41959383e-10 1.41894262e-07
 2.15901418e-05 1.25120735e-07 3.32206488e-04 1.14907622e-02
 6.84912616e-09 3.44665393e-15 3.45164924e-10 7.13251751e-08
 7.54117966e-04 1.46708548e-01 2.93007331e-15 9.01072359e-12
 1.33146951e-08 1.42232430e-20 3.73664737e-01 2.04886391e-07
 1.97910177e-09 1.02511931e-11 4.96580105e-05 1.82124078e-02
 5.63952890e-05 2.41106045e-06 1.81347430e-02 2.90562311e-05
 1.08071268e-02 1.22558773e-02 1.42988563e-03 3.10393631e-08
 1.32879019e-02 5.38110733e-04 4.26364350e-05 9.01057422e-02
 6.15172553e-07 2.18834430e-05 1.37329102e-04 4.76169586e-03
 8.65727663e-04 2.10792296e-05 1.88472867e-03 1.66423321e-02
 7.12039650e-07 8.06877324e-07 3.00475955e-03 4.30852175e-04
 4.85271215e-04 4.00871977e-05 1.86294317e-04 3.21323186e-01
 2.88407505e-02 1.17745996e-03 2.93385183e-05 3.55922878e-02
 5.60432563e-05 2.10529566e-03 1.34217739e-03 6.68925345e-02
 1.39886141e-03 9.62197781e-04 7.56055117e-04 9.90187221e-09
 3.91076965e-17 9.13552611e-09 1.23882946e-05 8.96721940e-06
 2.63241295e-12 2.73556039e-11 3.07680582e-11 9.86759652e-09
 8.87453556e-04 1.60829794e-10 2.44677067e-04 5.78938719e-09
 1.17662144e-04 2.32166052e-03 3.80176232e-07 1.21063888e-02
 9.80977535e-01 2.05259919e-02 2.00006962e-02 2.16230750e-03
 1.26302242e-03 5.08666039e-04 7.47883320e-03 9.82031465e-01
 1.58688426e-03 7.12361038e-02 5.70863485e-04 3.99851501e-02
 3.06266546e-03 7.52311945e-03 8.17030668e-04 1.50906444e-02
 3.42972598e-05 3.74113917e-02 1.65551901e-04 2.63139910e-08
 2.02443357e-11 1.31194944e-09 3.38369119e-08 1.19216788e-08
 1.60804052e-06 1.32228645e-10 3.24946996e-07 1.22622248e-06
 1.58152488e-07 3.84296417e-09 5.68628366e-06 6.67591280e-08
 3.82463412e-08 5.36356826e-09 4.26351733e-07 2.52006146e-07
 6.69234876e-11 1.83061530e-08 3.37918582e-10 1.49968904e-12
 1.68760419e-02 8.24454427e-03 3.00645828e-04 4.78744507e-04
 4.45008278e-04 1.29669905e-04 4.48137522e-04 2.12844312e-02
 2.28986733e-06 1.01229512e-06 6.01158899e-05 8.34792852e-04
 8.64320993e-03 3.48182657e-05 2.27816927e-05 8.30905139e-02
 1.20077293e-09 5.23524601e-09 4.89499663e-10 2.30544209e-10
 6.59172983e-09 3.38575592e-05 8.56493671e-07 2.06275041e-09
 5.14384283e-07 2.40981579e-04 4.51653853e-11 2.21282244e-04
 2.28470802e-01 3.13386336e-05 8.48452210e-01 1.54674053e-04
 2.49302387e-03 5.09578604e-06 4.66942787e-04 4.54423789e-05
 6.91444516e-01 2.35176649e-05 7.52018392e-02 6.15438148e-06
 1.00518315e-04 3.09437513e-04 1.93053081e-15 5.87999375e-06
 1.03740012e-05 1.76051063e-10 3.42736542e-01 6.79442286e-03
 5.05384803e-03 1.13342047e-08 2.16813415e-01 4.94540076e-10
 2.24893749e-01 9.40032623e-06 2.73990929e-01 9.50509129e-05
 3.94637465e-01 1.73721270e-12 2.14354694e-02 2.99543142e-04
 6.52164221e-03 3.22945380e-05 2.42277201e-06 1.11682320e-05
 1.40070915e-04 6.96458528e-07 2.09891205e-05 5.05477190e-04
 5.18858433e-04 1.40339136e-04 4.12809277e-05 9.11027193e-04
 4.19022253e-05 6.69257279e-05 2.39223242e-04 9.14387726e-07
 2.48924010e-08 4.21270936e-16 1.31781496e-06 1.37507796e-18
 1.15583237e-12 9.89304497e-15 1.08907052e-05 3.60656099e-06
 6.01437296e-06 2.01061157e-05 1.68010993e-05 4.42391092e-06
 1.12352446e-07 1.07954548e-11 2.45513917e-12 2.63892339e-08
 7.08616166e-10 5.42193651e-04 6.93359529e-15 5.32558331e-10
 2.50473067e-06 5.90644963e-11 9.43570846e-11 4.81654994e-11
 1.90894434e-09 6.96338959e-11 1.13891341e-09 1.03819289e-07
 3.22020151e-06 1.77971560e-05 2.32296912e-07 6.30465448e-02
 3.91125679e-04 6.00600761e-05 1.16602044e-08 2.38001347e-04
 2.87614882e-01 7.33211637e-03 1.53958797e-03 6.02661676e-05
 1.50370598e-03 9.97596979e-01 7.10520148e-03 3.69936228e-04
 1.14537761e-06 3.56336538e-09 1.18771407e-13 1.22389848e-12
 1.83787013e-13 1.24057138e-08 6.95285789e-13 1.58825161e-10
 3.81984818e-21 2.78829674e-07 1.57202873e-09 8.54461746e-08
 2.72575635e-05 2.37241848e-09 5.03066686e-12 1.32190075e-06
 2.02912487e-09 7.14847914e-08 5.82188368e-04 6.28296375e-01
 3.46541405e-04 2.97099352e-04 6.03765249e-04 9.34529543e-01
 2.29418765e-05 2.78860331e-04 8.87165697e-07 9.99312878e-01
 2.87088988e-05 4.70280647e-04 3.97226213e-05 3.01897526e-04
 3.02062486e-10 3.45333695e-09 3.22852500e-08 3.07842043e-07
 1.41411830e-11 4.48273099e-08 1.04914726e-07 6.38459907e-09
 1.14798546e-03 1.34367639e-07 1.91357732e-03 2.19713547e-05
 8.41015662e-06 2.94201482e-06 6.36983266e-09 5.40299970e-06
 1.55984958e-06 1.73492992e-06 3.05320737e-06 2.34193999e-06
 1.05859058e-07 1.11210738e-07 5.18698585e-07 3.60610630e-12
 1.99656170e-05 9.53137875e-04 6.00521673e-07 2.88336843e-09
 3.20344043e-06 6.62473758e-06 8.33788363e-06 8.39278619e-06
 3.45349312e-04 1.23888254e-04 9.37230311e-07 2.07788253e-05
 2.12674622e-05 1.10722249e-05 8.22226066e-05 3.35484743e-04
 3.89933586e-04 1.36431254e-06 2.05198967e-06 3.29256058e-04
 6.80462108e-05 3.20444269e-06 6.96427378e-05 9.60638090e-07
 4.69587103e-05 6.82258105e-05 3.66962887e-08 2.28431821e-03
 2.19166304e-05 3.76045704e-04 3.88624919e-08 2.03454653e-09
 6.55721095e-08 8.53911075e-08 1.18441426e-08 5.28799137e-06
 2.30678161e-08 6.39854889e-08 9.20521082e-09 3.05777181e-09
 1.66911121e-07 3.36514852e-08 5.99715499e-10 1.89930276e-08
 7.33734353e-08 3.25469235e-11 8.77047657e-10 2.49351303e-11
 6.42397746e-10 1.93700611e-09 2.28384339e-10 3.72918418e-10
 8.63591425e-15 3.48236249e-08 3.87212467e-08 2.17279030e-08
 1.12941958e-08 7.54844798e-10 3.45484492e-13 3.32085637e-10
 1.34873707e-13 1.92096829e-03 3.49261109e-09 3.99036324e-08
 3.49669875e-08 1.91113571e-07 9.94060429e-06 1.59836020e-07
 2.61490080e-10 6.83737233e-11 4.86378522e-05 5.57320634e-10
 2.01403022e-01 1.00718660e-06 4.36181494e-07 1.10360980e-03
 1.51800215e-02 6.98053846e-05 2.79261735e-06 5.34117222e-04
 1.63453842e-06 2.32398510e-04 2.14338303e-04 4.52910364e-02
 1.37351549e-07 7.15343271e-11 9.49686819e-06 2.07160213e-07
 2.18003988e-04 7.94440508e-04 1.16365322e-06 1.91751824e-05
 1.32183586e-05 4.02390957e-04 4.40530021e-05 3.39741391e-08
 1.38663466e-07 3.83782428e-08 6.23822212e-04 4.64983891e-08
 1.78339718e-07 2.35721529e-01 5.38368035e-08 9.20950970e-06
 3.40587292e-09 7.12233782e-03 4.86469269e-03 2.31508493e-05
 1.42385226e-09 5.81622124e-04 2.35658743e-10 8.04049851e-05
 1.88857317e-04 6.89073640e-05 5.12458769e-08 9.68011618e-01], shape=(860,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.], shape=(860,), dtype=float32)
predicted label rank:[1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 2
 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1
 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 2]
mse:tf.Tensor(0.06234928, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/sum3_000.smt2
true label:[1, 1]
true label rank:[1 1]
predicted label:tf.Tensor([0.80903906 0.9867976 ], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.018320192, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0260_000.smt2
true label:[1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2
 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1
 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2
 2 2 1 2 2 1 2 2 2 2 1 2 2 1 2 2 2 2 1 2 2 1 2 2 2 2 1 2 2 1 2 2 2 2 1 2 2
 1 2 2 2 2 1 2 2 1 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2
 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[9.99999285e-01 9.99998212e-01 1.00000000e+00 1.00000000e+00
 1.00000000e+00 9.99651551e-01 6.99892461e-01 8.42736244e-01
 9.51456487e-01 9.76590276e-01 9.99948621e-01 9.99812007e-01
 9.99841452e-01 1.00000000e+00 9.99993622e-01 9.50345099e-01
 2.33730674e-03 4.90280986e-03 9.52924609e-01 9.94237423e-01
 9.64184403e-01 9.59688306e-01 9.98298764e-01 1.00000000e+00
 9.63438988e-01 5.02486825e-02 9.31812763e-01 8.86746466e-01
 7.47512221e-01 6.80129290e-01 9.67490971e-01 9.80267406e-01
 9.51864004e-01 3.79088163e-01 9.37469125e-01 9.97426391e-01
 9.95790005e-01 9.94289160e-01 9.92201447e-01 9.96604264e-01
 9.78389382e-01 4.42525685e-01 9.99211550e-01 9.45046902e-01
 9.27163482e-01 9.40005302e-01 9.67240512e-01 9.91543531e-01
 9.57834005e-01 4.10245389e-01 9.97823119e-01 6.05732918e-01
 8.67677450e-01 6.13762736e-01 9.51612592e-01 9.45977449e-01
 5.72516441e-01 2.33036965e-01 9.25549388e-01 9.83368754e-01
 9.78229761e-01 9.20539856e-01 9.67563629e-01 9.77991819e-01
 7.30311275e-01 3.08572829e-01 9.89227176e-01 9.96509552e-01
 9.63130236e-01 7.62660623e-01 9.79305029e-01 9.85789716e-01
 9.90760684e-01 4.20507014e-01 9.45940554e-01 9.72607017e-01
 9.88887966e-01 9.37731743e-01 9.75190043e-01 9.91040468e-01
 9.89004016e-01 4.58388239e-01 9.39741254e-01 9.84127641e-01
 9.67102766e-01 9.75051522e-01 9.95371997e-01 9.93712366e-01
 9.96636987e-01 2.43490785e-01 9.99297738e-01 9.65725005e-01
 9.89010155e-01 9.71311808e-01 9.81915593e-01 9.89606500e-01
 9.93855119e-01 5.15850008e-01 9.45948482e-01 9.64083910e-01
 9.89270210e-01 9.83883858e-01 9.84701693e-01 9.93431151e-01
 9.85957026e-01 4.44243580e-01 9.28302348e-01 9.95723724e-01
 9.86433744e-01 9.89100039e-01 9.96214449e-01 9.86940444e-01
 9.91509557e-01 3.70189726e-01 9.90756989e-01 9.91447449e-01
 9.93370175e-01 9.93482351e-01 9.95230317e-01 9.98787045e-01
 9.95638967e-01 9.15740728e-02 9.98924255e-01 9.79635358e-01
 9.14875388e-01 9.78831172e-01 9.92265463e-01 9.94395673e-01
 9.88320351e-01 2.31156021e-01 9.88284349e-01 9.93548572e-01
 9.33510065e-01 9.72605407e-01 9.90095615e-01 9.92663503e-01
 9.88585591e-01 3.91963720e-01 9.95573580e-01 9.94280577e-01
 9.92035151e-01 9.97174680e-01 9.94858861e-01 9.98746157e-01
 9.98483658e-01 5.05856216e-01 9.98014092e-01 9.54662681e-01
 9.75722551e-01 9.91069674e-01 9.94107723e-01 9.94719148e-01
 9.83061731e-01 4.91627336e-01 9.97999907e-01 2.97344625e-01
 3.28421831e-01 6.31030560e-01 9.78943467e-01 9.81296659e-01
 9.49464083e-01 3.26053888e-01 9.95029211e-01 8.09485555e-01
 9.92055535e-01 9.82192338e-01 9.82155502e-01 9.92657185e-01
 9.74976540e-01 3.18026096e-01 9.95723963e-01 1.20303690e-01
 6.43222213e-01 9.15047884e-01 9.87887979e-01 9.84624565e-01
 8.85656416e-01 1.42878771e-01 9.96815979e-01 5.79074025e-03
 5.67309380e-01 5.06055474e-01 8.53726506e-01 9.02582884e-01
 2.22184658e-01 1.49677396e-01 9.61106420e-01 9.90248084e-01
 9.87042487e-01 9.94646668e-01 9.96602654e-01 9.97893035e-01
 9.94059443e-01 3.23000908e-01 9.86361802e-01 9.92437482e-01
 9.82810736e-01 9.84026313e-01 9.91594911e-01 9.96229172e-01
 9.94868994e-01 3.24178964e-01 9.98473763e-01 6.56561971e-01
 5.63044250e-01 3.27292264e-01 9.77225959e-01 9.59276021e-01
 5.77567816e-01 5.55838048e-02 9.81936574e-01 9.92590547e-01
 9.81650233e-01 9.73851919e-01 9.82650161e-01 9.94051814e-01
 9.52147901e-01 1.54939771e-01 9.83502269e-01 7.45656598e-06
 7.03172873e-06 2.20894814e-04 1.36524439e-04 5.54241487e-05
 1.87959831e-05 7.37166283e-06 3.99087730e-06 1.34390593e-03
 1.67268515e-03 3.14652920e-04 2.66063213e-03 1.19456649e-03
 8.35031271e-04 6.78122044e-04 1.00587595e-05 4.82136675e-05
 3.31021988e-06 4.31234730e-05 5.53995371e-04 5.47989221e-05
 7.41494023e-06 5.69701195e-04 1.51774287e-03 7.54594075e-05
 1.51960394e-05 7.99807603e-05 4.96262312e-03 1.31696463e-04
 2.26123175e-05 1.40368938e-04 2.05278397e-04 2.59013759e-05
 1.09569883e-04 2.19106674e-04 1.33645535e-03 7.39514828e-04
 1.29818916e-04 8.52346420e-04 5.74195765e-05 2.91854143e-04
 1.89703703e-03 2.10344791e-04 5.67363501e-02 7.37845898e-04
 1.51455402e-04 1.80435181e-03 3.44723463e-04 1.78694725e-04
 1.26153231e-04 3.73959541e-04 1.08120441e-02 1.94567442e-03
 7.97778368e-04 3.85046005e-04 2.08526850e-04 2.43744307e-05
 2.16558576e-03 2.58773565e-04 2.95889378e-03 1.60166621e-03
 1.82032585e-04 2.88173556e-03 1.73479319e-04 2.35397220e-05
 2.16811895e-04 2.91049480e-04 3.49068642e-03 3.00347805e-04
 2.09391117e-04 3.57240438e-04 1.57439709e-03 1.08512941e-04
 5.82993031e-04 4.41491604e-04 6.19220734e-03 3.79353762e-04
 1.14408183e-04 1.68997049e-03 2.37214565e-03 4.53892353e-05
 1.14412986e-04 9.97725074e-05 4.06509638e-03 2.76535749e-04
 3.69627560e-05 6.28829002e-04 1.23298168e-03 1.16152791e-04
 7.24019337e-05 5.79714775e-04 6.42976165e-03 6.85078630e-05
 4.72065221e-05 2.49952078e-04 2.33620405e-04 2.60800123e-04
 2.19911337e-04 8.10614292e-05 7.31319189e-04 4.50164080e-04
 6.87385545e-05 9.31710005e-04 1.06223997e-04 1.29938126e-04
 6.30559080e-05 1.21637953e-04 1.01599097e-03 2.55714585e-05
 1.53064728e-04 2.72300839e-03 6.71195984e-03 6.07871425e-06
 8.46803188e-04 5.93979257e-06 4.27785781e-05 8.12595681e-05
 5.98545682e-07 1.58369541e-04 1.98602676e-04 1.22814481e-05
 1.14967293e-06 8.48369564e-06 2.25142539e-02 3.64327243e-05
 7.67223128e-07 2.56553885e-05 4.50964872e-05 2.77657500e-06
 3.59815454e-06 8.35132414e-06 5.34895062e-03 1.07895445e-04
 1.64452904e-05 1.62422657e-04 1.38046232e-07 1.11171612e-05
 2.00510025e-04 1.05951885e-05 6.14583492e-04 7.50810359e-05
 9.16091085e-06 3.30861840e-05 3.62855616e-07 6.15451609e-06
 1.11577774e-05 4.18764785e-06 2.25096941e-03 7.78784283e-07
 2.27587725e-06 8.79508661e-06 1.09397399e-04 2.42176247e-06
 1.93787091e-05 1.54119903e-06 1.06704235e-03 6.10550051e-05
 1.76537560e-05 1.78158283e-04 2.53189428e-05 5.89640194e-06
 9.89485400e-08 1.78433475e-05 1.53584151e-05 9.42038896e-05
 2.26862653e-06 2.13261792e-05 7.77691603e-04 1.44780943e-05
 1.05606077e-05 5.61090064e-06 3.60131264e-04 2.99207641e-05
 5.36811558e-06 3.48731301e-05 1.86553137e-07 7.68947757e-06
 1.39325857e-04 1.87814236e-04 4.09060717e-03 1.18698801e-04
 1.80780888e-04 4.34324145e-03 1.85132631e-05 8.65541660e-05
 4.99753696e-05 9.04114131e-05 1.59123540e-03 1.41659139e-05
 6.90502493e-05 4.59223986e-04 2.59805420e-05 4.40776348e-04
 1.02265294e-05 9.79315519e-06 5.40643930e-04 6.40364033e-06
 5.69912891e-06 1.05175376e-03 3.98478460e-06 6.67759776e-03
 1.23947859e-04 5.46425581e-04 3.02803516e-03 1.99472904e-03
 8.98925919e-06 5.29557467e-04 4.68403101e-04 1.71691918e-05
 7.55883302e-05 3.83376755e-06 1.00320578e-03 2.02983618e-04
 1.57200211e-05 9.71823931e-04 1.40935183e-04 1.07028791e-05
 2.91082733e-06 1.76566700e-05 9.91018678e-05 1.20149307e-04
 2.07790617e-05 9.43540363e-05 3.98486853e-04 3.52316647e-06
 7.96207169e-05 1.67250633e-04 1.71780586e-04 3.44008731e-05
 5.90619748e-05 4.94271517e-04 8.30761837e-06 5.60263688e-05
 9.89051041e-05 3.46223424e-05 3.12501192e-03 4.03314829e-04
 2.00644936e-05 2.18093395e-04 9.85527731e-05 6.62294697e-05
 1.50114298e-04 2.82415513e-05 1.00338060e-04 5.30928373e-04
 2.25484371e-04 5.94030535e-05 4.19059434e-05 1.00471207e-05
 7.92147148e-06 3.44447471e-06 1.35600567e-04 8.97191203e-05
 3.55952602e-06 6.21377840e-05 1.96140409e-05 5.18421184e-05
 5.11305043e-05 5.98015067e-05 2.20730901e-03 3.16469886e-05
 1.66356564e-04 7.23659992e-04 8.38031701e-06 6.74655603e-05
 2.28762360e-06 4.38056159e-05 2.37953663e-02 6.02811160e-05
 3.84141858e-05 2.55197287e-04 7.58364986e-05 6.64068139e-05
 2.44982693e-05 5.56015002e-05 1.08462572e-03 3.87787819e-04
 2.79671513e-05 1.86622143e-04 1.37163852e-05 2.72214413e-04
 1.29767989e-06 4.16000706e-10 9.63028579e-05 7.70390034e-03
 5.53161028e-09 1.09315632e-04 6.32618139e-06], shape=(507,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0.], shape=(507,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2
 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1
 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2
 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 1 2 1 1 2 2 2 2 1 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 1 2 2 2 2 1
 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.026961204, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/four1.smt2-0027_000.smt2
true label:[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]
true label rank:[2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2]
predicted label:tf.Tensor(
[7.4900711e-01 8.5522562e-01 5.3966045e-04 1.8529379e-01 6.7064464e-03
 7.5443685e-03 6.0765147e-03 2.4344176e-02 1.8051267e-04 2.4320215e-02
 1.5773177e-03 9.4631314e-04 7.8412592e-03 3.3546686e-03 2.7336478e-03
 5.1399767e-01 3.4794140e-01], shape=(17,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.], shape=(17,), dtype=float32)
predicted label rank:[2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1]
mse:tf.Tensor(0.045945667, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/03.c_000.smt2
true label:[0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0]
true label rank:[1 2 1 1 2 1 1 1 2 2 1]
predicted label:tf.Tensor(
[0.68546087 0.5124922  0.80091    0.83274674 0.36326307 0.7132714
 0.58764625 0.5475634  0.9675653  0.8850002  0.2706251 ], shape=(11,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0.], shape=(11,), dtype=float32)
predicted label rank:[2 2 2 2 1 2 2 2 2 2 1]
mse:tf.Tensor(0.33539116, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/barthe2-big2_merged_safe.c-1_000.smt2
true label:[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 2 2 2 2 2 2 2 2 2]
predicted label:tf.Tensor(
[0.840073   0.97962415 0.66226274 0.9574537  0.8860481  0.9507842
 0.8985191  0.45218253 0.7104966  0.2755012  0.9979693  0.74520993], shape=(12,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1.], shape=(12,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 1 2 1 2 2]
mse:tf.Tensor(0.2587692, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/MOESI_2_e8_101_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1
 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 2 2 2 2 1 2 2 1 1 1
 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2
 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 2 2 2 2
 2 1 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 1 1
 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2
 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2
 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1]
predicted label:tf.Tensor(
[6.71465796e-06 6.51295518e-10 1.38593912e-02 1.30872130e-02
 4.52048787e-10 2.22831964e-04 1.60157681e-04 8.39632738e-11
 1.14911179e-21 4.49391609e-06 1.32457654e-24 1.49816275e-04
 2.83414125e-03 1.55841708e-02 1.67610049e-02 2.12669373e-04
 3.92645597e-04 1.82729363e-02 4.96222237e-05 2.83767781e-26
 5.27992597e-07 1.68674467e-15 1.77058578e-02 4.74786758e-03
 1.52558903e-11 4.65927988e-01 1.73260596e-05 2.32625008e-03
 3.10843408e-01 5.75401783e-01 7.07624137e-01 3.60089481e-01
 4.65041995e-02 7.02624803e-09 3.67900074e-01 8.19039345e-03
 1.80283189e-03 3.24262798e-01 5.46267629e-03 2.57645130e-01
 2.53227353e-03 3.63968611e-02 2.59013759e-05 3.64242987e-06
 4.39444228e-12 4.78130579e-03 1.06117957e-12 3.49244475e-02
 4.13183391e-01 1.26436055e-02 0.00000000e+00 4.71821725e-02
 7.01455772e-02 2.83882553e-11 1.04948878e-03 8.46455677e-14
 6.37769699e-04 8.63879919e-04 1.65122747e-03 1.73079967e-03
 8.87483358e-04 2.99096107e-04 2.68757343e-04 7.25626945e-04
 5.56200743e-04 6.16312027e-04 1.17370486e-03 4.78267670e-04
 8.84562731e-04 5.46276569e-04 2.63094902e-04 2.10292711e-07
 8.74638557e-04 1.25533342e-03 8.87870789e-04 6.74575567e-04
 6.66648149e-04 3.43471766e-04 7.02708960e-04 5.73992729e-04
 2.03102827e-04 6.25759363e-04 1.16881728e-03 5.49167395e-04
 1.29279524e-05 4.53472137e-04 3.03298235e-04 3.27289104e-04
 1.82986259e-03 2.53558159e-04 3.54558229e-04 1.61108375e-03
 2.55053895e-10 2.06738710e-04 4.44178295e-05 6.12351596e-06
 2.89306990e-05 9.36675042e-06 1.60420441e-05 3.92120564e-05
 3.70839334e-05 6.76677291e-06 2.55485447e-05 1.80157876e-05
 1.24744238e-05 1.32765372e-05 1.03472648e-05 2.89269465e-05
 3.97797121e-05 2.54783345e-06 3.46321176e-05 1.67018516e-06
 2.08997726e-03 1.90079212e-04 4.52667475e-04 5.47021627e-04
 1.21638179e-03 1.07669830e-03 7.31319189e-04 5.40286303e-04
 5.58882952e-04 2.88903713e-04 9.23395157e-04 1.07201934e-03
 2.02044845e-03 6.88552856e-04 1.38926506e-03 8.21143389e-04
 5.65052032e-04 1.64368230e-05 6.14809990e-03 1.79009140e-02
 1.43304467e-03 9.50393081e-03 4.07105684e-03 1.21509489e-04
 8.30994031e-06 2.13685632e-03 3.91611457e-03 1.25560164e-03
 2.24530697e-03 9.50471580e-01 9.60426807e-01 2.11737871e-01
 2.37730801e-01 3.12831819e-01 3.39708328e-01 1.93564564e-01
 4.31269407e-03 9.84144211e-03 6.89655542e-03 5.53593040e-03
 1.67827308e-02 7.41264224e-03 5.66285849e-03 9.18735743e-01
 8.53877306e-01 5.87883592e-03 1.19298697e-03 2.17956305e-03
 4.01592255e-03 2.32231617e-03 4.30315733e-04 7.23361969e-04
 6.13689423e-04 1.19993091e-03 2.75313854e-04 1.64392591e-03
 5.81294298e-04 4.92963195e-03 9.99999404e-01 9.99977350e-01
 9.99931931e-01 9.99769211e-01 1.19015872e-02 9.99748349e-01
 9.98591244e-01 9.85002637e-01 9.99772191e-01 7.63773918e-04
 9.91980433e-01 7.14430094e-01 1.25694275e-03 6.37739897e-04
 6.62267208e-04 9.17866886e-01 8.91484559e-01 9.90625024e-01
 1.00000000e+00 1.00000000e+00 9.99999762e-01 9.99716282e-01
 9.99874234e-01 9.99940217e-01 5.78933477e-01 6.94442749e-01
 6.08418584e-01 9.99999344e-01 9.99848843e-01 9.50097620e-01
 9.90838051e-01 9.99232829e-01 9.99998868e-01 9.99990702e-01
 9.99991655e-01 9.53834236e-01 9.15819526e-01 9.33663726e-01
 9.04531002e-01 9.37731862e-01 9.88581061e-01 9.90855753e-01
 9.99989748e-01 9.99996185e-01 7.63766050e-01 9.99999106e-01
 9.99999404e-01 9.99993801e-01 9.99992192e-01 9.99996305e-01
 1.00000000e+00 1.00000000e+00 9.99990821e-01 8.92333984e-01
 8.62776279e-01 6.99916124e-01 7.08402276e-01 7.94036150e-01
 6.84684336e-01 7.64568388e-01 1.00000000e+00 9.99925971e-01
 6.36663735e-01 9.99981821e-01 9.99991775e-01 9.99984622e-01
 9.99970973e-01 1.00000000e+00 8.74407649e-01 6.13807321e-01
 9.26451921e-01 9.18787599e-01 8.99744630e-01 9.20527458e-01
 8.82072866e-01 9.36205626e-01 9.43771958e-01 9.97767925e-01
 9.61280346e-01 9.84189987e-01 9.94265914e-01 9.86052752e-01
 8.55271816e-01 9.32712615e-01 8.61822128e-01 9.63394940e-01
 8.71585965e-01 9.14721131e-01 9.94281411e-01 9.95527446e-01
 9.95083272e-01 9.86806870e-01 9.89311576e-01 8.67173076e-01
 9.54788983e-01 9.10137057e-01 9.49936807e-01 9.15010929e-01
 9.32202697e-01 8.95848572e-01 9.46866751e-01 9.99969244e-01
 9.99832749e-01 9.99988377e-01 9.99987185e-01 9.99873519e-01
 9.17929053e-01 9.47991014e-01 9.24753189e-01 9.44372296e-01
 9.40162241e-01 8.86341631e-01 9.96020198e-01 9.97256339e-01
 9.98499334e-01 9.99259412e-01 9.98764932e-01 1.95766538e-01
 6.02019131e-02 3.94815207e-02 1.40282184e-01 2.04954147e-02
 9.96624708e-01 9.93275166e-01 9.50446725e-01 9.93760467e-01
 9.34992194e-01 2.32825279e-02 1.37860864e-01 2.58559376e-01
 6.84150338e-01 5.75711250e-01 6.79202020e-01 3.84916902e-01
 3.44250619e-01 7.63900995e-01 4.15538996e-01 3.53665769e-01
 4.25173759e-01 4.56464291e-03 2.01523304e-04 1.08027160e-02
 1.79494321e-01 2.63293654e-01 1.74114585e-01 4.05496359e-02
 9.25080299e-01 7.48816848e-01 7.51479626e-01 9.21199083e-01
 9.52977657e-01 9.80476022e-01 9.30502355e-01 9.84191895e-01
 9.77646351e-01 9.89804447e-01 2.01116800e-02 5.78293204e-03
 2.92757154e-02 1.26475692e-01 4.05709445e-02 2.72523165e-02
 8.23344290e-02 4.41154838e-03 1.62298381e-02 1.36810243e-02
 7.86742568e-03 1.36755407e-02 3.76072526e-03 5.78552485e-03
 1.70135498e-03 2.10858881e-02 2.65214682e-01 3.84023190e-02
 4.37962711e-02 4.48821187e-02 4.35800552e-02 3.56858671e-02
 8.45360756e-02 2.74443328e-02 9.77568865e-01 9.90725398e-01
 9.90768671e-01 1.49728090e-01 1.80315375e-02 1.86660886e-02
 3.04980755e-01 5.49883246e-02 4.27803397e-02 1.16314560e-01
 3.94001603e-02 2.67587602e-02 5.30197918e-02 4.55980599e-02
 7.58404136e-02 5.30084968e-03 7.56737590e-03 2.45660543e-04
 3.02160680e-02 8.36622715e-03 6.27160072e-04 8.25166702e-04
 2.90691853e-04 1.30385160e-04 3.07765603e-03 8.92072916e-04
 6.59167767e-04 3.28046083e-03 6.72340393e-04 6.32619049e-05
 4.66972551e-06 3.17633152e-04 4.89732520e-05 1.95205212e-04
 3.43978405e-04 6.47514389e-05 3.11106443e-04 4.21166420e-04
 4.26560640e-04 1.48564577e-04 3.97950411e-04 2.01523304e-04
 2.36511230e-04 7.14938642e-06 7.39482812e-06 2.62550969e-07
 1.48975849e-03 9.99953866e-01 9.99990344e-01 1.00000000e+00
 3.75219882e-01 9.88592744e-01 5.77187896e-01 9.39701438e-01
 9.65426564e-01 9.73783731e-01 1.00000000e+00 1.00000000e+00
 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99998331e-01
 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.71590757e-01
 9.65994477e-01 9.28367376e-01 9.77226734e-01 8.53900552e-01
 8.44942927e-01 2.86227821e-20 3.87959283e-11 6.98166013e-01
 1.34231210e-01 4.00742948e-01 9.99121403e-06 1.27030724e-13
 7.44185448e-02 5.30586237e-29 1.52757718e-08 6.59867050e-10
 4.80046838e-05 8.72236114e-07 1.58962177e-17 9.68856335e-01
 8.37876737e-01 1.04137957e-01 8.03259313e-02 9.73128200e-01
 8.90977144e-01 9.85481560e-01 9.95451927e-01 8.83644589e-07
 9.98434782e-01 9.45360065e-01 9.04910266e-01 7.28852987e-01
 8.57832789e-01 9.40142155e-01 9.53725696e-01 9.18673754e-01
 9.66403246e-01 9.99982595e-01 9.99940395e-01 9.76449668e-01
 6.40330136e-01 6.11984372e-01 4.08262014e-04 1.24573708e-04
 3.16768885e-04 4.66191769e-03 7.70208240e-03 5.67779243e-02
 1.91318741e-05 1.19035994e-05 1.78515911e-04 3.18616694e-05
 1.42630041e-02 1.34348571e-02 4.10296321e-02 9.14171636e-02
 1.31111741e-02 1.58586204e-02 2.32121050e-02 2.38919854e-02
 2.68369615e-01 9.20801342e-01 1.03940517e-01 2.48035938e-01
 1.79946661e-01 8.45462441e-01 6.89556122e-01 2.58980632e-01
 7.95059443e-01 4.08164382e-01 3.71978909e-01 3.48830283e-01
 6.02827370e-02 2.70941675e-01 7.98276544e-01 5.57174981e-02
 9.33397293e-01 1.45728797e-01 6.73586726e-02 1.03764057e-01
 2.25045085e-02 1.08220469e-04 1.53840184e-02 4.04565036e-02
 1.12414984e-08 1.37180090e-04 7.80797005e-03 3.67273390e-02
 4.03985679e-02 3.60054374e-02 4.90320921e-02 9.97336805e-02
 3.20261419e-02 2.51408815e-02 6.26823306e-02 8.63597691e-02
 3.54865789e-02 1.27047300e-04 9.16451536e-05 3.06785805e-05
 2.99036503e-04 1.92810076e-05 9.46733926e-05 4.55048680e-03
 2.21163034e-04 7.71313906e-04 8.77809653e-05 9.95970186e-05
 3.31938267e-04 1.03294042e-04 4.68070502e-05 2.67485102e-05
 1.16334252e-06 3.15315774e-05 2.02238662e-05 2.80566710e-05
 1.93075412e-05 3.92647416e-05 1.25597682e-21 1.57824159e-03
 4.74752378e-05 3.38549614e-02 3.23021290e-08 1.09328350e-04
 6.74409894e-05 8.63902242e-05 2.73713449e-05 1.92999840e-04
 1.35838985e-04 5.61475754e-04 5.95637066e-05 2.34702547e-05
 4.30762768e-04 1.65164471e-04 9.28726149e-05 9.25448537e-03
 2.90683420e-05 8.73059034e-04 6.22212887e-04 1.23079817e-05
 6.91562891e-04 4.46468592e-04 4.78563944e-09 8.31425190e-04
 2.49683857e-04 1.60455704e-04 3.52919102e-04 2.24089622e-03
 3.16392652e-05 1.41584987e-05 3.42821841e-05 1.26802533e-08
 2.71081924e-04 1.31815672e-04 9.25064087e-04 1.14333557e-10
 1.32465363e-03 7.55545334e-05 8.95724027e-24 9.54373913e-09
 4.47327402e-05 9.32598050e-06 1.66189857e-05 3.06963921e-04
 7.61392713e-03 1.35987997e-04 7.25935897e-05 2.53498554e-04
 8.36908817e-04 1.31314993e-03 3.17959202e-05 2.78291762e-01
 2.26255387e-01 5.61035514e-01 3.65692556e-01 4.53696489e-01
 3.09064209e-01 4.11851406e-01 2.66259253e-01 2.30917126e-01
 2.12805808e-01 3.28224361e-01 4.24031407e-01 3.42217088e-03
 6.80565834e-04 9.51175690e-02 3.14235091e-02 1.01519508e-05
 8.97831619e-02 1.41334534e-02 8.87662172e-04 3.86552215e-02
 7.73817301e-04 1.50101483e-02 9.02846754e-02 1.34203911e-01
 1.53395534e-03 1.05164707e-01 5.17600775e-02 1.18899345e-02
 1.03792548e-01 4.97361720e-02 2.33957767e-02 7.36892223e-04
 2.05173790e-02 6.06737137e-02 4.19583619e-02 4.69442606e-02
 1.20619625e-01 2.54634023e-03 1.08811796e-01 2.37822860e-01
 9.99830127e-01 9.99619305e-01 9.93938267e-01 9.99160528e-01
 6.02874100e-01 1.00000000e+00 9.95653808e-01 5.50282538e-01
 9.19994593e-01 9.96087313e-01 6.15737200e-01 9.56249595e-01
 8.63991022e-01 1.74997425e-07 0.00000000e+00 4.29417795e-15
 0.00000000e+00 1.78166121e-01 5.44901416e-11 1.26729932e-24
 1.10877026e-13 0.00000000e+00 1.61974758e-01 6.10298587e-35
 5.92992183e-06 4.73469111e-11 3.68747626e-24 2.22414801e-22
 9.12647247e-02 6.50687915e-15 1.04657811e-05 3.39805440e-20
 5.76446002e-10 5.56771393e-21 2.32849937e-12 5.46946049e-01
 9.51168776e-01 3.63653898e-03 2.90492181e-07 3.40691099e-06
 2.41705775e-03], shape=(669,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.
 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.], shape=(669,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1
 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 2 2 2 2 1 2 2 1 1 1
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 2 2 2 2
 2 1 1 1 2 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 2 1
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1
 2 2 1 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1
 1 1 1]
mse:tf.Tensor(0.06262469, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/heapsort_true-unreach-call.c.flat_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.9996396  0.23885167 0.689364   0.25123942 0.27799836 0.98549664
 0.9735068  0.38338804 0.9952575  0.6676369  0.9767432  0.9864416
 0.9783179  0.9114695 ], shape=(14,), dtype=float32)
rounded label:tf.Tensor([1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1.], shape=(14,), dtype=float32)
predicted label rank:[2 1 2 1 1 2 2 1 2 2 2 2 2 2]
mse:tf.Tensor(0.16131522, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/seesaw.c_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.9999828  0.99784315 0.9930358  1.         0.97591746 0.96173704
 1.         0.9822404 ], shape=(8,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1.], shape=(8,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.0003015725, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/test_locks_12.c-1_000.smt2
true label:[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1
 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 1
 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1
 1 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 2 2
 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2
 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[6.09835327e-01 6.41646981e-03 1.97014630e-01 1.82894677e-01
 1.85981184e-01 2.87610054e-01 2.23500997e-01 1.71802729e-01
 2.75255650e-01 3.19021046e-01 3.27317178e-01 2.00751543e-01
 1.98656499e-01 2.37549454e-01 3.24032962e-01 1.86417520e-01
 1.13268465e-01 1.41942590e-01 1.55929357e-01 2.63982177e-01
 2.53927529e-01 2.86860704e-01 8.77253115e-02 9.96448994e-01
 9.91201341e-01 5.80903471e-01 6.51270390e-01 6.67539001e-01
 8.02899778e-01 5.14900148e-01 7.50485182e-01 7.48516858e-01
 8.39653492e-01 4.39958483e-01 6.58322632e-01 9.12456393e-01
 6.48288608e-01 8.88645291e-01 5.70478797e-01 7.70141423e-01
 8.81044507e-01 7.78606057e-01 6.87704921e-01 9.97866750e-01
 9.99729276e-01 9.96544600e-01 9.97664571e-01 6.17381811e-01
 9.33388770e-02 4.99370992e-02 9.44650352e-01 3.43299180e-01
 6.34840071e-01 4.13605809e-01 4.65942234e-01 6.17359936e-01
 5.65777004e-01 5.11678159e-01 6.90364838e-01 6.15331411e-01
 5.96748412e-01 2.97400177e-01 2.46120870e-01 5.08348703e-01
 4.70400631e-01 4.49834257e-01 5.38443863e-01 4.31539059e-01
 5.38187563e-01 4.92912889e-01 4.86637801e-01 6.58222973e-01
 5.54869771e-01 9.43716049e-01 8.75506341e-01 5.10858715e-01
 5.31249642e-01 5.25056005e-01 5.34203470e-01 6.42607570e-01
 3.65388751e-01 6.38779819e-01 7.21278608e-01 6.66868448e-01
 7.40333319e-01 4.91819561e-01 4.14859593e-01 3.15949917e-01
 6.81613147e-01 4.27642107e-01 4.64554667e-01 4.86996382e-01
 4.50513780e-01 7.10399210e-01 9.97562051e-01 9.97182131e-01
 9.62891340e-01 6.27688169e-01 4.65491205e-01 4.73671287e-01
 4.73312289e-01 4.58359957e-01 5.47704160e-01 5.80071867e-01
 4.84863341e-01 5.03500044e-01 4.49222744e-01 5.17445564e-01
 5.25237978e-01 4.30133611e-01 1.65706187e-01 6.55800104e-03
 2.28434801e-01 7.93683529e-03 5.35409451e-02 2.51328945e-03
 4.21372652e-02 1.29474968e-01 1.12243950e-01 6.12903237e-02
 6.44071698e-02 2.24804878e-02 9.48822200e-02 6.15111589e-02
 2.44646937e-01 1.06201768e-01 1.43723905e-01 8.44034851e-02
 7.11245239e-02 2.81736851e-01 3.14100921e-01 3.47265244e-01
 2.16617823e-01 2.96110213e-01 4.27517146e-01 9.86339688e-01
 9.82110620e-01 2.53582507e-01 2.97471523e-01 2.15439528e-01
 2.40885377e-01 2.69860387e-01 2.57653654e-01 2.54250050e-01
 2.81232178e-01 3.05495560e-01 3.20443422e-01 4.72308874e-01
 4.71266270e-01 7.97963679e-01 4.58729237e-01 6.30773365e-01
 5.13568282e-01 6.72854781e-01 3.20577711e-01 9.71382856e-01
 4.21678543e-01 7.92539954e-01 5.67011893e-01 9.01844025e-01
 7.77063608e-01 3.38042080e-01 3.96942675e-01 3.90475661e-01
 1.62266821e-01 3.51369262e-01 5.42697310e-02 3.65840048e-01
 1.59907997e-01 3.17189097e-02 2.70557404e-02 3.86365265e-01
 9.10233259e-02 9.41845179e-01 3.29060733e-01 2.06104934e-01
 5.98177850e-01 4.85745966e-02 3.70854199e-01 1.40350282e-01
 6.55151904e-02 8.41199756e-02 8.59070718e-02 4.74285185e-02
 5.89193404e-02 2.86450684e-02 6.26886487e-02 5.40551841e-02
 4.15438414e-03 4.19506431e-03 8.94713402e-03 5.98073900e-02
 5.66567779e-02 1.80343091e-02 6.26192987e-02 3.18058729e-02
 2.26018429e-02 5.75714111e-02 1.29135549e-02 2.35836208e-02
 2.92583704e-02 1.70546472e-02 2.14504302e-02 2.34692991e-02
 8.27035308e-03 1.35660172e-04 2.28964090e-02 4.81666923e-02
 2.52847672e-02 2.28350967e-01 1.47755921e-01 2.45336682e-01
 1.52235419e-01 2.96422690e-01 3.09474945e-01 1.91184402e-01
 3.07204306e-01 5.18721938e-02 2.38964230e-01 7.29069710e-02
 6.55778050e-02 8.59950066e-01 9.69827175e-04 4.62743640e-03
 2.39405721e-01 1.90916628e-01 2.67408997e-01 3.20567191e-01
 3.15373540e-01 3.33918571e-01 3.01773667e-01 3.47287476e-01
 2.90222019e-01 6.19795918e-02 9.07116532e-02 7.78174996e-02
 6.15116656e-02 5.91685772e-02 6.37127757e-02 8.88147652e-02
 4.46100235e-02 1.26464605e-01 8.97459090e-02 1.18988127e-01
 3.95520031e-02 1.15993410e-01 3.76205742e-02 7.57321119e-02
 5.55585027e-02 7.90019929e-02 7.70956278e-04 2.23031640e-03
 4.59600389e-02 7.13930428e-02 3.99108231e-02 9.29012895e-03
 8.70305300e-03 1.70816481e-02 1.70163512e-02 2.81134844e-02
 1.87995136e-02 1.49195492e-02 9.56165791e-03 2.02525556e-02
 1.75982714e-04 3.16261430e-05 4.07010317e-04 6.37741905e-05
 3.61502171e-03 3.32409143e-03 4.51417863e-02 1.39310062e-02
 4.62185740e-02 1.18521750e-02 2.67527521e-01 2.35431880e-01
 3.30353498e-01 4.09992218e-01 2.33520627e-01 1.05527043e-03
 3.36002111e-02 8.30453634e-03 6.23524189e-04 3.23474407e-04
 1.55550241e-01 3.18359733e-01 1.64939255e-01 3.49512160e-01
 1.87102079e-01 1.42679274e-01 6.50042593e-02 5.96311688e-03
 4.64868248e-02 1.72737539e-02 4.11353409e-02 3.06212604e-02
 4.04518247e-02 8.25127959e-03 7.69486129e-02 9.14980173e-02
 1.34078860e-01 1.73539817e-01 5.67707419e-03 2.84910202e-04
 6.59883022e-04 9.09446239e-01 5.76424301e-01 7.19040990e-01
 9.56719518e-01 3.57830346e-01 8.41570509e-05 3.35751176e-02
 6.04531169e-03 9.34351087e-01 1.58103485e-05 8.89233415e-05
 7.90682952e-06 5.18671751e-01 2.17602847e-05 9.24514461e-05
 1.45140886e-02 1.12694472e-01 6.14696683e-06 1.72108114e-02], shape=(324,), dtype=float32)
rounded label:tf.Tensor(
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], shape=(324,), dtype=float32)
predicted label rank:[2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 1 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 1 1 2 1 2 1 1 2 2 2 2 2 2 1 1 2 1 1 2 1 2 1 1 2 2 2
 2 2 2 2 2 2 1 2 2 2 2 1 1 1 2 1 1 1 1 2 2 2 2 2 1 1 1 1 2 2 1 2 1 2 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1
 1 2 1 2 2 2 1 2 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1]
mse:tf.Tensor(0.38031837, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/break_single_merged_safe.c-1_000.smt2
true label:[1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1]
predicted label:tf.Tensor([0.5277104  0.9996078  0.91153836 0.9733136  0.9926232 ], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.046329938, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/SYNAPSE_3_e7_1444_e7_638_000.smt2
true label:[1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1]
true label rank:[2 1 1 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 2 2 2 2 1 1 1 2 2 2 2
 1 2 2 2 2 1 2 2 2 2 2 2 1 2 1 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2
 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 1 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1
 2]
predicted label:tf.Tensor(
[1.08459145e-01 1.06398938e-05 2.60155976e-01 3.67627740e-01
 9.80454683e-03 1.19060278e-02 7.41864145e-01 4.49553490e-01
 8.58456492e-01 4.35862899e-01 3.31699848e-03 2.99236059e-01
 2.14207917e-01 3.04811686e-01 3.24945480e-01 3.26176941e-01
 1.35707140e-01 3.83291245e-02 2.14697003e-01 2.16357023e-01
 1.55482024e-01 2.20507383e-04 7.44324625e-02 9.17468965e-02
 6.26561132e-06 1.05177671e-01 5.04237413e-03 1.24426186e-02
 1.14945143e-01 6.84919834e-01 8.98305178e-02 6.26606643e-02
 5.98309338e-02 1.71959400e-04 4.90071177e-02 5.35675287e-02
 7.63125420e-02 7.76832700e-02 6.37666583e-02 9.42011774e-02
 1.00775272e-01 9.52889442e-01 9.99977350e-01 6.97426796e-01
 9.88842249e-01 4.97728586e-04 2.30733156e-02 2.18490362e-02
 7.24518299e-03 3.98683548e-03 2.11000443e-03 4.44138050e-03
 1.21068954e-02 8.33338499e-03 1.06070936e-02 1.66758001e-02
 2.21504271e-02 1.45335793e-02 9.98011708e-01 9.99997735e-01
 9.39075768e-01 9.99723077e-01 9.24765773e-05 9.90497112e-01
 8.07568192e-01 9.15781856e-01 8.65951717e-01 9.67385173e-01
 5.31456828e-01 4.43707347e-01 9.95558918e-01 4.70015526e-01
 7.30806291e-01 7.41329014e-01 9.77203727e-01 9.99969542e-01
 9.98067439e-01 9.99382138e-01 5.71801960e-01 8.79302025e-01
 9.93466794e-01 9.93303299e-01 9.47480977e-01 8.82402539e-01
 9.54510808e-01 5.26847124e-01 5.20774662e-01 4.58560765e-01
 6.18889213e-01 9.99997258e-01 9.99993563e-01 9.99353766e-01
 9.86274123e-01 9.97785807e-01 9.99947190e-01 9.98701990e-01
 9.99078870e-01 9.99755263e-01 9.34844553e-01 2.33465403e-01
 8.43614936e-01 9.99971628e-01 9.65074897e-01 9.99966979e-01
 9.52893734e-01 9.99948978e-01 8.06860805e-01 9.70127463e-01
 9.52981234e-01 9.94165123e-01 9.99535561e-01 9.99482691e-01
 2.22785457e-05 9.89595532e-01 2.48392582e-01 6.24491440e-05
 9.10701573e-01 9.34276342e-01 9.90782738e-01 9.97277796e-01
 9.97028351e-01 8.13401759e-01 8.71985793e-01 8.17427814e-01
 9.11280513e-01 9.57439303e-01 2.61810273e-01 5.48058748e-03
 9.90062952e-04 6.79619610e-02 7.58594036e-01 1.26586199e-01
 6.24595404e-01 9.18101788e-01 9.57955003e-01 9.69403207e-01
 9.99770284e-01 7.81018555e-01 9.80244040e-01 9.78620827e-01
 6.62124455e-01 9.56880987e-01 7.01096058e-01 5.14567837e-05
 1.05497718e-01 7.12394714e-04 8.00350010e-02 3.86148691e-04
 1.34944916e-03], shape=(149,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.
 0. 0. 0. 0. 0.], shape=(149,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 2 2 2 2 2 2 1 2 1 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2
 2 1 2 1 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 2 1 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1
 1]
mse:tf.Tensor(0.09317931, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/large_const_true-unreach-call.c.flat_000.smt2
true label:[1, 1, 0, 1, 1, 0, 1]
true label rank:[2 2 1 2 2 1 2]
predicted label:tf.Tensor(
[0.5764782  0.9702313  0.90138996 0.5760491  0.9777546  0.99383324
 0.9330338 ], shape=(7,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1.], shape=(7,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1]
mse:tf.Tensor(0.3093113, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/inf6.correct.nts.horn-0001_000.smt2
true label:[1, 1, 0, 1, 1, 1, 1, 1, 0, 1]
true label rank:[2 2 1 2 2 2 2 2 1 2]
predicted label:tf.Tensor(
[0.75794756 0.9099037  0.2155478  0.2009792  0.18851036 0.02553633
 0.24182999 0.50647086 0.9450124  0.9666586 ], shape=(10,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 0. 0. 0. 0. 1. 1. 1.], shape=(10,), dtype=float32)
predicted label rank:[2 2 1 1 1 1 1 2 2 2]
mse:tf.Tensor(0.40722495, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/barthe2_merged_safe.c-1_000.smt2
true label:[0, 1, 1, 1, 1, 0, 1, 1, 1, 1]
true label rank:[1 2 2 2 2 1 2 2 2 2]
predicted label:tf.Tensor(
[0.77528334 0.9627366  0.4209599  0.5959789  0.21904144 0.28434354
 0.60911    0.50503564 0.9907527  0.8309889 ], shape=(10,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 0. 0. 1. 1. 1. 1.], shape=(10,), dtype=float32)
predicted label rank:[2 2 1 2 1 1 2 2 2 2]
mse:tf.Tensor(0.22181559, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/reverse_div_unsafe.c_000.smt2
true label:[1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2
 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1
 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[1.06302291e-01 2.09170938e-01 1.46868825e-03 9.99996901e-01
 1.73795223e-03 6.14523888e-03 5.78075647e-04 6.80812263e-06
 1.00134261e-04 2.27787495e-02 8.10652971e-04 3.57081049e-08
 6.67867312e-07 3.60906124e-04 1.52140856e-04 3.42685689e-06
 8.00841462e-06 3.11195850e-04 5.19157584e-06 3.96821598e-08
 2.19559806e-05 8.46426262e-11 5.35061488e-08 1.39667690e-02
 5.34419200e-07 1.10891461e-03 3.09970975e-03 2.28354335e-03
 2.09909678e-03 3.78221273e-04 2.70825624e-03 1.25116110e-03
 9.68307257e-04 2.17705965e-04 8.13698769e-03 3.21731329e-01
 8.54539550e-09 4.34503555e-02 2.39551067e-04 4.61204529e-01
 5.05776043e-08 3.88188255e-06 7.03549517e-07 4.51828811e-07
 5.64631478e-07 7.46352744e-05 5.01946806e-06 1.49934831e-05
 4.10973298e-05 2.52944719e-05 5.14129283e-07 1.20073646e-05
 2.11833558e-05 3.86267900e-04 1.32054090e-03 1.02427514e-07
 1.22158170e-01 2.13600488e-05 3.62989008e-02 7.59391260e-05
 1.69852376e-03 1.30361319e-03 8.41170549e-04 3.14915180e-03
 7.57008791e-04 8.51780176e-04 2.13104486e-03 1.40568614e-03
 2.92912126e-03 1.65626407e-03 5.57005405e-04 1.01191401e-02
 3.64327389e-06 1.28495395e-02 3.10335755e-01 4.96983528e-04
 1.10518038e-02 1.86228752e-03 3.87259606e-05 1.25437975e-04
 3.57070565e-03 1.09969193e-07 6.91321492e-03 2.17711926e-02
 4.92809713e-02 3.36921215e-03 2.63306731e-07 9.99812841e-01
 1.25682503e-01 7.42423534e-03 1.00000000e+00 6.47622347e-03
 9.69588757e-04 3.89251113e-03 4.93428111e-02 4.06062603e-03
 1.12783551e-01 5.72261214e-03 2.17847526e-02 2.58516669e-02
 7.35574961e-03 1.20214820e-02 3.58992815e-03 1.87447667e-03
 3.67310643e-03 7.81193852e-01 5.43591380e-03 5.57155848e-01
 2.84377694e-01 5.24663925e-01 9.22051907e-01 9.65851784e-01
 9.23818588e-01 5.32885671e-01 6.20604038e-01 1.76372230e-02
 1.48290426e-01 3.61060202e-02 7.78280795e-01 4.30593431e-01
 2.38469929e-01 2.01036334e-02 2.22293109e-01 1.35996938e-03
 2.49412656e-03 3.07270885e-03 5.55422902e-03 4.72307205e-03
 2.29781866e-03 4.66373563e-03 1.09108686e-02 6.30047580e-05
 4.12076712e-04 7.74426341e-01 5.04311383e-01 6.62091613e-01
 9.24679637e-01 5.82385778e-01 3.19697857e-02 5.02940536e-01
 1.57059729e-02 4.08295691e-02 1.27512217e-03 1.79544022e-05
 6.07323647e-03 3.04454565e-03 1.30549550e-01 8.13702718e-06
 3.46403103e-05 4.65827907e-05 2.96711922e-04 2.18132436e-02
 8.20344687e-03 1.68452086e-10 2.44141817e-02 2.41887137e-05
 2.18386603e-07 7.48445028e-10 2.05400586e-03 2.67008305e-01
 5.75557351e-03 1.04625928e-04 3.04439664e-03 4.91591800e-06
 3.72737646e-04 5.24377227e-02 1.38867199e-02 1.42922490e-05
 1.74553570e-05 8.75998303e-05 1.24812126e-04 1.20764971e-03
 2.06410885e-03 3.39537859e-03 1.52063370e-03 6.04712963e-03
 2.90453434e-04 3.34382057e-04 1.25905871e-03 5.67602510e-05
 7.22527504e-04 7.36743212e-04 3.23325396e-04 1.71065331e-04
 8.05765390e-04 3.16889346e-01 1.58149600e-02 1.30699068e-01
 2.18580961e-02 4.48462069e-01 1.15141042e-07 6.61750455e-05
 1.06305182e-02 2.37554312e-03 5.47609375e-07 9.67085361e-04
 6.42180443e-04 1.20955706e-03 7.94053078e-04 9.01490450e-04
 5.07920980e-04 5.28802411e-05 4.53770161e-04 1.19842160e-04
 3.70705128e-03 4.00087237e-03 2.22438574e-03 2.57939100e-04
 1.05040432e-04 7.14932830e-05 9.99987364e-01 1.93669647e-01
 4.93979460e-05 1.00000000e+00 4.21772301e-02 6.54697418e-04
 9.25129652e-03 1.21120512e-02 7.85908103e-03 7.35947788e-02
 4.63902950e-03 4.12031770e-01 3.44726270e-09 1.65950695e-07
 1.27482579e-07 4.33405205e-08 7.81013341e-07 6.59199648e-12
 7.25404314e-09 1.49501386e-12 8.05112137e-08 1.59203140e-09
 7.39657668e-10 1.86724608e-10 4.66940614e-13 1.10152190e-08
 7.90613777e-13 9.30739152e-10 1.80269488e-08 1.30094548e-07
 6.99236363e-11 4.13095296e-12 1.32927322e-10 1.44614709e-10
 8.94520490e-05 1.99705362e-04 1.54593587e-03 2.46822834e-04
 4.71633673e-03 9.91427898e-03 3.48806381e-04 6.31359220e-03
 3.81025672e-03 3.11088562e-03 9.30786133e-04 1.18070543e-02
 1.46173588e-05 1.83850527e-04 6.03616238e-04 1.23465061e-03
 2.67696381e-03 2.55048275e-04 1.52975321e-04 2.11358070e-04
 4.60122824e-02 3.56942415e-04 2.11429000e-02 2.75224447e-04
 1.82138920e-01 1.23530626e-04 1.17344886e-01 4.50818192e-07
 2.92306542e-01 2.71877781e-07 1.95930454e-07 4.26739454e-04
 1.16877936e-06 1.51157379e-04 7.10630320e-06 7.32680292e-07
 5.11895859e-09 8.02190189e-05 3.11076641e-04 2.12708801e-06
 7.05684361e-05 6.15055569e-06 1.92829967e-03 1.26332045e-04
 3.12859868e-07 6.20431319e-06 9.62823629e-04 6.86782369e-06
 4.57052411e-05 2.94460356e-02 6.26976422e-12 1.49214268e-03
 3.62750798e-05 6.77487333e-05 1.78244710e-03 4.48809743e-07
 1.61293315e-07 9.81529524e-10 9.77842865e-06 1.79287611e-06
 1.21323581e-07 1.80717223e-06 3.07691097e-03 2.79644132e-03
 2.62379646e-04 6.98985314e-12 1.89760050e-16 9.38425007e-15
 2.91807856e-10 6.43861117e-14 1.00484259e-12 2.40421567e-08
 5.52785769e-12 9.78486294e-14 3.22205305e-12 2.01276196e-09
 5.00366693e-10 4.08813825e-13 4.66301824e-12 4.44470307e-14
 1.43876946e-12 2.57725655e-12 9.22582344e-10 7.52883812e-13
 1.11988934e-11 1.20710789e-10 2.98547749e-11 3.93651159e-18
 3.89197469e-03 3.24994326e-04 3.42509120e-05 1.72108412e-04
 4.12339505e-05 4.90307808e-04 2.95594335e-03 1.39701366e-03
 4.24474478e-04 1.10855699e-03 1.07303262e-03 3.46842408e-03
 2.78234482e-04 1.16973519e-02 5.84691763e-04 9.96696108e-05
 1.05386098e-04 1.17057869e-04 2.89669633e-03 4.66841459e-02
 8.71831144e-05 3.13768542e-05 4.10777966e-06 8.90362263e-03
 1.79976225e-03 9.99990642e-01 1.85838044e-02 3.14622283e-01
 1.00000000e+00 5.71431592e-05 7.88314978e-08 3.81542304e-05
 1.96696222e-02 9.69508290e-03 7.99162388e-01 3.57478857e-04
 5.40970504e-01 5.05596399e-04 9.14589167e-01 3.29911709e-04
 8.04888844e-01 4.51505184e-04 9.03392792e-01 4.33859229e-03
 6.83754683e-04 4.32443619e-03 9.41509861e-05 3.13569763e-06
 1.68873926e-09 2.59169936e-03 5.81958648e-10 9.13321972e-04
 6.00099564e-03 2.48759985e-04 1.71664357e-03 1.37847066e-02
 6.75004721e-03 8.14199448e-04 6.40487671e-03 4.09334898e-04
 1.82079725e-06 2.34550953e-06 7.25726859e-05 2.00701365e-07
 6.79317964e-06 9.76762176e-03 2.06637383e-03 1.14852190e-02
 1.62684917e-03 1.31846070e-02 2.96354294e-04 4.78863716e-04
 3.22966162e-06 5.30903435e-07 3.38447692e-09 7.75503550e-10
 1.79485782e-09 5.76747709e-07 1.52806024e-05 6.97273322e-07
 1.52879404e-10 1.17569368e-06 2.94444988e-07 1.34287763e-08
 4.59741358e-07 5.60526559e-09 2.94065586e-07 9.42491293e-01
 6.10340112e-10 5.87259233e-01 4.22847046e-09 5.26181340e-01
 4.85748053e-04 4.92067426e-01 1.84086675e-05 6.76839352e-01
 9.48390365e-03 9.29730058e-01 4.86519933e-03 1.15642088e-05
 6.37844132e-05 8.75502825e-04 1.27938947e-07 3.17066908e-04
 4.00958867e-12 6.05553389e-04 1.66434050e-03 6.38633365e-15
 2.66898628e-08 2.30910580e-08 2.88844109e-04 7.72167260e-19
 4.07746654e-07 5.88358606e-09 2.85146819e-12 1.28088664e-12
 1.81363375e-05 1.01649761e-03 2.37814265e-11 4.41985160e-09
 3.20300217e-07 2.88813362e-10 4.60976979e-10 3.80307436e-04
 7.39760267e-11 5.14394517e-13 5.56198749e-08 5.78442005e-09
 5.00826281e-05 2.17458569e-06 7.86996932e-13 1.41073195e-11
 1.63342662e-07 2.60614522e-19 2.53224790e-01 1.40214865e-06
 7.95673805e-10 8.61827103e-12 1.11555210e-09 2.11197138e-03
 2.07811594e-04 8.84370911e-06 1.16048157e-02 9.89660621e-03
 2.84802616e-02 7.28523731e-03 1.63689256e-03 9.22670829e-09
 8.22961330e-04 7.47451186e-03 1.57564878e-04 1.11512840e-02
 7.31079490e-06 4.59581614e-04 2.44814157e-03 1.10347271e-02
 2.54744291e-03 1.10186040e-02 2.01832652e-02 5.50577402e-01
 5.01394272e-04 3.09139490e-04 7.68047571e-03 5.06779552e-03
 1.59843564e-02 3.17260623e-03 1.83612108e-04 1.76402628e-02
 7.14048743e-03 2.65157223e-03 2.01642513e-04 4.54911590e-03
 8.33094120e-04 2.43484974e-03 9.27031040e-03 1.24610960e-02
 2.13390589e-03 2.84495950e-03 1.12199072e-04 2.32815742e-04
 4.17823819e-15 6.87303555e-07 1.40572354e-06 7.15910573e-05
 2.35273412e-10 6.44498552e-11 1.86845117e-09 6.05545978e-08
 2.80994177e-03 1.56784044e-08 1.72990985e-05 1.82288215e-06
 2.56898238e-06 1.42368674e-03 9.47235319e-14 9.59343964e-08
 3.49861220e-05 1.04591154e-05 9.98437524e-01 3.31372023e-04
 1.94519758e-04 3.59624624e-04 9.88560915e-03 9.77286696e-01
 1.84831023e-03 8.53357911e-02 6.96182251e-04 3.37524116e-02
 4.73031402e-03 9.31903720e-03 9.76711512e-04 2.22503841e-02
 1.50206188e-05 6.72012568e-04 1.50648902e-05 1.76306018e-11
 2.11119663e-12 5.20834903e-11 1.49751045e-09 1.82576054e-09
 6.16168094e-08 6.46531873e-13 7.00294134e-09 1.03161184e-07
 3.23823057e-09 5.43457640e-11 9.43133216e-08 1.52383406e-09
 6.35740016e-10 1.42011139e-10 1.12860121e-08 4.42380070e-08
 4.42254957e-13 3.10655696e-10 4.21066957e-12 4.81575229e-14
 1.16193295e-03 3.86050344e-03 5.28148739e-05 7.03126192e-04
 6.52698654e-05 7.42838456e-05 1.13853624e-04 3.32158804e-03
 3.46388873e-07 5.54274777e-07 1.82449818e-04 1.30796432e-03
 9.63985920e-04 1.33715457e-05 3.46495617e-05 2.81852484e-03
 9.52405377e-11 1.55118089e-11 3.73454184e-11 2.52107666e-12
 4.44011361e-09 6.33073753e-08 2.37057793e-05 2.02932893e-10
 1.30313722e-07 1.12783090e-08 9.19139385e-03 5.18068671e-02
 9.76383328e-01 3.11449170e-03 9.96660709e-01 2.13746130e-02
 7.83941507e-01 2.32988596e-03 9.76649821e-01 5.08165359e-03
 9.76728499e-01 4.21229005e-03 9.43830252e-01 2.90617347e-03
 2.08700299e-02 1.56555689e-05 1.15446562e-17 7.59086333e-07
 1.61815450e-07 5.17740711e-11 8.25569034e-03 9.25153494e-04
 3.46362591e-04 1.11553877e-10 5.22032380e-03 9.24103502e-11
 3.75971198e-03 1.59126284e-06 1.24557614e-02 8.33962440e-06
 8.49083066e-03 1.47438905e-13 3.63379717e-04 2.60023553e-05
 2.38686800e-04 3.49481547e-06 6.03096851e-07 5.70720022e-06
 4.07816297e-05 7.49098092e-07 1.15010125e-05 2.52184545e-05
 2.29567289e-04 9.66559892e-05 2.23301504e-05 7.39336014e-04
 7.02426905e-06 3.70945781e-05 1.61526532e-05 8.04783052e-13
 6.08351980e-16 4.18546372e-23 1.40054140e-11 1.19824878e-25
 3.15810682e-19 6.10433322e-21 6.61310082e-07 8.37438506e-07
 1.59839516e-07 7.33752927e-07 1.46173647e-06 2.57253237e-06
 1.56056387e-06 1.56853150e-06 2.78331413e-06 1.66138507e-05
 2.60770321e-04 5.77282906e-03 1.01910853e-08 1.34393158e-05
 2.64495611e-04 9.80915356e-05 4.47840503e-05 3.65385349e-05
 1.21173263e-03 2.80737877e-04 1.24439111e-05 2.58943987e-06
 4.77540698e-06 1.76192261e-05 1.64921005e-06 7.63753342e-05
 6.21926229e-05 1.28722888e-06 4.54310438e-08 1.26528757e-05
 4.68355119e-02 1.64754456e-05 1.61176831e-06 1.32489513e-05
 1.13379690e-04 1.72803700e-02 2.89291143e-04 1.76108933e-05
 2.51489837e-06 8.61154840e-05 1.09495818e-06 2.23588728e-07
 9.96205199e-06 1.60563388e-07 1.11242094e-04 2.54033898e-06
 7.02913017e-09 1.07086526e-04 1.05307234e-04 9.10120889e-06
 3.14384699e-04 1.27553940e-04 7.25744144e-07 2.48450050e-07
 7.30401711e-11 9.05485520e-10 3.00838547e-05 9.10001993e-03
 2.71529534e-05 2.30822443e-05 5.40119945e-05 1.83733106e-02
 1.95856119e-05 7.54262010e-06 8.03754219e-08 4.79432940e-03
 7.86979072e-05 6.88790402e-09 1.05431434e-04 4.43679128e-05
 3.20457872e-07 1.88464639e-06 6.27164900e-06 2.32124739e-06
 6.69735527e-07 7.54241455e-07 3.48601930e-07 1.52044670e-08
 2.91198492e-04 3.97922292e-07 5.45412302e-04 3.23948516e-05
 1.39652575e-05 1.17940690e-05 6.75035228e-09 1.07829246e-05
 1.59462775e-06 1.76461560e-06 4.02763271e-06 1.27395206e-05
 2.40137553e-07 1.36072288e-07 6.11081305e-07 3.81530953e-11
 5.10058499e-06 2.10881233e-04 4.46814056e-07 2.68218457e-07
 1.52282018e-05 5.58157899e-06 7.34806061e-04 1.38673186e-03
 1.54675841e-02 6.49650693e-02 2.19136477e-04 5.88059425e-04
 1.21507049e-03 1.14831328e-03 5.84483147e-04 1.10338777e-01
 2.89398432e-03 5.27720294e-05 1.41501427e-04 2.67369449e-01
 8.57621431e-04 1.68575134e-05 1.52978301e-03 1.59275442e-05
 9.80913639e-04 1.47205591e-03 3.96017299e-07 7.74654448e-02
 2.24888325e-04 8.28522444e-03 8.33481550e-04 2.86191702e-04
 5.45024872e-04 5.81395626e-03 3.17871571e-04 3.73134017e-03
 8.94933939e-04 3.95178795e-04 8.16971064e-04 1.02445483e-03
 8.47816467e-04 2.57551670e-04 1.96605921e-04 5.62161207e-04
 2.28554010e-04 2.66138049e-05 4.45515470e-05 8.09574317e-07
 9.66295411e-05 2.25037336e-04 7.62317950e-06 2.74710073e-05], shape=(796,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0.], shape=(796,), dtype=float32)
predicted label rank:[1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 2
 2 2 2 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1
 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.0331888, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/08.c_000.smt2
true label:[1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]
true label rank:[2 2 1 1 1 2 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1]
predicted label:tf.Tensor(
[0.9122297  0.976051   0.6769954  0.8829122  0.13141298 0.34986305
 0.51674247 0.4927576  0.98039085 0.70288265 0.5901585  0.718902
 0.70663637 0.5389112  0.48218858 0.03704393 0.83708835 0.32300064
 0.36360955 0.57077533 0.96547806 0.89274776 0.41616705], shape=(23,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0.], shape=(23,), dtype=float32)
predicted label rank:[2 2 2 2 1 1 2 1 2 2 2 2 2 2 1 1 2 1 1 2 2 2 1]
mse:tf.Tensor(0.4047521, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/bandec.smt2-0157_000.smt2
true label:[1, 1, 0, 0]
true label rank:[2 2 1 1]
predicted label:tf.Tensor([0.5614991  0.22981334 0.03660429 0.6723889 ], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 1.], shape=(4,), dtype=float32)
predicted label rank:[2 1 1 2]
mse:tf.Tensor(0.3097293, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/PRODUCER_CONSUMER_3_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 1 1 1
 2 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 2 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 2]
predicted label:tf.Tensor(
[6.13971293e-01 4.75539565e-02 4.45132792e-01 7.44233787e-01
 4.56205457e-01 1.64807111e-01 2.78639972e-01 2.90969014e-03
 6.18650229e-05 1.00000000e+00 9.93517220e-01 2.27550045e-09
 0.00000000e+00 1.10464782e-01 8.96348967e-14 2.25290656e-02
 5.33608198e-02 2.48616934e-03 2.34094262e-03 4.97497048e-08
 1.77511573e-03 8.02465462e-13 1.55564539e-08 6.08772039e-04
 2.41670523e-06 2.14228034e-03 5.96782148e-01 8.26551020e-02
 7.50580132e-02 2.22863555e-02 6.88200295e-02 5.81144691e-02
 4.92863357e-02 2.30470896e-02 3.27012241e-01 2.03326941e-02
 1.43598372e-05 5.30985296e-02 5.84445298e-02 8.19244981e-02
 1.40696764e-04 7.56880641e-03 3.69697809e-04 5.44348359e-03
 1.10972941e-01 1.10968381e-01 1.52659744e-01 9.96379554e-02
 1.74915195e-02 9.32137072e-02 9.02500212e-01 2.96264887e-04
 1.32766634e-01 1.39653683e-01 1.38572633e-01 1.69968009e-01
 4.04754281e-03 7.95336068e-01 8.58877063e-01 3.65682542e-01
 4.00798947e-01 3.81776690e-03 1.69239670e-01 3.08395922e-01
 2.93179274e-01 4.52853441e-02 2.99705356e-01 1.49915397e-01
 6.92060590e-02 3.59398425e-02 1.13756955e-02 6.23752475e-02
 7.04616308e-04 3.97239327e-02 1.95736289e-02 3.58534753e-02
 2.38239765e-03 4.60901260e-02 1.12557411e-03 7.86108613e-01
 8.41403365e-01 4.78221178e-02 7.89968669e-02 5.95688820e-03
 3.49367857e-02 2.18906999e-02 1.45310163e-02 9.67130065e-03
 1.15605503e-01 4.28193808e-03 6.10173047e-02 1.37112588e-01
 3.27714980e-02 1.74627632e-01 2.07617283e-02 4.89385128e-02
 6.73825443e-02 5.53458035e-02 9.70256329e-03 1.03662699e-01
 8.45316052e-03 1.73379987e-01 4.80661839e-01 4.92621303e-01
 2.07895160e-01 9.98839140e-01 9.95573699e-01 9.52929437e-01
 9.65161681e-01 7.46958494e-01 9.28570509e-01 2.14668810e-02
 7.56093204e-01 1.22671723e-02 1.05500460e-01 4.27327693e-01
 1.21071041e-02 4.12464142e-04 6.04540050e-01 1.00248158e-02
 6.15960836e-01 5.49156606e-01 1.84352100e-02 2.16361284e-02
 4.29075360e-02 1.59596205e-02 2.50151753e-02 1.31624639e-02
 1.27035677e-02 2.09431648e-02 3.02137315e-01 1.93959475e-03
 1.28684461e-01 2.98091441e-01 9.76702571e-01 1.81468070e-01
 2.19688326e-01 1.95317119e-01 2.33805329e-01 1.29999191e-01
 1.68327302e-01 2.76656896e-01 2.42746264e-01 1.84631288e-01
 8.94350111e-01 4.06172872e-03 3.39827687e-01 1.74283981e-04
 3.37421894e-04 9.62894559e-01 9.97697234e-01 8.85968804e-01
 9.50611353e-01 8.65401983e-01 7.75314450e-01 7.52986491e-01
 8.64497423e-01 9.63724017e-01 7.46852219e-01 9.81408119e-01
 9.43257093e-01 8.47110748e-01 7.27770627e-01 3.12149465e-01
 9.97034431e-01 9.99233365e-01 7.83482552e-01 9.97124553e-01
 1.27049600e-06 2.29912996e-03 1.60372376e-01 1.84423327e-02
 2.27063894e-04 8.14233124e-02 9.61622596e-03 4.06742096e-04
 8.88109207e-04 1.58687294e-01 2.26984918e-02 2.19016373e-01
 1.71262026e-03 2.35977769e-03 2.51996815e-02 1.99300051e-03
 5.38499594e-01 1.51455402e-04 5.64384460e-03 3.06484103e-03
 1.04156137e-02 8.20311904e-03], shape=(190,), dtype=float32)
rounded label:tf.Tensor(
[1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], shape=(190,), dtype=float32)
predicted label rank:[2 1 1 2 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2
 1 2 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1
 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 1 1 1 1 1]
mse:tf.Tensor(0.20579796, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/bandec.smt2-0036_000.smt2
true label:[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
true label rank:[1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2]
predicted label:tf.Tensor(
[0.7188733  0.10178405 0.03985664 0.21329695 0.05614775 0.02193823
 0.01129177 0.0524784  0.00762945 0.01083824 0.03724036 0.00835669
 0.05020356 0.01000059 0.3362593  0.35379913 0.34346664 0.00076485
 0.00104028 0.00085345 0.00251547 0.06541601 0.00305468 0.10107428
 0.01951554 0.0171909  0.19448295], shape=(27,), dtype=float32)
rounded label:tf.Tensor(
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0.], shape=(27,), dtype=float32)
predicted label rank:[2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.122269526, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0140_000.smt2
true label:[1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1]
true label rank:[2 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2
 1 1 2 2 1 1 2 2 2 1 1 1 2 1 1 1 2]
predicted label:tf.Tensor(
[0.49296907 0.0030472  0.00135344 0.00351757 0.00591546 0.02513739
 0.03489763 0.00463003 0.1351276  0.29466718 0.25725785 0.05087355
 0.21765769 0.4105693  0.21246693 0.22512195 0.7384938  0.675044
 0.4139585  0.41716322 0.13171598 0.0450941  0.01615149 0.08994374
 0.02993807 0.09031838 0.451204   0.01895446 0.58763367 0.00376722
 0.06105807 0.02912584 0.68331146 0.6776915  0.09489658 0.79720867
 0.9388491  0.18278638 0.49564967 0.4083872  0.42159176 0.18799558
 0.9829686  0.93771434 0.552073   0.96012235 0.01238647 0.30456838
 0.28045708 0.26311743 0.8772345  0.41889122 0.00149983 0.49603018], shape=(54,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0.
 0. 0. 1. 0. 0. 0.], shape=(54,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 2 2
 1 1 1 1 1 2 2 2 2 1 1 1 1 2 1 1 1]
mse:tf.Tensor(0.17383525, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/bandec.smt2-0188_000.smt2
true label:[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]
true label rank:[1 1 1 1 1 1 2 1 1 1 1 1 2 1]
predicted label:tf.Tensor(
[7.9021579e-01 2.5110018e-01 1.9325584e-02 1.2183189e-03 1.6441345e-03
 5.0875163e-01 5.2728653e-03 1.3896823e-04 1.3900897e-01 1.5464175e-01
 8.5109472e-03 7.8821480e-03 2.7000344e-01 4.3546003e-01], shape=(14,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(14,), dtype=float32)
predicted label rank:[2 1 1 1 1 2 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.19300519, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0115_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]
true label rank:[2 2 2 2 2 2 2 1 2 2 2 2]
predicted label:tf.Tensor(
[0.9597643  0.9774576  0.9512016  1.         0.98523855 0.93695813
 0.92884946 0.5468191  0.9913651  0.8411086  0.6251274  0.50663936], shape=(12,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(12,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.060169112, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/nest-len.c_000.smt2
true label:[1, 1, 1, 1, 1, 1, 0, 1, 0]
true label rank:[2 2 2 2 2 2 1 2 1]
predicted label:tf.Tensor(
[0.99435854 0.99720216 0.9939146  1.         0.99931276 0.72461975
 0.8098205  0.50631684 0.9986006 ], shape=(9,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(9,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.219183, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/nest-if1.c_000.smt2
true label:[1, 1, 1, 1, 1, 0, 1, 0, 1]
true label rank:[2 2 2 2 2 1 2 1 2]
predicted label:tf.Tensor(
[0.97232276 0.9504279  0.989681   0.9999995  0.8080888  0.66920495
 0.64504886 0.6389593  0.81551087], shape=(9,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(9,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.11736563, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/bandec.smt2-0178_000.smt2
true label:[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
true label rank:[1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2]
predicted label:tf.Tensor(
[4.6635085e-01 1.4756176e-01 8.6818069e-02 3.2830644e-01 4.0144882e-01
 3.2054186e-03 1.3148785e-04 9.4341314e-01 2.0121634e-03 7.2196126e-04
 1.7461777e-03 7.0309639e-04 1.5179813e-03 6.4614415e-03 4.3037206e-02
 9.2021370e-01 4.3410063e-03 4.0361285e-04 1.9928813e-04 3.7440956e-03
 4.9971798e-01 3.2726169e-01 3.2862872e-02 1.0260099e-01 3.7669837e-03
 3.5583973e-04 3.0658841e-03 1.7208576e-02 3.1188905e-01 1.7027995e-01], shape=(30,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.], shape=(30,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.15352231, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0102_000.smt2
true label:[1, 1]
true label rank:[1 1]
predicted label:tf.Tensor([0.54449326 0.31850126], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 0.], shape=(2,), dtype=float32)
predicted label rank:[2 1]
mse:tf.Tensor(0.3359635, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/nested-while_merged_safe.c-1_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.66623276 0.99740314 0.5984876  0.9187583  0.9101578  0.99238604
 0.9873744  0.986017   0.99917316 0.9995508  0.6793921  0.73959696
 0.8708923  0.7801696  0.6307994  0.9743912  0.71858066 0.8168675
 0.9777529  0.98755103 0.9655831  0.6086602  0.11328727 0.5858011
 0.7878536 ], shape=(25,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.
 1.], shape=(25,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2]
mse:tf.Tensor(0.07723221, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/const_1-1.c-1_000.smt2
true label:[1, 1]
true label rank:[1 1]
predicted label:tf.Tensor([0.7590914  0.99997175], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.029018482, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/002-horn_000.smt2
true label:[1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1]
true label rank:[2 2 2 2 2 2 1 1 1 2 2 2]
predicted label:tf.Tensor(
[0.92882323 0.70639515 0.45755392 0.99994534 0.85403156 0.5294693
 0.9927235  0.8981073  0.9794904  0.6584988  0.99247026 0.35697842], shape=(12,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0.], shape=(12,), dtype=float32)
predicted label rank:[2 2 1 2 2 2 2 2 2 2 2 1]
mse:tf.Tensor(0.3258232, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0091_000.smt2
true label:[1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]
true label rank:[2 2 1 1 1 2 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1]
predicted label:tf.Tensor(
[0.9122297  0.976051   0.6769954  0.8829122  0.13141298 0.34986305
 0.51674247 0.4927576  0.98039085 0.70288265 0.5901585  0.718902
 0.70663637 0.5389112  0.48218858 0.03704393 0.83708835 0.32300064
 0.36360955 0.57077533 0.96547806 0.89274776 0.41616705], shape=(23,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0.], shape=(23,), dtype=float32)
predicted label rank:[2 2 2 2 1 1 2 1 2 2 2 2 2 2 1 1 2 1 1 2 2 2 1]
mse:tf.Tensor(0.4047521, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0278_000.smt2
true label:[0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1]
true label rank:[1 2 1 ... 2 1 2]
predicted label:tf.Tensor([0.07799852 0.00890988 0.00674158 ... 0.7978357  0.8640437  0.01756057], shape=(1042,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. ... 1. 1. 0.], shape=(1042,), dtype=float32)
predicted label rank:[1 1 1 ... 2 2 1]
mse:tf.Tensor(0.58109605, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/SYNAPSE_5_e2_1525_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 2 2 1 1 1 1 1 1 2 1 2 1 2
 2 2 2 1 1 1 2 1 1 1 1 2 2 1 2 2 1 1 2 2 2 2 2 1 1 1 2 1 2 2 1 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2
 1 2 2 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 2 2 2 2 2 2 2
 1 1 1 1 1 1 1 2 1 1 2]
predicted label:tf.Tensor(
[7.50637054e-02 2.80088186e-03 4.44660783e-02 4.66996193e-01
 2.20326483e-02 4.12487984e-02 5.33834398e-02 3.63498926e-04
 6.86312675e-01 3.30848634e-01 1.37720406e-02 5.71310520e-03
 1.03294671e-01 2.26277143e-01 1.56906515e-01 1.00976616e-01
 8.20050836e-02 8.67205262e-02 6.47696853e-03 9.65714455e-04
 1.53187543e-01 2.56650173e-06 1.89014673e-02 2.59197593e-01
 8.10053349e-02 2.40960121e-02 5.43965995e-02 6.71118498e-03
 4.73777950e-02 9.30070877e-03 8.81073475e-02 4.36301231e-02
 5.69159985e-02 2.17152238e-02 3.71321440e-02 4.37740664e-06
 1.05814861e-05 5.90562820e-04 4.00450230e-02 1.31121308e-01
 1.70147717e-01 3.22458148e-03 4.56745625e-02 6.07626438e-02
 6.41479790e-02 4.86291051e-02 1.24099463e-01 4.25347984e-02
 2.67588496e-02 1.75672174e-02 9.60440389e-16 1.53060049e-01
 1.42604113e-03 1.00793507e-08 6.53606355e-02 2.05655624e-06
 8.10903907e-02 9.91655529e-01 3.46770585e-02 6.15865565e-06
 0.00000000e+00 1.00222899e-10 0.00000000e+00 1.42630370e-32
 3.53945971e-01 9.99999762e-01 3.31694305e-01 3.21412504e-01
 2.28762627e-04 1.55774087e-05 8.64060752e-08 9.96186018e-01
 2.52425671e-04 9.99679137e-17 5.08846581e-01 6.94849491e-01
 5.27553976e-01 2.08578676e-01 3.18591297e-01 0.00000000e+00
 3.54692876e-01 5.96447825e-01 5.79380035e-01 5.80272198e-01
 2.50803828e-02 4.13875192e-01 3.78139943e-01 2.86913633e-01
 5.67721665e-01 3.32703292e-01 4.32984561e-01 5.74929297e-01
 2.86027312e-01 5.33995390e-01 6.03269815e-01 4.38098013e-01
 1.26616657e-02 2.37955719e-01 4.20504004e-01 4.41055596e-01
 4.45524961e-01 2.51448452e-02 3.28257143e-01 3.39078635e-01
 3.21870118e-01 3.15005779e-01 4.07787085e-01 4.13962901e-01
 4.08628821e-01 2.06309706e-01 4.46089804e-01 1.00630730e-01
 4.42055404e-01 4.69543040e-02 9.94549334e-01 5.87876201e-01
 4.84504998e-01 5.00719607e-01 4.88379329e-01 5.48681974e-01
 4.60433125e-01 9.91337657e-01 4.47745025e-01 4.60354060e-01
 4.65197980e-01 5.12369692e-01 9.99992549e-01 9.98445272e-01
 9.69910383e-01 4.33599800e-01 4.73465323e-01 9.96372104e-01
 9.83270884e-01 4.49762553e-01 4.82217610e-01 4.31180298e-01
 7.73812056e-01 4.78739172e-01 1.05362475e-01 2.54954100e-02
 9.97464061e-01 9.56363440e-01 9.99517083e-01 6.63668811e-01
 8.48369122e-01 9.99682963e-01 9.38405752e-01 9.16831732e-01
 9.57511902e-01 9.72724378e-01 9.87649322e-01 6.96310639e-01
 7.64259040e-01 6.93517506e-01 6.67781234e-01 6.60996914e-01
 7.08526373e-01 9.90910649e-01 9.97325182e-01 7.92052269e-01
 8.50168228e-01 9.90418315e-01 9.95584249e-01 1.20261312e-03
 9.61888313e-01 4.81296033e-01 3.93774569e-01 5.68139911e-01
 4.57798153e-01 3.67471755e-01 3.55574399e-01 4.54642743e-01
 3.60144675e-01 5.47653913e-01 9.92862403e-01 1.47352338e-01
 6.19792044e-01 3.78395706e-01 7.29323924e-01 6.89567327e-01
 5.19940674e-01 9.87586856e-01 1.28931314e-01 2.59990156e-01
 2.82108814e-01 9.97529149e-01 6.77194774e-01 4.44376171e-02
 2.54162610e-01 7.50842392e-02 7.71155953e-03 3.44949961e-01
 3.02575707e-01 9.43498790e-01 9.99939561e-01 3.65257829e-01
 3.51782113e-01 5.30138493e-01 2.82324880e-01 2.68857956e-01
 8.34548831e-01 5.60393870e-01 5.78332901e-01 6.00118279e-01
 3.34850371e-01 3.21068168e-01 2.89480746e-01 3.59965146e-01
 3.13702554e-01 2.56715775e-01 6.74357059e-09 7.32964763e-05
 1.48560684e-06 6.64000094e-01 9.94843721e-01 6.87152982e-01
 7.99610138e-01 1.07127428e-03 9.94843185e-01 9.99998808e-01
 4.24292326e-01 9.93859649e-01 1.53125220e-05 7.63371587e-01
 9.98846769e-01 7.87253857e-01 6.77133918e-01 6.23282254e-01
 6.93396747e-01 1.25725269e-02 8.11874866e-04 3.35379422e-01
 4.90581572e-01], shape=(233,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1.
 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1.
 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.
 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.], shape=(233,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1
 2 2 2 1 1 1 1 2 2 2 1 1 1 1 2 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 2 1 2 1 2 1 2 1 1 1 2 2 2 2 1 1 2 2 1 1 1 2 1 1 1 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 1 2 1 1 1 1 1 2 2 1 2 1 2 2 2 2 1 1 1
 2 2 1 1 1 1 1 1 2 2 1 1 2 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 2 2 2 2 1 2 2 1 2
 1 2 2 2 2 2 2 1 1 1 1]
mse:tf.Tensor(0.23811746, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/bandec.smt2-0159_000.smt2
true label:[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[7.4180275e-01 6.4569849e-01 1.7988771e-02 5.2870452e-02 5.1014745e-01
 1.6202390e-02 2.9265881e-03 7.6521635e-02 6.7499906e-01 9.3175769e-03
 1.3213456e-03 9.2210531e-02 5.4205120e-02 3.2657474e-02 5.1132220e-01
 2.5242746e-02 1.9109547e-03 6.1288476e-04 4.6488586e-01 4.4601884e-01
 1.5126079e-02 2.2739410e-02 3.0383003e-01 1.7836118e-01], shape=(24,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(24,), dtype=float32)
predicted label rank:[2 2 1 1 2 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.08430511, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/car_4_e3_57_e4_1047_000.smt2
true label:[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2
 1 1 1 1 1 2 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[1.61909320e-05 2.73043156e-07 2.34436989e-03 9.99998808e-01
 0.00000000e+00 1.10390782e-03 4.47899103e-04 6.77204132e-03
 2.86361628e-05 2.88984179e-03 2.73248553e-03 2.11585029e-05
 1.49687025e-06 4.27650349e-07 1.74956828e-01 9.55884159e-02
 2.59701838e-09 7.59955645e-02 6.05813660e-24 6.88993805e-06
 1.37808919e-03 1.12334448e-07 1.15201397e-06 1.06260180e-03
 2.03281641e-04 2.80597806e-03 1.07628446e-04 6.65962994e-02
 0.00000000e+00 6.23613596e-04 3.75747681e-04 3.00935244e-05
 9.49597359e-03 2.67422839e-09 4.21010227e-05 1.13255918e-01
 8.28224472e-07 7.25001097e-04 5.62876463e-04 1.28713220e-01
 1.82735985e-05 1.71960562e-06 1.25508421e-07 9.34749246e-02
 7.02461302e-02 8.02176893e-02 1.08769417e-01 4.61730361e-02
 5.52666187e-02 3.41875255e-02 7.31869340e-02 2.11954117e-02
 1.53283775e-02 7.60111213e-02 7.47784674e-02 3.33657812e-09
 4.43971038e-01 9.10313006e-11 1.33203268e-01 8.14066523e-12
 8.27485565e-05 1.93615938e-06 8.87927413e-03 7.74423188e-06
 2.68823504e-02 1.74192786e-02 3.71843576e-04 5.84670079e-06
 3.33368778e-04 6.35725257e-07 9.23614716e-05 6.11901283e-04
 3.45129752e-06 1.04281074e-15 1.57375398e-05 1.34544666e-06
 8.99599433e-01 1.65194273e-04 1.43536681e-06 4.76474406e-06
 5.89428484e-01 5.46075046e-01 3.05563211e-04 3.91691923e-04
 2.70420313e-03 2.08011270e-03 4.64878613e-05 2.01225281e-04
 2.19349861e-02 1.64584217e-05 2.79238702e-05 6.91206753e-02
 5.63515823e-05 4.12483513e-02 8.57604464e-05 2.63911486e-03
 3.01049319e-08 6.60824776e-03 1.90082192e-03 1.04296207e-03
 7.58849206e-10 1.61856413e-04 1.12172114e-04 3.33838463e-02
 2.42484657e-05 1.39888436e-01 1.08701555e-04 7.95570910e-02
 8.61018598e-02 2.92613506e-02 9.28782225e-02 1.97409391e-02
 1.00799441e-01 2.11541951e-02 5.21130264e-02 2.17142105e-02
 1.59931779e-02 9.18501914e-02 8.54138732e-02 6.04505942e-07
 5.24335506e-11 3.56429469e-10 6.58625140e-05 3.84539334e-08
 1.28239393e-04 3.82065773e-04 2.62498856e-04 2.91667489e-11
 8.51115146e-06 2.74643662e-06 1.47528350e-02 8.72105360e-04
 2.68024206e-03 2.52902508e-04 6.73410296e-03 7.95570016e-03
 2.27433001e-23 1.80393457e-04 1.06484713e-05 5.33667207e-03
 9.95009542e-01 1.06225610e-02 7.22002983e-03 3.68943810e-03
 7.85648823e-03 1.86264515e-03 3.34578753e-03 8.36938620e-04
 9.46303308e-02 1.71507065e-06 4.36300297e-06 9.02971327e-02
 1.70086354e-01 1.24910861e-01 1.07233793e-01 9.16242599e-04
 3.87859344e-03 3.70144844e-04 1.92284584e-04 2.20978260e-03
 4.26396728e-03 7.32809007e-02 1.11261219e-01 3.09005060e-07
 2.99414023e-05 1.55410707e-01 8.37649405e-02 1.70154810e-01
 1.21323079e-01 8.28650594e-03 1.19149387e-02 9.25801694e-02
 7.13339448e-03 9.49165225e-03 3.80461216e-02 2.29039282e-01
 4.56154346e-04 5.06454706e-03 2.31919467e-01 2.38080740e-01
 2.54161954e-01 2.12285101e-01 5.32951951e-03 5.85907698e-03
 8.57499242e-03 1.16330385e-02 2.49696970e-02 1.75098181e-02
 6.22333288e-02 5.61783016e-02 7.21760784e-09 8.65184234e-07
 3.56699526e-02 2.49944329e-02 1.05888963e-01 6.60620630e-02
 4.86838818e-03 1.64733231e-02 1.53818727e-03 1.25259757e-02
 1.58932805e-03 1.48835778e-03 6.95107877e-02 1.46377952e-05
 2.74807215e-04 8.14575255e-02 1.25141174e-01 1.86011553e-01
 9.53725874e-02 3.59565020e-04 1.88052654e-04 5.17278910e-04
 1.91056728e-03 3.03854942e-02 1.30993128e-03 5.39636016e-02
 1.01139039e-01 1.38916820e-01 7.71102350e-06 3.46326828e-02
 1.09059513e-01 1.47745222e-01 7.59428740e-02 9.75310802e-04
 2.19216943e-03 3.18604708e-03 3.28050554e-02 1.78033113e-03
 1.25432312e-02 2.80348957e-01 1.45417452e-03 2.22593546e-04
 2.89360017e-01 1.52260989e-01 2.74343908e-01 2.59389371e-01
 9.79930162e-04 1.25524402e-03 2.83041596e-03 6.74545765e-03
 4.32789326e-03 2.46882439e-03 1.67204320e-01 1.78136379e-01
 3.90032528e-06 7.42322954e-05 1.11986428e-01 1.40920222e-01
 1.24744266e-01 1.55033976e-01 1.59676347e-07 2.31769681e-03
 4.20432480e-05 7.93920335e-05 8.78407591e-05 2.66671181e-04
 6.32870965e-08 1.91865504e-01 2.69930184e-01 2.52716213e-01
 1.87192291e-01 5.42994272e-08 1.10405266e-01 6.20707572e-01
 1.98239177e-01 1.88187957e-01 5.50140794e-05 1.51835382e-02
 6.65128231e-04 4.02241945e-04 8.70346308e-01 9.63595688e-01
 9.53799605e-01 5.69908023e-01 6.66921258e-01 6.01305366e-01
 3.98338139e-02 1.15627646e-02 5.75062633e-03 1.30402744e-02
 4.42957878e-03 2.74848938e-03 1.98426843e-03 3.30372453e-02
 6.63362145e-02 3.48231196e-02 7.81224072e-02 7.52938271e-01
 1.04207993e-01 6.93304539e-02 4.00831401e-02 5.10282516e-02
 2.74161696e-02 7.22177625e-02 1.03727132e-01 1.01946265e-01
 2.05644965e-03 9.40128157e-05 6.92188740e-04 1.14325285e-02
 1.60074025e-01 1.96005672e-01 1.25529319e-01 1.97314650e-01
 2.65952945e-03 9.57221091e-02 5.72681427e-03 9.05242860e-02
 1.07919216e-01 1.92482769e-01 7.78851518e-06 1.19421043e-06
 4.09650653e-07 3.64925891e-01 1.64395571e-03 7.12752342e-04
 1.66042519e-05 7.73081592e-06 2.33173370e-04 7.51435757e-04
 5.39124012e-04 1.87939405e-03 5.98821462e-05 7.23871589e-03
 3.12119722e-04 6.38991594e-04 1.57564878e-04 2.18510628e-04
 7.03185797e-04 4.58222628e-03], shape=(330,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(330,), dtype=float32)
predicted label rank:[1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.0435634, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/spline-fixed.smt2-0008_000.smt2
true label:[0, 1]
true label rank:[1 2]
predicted label:tf.Tensor([0.06467709 0.01965368], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 0.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.482631, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/minepump_spec4_product57_true-unreach-call.cil.c.flat_000.smt2
true label:[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1]
true label rank:[1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 1 2 2 1 2 2 2 2
 2 2 2 2 2 1 1 2 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 2]
predicted label:tf.Tensor(
[2.8274554e-01 8.5157609e-01 7.9772305e-01 6.7938137e-01 5.0555503e-01
 1.5918839e-01 5.9773785e-01 5.4593480e-01 7.5332820e-02 1.1337638e-02
 8.0115807e-01 1.0006905e-04 9.6315265e-02 6.4280689e-02 3.1181663e-01
 7.8232110e-02 3.5920143e-03 9.2257673e-01 6.4658523e-03 2.4171235e-05
 3.5624015e-01 3.3429632e-01 7.7612621e-01 5.3253472e-02 1.2495905e-02
 1.9306049e-01 5.8446616e-02 1.9061667e-01 5.8966470e-01 5.6248075e-01
 2.4225473e-02 2.4727118e-01 9.9473298e-01 5.4224354e-01 5.7682008e-01
 3.2890266e-01 4.9766314e-08 4.2735875e-01 1.6498655e-02 3.6594692e-01
 2.0276471e-07 8.9436769e-04 2.6108169e-06 5.6930739e-01 4.4810888e-01
 7.8356946e-01 3.1050615e-08 6.5311903e-01 5.5806363e-01 2.9465884e-02
 5.3523183e-02 4.2944688e-01 4.4764018e-01 2.2001885e-05 7.5117052e-03
 9.7178474e-07 9.4621027e-01 9.9155700e-01 2.3345068e-01 9.6472836e-01
 2.9926682e-01], shape=(61,), dtype=float32)
rounded label:tf.Tensor(
[0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1.
 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0.], shape=(61,), dtype=float32)
predicted label rank:[1 2 2 2 2 1 2 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 2 2 1 1 2 2 2 1 1
 1 1 1 1 1 1 2 1 2 1 2 2 1 1 1 1 1 1 1 2 2 1 2 1]
mse:tf.Tensor(0.40788567, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/FIREFLY_8_e2_1711_e2_2673_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 1 1 1 1 2 1 2 2 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 2 2 1 2 1 1 1 1 1 2 1 1 1
 2 2 1 1 2 1 2 1 2 2 2 1 2 1 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1
 2 2 1 1 2 1 1 2 1 2 1 2 2 1 1 1 2 2 1 2 1 1 2 1 1 2 2 1 1 1 2 2 1 2 1 1 2
 1 2 2 1 1 1 1 2 2 1 1 1 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 1 2 2 1 1 1 2 1 2 1
 2 1 1 2 1 1 1 2 2 1 1 1 2 2 1 1 1 2 1 2 1 2 1 1 1 1 2 1 1 1 2 2 1 1 1 2 2
 1 1 1 2 1 2 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 2 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1
 1 1 2 1 1 1 2 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 1 1 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 2 1 2 1 1 2 2 1 1 1
 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 1 2 1 1 1 1 2 2 1 1
 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1
 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 2 2 2 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 2 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 2 1 1 1 1 1 1 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[3.33231688e-03 2.45121121e-03 6.73860312e-04 4.85002995e-03
 7.31338143e-01 8.46832991e-04 2.49773264e-04 1.71264601e-05
 3.31170886e-05 2.40999962e-05 4.81879711e-03 1.93074584e-06
 1.09836459e-03 1.13886595e-03 1.18330121e-03 6.97940588e-04
 6.34998083e-04 5.29259443e-04 6.18487597e-04 1.96782112e-05
 2.68399715e-04 2.20745802e-04 2.25514174e-04 4.99829650e-03
 1.16387010e-03 3.88172269e-03 3.08993459e-03 2.57256627e-03
 7.12311268e-03 4.90367413e-04 7.72684813e-03 6.28298521e-03
 7.32088089e-03 9.91672277e-04 2.08994746e-03 2.54583359e-03
 4.75361943e-03 6.62171841e-03 7.40647316e-04 1.29480660e-02
 1.64344907e-03 7.46876001e-04 9.55760479e-04 2.60183215e-03
 1.76575780e-03 1.39394442e-05 5.53150356e-01 3.00478935e-03
 3.15491121e-07 7.47919083e-04 3.43796611e-03 1.26171411e-08
 5.56209670e-05 6.81094461e-05 1.24025345e-03 3.21584940e-03
 3.61597538e-03 4.73317504e-03 5.39144874e-03 7.54836202e-03
 3.22152804e-10 6.14523888e-04 8.10689653e-06 2.25132704e-03
 1.99478865e-03 1.10870600e-03 2.73593474e-12 1.54768331e-09
 3.15397978e-03 1.19748712e-03 6.57767057e-04 3.38974595e-03
 1.74453855e-03 2.06571817e-03 3.37123902e-06 1.21992826e-03
 2.16299295e-03 1.67152286e-03 1.94016099e-03 8.61078501e-04
 1.93057731e-05 1.02773309e-03 1.67804956e-03 1.06495619e-03
 1.19128823e-03 1.15013123e-03 9.06795263e-04 1.01920962e-03
 2.72914767e-03 2.46703625e-04 5.48839569e-04 3.28445435e-03
 8.02138448e-03 1.09933317e-02 2.39223242e-04 4.49097391e-11
 4.50153254e-14 3.91452387e-13 2.19106674e-03 2.71597505e-03
 2.87860632e-03 1.81475282e-03 1.40163302e-03 1.33290887e-03
 1.24824047e-03 1.00767612e-03 2.05001235e-03 2.69821286e-03
 1.22418404e-02 7.86176324e-03 1.78664923e-04 6.54906034e-04
 1.41939950e-06 3.19382846e-02 1.97530389e-01 7.99780786e-02
 9.39698815e-02 1.01095354e-09 1.20673597e-01 5.92771173e-03
 6.94468617e-03 2.48420238e-03 9.09876823e-03 8.66075061e-05
 1.95917189e-02 7.22020864e-04 2.54666156e-05 9.28303599e-03
 6.03461266e-03 8.29714537e-03 1.19201839e-02 3.94528508e-02
 1.88654661e-03 1.06086135e-02 4.58353758e-03 4.80523705e-03
 5.42011857e-03 4.70522046e-03 6.43518567e-03 1.98826194e-03
 4.26468253e-03 3.58366966e-03 6.15760684e-03 4.38275933e-03
 5.31762838e-03 1.72838569e-02 1.41217113e-02 2.12163329e-02
 1.03754515e-04 6.19982393e-06 3.39507759e-02 1.23317339e-04
 3.00943851e-04 1.54729987e-05 4.16815281e-04 1.26421452e-04
 1.26272440e-04 1.82631865e-08 1.01930499e-02 1.73878074e-02
 2.21873522e-02 1.15578175e-02 1.55597925e-04 2.59497464e-02
 7.00458168e-06 9.49862533e-06 1.07390583e-02 1.93678141e-02
 1.82034671e-02 1.18232369e-02 6.83268905e-03 1.26145482e-02
 2.76484191e-02 3.20119858e-02 4.16471064e-02 3.15969288e-02
 2.97595263e-02 6.76664710e-03 3.53425741e-02 1.89080834e-02
 3.08067799e-02 3.77534628e-02 3.04213762e-02 1.77587867e-02
 1.49487853e-02 2.33949721e-02 1.87374055e-02 9.13693034e-18
 5.50429344e-01 1.17873549e-02 1.82323456e-02 2.05491185e-02
 1.90244317e-02 3.95683706e-01 1.92264270e-06 4.76182103e-01
 3.75999361e-01 2.66878009e-02 3.39258969e-01 2.64796615e-03
 2.07580626e-02 8.71598721e-03 1.73134804e-02 3.06394398e-02
 1.75986588e-02 1.39866471e-02 3.10096145e-02 2.63777673e-02
 2.19512880e-02 1.23082101e-02 6.93374872e-03 1.90621614e-03
 1.53832436e-02 4.51569259e-02 3.38054001e-02 2.01821327e-02
 2.33186483e-02 2.83288956e-03 8.36856971e-19 3.84292006e-03
 1.68745220e-02 5.63321412e-02 1.04796648e-01 2.78979540e-04
 5.72028875e-06 2.14557439e-01 5.51940560e-01 1.89001262e-02
 2.29712129e-02 1.62672400e-02 1.89426541e-02 2.29290724e-02
 1.08662323e-18 8.42288136e-03 3.34024429e-04 4.36664820e-02
 3.21979802e-16 1.31881638e-20 2.11245497e-05 1.06201768e-02
 7.89437049e-09 1.75451106e-24 7.28264695e-06 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 1.49448389e-19 2.62046197e-33
 0.00000000e+00 2.15515524e-01 1.00000000e+00 1.43792584e-14
 6.57404482e-01 2.69842148e-03 0.00000000e+00 7.79480615e-05
 2.19613314e-04 1.73504196e-14 2.39020586e-03 1.66484714e-03
 0.00000000e+00 0.00000000e+00 4.96259332e-03 3.94916534e-03
 8.15668702e-03 4.41506505e-03 1.27163529e-02 2.74100900e-03
 1.34931505e-02 2.75465846e-03 3.14247608e-03 3.13585997e-03
 8.23456049e-03 6.58395886e-03 2.67663598e-03 3.98436189e-03
 6.83003664e-03 0.00000000e+00 4.54783440e-04 0.00000000e+00
 2.78866291e-03 2.00352073e-03 0.00000000e+00 6.48719072e-03
 2.91617355e-19 8.15302134e-04 4.87017632e-03 4.93526459e-04
 6.64862990e-03 9.70125198e-04 4.23772519e-08 2.33116746e-03
 2.91189551e-03 5.69641590e-04 5.14671206e-03 1.18493736e-02
 2.83542275e-02 3.62422475e-06 2.28546858e-02 2.59563625e-02
 9.07877088e-03 3.05006802e-02 2.55382061e-02 1.56154037e-02
 1.24245882e-04 6.96172118e-02 1.32982135e-02 1.50295794e-02
 5.04425168e-03 1.18523021e-04 6.18255138e-03 9.29707289e-03
 1.68186128e-02 4.73610759e-02 4.28578258e-03 4.54283953e-02
 3.06913257e-03 3.24501991e-02 6.48665428e-03 6.43930435e-02
 5.31710139e-05 2.72483230e-02 2.31617689e-03 2.96413898e-04
 7.02163577e-03 1.13650382e-01 1.15749538e-02 3.97756696e-03
 3.69656980e-02 5.13897061e-01 4.97319698e-02 4.60567474e-02
 4.45247423e-07 4.74424362e-02 1.51385158e-01 4.49956656e-02
 5.36965728e-02 5.76975942e-02 1.89503938e-01 1.36259943e-01
 8.73078406e-02 4.91915345e-02 9.43758488e-02 5.28897345e-02
 1.93627566e-01 1.05616242e-01 1.10066772e-07 8.71844888e-02
 8.01930726e-02 9.38214362e-02 3.06603909e-02 3.20103765e-03
 4.20245171e-01 7.67726600e-02 1.27642691e-01 1.55717999e-01
 1.54071510e-01 1.48908694e-05 7.04564750e-02 1.22268796e-01
 1.00206375e-01 1.72188401e-01 1.55784190e-02 1.65012181e-02
 1.20301396e-01 2.65391171e-02 1.55144453e-01 1.80344075e-01
 5.54808974e-02 6.68806136e-02 9.07675624e-02 9.98673558e-01
 3.80992162e-07 9.49849486e-02 2.14246809e-02 1.63577809e-08
 6.02394342e-04 1.59919262e-04 7.86006451e-04 8.78861547e-03
 1.27694011e-02 8.60393047e-04 1.16945505e-02 7.35759735e-04
 2.24527419e-02 2.85515189e-03 1.57963037e-02 6.14763223e-07
 4.77540260e-19 5.68389893e-03 1.33433342e-02 1.79636478e-03
 1.12605423e-01 9.69961286e-03 1.27018034e-01 2.50097215e-02
 1.08299821e-18 3.02309394e-01 5.83220422e-02 3.37848961e-02
 1.03130937e-02 1.33991114e-06 3.48452330e-01 1.01661086e-02
 1.50717020e-01 1.01949036e-01 6.21144772e-02 4.35489416e-01
 1.33910716e-01 2.39751041e-02 9.52005386e-02 2.72806883e-02
 2.97834873e-02 2.79105306e-02 1.31726474e-01 2.04654008e-01
 1.49597824e-01 1.05529994e-01 1.09067887e-01 1.30112350e-01
 1.06239021e-02 2.62972713e-02 4.90933359e-02 2.53484845e-02
 9.05578732e-02 7.47793913e-03 1.03121608e-01 6.94528222e-02
 4.90524173e-02 2.38135517e-01 3.23612988e-01 1.41109526e-02
 2.30467021e-02 2.85929441e-02 1.14541650e-02 3.72344255e-03
 3.27295661e-02 2.20020115e-02 3.68953347e-02 4.36263978e-02
 6.69850707e-02 1.13581508e-01 9.36272144e-02 8.10009837e-02
 5.21595180e-02 6.49788678e-02 1.24524355e-01 1.87152922e-02
 7.34308660e-02 4.68100905e-02 4.16508913e-02 6.82044029e-02
 8.20253491e-02 7.94996447e-12 2.10620761e-01 1.89838499e-01
 2.10278004e-01 8.17721188e-02 1.03819758e-01 3.21084768e-01
 9.99557614e-01 3.75000297e-07 2.09908187e-02 2.33350396e-02
 1.39121026e-01 8.81362975e-01 2.68504918e-01 9.55976367e-01
 8.06646567e-05 3.75449657e-04 2.78800726e-04 3.34485558e-05
 1.33669376e-03 9.80595350e-01 3.01298559e-01 7.76407123e-03
 5.79527617e-01 6.32743359e-01 5.52207708e-01 5.35566866e-01
 5.45949638e-01 9.99998748e-01 1.70406640e-01 9.97689128e-01
 3.73901213e-29 2.07892179e-01 5.68134964e-01 8.34774017e-01
 6.05354273e-08 9.99945045e-01 0.00000000e+00 6.24816835e-01
 1.76260829e-01 1.97877437e-01 1.47484541e-02 4.73543108e-02
 9.93498109e-31 8.68079066e-03 4.30657268e-02 5.78165054e-04
 2.98314973e-07 2.74583697e-03 9.58055854e-01 8.47820401e-01
 3.93397422e-05 9.26136971e-04 2.19523907e-04 9.23997164e-03
 1.28073353e-07 2.76480019e-02 1.04695261e-02 2.86158919e-03
 2.93630362e-03 8.43374210e-07 9.96942043e-01 7.41931915e-01
 2.81201005e-02 8.65515471e-02 9.92861152e-01 1.81182951e-01
 3.23537618e-01 3.40184927e-01 8.37627886e-05 5.81896305e-03
 4.38537281e-05 2.78912902e-01 3.10570240e-01 6.26760423e-02
 1.49029493e-03 6.60508871e-04 9.97460723e-01 9.85473633e-01
 1.55584455e-01 4.89809632e-01 1.56453507e-06 3.74262643e-12
 9.99565542e-01 8.16881657e-04 5.20186418e-08 9.82372880e-01
 9.84743118e-01 4.82513368e-01 1.15660250e-01 6.68668151e-02
 5.20594776e-01 3.31900626e-01 7.47560859e-02 9.99999762e-01
 9.40123465e-11 5.86389210e-16 9.99995887e-01 1.45562653e-12
 9.99745488e-01 7.55432487e-01 6.16132319e-02 5.12510538e-04
 2.21277623e-05 3.53306532e-03 2.27479488e-01 4.55054402e-01
 2.65740454e-02 4.87239957e-02 1.74195707e-01 2.21453249e-01
 4.88027632e-02 7.47445226e-03 9.81475830e-01 3.96162271e-03
 3.57087851e-01 6.69206083e-02 1.46683484e-01 5.98425746e-01
 2.94066370e-02 9.99405026e-01 2.75385678e-02 1.85209513e-02
 9.05647874e-03 8.35785270e-03 1.50707066e-02 1.76286995e-01
 5.28528094e-01 1.82875037e-01 3.85132134e-02 1.40775532e-01
 4.72749382e-01 2.02113390e-03 9.98194814e-01 2.63780951e-02
 2.96289682e-01 1.27773166e-01 1.03897512e-01 9.00531530e-01
 1.19057745e-01 2.21485341e-09 5.43768108e-01 7.88617909e-01
 4.60389078e-01 3.60799015e-01 2.00717032e-01 2.08738923e-01
 4.23068970e-01 9.99969721e-01 1.12452144e-05 4.61328673e-05
 7.19676430e-10 9.99165237e-01 4.45373058e-01 5.21709859e-01
 1.51824653e-02 5.33558667e-01 2.72766292e-01 9.69231427e-02
 1.39600271e-14 1.58477693e-11 5.64203262e-01 1.10496283e-02
 3.24315637e-01 9.34487879e-02 9.97002602e-01 7.56044984e-01
 1.15067780e-01 1.90022588e-03 6.33642375e-02 3.26287210e-01
 5.36455750e-01 2.76082158e-02 4.04840171e-01 1.15190148e-02
 4.59729016e-01 4.40949202e-02 3.59901369e-01 1.55877411e-01
 5.28558314e-01 7.28124380e-02 3.80053580e-01 3.90180945e-01
 1.81790056e-05 6.28230512e-01 1.17660373e-01 7.01396108e-01
 1.00000000e+00 3.32310498e-01 2.70850122e-01 9.26302671e-02
 2.27562547e-01 9.34985161e-01 2.43870080e-01 4.19304967e-01
 4.49547768e-01 1.93674326e-01 3.68969411e-01 1.00888214e-14
 3.00682664e-01 8.60836804e-02 4.44070995e-01 1.97865039e-01
 7.35404677e-15 4.16588873e-01 1.37218535e-02 2.22091913e-01
 1.21296346e-02 1.55781932e-11 1.77280009e-01 3.49896073e-01
 4.95471150e-01 2.28852272e-01 2.90174903e-05 5.01999712e-05
 8.67875934e-01 1.31191442e-07 5.10325833e-07 1.20130181e-03
 9.74211872e-01 9.80504751e-01 9.76479173e-01 9.78563786e-01
 9.70304370e-01 5.06798327e-01 5.61649561e-01 9.71113861e-01
 9.39893544e-01 9.34183359e-01 9.35786009e-01 9.59934115e-01
 6.72221959e-01 9.98967528e-01 9.99989510e-01 9.97562349e-01
 9.89192486e-01 9.80841398e-01 9.90039229e-01 9.99420524e-01
 9.61065173e-01 9.63211894e-01 9.48744416e-01 9.96580243e-01
 9.88234282e-01 9.58640456e-01 9.99661922e-01 9.99395370e-01
 6.60852194e-02 1.65852904e-03 9.97169256e-01 9.98130322e-01
 9.87977147e-01 6.85460150e-01 9.98727560e-01 9.97981548e-01
 6.23349726e-01 5.87215361e-08 6.98903823e-05 4.91479874e-01
 5.31574464e-08 6.27565384e-03 5.32935829e-08 5.61341405e-01
 5.18925190e-02 5.58822036e-01 3.88263199e-09 9.32200976e-07
 5.57557404e-01 3.67746621e-01 4.07636702e-01 4.37800556e-01
 1.06104136e-01 5.92798889e-02 4.03994262e-01 2.29721844e-01
 4.41739351e-01 2.01253295e-02 1.51771307e-03 3.69616210e-01
 9.99675035e-01 1.06439471e-01 9.71350670e-02 5.63573241e-02
 4.49096842e-06 1.77568793e-02 1.35675073e-02 9.45270061e-04
 4.27688032e-01 4.03683259e-07 1.69394856e-21 3.39168693e-10
 3.78417951e-16 6.84269863e-10 3.29831948e-07 1.38246943e-08
 2.24985838e-01 1.35911554e-01 3.10227036e-01 2.55223632e-01
 2.42500544e-01 3.23281944e-01 1.95741653e-04 3.41206789e-04
 3.15298915e-01 1.91341639e-02 4.27947640e-02 5.55634141e-01
 2.86743641e-01 2.11757720e-02 5.13289273e-01 1.51610970e-02
 3.85571152e-01 1.94180548e-01 5.11923432e-03 7.28230305e-07
 1.33603811e-04 6.35181069e-01 5.66551805e-01 3.31344604e-02
 1.70029998e-02 3.97862822e-01 8.03764760e-02 4.77919400e-01
 5.46777248e-02 2.38442153e-01 5.80209851e-01 9.82856000e-06
 1.68213631e-07 8.43136938e-09 1.12519172e-09 1.38303942e-15
 4.64193397e-12 8.52196592e-07 2.56081522e-02 2.13202834e-03
 1.93321705e-02 3.38745117e-03 1.77606940e-03 2.22960114e-03
 8.76247883e-04 4.43160534e-04 1.60050690e-02 1.59775317e-02
 1.43855214e-02 5.48005104e-04 1.03342533e-03 3.55167089e-07
 2.63037691e-07 5.30922115e-02 2.14880705e-03 9.92074609e-03
 5.03897369e-01 5.02440035e-01 5.04726887e-01 3.45686078e-03
 4.45058540e-05 6.59649741e-05 1.62285268e-02 1.03596911e-04
 1.01799576e-11 8.50146886e-09 1.88280940e-02 5.04222155e-01
 9.65946913e-03 1.41392052e-02 1.86560154e-02 1.80259347e-02
 3.08804691e-01 1.59095824e-02 4.81745005e-02 4.99795109e-01
 2.27538564e-07 1.59221369e-09 3.95950994e-10 5.19258833e-07
 2.36209686e-24 1.90740913e-12 7.10720371e-08 2.61571109e-02
 1.83416605e-02 9.92095470e-03 4.03915644e-02 1.47342682e-04
 1.56521797e-04 1.24216080e-04 8.37355852e-03 3.69966030e-04
 2.75641680e-04 1.32764280e-02 3.56584787e-04 1.78491175e-02
 2.66224146e-04 1.79821253e-03 3.26281786e-03 5.83070517e-03
 4.70159794e-05 9.98165250e-01 9.65466440e-01 8.28484058e-01
 8.79965782e-01 2.61157453e-02 7.27614606e-05 1.79499388e-03
 3.16483201e-05 7.97952533e-01 4.06652689e-03 3.92443762e-05
 5.55959344e-03 5.51429391e-03 6.51210189e-01 2.87926197e-03
 4.87112999e-03 9.63845313e-01 6.39468431e-04 4.30989676e-05
 1.05974523e-05 4.38643547e-05 8.66413116e-04 6.18427992e-04
 1.04442093e-04 9.87922613e-05 7.58782408e-05 7.43580604e-05
 7.93631189e-05 6.15593791e-03 4.77185845e-03 1.20867822e-04
 9.01467502e-05 1.36882067e-04 4.77740169e-03 2.48247385e-03
 4.97338176e-03 1.42991543e-04 9.51377879e-05 7.42282573e-05
 1.97499990e-03 2.89637701e-05 9.53912735e-04 1.64863467e-03
 6.96629286e-04 2.38809288e-02 9.97844696e-01 9.74636436e-01
 9.30263519e-01 2.26866603e-02 9.35251236e-01 2.11598873e-02
 1.41967237e-02 2.30455697e-02 9.02117193e-01 9.37164962e-01
 6.98804855e-04 5.83782792e-03 6.30745292e-03 8.38454366e-02
 2.65046358e-01 4.45421040e-02 1.41289830e-03 9.34123874e-01
 1.34956837e-03 2.11149454e-03 2.75850296e-04 6.84119463e-02
 1.78152323e-03 4.56903875e-02 1.86052918e-03 1.42726302e-03
 1.79967284e-03 1.68082118e-03 1.46645308e-03 5.41162491e-03
 5.67853451e-04 3.36319208e-04 1.35844946e-02 1.02961063e-03
 2.22790837e-02 1.77057683e-02 2.03774571e-02 4.94986773e-04
 2.08139718e-02 2.28442550e-02 1.25036836e-02 1.18609071e-02
 1.52132809e-02 1.32682972e-05 4.76839840e-02 1.39423082e-06
 3.78042459e-03 9.58523870e-01 9.62102890e-01 9.96478558e-01
 9.99993026e-01 1.00000000e+00 9.97934818e-01 2.04058324e-06
 4.36650325e-08 9.99788046e-01 2.21521311e-16 1.33031136e-07
 3.71460279e-10 2.13679671e-03 6.69695291e-05 1.93614169e-09
 8.71077776e-01 8.98114013e-05 1.20547374e-11 1.87767557e-09
 5.29944311e-09 5.41714867e-11 1.00722917e-13 1.77131092e-08
 8.70721124e-05 1.84512004e-07 9.69995426e-08 9.72839516e-08
 1.83795539e-08 4.53130689e-09 2.32125048e-11 2.61236491e-05
 5.81674612e-06 3.08598658e-07 2.53252172e-13 5.03941111e-10
 7.15241972e-12 6.34019398e-06 5.29166641e-07 2.38033479e-07
 1.67002509e-05 1.83588266e-03 1.41609025e-05 1.07559799e-06], shape=(988,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.
 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1.
 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0.], shape=(988,), dtype=float32)
predicted label rank:[1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 1 1 1 1 1 2 1 1 2
 2 2 2 2 2 1 2 1 1 2 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1
 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 2 1 1 2 2 1 1 1 2 1 1 2 1 1 2
 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 1 1 1 1 1 1 2 1 1 1 1 1 2 1
 1 1 1 2 1 1 2 2 1 1 1 1 1 2 1 1 1 2 1 2 1 2 1 1 1 1 2 1 1 1 2 2 1 1 1 1 2
 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 1 1 2 2 2 2 2 2 2 1 1 1 1 1 1 2 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 2 2 1 1
 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1
 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 2 2 2 1 1 1 1 2 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 2 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 2 1 1 1 1 1 1 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.044349976, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/02.c_000.smt2
true label:[1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]
true label rank:[2 1 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1]
predicted label:tf.Tensor(
[0.78874034 0.00721622 0.00283125 0.94062847 0.8018713  0.29635412
 0.39009428 0.0226889  0.26892847 0.18181616 0.62606347 0.1133537
 0.564455   0.29023093 0.28141934 0.56593364 0.06112576 0.67260355], shape=(18,), dtype=float32)
rounded label:tf.Tensor([1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1.], shape=(18,), dtype=float32)
predicted label rank:[2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 2 1 2]
mse:tf.Tensor(0.12152907, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/bandec.smt2-0260_000.smt2
true label:[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[7.4345446e-01 8.5448682e-01 3.9319754e-01 1.0307276e-01 1.1250231e-01
 5.0378734e-01 2.6199222e-04 2.4941564e-04 5.5335921e-01 5.5726868e-01
 8.4395753e-05 7.2990078e-01 3.6167639e-01 5.5766302e-01 1.0620683e-02
 5.6377649e-03 9.0113550e-02 2.2798586e-01], shape=(18,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0.], shape=(18,), dtype=float32)
predicted label rank:[2 2 1 1 1 2 1 1 2 2 1 2 1 2 1 1 1 1]
mse:tf.Tensor(0.15995559, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/svd-some-loop.c_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.99999404 0.9999908  0.99995506 1.         1.         0.9999575
 0.92559123 0.5616411  0.90941143 0.38221556 0.9799382  0.93032   ], shape=(12,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.], shape=(12,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 2 2 1 2 2]
mse:tf.Tensor(0.049401402, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/test_locks_10.c-1_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1
 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1
 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 2 2 2 2 2 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 1
 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2]
predicted label:tf.Tensor(
[3.6795288e-01 3.1641591e-01 2.8869629e-01 2.6903468e-01 2.8826016e-01
 3.7609738e-01 3.1696281e-01 2.6874048e-01 3.3259827e-01 3.9294529e-01
 3.6562359e-01 2.6862633e-01 3.2968116e-01 8.8441718e-01 2.8269187e-01
 4.9047726e-01 3.5464436e-02 1.2715608e-02 5.4075259e-01 5.6969738e-01
 5.7559061e-01 5.3288877e-01 4.9835831e-01 5.5157650e-01 5.4832298e-01
 5.2995622e-01 4.4791567e-01 7.3332119e-01 8.2184207e-01 8.6308134e-01
 8.9164269e-01 9.6469557e-01 6.0653454e-01 4.9066535e-01 6.6450256e-01
 7.6868701e-01 6.8139130e-01 7.3932350e-01 6.8244624e-01 9.5526886e-01
 9.3337333e-01 9.7322923e-01 6.9967228e-01 7.0637155e-01 6.7410314e-01
 7.2296411e-01 7.1675086e-01 7.0246780e-01 2.2211534e-01 1.5168616e-01
 2.7191341e-01 1.7095169e-01 9.5607817e-02 8.2564676e-01 8.4476566e-01
 4.0673026e-01 3.5163766e-01 2.8489333e-01 4.6722367e-01 4.4382927e-01
 2.6358646e-01 1.3894820e-01 1.2999591e-01 3.9455324e-02 3.0694902e-02
 2.4198025e-02 4.1462332e-02 3.9661258e-02 7.4827313e-02 7.3657244e-02
 3.1192005e-03 7.4206591e-03 5.3179264e-04 4.9334079e-02 3.1029135e-02
 2.4675816e-02 3.3246130e-02 9.2414916e-03 8.1986749e-01 2.5729898e-01
 1.9312054e-01 2.4338675e-01 2.7049437e-01 2.6649237e-01 2.6858348e-01
 2.2695127e-01 2.0135063e-01 2.1504387e-01 3.1238127e-01 2.0686892e-01
 2.1672553e-01 3.1848276e-01 2.0250499e-01 9.6746421e-01 6.8330806e-01
 9.6832758e-01 9.8979139e-01 1.8385231e-02 2.4442732e-02 3.5862267e-02
 3.7438929e-02 3.9982319e-02 2.5992125e-02 8.3597004e-03 9.5096231e-04
 4.2978227e-03 1.0862887e-02 2.8178871e-02 5.5031389e-02 2.9534101e-03
 6.7859830e-05 2.4911761e-04 2.3717135e-02 2.1012425e-03 8.4031224e-03
 1.2681574e-02 1.6216576e-02 1.9034237e-02 1.6345382e-02 1.0612756e-02
 2.8407297e-01 2.2212514e-01 3.0523589e-01 2.5237817e-01 3.6291271e-01
 2.6400861e-01 3.2614607e-01 3.0782178e-01 9.8556757e-02 5.3732395e-03
 5.6430352e-01 4.7116473e-01 1.8555510e-01 3.8913852e-01 1.1317411e-01
 1.2623411e-01 9.7966540e-01 2.6228321e-01 2.8182521e-01 1.6513571e-01
 1.9693154e-01 2.0789641e-01 3.1979370e-01 2.4637759e-01 3.1131157e-01
 4.0673026e-01 4.0702444e-01 1.9949186e-01 2.0758969e-01 7.8611493e-01
 1.8073022e-03 9.5744610e-01 3.1152380e-01 2.0206961e-01 2.4066585e-01
 1.7001325e-01 2.4526712e-01 4.2047983e-01 1.6300589e-01 4.7261992e-01
 2.7629358e-01 1.2226808e-01 1.6995770e-01 1.6890830e-01 2.5336914e-05
 1.3299791e-05 8.5668566e-05 6.1293031e-05 1.6424358e-03 9.7574186e-05
 3.6528707e-04 9.8019838e-04 1.7481148e-03 1.7815232e-03 6.5158606e-03
 2.4446845e-03 9.3997365e-01 9.9054790e-01 9.9903798e-01 6.1275053e-01
 7.1363258e-01 8.2804000e-01 5.5924416e-01 5.1208884e-01 6.6842109e-01
 6.3939017e-01 4.0983716e-01 5.9505635e-01 4.2493978e-01 3.9217049e-01
 6.1388010e-01 8.0750084e-01 8.4813750e-01 5.2602410e-01 6.7633557e-01
 2.7982634e-01 2.6387376e-01 3.3874857e-01 1.5397283e-01 1.3681594e-01
 2.3638001e-01 1.6977933e-01 8.0924839e-02 2.8924048e-03 9.7694719e-01
 1.7591465e-01 2.4513525e-01 9.1856372e-01 5.4498315e-03 9.6501374e-01
 1.3617402e-01 4.7650635e-02 1.6746223e-03 9.7074723e-01 8.3708131e-01
 1.2292385e-01 6.3368785e-01 5.3099096e-03 3.8798213e-02 7.6457775e-01
 2.2569120e-02 9.1197962e-01 1.0537195e-01 1.3651249e-01 2.6702374e-01], shape=(225,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1.
 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.
 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 0. 1. 0. 0. 0.], shape=(225,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2 1 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1
 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2
 2 1 2 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 1 1 2 2 1 2 1 1 2 1 2
 1 1 1]
mse:tf.Tensor(0.3478258, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/dillig01.c_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.92815536 0.8312522  0.9882209  0.99982184 0.99735093 0.99977934
 0.9787986  0.9906181 ], shape=(8,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1.], shape=(8,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.0042901034, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/s3_srvr_8.cil.c-1_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1
 1 1 1 2 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 1 1 1 1 2 2 1
 1 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1
 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1]
predicted label:tf.Tensor(
[3.36353183e-02 2.10342109e-02 1.40462816e-02 1.35251880e-03
 6.81936741e-04 2.76750624e-02 1.97822750e-02 1.13786161e-02
 2.75795460e-02 1.88476145e-02 5.73357165e-01 1.34079754e-02
 1.45041645e-02 4.09087539e-03 3.19057703e-02 1.24340057e-02
 6.21023774e-03 9.69442725e-03 1.60604715e-04 2.08681822e-03
 3.56885791e-03 8.98259878e-03 9.03904438e-04 9.77385819e-01
 1.13602161e-01 6.37842119e-02 5.25708515e-07 6.21231198e-02
 8.10955465e-02 3.11401486e-03 8.68348479e-02 1.75685873e-05
 7.48024285e-02 4.65314343e-10 7.75170326e-03 4.35457230e-02
 3.35413218e-03 7.90818930e-02 6.88974857e-02 9.37684476e-02
 9.23321843e-01 1.15651380e-12 1.50820086e-11 2.75435091e-11
 9.02491265e-16 1.41700403e-08 9.88983214e-01 2.13497877e-03
 1.00587010e-02 3.18813026e-02 3.83724868e-02 4.08903360e-02
 2.59554386e-03 4.19593453e-02 3.57403013e-21 1.56105220e-01
 1.45570338e-02 4.96044755e-02 7.66550004e-02 9.84286547e-01
 6.94492579e-01 2.20998287e-01 9.42371625e-10 6.35579526e-02
 4.17910814e-02 9.33468580e-01 2.57806604e-17 6.38943911e-03
 2.56070495e-03 1.40833855e-03 4.88822803e-23 4.23263490e-01
 3.26786220e-01 3.52827609e-01 2.92114943e-01 3.17274272e-01
 2.91008115e-01 2.61547863e-01 3.01306278e-01 3.26480269e-01
 2.01072097e-02 5.09920716e-03 8.08012486e-02 3.11967313e-01
 2.82634676e-01 2.46026844e-01 2.07649320e-01 2.26093173e-01
 3.57156575e-01 2.63643861e-02 5.44710755e-02 5.73972404e-01
 1.28228664e-02 6.50370896e-01 1.29938126e-04 4.18007374e-04
 9.50902700e-04 7.60988332e-05 9.76443291e-04 1.55603886e-03
 1.68269873e-03 1.35982037e-03 1.20186806e-03 6.69062138e-04
 9.75310802e-04 1.10333974e-06 1.50462383e-05 4.23401594e-04
 1.91590190e-03 2.94047489e-08 2.17402567e-06 8.05471209e-05
 3.28925252e-03 8.74150646e-05 2.59312446e-06 2.28311080e-07
 9.56496933e-07 8.79983819e-09 2.53299561e-07 3.74113023e-02
 4.58407998e-02 4.50272523e-07 6.39117360e-02 3.98762822e-02
 8.32575858e-02 1.38700008e-04 7.56231546e-02 4.38421965e-04
 2.90814936e-02 3.02672386e-04 5.86692691e-02 1.28158867e-01
 5.10240943e-06 6.08837306e-02 3.16597521e-02 4.14153636e-02
 2.50584781e-02 8.48811865e-03 8.55381010e-09 2.03019381e-03
 2.29701400e-03 7.71141052e-03 1.72162056e-03 2.16653645e-02
 2.42215991e-02 5.96655905e-02 6.43382370e-02 2.11222768e-02
 2.58392990e-02 4.21962440e-02 3.22908163e-03 5.71578741e-03
 6.38522506e-02 4.34371233e-02 2.16818750e-02 1.55596435e-02
 3.36681902e-02 4.08514738e-02 1.08228326e-02 8.58177543e-02
 6.12890720e-03 4.77790833e-04 3.09288502e-04 1.93476677e-04
 3.45796347e-04 2.44064867e-01 1.48578495e-01 2.60601163e-01
 2.05365270e-01 1.22977167e-01 8.33450854e-02 2.17248052e-01
 2.79368997e-01 2.88993120e-04 1.52736902e-04 2.28228271e-01
 2.55430102e-01 3.65718901e-02 2.56144881e-01 2.35855818e-01
 2.65565157e-01 9.99180317e-01 9.54052739e-05 5.25027514e-04
 2.21520662e-04 7.68840313e-04 2.13795900e-03 1.00249350e-01
 6.41823709e-02 5.63966930e-02 9.47090387e-02 9.26259458e-02
 9.36753154e-02 4.28721309e-02 7.31940567e-02 9.82949138e-02
 1.26541613e-06 2.52837981e-06 5.75644672e-02 7.95402229e-02
 1.52288973e-02 6.92101419e-02 7.89741576e-02 8.69841874e-02
 9.98860836e-01 2.35154562e-06 2.87264585e-04 1.87910439e-06
 5.74654791e-07 4.64665618e-06 4.52911854e-03 9.18787718e-03
 4.69103456e-03 1.26821101e-02 1.52947307e-02 6.11424446e-03
 1.44248605e-02 1.12122297e-03 8.63668323e-03 1.70491934e-02
 1.05353594e-02 2.80879736e-02 1.19665861e-02 1.87218189e-04
 3.09783220e-03 2.24927068e-03 6.15814328e-03 1.16629303e-02
 4.65860367e-02 3.63454223e-03 1.98206306e-03 1.66154504e-02
 1.54692829e-02 3.04242969e-03 1.28713250e-01 8.93141031e-02
 8.76775980e-02 1.26123935e-01 9.95905995e-02 1.09561771e-01
 9.13011730e-02 1.43994778e-01 1.01467967e-02 1.43285692e-02
 7.22506344e-02 1.58018559e-01 1.97474957e-02 2.79061405e-05
 8.81130695e-02 1.16530806e-01 6.47796988e-02 1.55528963e-01
 8.93470645e-03 2.03050077e-02 1.24359131e-03 6.89348578e-03
 3.63785028e-03 1.35921538e-02 1.74180567e-02 2.30087042e-02
 1.96782351e-02 1.08337104e-02 1.32289231e-02 2.29522288e-02
 1.18954480e-02 1.39684677e-02 3.06377709e-02 3.57776582e-02
 3.33507359e-02 3.33890319e-02 1.04050398e-01 1.32177472e-02
 4.85395789e-02 1.72975957e-02 1.59353018e-02 7.93465972e-03
 2.35245228e-02 1.12118721e-02 5.12129068e-03 1.45902038e-02
 1.70037150e-03 2.93132961e-02 2.03958154e-02 3.70847881e-02
 2.33315527e-02 2.51130462e-02 2.57639587e-02 9.75522697e-02
 2.31218451e-06 1.64370537e-02 2.19753981e-02 2.51576602e-02
 5.65825701e-02 2.84477770e-02 3.89861166e-02 3.20791602e-02
 3.07323933e-02 1.63998902e-02 8.34527314e-02 1.98432803e-03
 6.99618459e-03 2.97278166e-04 5.90947270e-03 2.31206417e-03
 9.74802375e-01 5.44512570e-02 7.82749772e-01 2.34839618e-01
 2.32500196e-01 2.43377686e-03 1.63733959e-04 1.82819575e-01
 4.74672973e-01 9.08139825e-01 8.95931721e-02 1.44964784e-01
 1.01200581e-01 9.50157762e-01 5.79986870e-02 1.25446320e-02
 1.42767429e-01 9.85693932e-01 5.12558222e-03 3.95956635e-03
 3.54087353e-03 9.61482525e-04 3.97520363e-02], shape=(327,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.], shape=(327,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 1 1 1 1 1]
mse:tf.Tensor(0.070215054, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0036_000.smt2
true label:[1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1]
predicted label:tf.Tensor([0.9710858  0.78709894 0.9965352  0.9853965  0.9080845  0.935447  ], shape=(6,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1.], shape=(6,), dtype=float32)
predicted label rank:[1 1 1 1 1 1]
mse:tf.Tensor(0.0098339515, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/cyclic.smt2-0007_000.smt2
true label:[1, 0]
true label rank:[2 1]
predicted label:tf.Tensor([0.80750346 0.7854973 ], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.32703045, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0031_000.smt2
true label:[1, 1, 0]
true label rank:[2 2 1]
predicted label:tf.Tensor([0.9838793  0.98236966 0.83568925], shape=(3,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)
predicted label rank:[1 1 1]
mse:tf.Tensor(0.23298241, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/minepump_spec5_product56_true-unreach-call.cil.c.flat_000.smt2
true label:[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
true label rank:[1 1 1 2 1 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 2 2 1 1 2 2 2 2
 1 1 2 2 1 1 1 1 1 2 1 2 2 2 2 2 1 2 1 1 1 1 1 1 2 2 1 2 2 2 2 2 2 1 1 2 2
 2 2 1 1 1 2 2 2 2 2 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1 2 2 2 2 2 2 2 1 1 1 2 2
 1 1 2 1 2 2 2 2 2 2 2 1 1 1 1 2 1 2 1 2 1 1 1 2 1 1 2 1 1 1 2 2 1 2 2 2 2
 2 2 2 1 1 1 2 1 1 2 2 2 1 2 2 2 2 2 2 2 2 2 1 1 1 2 2 2 1 2 1 1 2 2 2 1 1
 1 2 2 2 2 2 1 2 1 1 1 1 2 2 2 2 1 2 1 1 1 1 2 1 1 1 2 2 2 2 2 1 1 1 1 1 1
 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2]
predicted label:tf.Tensor(
[2.18975723e-01 3.68420839e-01 3.50712836e-02 5.48705876e-01
 7.91290820e-01 3.05680931e-01 6.73968196e-02 6.88192785e-01
 1.65259749e-01 8.83624971e-01 1.79181308e-01 3.38452160e-02
 3.29795778e-02 1.27731115e-01 5.33640623e-01 5.47397137e-03
 1.93176806e-01 1.95600569e-01 2.16928512e-01 8.04868460e-01
 2.32435882e-01 2.50218570e-01 8.81741464e-01 4.07848716e-01
 2.29012616e-35 1.47652239e-01 2.32815713e-01 7.60678530e-01
 9.32636857e-03 6.58710003e-01 9.93205190e-01 3.23429465e-01
 1.66451991e-01 1.52617693e-04 1.55297965e-01 1.08326972e-01
 1.73844218e-01 1.60020262e-01 2.16030478e-02 8.26660514e-01
 8.52354765e-02 1.12977833e-01 4.45538431e-01 1.86386585e-01
 1.28170520e-01 7.40617514e-02 1.25027448e-01 4.12832439e-01
 4.34654921e-01 4.26455706e-01 4.35914457e-01 4.44317311e-01
 4.33812916e-01 4.42179322e-01 1.73092484e-02 5.14443159e-01
 5.65171242e-01 4.91292983e-01 5.76798499e-01 5.56156278e-01
 5.24098098e-01 1.11657888e-01 2.61783987e-01 5.04530847e-01
 1.85265183e-01 5.10133266e-01 5.31026185e-01 4.86247748e-01
 5.08086026e-01 4.34254050e-01 3.11321020e-03 5.30161023e-01
 3.37973237e-03 6.02605879e-01 5.77368200e-01 8.05416524e-01
 5.68219721e-01 8.47860277e-02 1.29651845e-01 1.70854032e-01
 6.10813797e-02 1.55238092e-01 1.90165848e-01 1.58459425e-01
 7.84330070e-02 4.61751670e-01 2.61211395e-02 2.77059674e-02
 2.12917984e-01 8.76533687e-02 1.00923687e-01 9.93403554e-01
 4.36678410e-01 1.07852489e-01 9.03733015e-01 5.03302097e-01
 1.23714927e-09 1.25979185e-02 1.02502704e-02 4.04066831e-01
 3.98152500e-01 3.70174646e-04 2.21872389e-01 3.50339562e-01
 3.52801204e-01 3.18372667e-01 3.61863434e-01 4.15111482e-01
 4.13687855e-01 2.01446384e-01 4.45937753e-01 1.72231108e-01
 4.25592452e-01 5.54317772e-01 1.05606526e-01 5.14203131e-01
 5.07384062e-01 5.16415298e-01 5.12724280e-01 4.98174280e-01
 4.96407360e-01 4.37398612e-01 2.73516983e-01 5.04454970e-01
 3.80075842e-01 3.50816429e-01 9.91650343e-01 4.98778105e-01
 4.83990401e-01 1.66207552e-04 5.18003166e-01 5.21390438e-01
 4.75082308e-01 1.55451894e-02 9.77238655e-01 2.40814388e-01
 6.86946511e-03 4.12144899e-01 7.55652785e-03 2.27902383e-01
 3.46568018e-01 3.55536878e-01 4.47888285e-01 1.32083893e-04
 4.21410918e-01 5.17395437e-01 5.32242060e-01 4.06956643e-01
 4.54554796e-01 6.83646202e-01 5.15368581e-01 5.13225794e-04
 9.77092981e-03 1.08498365e-01 4.99170750e-01 3.60793650e-01
 5.12015283e-01 7.03804016e-01 4.48882580e-04 5.09535849e-01
 3.32997915e-05 7.56668866e-01 8.73446465e-04 3.74197960e-04
 8.20414722e-02 7.58375287e-01 9.66627300e-02 3.58998775e-04
 6.33013248e-03 8.50639663e-06 2.75245190e-01 3.68599653e-01
 3.75997871e-01 9.11405385e-01 3.98767799e-01 7.11880624e-02
 9.82696891e-01 7.30552793e-01 9.70291793e-01 7.10258305e-01
 4.44786966e-01 4.65801120e-01 2.61747539e-02 9.98946309e-01
 2.11682975e-01 3.47968400e-01 1.91151708e-01 9.93239045e-01
 2.00013787e-01 5.06967663e-05 2.28670686e-01 1.33902371e-01
 1.43400609e-01 1.06491834e-01 2.90212870e-01 7.49402046e-01
 7.75727689e-01 1.62979486e-05 9.82937217e-03 1.33748949e-02
 5.69033623e-03 2.53283679e-02 2.21477449e-02 3.48944366e-02
 2.70731747e-02 5.71726741e-06 1.59495248e-05 6.23499155e-02
 3.50413024e-02 1.22269988e-03 1.60813332e-04 1.89424445e-05
 8.41616988e-02 9.95937049e-01 9.83009219e-01 3.63729358e-01
 9.90598202e-01 1.95859641e-01 1.37513965e-01 6.91557527e-02
 1.59132332e-01 2.90388465e-01 4.10870612e-02 5.90026677e-01
 2.94339001e-01 5.90212703e-01 4.71953839e-01 2.59841442e-01
 3.40394497e-01 3.14944446e-01 3.31502855e-01 3.70965987e-01
 4.07882690e-01 2.67276764e-02 9.99999642e-01 5.34991801e-01
 9.98215079e-01 4.53979538e-08 1.98942289e-05 1.68703496e-02
 3.22616100e-03], shape=(241,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1.
 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 0.], shape=(241,), dtype=float32)
predicted label rank:[1 1 1 2 2 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 1 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1
 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 1 1 2 1 2 2 1 2 1 1 2 1 2
 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 1 2 2 2 2 1 1 1 1 2 1 1 2 1 1 1 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 2 2 1
 1 2 2 1 1 1 1 1 2 2 1 2 1 2 1 1 1 2 1 1 1 1 1 1 1 2 1 1 2 2 2 2 1 1 1 2 1
 1 1 2 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1
 1 2 1 2 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1]
mse:tf.Tensor(0.31055808, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/minepump_spec2_product64_true-unreach-call.cil.c.flat_000.smt2
true label:[0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]
true label rank:[1 1 1 2 2 1 1 1 2 2 1 2 2 2 2 1 2 2 1 1 2 2 1 2 2 2 1 1 2 2 2 1 1 2 2 2 2
 2 1 1 1 1 1 2 2 2 2 2 1 1 2 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1 2 1 1 1 2 1 2
 2 2 1 1 1 2 2 2 2 1 1 2 1 1 2 2 2 2 1 1 1 1 2 2 2 2 2 2 1 1 2 2 2 2 1 1 1
 1 1 2 2 2 2 2 2 2 2 1 1 2 2 1 1 1 1 2 2 2 2 2 1 2 2 2 2 2 1 1 1 2 2 1 1 2
 1 2 2 1 1 1 2 2 2 2 2 2 2 1 1 2 2 2 1 1 1 2 1 2 2 1 1 1 2 2 2 2 2 2 2 1 1
 2 1 1 2 1 1 2 1 2 2 2 1 1 1 1 2 2 2 2 2 2 2 2 1 1 2 1 1 1 2 1 2 2 2 1 1 1
 1 2 2 2 2 2 2 2 2 2 1 1 2 2 1 1 2 1 1 2 2 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2
 1 1 2 2 1 1 1 2 2 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 1 2 2 1 1 2 2 1 1 1 2 2
 2 2 2 2 2 2 2 2 2 1 2 2 1 1 1 2 2 1 1 2 2 1 1 1 1 2 2 2 2 1 1 1 2 1 2 2 2
 1 1 2 1 2 2 2 2 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 2 2 2 1 1 1 1 2 1 1 1 2 2 2
 1 1 2 1 2 2 2 2 1 1 1 1 1 2 2 2 2 2 2 1 1 2 2 1 1 2 2 2 2 1 1 1 1 1 2 2 2
 2 1 1 2 2 2 1 1 1 2 2 2 2 2 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 1 2 2 2 2 2 2 1
 1 2 1 1 1 1 1 2 2 2 1 1 1 1 2 2 2 2 2 2 2 1 1 2 1 1 1 1 1 1 2 2 2 2 2 2 2
 2 1 1 1 2 1 1 1 1 1 1 1 2 2 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 2 2 1 1 2 2 2 2
 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1
 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 2]
predicted label:tf.Tensor(
[9.42197442e-03 7.77218282e-01 2.20932222e-07 8.66730094e-01
 2.39148994e-06 8.94032121e-01 2.82767594e-01 2.59172916e-03
 2.56305337e-01 3.23185205e-01 2.74362832e-01 5.32159209e-03
 4.04793024e-03 4.00792211e-01 4.69472945e-01 7.29391038e-01
 3.45395356e-01 3.26403975e-01 6.00252688e-01 4.33208138e-01
 1.29169226e-02 2.88833559e-01 1.26988292e-01 5.69623351e-01
 5.69594324e-01 4.32354808e-01 5.23488879e-01 2.29326367e-01
 5.65604985e-01 3.76155108e-01 5.39525688e-01 5.31933188e-01
 5.80342114e-01 5.85081577e-02 1.13479793e-02 9.89282429e-01
 4.80215698e-01 5.09392798e-01 4.97175336e-01 4.83097792e-01
 5.05150437e-01 6.91616714e-01 5.67377746e-01 5.03161848e-01
 4.95474696e-01 7.97747135e-01 4.91702139e-01 5.43518901e-01
 4.90935624e-01 4.76206303e-01 4.86369997e-01 1.11248702e-01
 9.09388661e-01 5.32397211e-01 5.46628714e-01 5.56574523e-01
 5.81180334e-01 5.46650827e-01 9.58046496e-01 7.04753518e-01
 4.80020195e-01 4.73897606e-01 4.20363009e-01 5.61171651e-01
 5.58352590e-01 5.64887166e-01 5.74436665e-01 4.21725124e-01
 2.58513182e-01 4.43768889e-01 4.17367339e-01 6.54650152e-01
 3.83703858e-01 5.89231610e-01 8.69473398e-01 4.64449227e-01
 8.90928864e-01 7.69703329e-01 3.78573835e-01 5.39587021e-01
 3.76755327e-01 5.45342624e-01 5.59768379e-01 5.29196501e-01
 6.95911288e-01 8.39250684e-01 6.94752634e-02 9.88732338e-01
 4.35936749e-01 3.46045852e-01 3.68073761e-01 4.05056894e-01
 3.64086568e-01 3.93559039e-01 4.34060097e-01 3.81847143e-01
 9.05592799e-01 4.38304067e-01 4.07232523e-01 4.05295134e-01
 3.93202901e-01 3.92710090e-01 4.78251457e-01 4.76264179e-01
 3.62781465e-01 9.88273203e-01 4.41141784e-01 4.71207649e-01
 4.08780813e-01 4.18928266e-01 5.22506952e-01 4.08282161e-01
 9.11849380e-01 5.69161236e-01 4.55636740e-01 6.07792437e-01
 4.72812533e-01 4.80614930e-01 4.80559051e-01 4.79005069e-01
 4.58824277e-01 4.20077860e-01 4.66935635e-01 8.60869050e-01
 9.84716058e-01 5.62055588e-01 5.51704586e-01 9.95136857e-01
 8.60712409e-01 5.34629941e-01 7.66202092e-01 5.36715388e-01
 4.72881347e-01 3.72200668e-01 2.96872139e-01 4.91884321e-01
 5.74754000e-01 5.37876248e-01 5.48017859e-01 4.38234061e-01
 5.11919618e-01 5.10396898e-01 8.40899289e-01 5.72817445e-01
 4.72962916e-01 7.78335631e-02 9.86879706e-01 5.48277199e-01
 9.81210828e-01 7.32431650e-01 5.76665461e-01 6.00236773e-01
 7.85888132e-10 9.48208690e-01 9.64992642e-01 9.28136408e-01
 5.22844553e-01 7.61781931e-01 5.02572000e-01 8.19834173e-01
 6.72054768e-01 2.78165787e-01 4.45480764e-01 4.53812242e-01
 8.17184985e-01 4.80894536e-01 9.03982759e-01 6.50796235e-01
 4.36005205e-01 4.81262565e-01 4.71571058e-01 4.87108052e-01
 5.05452693e-01 5.17885268e-01 4.92022991e-01 4.95406032e-01
 5.43458998e-01 4.77870226e-01 5.06273270e-01 5.01639545e-01
 5.01361907e-01 5.13310611e-01 4.05501336e-01 3.92693996e-01
 4.28592533e-01 4.96081382e-01 4.80413526e-01 4.88297671e-01
 3.07589769e-04 9.99272406e-01 9.54230070e-01 3.23772430e-04
 3.06892753e-01 2.26485431e-01 3.26110125e-01 3.25430542e-01
 3.10071349e-01 3.46669734e-01 9.93469238e-01 2.80278921e-01
 3.30970854e-01 3.07901084e-01 2.67325461e-01 3.04911554e-01
 2.83377886e-01 2.73977757e-01 9.98148203e-01 3.59655738e-01
 2.88636148e-01 2.56654233e-01 3.62027287e-01 4.54593569e-01
 2.50928342e-01 8.94771218e-01 1.76072329e-01 9.02479410e-01
 4.94164795e-01 4.96681452e-01 4.92497444e-01 6.05768144e-01
 4.78425026e-01 5.10697484e-01 5.42890012e-01 6.50697887e-01
 5.61823666e-01 4.55119193e-01 4.56365973e-01 5.17179966e-01
 4.96048629e-01 3.97505403e-01 5.15899599e-01 5.98796368e-01
 4.86162961e-01 4.42063034e-01 1.04774833e-02 4.60675299e-01
 5.49153745e-01 5.41682243e-01 5.72272837e-02 3.45050693e-02
 5.21688938e-01 5.00038683e-01 4.65761214e-01 4.87965971e-01
 4.20222193e-01 5.25379300e-01 4.30823088e-01 4.16413903e-01
 4.41574454e-01 4.53539848e-01 3.90107602e-01 4.47508663e-01
 5.01085281e-01 4.89161134e-01 4.59963650e-01 4.64649677e-01
 5.22528946e-01 1.40561640e-01 4.50154513e-01 4.93461758e-01
 4.37447786e-01 4.43673819e-01 4.35005724e-01 4.80082661e-01
 4.54246700e-01 1.24647349e-01 3.02856147e-01 1.57941669e-01
 3.50621909e-01 4.12643343e-01 4.99254674e-01 3.42586160e-01
 4.87729609e-01 3.90922606e-01 4.32136595e-01 4.10336465e-01
 4.76531953e-01 4.84014213e-01 3.86530459e-01 4.02552903e-01
 4.80212539e-01 2.28832155e-01 3.80367309e-01 2.34073907e-01
 2.28535146e-01 4.12294805e-01 3.59709710e-01 4.82733727e-01
 4.23985898e-01 3.50744367e-01 4.72187907e-01 3.11077595e-01
 4.29057300e-01 3.21424127e-01 6.84282668e-07 2.78515518e-02
 1.17498636e-03 7.00324774e-04 6.16839528e-03 1.32206678e-02
 3.26320231e-02 5.33705950e-03 3.67498606e-01 3.42144310e-01
 3.17312449e-01 6.32217348e-01 3.55560690e-01 3.41881365e-01
 3.61796439e-01 5.22437036e-01 9.31459129e-01 3.54410917e-01
 2.94184804e-01 3.31530631e-01 3.08334291e-01 3.14691544e-01
 3.77201468e-01 3.72904420e-01 1.25746727e-02 5.43860853e-01
 2.31048465e-02 8.87509525e-01 1.05404854e-03 8.70837092e-01
 3.74019980e-01 9.93255734e-01 8.06360781e-01 1.92033917e-01
 9.28708076e-01 8.67642522e-01 8.94126773e-01 8.24527144e-01
 7.62728810e-01 2.88570017e-01 7.20483601e-01 7.17586577e-02
 3.50662351e-01 5.48034906e-03 8.71461749e-01 5.79929531e-01
 6.82102561e-01 8.00247371e-01 9.05667961e-01 6.08294010e-02
 5.00930846e-02 2.47948676e-01 9.47792530e-01 9.71681297e-01
 4.74669158e-01 3.29223454e-01 3.67895633e-01 3.34690630e-01
 3.08938324e-01 3.00897956e-01 7.43958652e-02 1.24753028e-01
 8.37197423e-01 2.46788055e-01 3.89449716e-01 4.04587477e-01
 3.92415524e-01 1.11486405e-01 4.09203768e-02 4.85312641e-01
 9.67396557e-01 9.98499036e-01 9.96799171e-01 4.35811937e-01
 6.86499298e-01 4.86183137e-01 7.95347333e-01 6.71073496e-01
 6.26441538e-01 7.00755000e-01 5.91318965e-01 6.48345828e-01
 7.74852753e-01 7.61799872e-01 5.86770535e-01 7.02785850e-01
 8.70876133e-01 8.02625597e-01 2.94370860e-01 9.69170809e-01
 9.83196080e-01 9.80242193e-01 2.02620029e-03 1.43715262e-01
 1.62671357e-01 3.12044919e-02 1.23931140e-01 5.39654493e-02
 5.70099073e-05 2.45839357e-04 1.45524412e-01 2.68214345e-02
 4.24339145e-01 1.28747612e-01 3.73736799e-01 1.55985057e-01
 2.88477957e-01 6.29426956e-01 4.02647853e-02 1.81302011e-01
 8.98591578e-02 4.64297205e-01 2.61680543e-01 1.29282475e-04
 2.11089849e-04 2.83433378e-01 9.60537195e-01 3.98751199e-01
 2.99145907e-01 9.60844159e-02 3.02856743e-01 2.48968601e-04
 9.14143026e-02 3.99612963e-01 3.15700948e-01 3.16319853e-01
 9.81843472e-03 7.83413649e-03 1.64227694e-01 1.66785598e-01
 2.90484130e-02 1.43404603e-01 1.45559102e-01 8.24339092e-02
 2.07668185e-01 1.36317074e-01 8.22275162e-01 3.22343707e-01
 2.88934052e-01 4.45542872e-01 2.28631179e-05 9.96791184e-01
 3.82665873e-01 3.93478453e-01 3.18878770e-01 4.49425399e-01
 4.51521039e-01 3.94145876e-01 4.36372191e-01 4.49518293e-01
 6.27413392e-03 9.80990887e-01 4.70129311e-01 4.51335251e-01
 4.45431471e-01 4.69594359e-01 4.92004067e-01 3.86967719e-01
 8.36592138e-01 6.93743686e-06 8.55898857e-03 7.53432512e-04
 3.29340398e-02 3.26489508e-02 1.78076714e-01 4.83244658e-04
 1.46611631e-02 1.93327665e-04 4.85831499e-03 1.96754932e-04
 3.62499654e-02 5.30362129e-03 1.71656013e-02 4.09729183e-02
 5.01587692e-07 2.24204361e-02 1.54673159e-02 3.77995074e-02
 3.41657341e-01 8.42182755e-01 5.55230254e-05 5.77395476e-05
 2.52688825e-02 1.88550055e-02 9.33322608e-02 1.54566635e-06
 7.37607479e-04 4.46248055e-03 1.01183057e-02 1.97438419e-01
 5.35118163e-01 9.10634696e-02 2.98332959e-01 1.36387944e-01
 3.10172439e-02 1.90773934e-01 1.78973407e-01 5.47136664e-02
 2.84824163e-01 1.99463071e-10 8.26836999e-09 8.61011207e-01
 2.37442553e-01 4.85741109e-01 4.61089611e-01 4.85248029e-01
 4.77304757e-01 4.61316824e-01 4.39657420e-01 4.43263888e-01
 4.51909065e-01 4.56794560e-01 4.65402901e-01 4.50271010e-01
 4.77946222e-01 4.41325247e-01 4.65942472e-01 2.13469229e-06
 8.82076183e-16 1.47849321e-04 1.43810022e-08 1.57983663e-07
 2.39297044e-08 5.87082923e-07 1.94397569e-03 4.52761054e-02
 1.45110488e-03 8.27902555e-03 9.31352377e-04 4.86433506e-04
 3.71748209e-03 1.00000000e+00 2.59537565e-08 2.14844942e-03
 3.19367727e-11 4.38723862e-02 4.73487377e-03 3.15455486e-06
 3.45836626e-09 7.91430473e-04 5.25370240e-03 7.79366493e-03
 1.19489431e-03 1.57629550e-02 6.76661730e-04 4.99060750e-03
 3.14891338e-04 1.92952454e-01 1.40209526e-01 1.75427049e-05
 9.71555528e-06 9.85420108e-01 9.47078049e-01 1.96149576e-05
 4.22106445e-01 2.78060555e-01 1.14663720e-01 5.40435314e-04
 9.99998569e-01 2.14884892e-08 2.05491155e-01 1.47305876e-01
 5.76631308e-01 6.03258610e-04 5.25554717e-02 1.56071782e-03
 6.20275736e-04 2.00778246e-04 1.11261010e-03 1.81779265e-03
 2.94967180e-07 1.21390425e-04 2.73904607e-05 1.12073685e-05
 3.87042761e-04 2.65896320e-04 1.08027458e-03 3.23653221e-04
 1.53183937e-03 5.45006651e-10 1.03731990e-01 9.17466879e-02
 8.75085592e-04 9.50630769e-14 5.41150570e-04 9.98636127e-01
 8.77784491e-01 2.42703946e-09 7.13683903e-01], shape=(583,), dtype=float32)
rounded label:tf.Tensor(
[0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1.
 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1.
 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1.
 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1.
 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1.
 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0.
 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0.
 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 0. 1.], shape=(583,), dtype=float32)
predicted label rank:[1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 2 2 1 2 1 2 1 2 2 2 1 1 2 1
 2 1 1 2 2 2 2 1 2 1 2 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 2 2 2 2 1 1 1 1 2 1 2
 2 1 2 2 1 2 1 2 2 2 2 2 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2
 1 2 2 1 2 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 1 1 1 2 2 2 1 2 2 2 2 1 1 2 2
 2 2 2 2 1 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 1 1 1 1 2 2 1 1 2 1 2 2 2 2 1 1 1
 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 1 1 1 2 1 2
 2 2 2 1 1 2 1 1 2 2 1 1 1 1 2 2 1 1 2 2 1 1 1 2 1 1 1 1 1 1 2 1 1 1 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 2 1 2 2 2 2 2
 1 2 1 1 1 2 2 2 2 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 2 1 2 1
 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1
 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 2 1 1
 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2]
mse:tf.Tensor(0.33560959, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/SYNAPSE_6_e3_1666_e5_1558_000.smt2
true label:[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
true label rank:[2 2 1 1 2 1 1 2 1 2 1 2 2 1 1 2 1 2 2 2 1 2 2 2 2 2 2 1 1 1 2 2 1 1 1 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2 2
 2 1 1 2 1 2 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 2]
predicted label:tf.Tensor(
[9.94808197e-01 7.03440833e-07 1.39503747e-01 5.33083260e-01
 1.02990866e-03 1.08066201e-02 2.85325050e-02 1.00000000e+00
 8.89953971e-01 9.99995947e-01 5.59145212e-03 1.00000000e+00
 9.99882221e-01 1.83040202e-02 6.28318429e-01 2.45783150e-01
 1.35113388e-01 3.18534046e-01 9.99288917e-01 7.14070797e-02
 1.01123184e-01 9.62673128e-01 4.04941857e-01 9.93221700e-01
 3.37891906e-01 9.68078732e-01 1.92594260e-01 1.17136424e-05
 7.02471137e-02 1.16931498e-02 8.76660407e-01 3.79242748e-01
 4.21637416e-01 2.78805614e-01 8.27461481e-04 3.59427035e-01
 4.12388891e-01 5.13309538e-01 4.25116837e-01 4.73207474e-01
 5.39435029e-01 4.23423678e-01 4.46168900e-01 5.33831537e-01
 4.71673876e-01 4.54869717e-01 1.48960948e-03 9.29848194e-01
 8.62757325e-01 7.91463375e-01 9.11607981e-01 1.58410579e-01
 9.18219447e-01 8.47562313e-01 8.78292382e-01 8.89303923e-01
 8.78583908e-01 8.79473805e-01 9.17870402e-01 9.01103735e-01
 9.26080346e-01 8.25373530e-01 7.91979671e-01 3.06142449e-01
 9.88605261e-01 6.34209275e-01 4.74454463e-01 7.84014583e-01
 4.29989964e-01 5.95181644e-01 7.58158922e-01 9.93527770e-01
 9.33140874e-01 9.53452229e-01 9.90858436e-01 5.74238539e-01
 9.99999464e-01 9.99591112e-01 9.99995589e-01 3.56727421e-01
 1.82687700e-01 9.96904850e-01 9.99114752e-01 9.46313262e-01
 9.77077007e-01 9.26067472e-01 9.47724581e-01 5.85066557e-01
 8.21294308e-01 4.13274586e-01 1.00000000e+00 1.00000000e+00
 1.00000000e+00 9.99991775e-01 9.99965191e-01 9.99998450e-01
 9.99966800e-01 9.99915123e-01 9.99997854e-01 9.94939446e-01
 9.96868968e-01 9.72965240e-01 9.85245109e-01 9.74643350e-01
 9.83213723e-01 9.74244833e-01 9.21824813e-01 9.99991179e-01
 9.99964774e-01 9.99844313e-01 9.99724746e-01 9.99655664e-01
 9.99899745e-01 8.06512833e-01 6.91629767e-01 9.02999997e-01
 8.75394762e-01 8.86731863e-01 8.80586386e-01 9.06257391e-01
 8.78821075e-01 8.03661346e-01 9.81979251e-01 8.30512285e-01
 6.38729692e-01 9.34268773e-01 8.71799111e-01 8.92616749e-01
 7.45771468e-01 1.00000000e+00 9.03340816e-01 7.29779363e-01
 7.61519313e-01 5.85124493e-01 8.59402895e-01 7.50593305e-01
 9.99209166e-01 8.37124169e-01 2.18209624e-02 5.83532155e-01
 2.27457881e-02 1.33226395e-01 1.15789652e-01 8.24247837e-01
 8.10817182e-01 2.06005186e-01 2.28337109e-01 6.46707952e-01
 1.43820405e-01 2.77036101e-01 5.38438201e-01 6.81974292e-01
 7.40842342e-01 8.02961230e-01 4.85030770e-01 1.12214446e-01
 1.67611122e-01 4.11929131e-01 9.98604596e-02 3.01907182e-01
 9.59512711e-01 2.18235030e-09 2.80078666e-06 5.17758090e-05
 9.98994708e-01 9.99999523e-01 9.99994755e-01 9.99482691e-01
 9.97376800e-01 1.00000000e+00 9.79995251e-01 9.99342740e-01
 7.05495775e-02 2.72386968e-01 1.18067861e-03 6.58659469e-15
 3.49231664e-06 6.91932976e-01 3.66376847e-01 1.07941628e-02
 2.04629302e-02 8.95678997e-04 9.98407364e-01], shape=(183,), dtype=float32)
rounded label:tf.Tensor(
[1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1.
 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1.
 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1.
 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.], shape=(183,), dtype=float32)
predicted label rank:[2 1 1 2 1 1 1 2 2 2 1 2 2 1 2 1 1 1 2 1 1 2 1 2 1 2 1 1 1 1 2 1 1 1 1 1 1
 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 1 2 2 1 2 1 2 2 2 2 2
 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 1 1 2 2 1 1 2
 1 1 2 2 2 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 2]
mse:tf.Tensor(0.16392796, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/16.c_000.smt2
true label:[1, 1, 0, 1, 1, 1, 1, 0, 1, 1]
true label rank:[2 2 1 2 2 2 2 1 2 2]
predicted label:tf.Tensor(
[0.02147785 0.11053231 0.00412527 0.00957403 0.04843229 0.73173565
 0.03009593 0.13301906 0.95685375 0.81357783], shape=(10,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 1. 0. 0. 1. 1.], shape=(10,), dtype=float32)
predicted label rank:[1 1 1 1 1 2 1 1 2 2]
mse:tf.Tensor(0.47020888, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0264_000.smt2
true label:[1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2
 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1
 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2
 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2
 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 1 2 2 2 2 2
 1 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[9.99999285e-01 9.99998212e-01 1.00000000e+00 1.00000000e+00
 1.00000000e+00 9.99651551e-01 6.99892640e-01 8.42736244e-01
 9.50656116e-01 9.72945511e-01 9.99949217e-01 9.99812126e-01
 9.99841213e-01 1.00000000e+00 9.99993682e-01 9.50410247e-01
 2.33325362e-03 5.20044565e-03 9.52557325e-01 9.94237423e-01
 9.64184403e-01 9.59688425e-01 9.98298764e-01 1.00000000e+00
 9.63438988e-01 5.02481759e-02 9.31813359e-01 7.83368826e-01
 4.75216299e-01 1.78417087e-01 9.61846948e-01 9.71891522e-01
 7.42828965e-01 2.13007301e-01 6.13318980e-01 9.95674253e-01
 9.92203355e-01 9.89354968e-01 9.85539913e-01 9.92617130e-01
 9.73913670e-01 5.20314276e-01 9.98579562e-01 8.81403923e-01
 7.99676001e-01 9.48748708e-01 9.46975291e-01 9.92069840e-01
 9.67680871e-01 4.20070887e-01 9.98436332e-01 9.92056966e-01
 9.96822596e-01 9.84608293e-01 9.90332127e-01 9.92210329e-01
 9.94611323e-01 4.89339322e-01 9.95841384e-01 9.92711544e-01
 9.92759585e-01 9.75372434e-01 9.72105980e-01 9.84755397e-01
 9.61298943e-01 4.30896223e-01 9.94473934e-01 9.96434569e-01
 9.67317939e-01 9.43098307e-01 9.82283115e-01 9.91956949e-01
 9.91400957e-01 3.73789668e-01 9.50216055e-01 9.40845132e-01
 9.79293346e-01 8.77712369e-01 9.37733889e-01 9.82587457e-01
 9.82459188e-01 4.76737857e-01 8.76222372e-01 7.81755209e-01
 6.30409956e-01 6.44806027e-01 9.81854856e-01 9.55815077e-01
 9.87112045e-01 2.13810056e-01 9.98056233e-01 8.51426363e-01
 9.66851115e-01 9.51349020e-01 9.74313259e-01 9.79053438e-01
 9.79334950e-01 2.26762563e-01 1.78092360e-01 9.16812301e-01
 9.89947677e-01 9.69093800e-01 9.74712729e-01 9.92950678e-01
 9.84466672e-01 4.22839344e-01 8.05917382e-01 9.90197897e-01
 9.46242869e-01 9.61101830e-01 9.88027453e-01 9.56905305e-01
 9.70873117e-01 3.04296255e-01 9.80284452e-01 9.88254070e-01
 9.90441203e-01 9.87591028e-01 9.90946531e-01 9.97797549e-01
 9.91290808e-01 9.88689661e-02 9.98411000e-01 9.94894505e-01
 9.55257416e-01 9.90002573e-01 9.94256794e-01 9.98027682e-01
 9.97894943e-01 2.95536309e-01 9.97348130e-01 9.92163420e-01
 8.72519493e-01 9.72895741e-01 9.86470520e-01 9.90178347e-01
 9.87064838e-01 3.43123078e-01 9.95179176e-01 9.92788553e-01
 9.94922996e-01 9.96235788e-01 9.89657283e-01 9.98441339e-01
 9.97894287e-01 4.25965160e-01 9.97912943e-01 9.33868468e-01
 7.58173108e-01 9.79388475e-01 9.80958521e-01 9.85667109e-01
 9.77501154e-01 5.00345111e-01 9.94574189e-01 8.55397224e-01
 8.89279008e-01 9.31037426e-01 9.87524390e-01 9.90531743e-01
 9.69747901e-01 3.79131019e-01 9.96096134e-01 1.88879907e-01
 9.57685590e-01 9.49477673e-01 9.75249410e-01 9.89934564e-01
 9.15200949e-01 1.58179015e-01 9.92567420e-01 2.13479996e-03
 9.60916281e-04 1.61987543e-03 1.59883499e-02 3.43838334e-03
 9.92327929e-04 2.89472938e-03 1.60067201e-01 2.77643800e-02
 8.35186958e-01 9.40162301e-01 9.39314961e-01 9.57858980e-01
 6.84044361e-01 2.25357324e-01 9.88680243e-01 1.66030526e-02
 1.29735470e-03 3.64336371e-03 9.29647803e-01 1.92727149e-02
 5.07438183e-03 1.61462128e-02 9.53415036e-03 9.95176792e-01
 9.87236381e-01 9.83596206e-01 9.95435238e-01 9.96663988e-01
 9.96050835e-01 3.50970566e-01 9.93974030e-01 5.50271869e-01
 3.72115225e-01 1.73123360e-01 9.84870434e-01 9.72149253e-01
 4.12836671e-01 5.97910285e-02 9.71440732e-01 9.95528579e-01
 9.91782546e-01 9.84906912e-01 9.88264322e-01 9.94414210e-01
 9.77145731e-01 2.86494195e-01 9.95904803e-01 7.86427699e-05
 7.30449829e-05 1.30051374e-03 1.26248598e-03 5.50866127e-04
 1.43587589e-04 6.49348513e-05 3.32474709e-04 1.07558668e-02
 1.43668056e-02 2.41273642e-03 1.94848180e-02 1.44151449e-02
 8.24445486e-03 6.38899207e-03 1.53326582e-05 9.81390476e-04
 8.14577361e-05 1.17853284e-03 1.63201094e-02 2.28717923e-03
 1.27911568e-04 1.17037296e-02 5.22493720e-02 2.89306045e-03
 3.54260206e-04 2.40170956e-03 7.30072856e-02 3.58775258e-03
 4.66644764e-04 3.06314230e-03 1.51538074e-01 1.75327063e-04
 6.12735748e-04 1.17948651e-03 9.91916656e-03 1.01140738e-02
 5.19484282e-04 3.45999002e-03 1.26949549e-02 5.78254461e-04
 2.14120746e-03 3.10957432e-04 2.06064373e-01 1.10343099e-03
 2.75880098e-04 1.63230300e-03 7.65860081e-04 4.31150198e-04
 7.62164593e-04 1.03464723e-03 6.98759258e-02 1.29666626e-02
 2.58624554e-03 1.01798773e-03 1.03151798e-03 5.56505183e-05
 5.24687767e-03 5.06907701e-04 6.03762269e-03 3.56751680e-03
 4.18812037e-04 5.81431389e-03 4.43169475e-03 6.57836063e-05
 5.09291887e-04 7.60555267e-04 8.11344385e-03 8.66591930e-04
 5.49018383e-04 1.05965137e-03 9.93418694e-03 8.46112525e-05
 4.05192375e-04 2.90781260e-04 4.12064791e-03 2.46435404e-04
 1.02311104e-04 1.10778213e-03 1.17927790e-03 2.90437092e-05
 7.25380887e-05 6.24338936e-05 2.82260776e-03 1.91867352e-04
 3.21754451e-05 4.61965799e-04 1.80959702e-04 7.92503357e-04
 4.52071428e-04 3.66190076e-03 4.15153801e-02 4.55319881e-04
 3.10570002e-04 1.62029266e-03 1.46329403e-04 6.19679689e-04
 5.87522984e-04 2.04294920e-04 1.84071064e-03 1.28820539e-03
 1.70439482e-04 2.36499310e-03 1.57147646e-04 8.64502788e-03
 3.35410237e-03 4.92280722e-03 4.51079607e-02 1.33410096e-03
 5.87207079e-03 8.21298957e-02 1.00588918e-01 1.98215246e-04
 2.07059085e-02 1.36852264e-04 8.13782215e-04 1.93655491e-03
 1.24787312e-05 3.17409635e-03 1.34795904e-04 3.87907028e-04
 2.47548724e-05 1.96993351e-04 6.15387559e-01 1.21727586e-03
 2.07327030e-05 8.07881355e-04 1.29298568e-02 2.51229039e-06
 3.51955282e-06 7.84785698e-06 4.15626168e-03 1.02859063e-04
 1.52555731e-05 1.13656613e-04 3.91975817e-07 2.24691084e-05
 3.07053328e-04 1.71104275e-05 1.07213855e-03 1.16380761e-04
 1.72142609e-05 7.64177385e-05 2.43321256e-06 3.67671251e-04
 5.46664000e-04 2.20149755e-04 5.45253575e-01 3.71302885e-05
 6.43420863e-05 3.91662121e-04 1.05723232e-01 1.63052864e-05
 1.20050805e-04 6.94037499e-06 5.59714437e-03 4.36395407e-04
 1.28984451e-04 7.39902258e-04 3.25056426e-05 7.69601102e-05
 7.79864934e-07 1.10198016e-04 1.03415870e-04 1.03157759e-03
 2.64681130e-05 2.00003386e-04 3.29136848e-04 6.11513853e-04
 6.70880079e-04 1.05720603e-04 2.68677771e-02 1.51523948e-03
 1.23284059e-04 5.21123409e-04 4.68130565e-06 9.81711310e-06
 1.78396702e-04 2.66164541e-04 7.05924630e-03 1.71154737e-04
 2.43365765e-04 9.85953212e-03 4.46627892e-05 3.06010246e-04
 1.75595284e-04 3.49104404e-04 4.97919321e-03 5.48615644e-05
 2.28971243e-04 1.29085779e-03 5.11944294e-04 1.55714154e-03
 3.07705268e-05 3.09935022e-05 1.74859166e-03 2.00222494e-05
 2.02448027e-05 3.22172046e-03 5.02639978e-06 4.98628318e-02
 4.69058752e-04 2.06512213e-03 1.44720972e-02 1.03749931e-02
 3.71414462e-05 2.02780962e-03 7.70956278e-04 5.34266233e-04
 5.71724772e-03 1.26272440e-04 8.59618545e-01 2.87366360e-01
 5.73962927e-04 5.76822758e-02 1.32662058e-03 6.15506815e-06
 1.73479759e-06 9.76519550e-06 5.61330635e-05 5.94752710e-05
 1.15988132e-05 5.97360740e-05 1.06176289e-04 2.82635233e-06
 6.54121905e-05 1.38223171e-04 1.43557787e-04 2.85774513e-05
 4.88575133e-05 4.14222479e-04 6.47510342e-06 3.76448297e-05
 5.48832286e-05 2.30861187e-05 1.81028247e-03 2.30491161e-04
 1.11652498e-05 1.20913937e-04 4.60900774e-05 6.18305785e-05
 1.29789114e-04 2.57724114e-05 9.48461748e-05 5.08487225e-04
 2.14159489e-04 5.25975811e-05 3.75763193e-05 7.25152267e-06
 5.70599241e-06 2.48507763e-06 1.01935366e-04 6.66187334e-05
 2.60527554e-06 4.38498828e-05 1.45009499e-05 3.60907106e-05
 3.42384992e-05 4.17499323e-05 1.50841475e-03 2.19395915e-05
 1.13446098e-04 5.11944294e-04 5.52014626e-06 4.42200253e-05
 1.16039519e-06 2.81339162e-05 1.49808228e-02 3.93305163e-05
 2.38914326e-05 1.54495239e-04 3.60521153e-05 4.20706419e-05
 1.54248064e-05 3.49793481e-05 6.72787428e-04 2.43186951e-04
 1.75170917e-05 1.07562264e-04 7.80683149e-06 1.99466944e-04
 1.86244350e-07 1.12181541e-15 8.90885907e-11 2.68161297e-04
 4.39157735e-19 1.09315632e-04 4.26121869e-06], shape=(507,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1.
 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0.
 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.
 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0.], shape=(507,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 1 2 2 1 1 2 2 2 1 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1
 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 1 2 2 2 2 2
 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 1 2 1 1 1 1 1 1 1 1 1 2 2 2 2 2
 1 2 1 1 1 2 1 1 1 1 2 2 2 2 2 2 1 2 2 1 1 2 2 1 1 2 2 2 2 2 2 2 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.040459726, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/bandec.smt2-0210_000.smt2
true label:[0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]
true label rank:[1 2 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 2]
predicted label:tf.Tensor(
[6.58917010e-01 7.68096983e-01 2.93578804e-02 3.52054834e-04
 1.84396207e-02 8.33654106e-02 3.70538235e-03 1.01572245e-01
 7.61875987e-01 6.52527809e-03 5.20467758e-03 5.80717742e-01
 3.90554368e-02 4.20185924e-03 4.29174304e-03 2.57433385e-01
 7.72230327e-02 8.31943750e-03 1.55267715e-02 4.91751075e-01
 3.49296391e-01], shape=(21,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(21,), dtype=float32)
predicted label rank:[2 2 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.1975018, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/loop__loop2_000.smt2
true label:[1, 1, 0, 1, 1]
true label rank:[2 2 1 2 2]
predicted label:tf.Tensor([0.92133105 0.71830773 0.8198408  0.998534   0.88038605], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.15439758, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/bandec.smt2-0131_000.smt2
true label:[0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 2 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[2.0531771e-01 4.5481718e-01 1.4006585e-02 1.7304331e-02 3.8598418e-02
 5.7406992e-01 1.5660822e-02 3.4929514e-03 2.6836097e-03 1.5708822e-01
 1.5082115e-01 5.3646952e-01 6.3067675e-04 2.9122263e-02 4.1900277e-03
 5.1805377e-04 1.7575324e-03 3.2328516e-01], shape=(18,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], shape=(18,), dtype=float32)
predicted label rank:[1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1]
mse:tf.Tensor(0.10480307, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/gcd01_true-unreach-call_true-no-overflow_true-termination_000.smt2
true label:[0, 0, 0, 1, 0, 0, 0, 1]
true label rank:[1 1 1 2 1 1 1 2]
predicted label:tf.Tensor(
[0.7869984  0.88679194 0.58235604 0.48448163 0.94696605 0.78068393
 0.9639759  0.97586   ], shape=(8,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 0. 1. 1. 1. 1.], shape=(8,), dtype=float32)
predicted label rank:[2 2 2 1 2 2 2 2]
mse:tf.Tensor(0.5558386, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/21.c_000.smt2
true label:[0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1]
true label rank:[1 2 1 1 2 2 1 1 1 1 2 2 1 1 1 1 1 2 2 1 1 1 1 2 2]
predicted label:tf.Tensor(
[1.2117326e-03 6.4241672e-01 2.0872369e-05 6.8053007e-03 3.6831170e-02
 7.2168374e-01 5.7307720e-02 2.1923512e-02 3.8192987e-02 7.3326379e-02
 7.4924546e-01 4.8982650e-02 3.5462379e-03 1.4094189e-01 1.0267794e-02
 2.7261674e-03 1.0420269e-01 6.4826882e-01 1.3779551e-01 2.0978409e-01
 3.8396090e-02 1.2458795e-01 4.8956156e-02 5.5761731e-01 8.2577479e-01], shape=(25,), dtype=float32)
rounded label:tf.Tensor(
[0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
 1.], shape=(25,), dtype=float32)
predicted label rank:[1 2 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 2 2]
mse:tf.Tensor(0.13193595, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/bandec.smt2-0238_000.smt2
true label:[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.4471311  0.45754886 0.19564259 0.36444652 0.10713387 0.4824758
 0.00179681 0.09529603 0.00295156 0.00401038 0.17295143 0.0053156
 0.00221393 0.3568363  0.05870238 0.47611788 0.01078001 0.00645903
 0.37429416 0.16667786], shape=(20,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.074746475, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/rtp_1_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]
true label rank:[1 1 1 ... 1 1 1]
predicted label:tf.Tensor([0.00023651 0.02072906 0.00010509 ... 0.00078794 0.00156271 0.00110519], shape=(1682,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(1682,), dtype=float32)
predicted label rank:[1 1 1 ... 1 1 1]
mse:tf.Tensor(0.07726143, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/jm2006_variant_true-unreach-call.c.flat_000.smt2
true label:[1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1]
predicted label:tf.Tensor([0.0403766  0.06474447 0.79283535 0.98228157 0.558252  ], shape=(5,), dtype=float32)
rounded label:tf.Tensor([0. 0. 1. 1. 1.], shape=(5,), dtype=float32)
predicted label rank:[1 1 2 2 2]
mse:tf.Tensor(0.4067905, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/bandec.smt2-0148_000.smt2
true label:[1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[7.0228541e-01 8.0994034e-01 8.3554614e-01 1.0951161e-03 4.4872946e-01
 7.9491466e-02 2.3863912e-03 3.0437410e-03 7.4781477e-03 3.9935112e-03
 2.1791458e-03 7.4779987e-04 3.9693773e-02 5.7303357e-01 1.1560321e-03
 3.6946298e-05 4.7347158e-02 3.3204857e-01 5.1709765e-01 4.4099987e-02
 7.7706277e-03 9.8251104e-03 8.6176395e-04 1.3403526e-01 8.8846684e-04
 7.5913966e-03], shape=(26,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0.], shape=(26,), dtype=float32)
predicted label rank:[2 2 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1]
mse:tf.Tensor(0.0657466, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/06.c_000.smt2
true label:[0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1]
true label rank:[1 2 2 1 1 2 2 1 1 2 2 2 1 1 1 2 1 1 1 2]
predicted label:tf.Tensor(
[0.84196055 0.46392995 0.677114   0.38503143 0.55851233 0.6214248
 0.58882344 0.5575863  0.11201888 0.6232363  0.93972504 0.9882735
 0.8635378  0.6988728  0.7016813  0.64193404 0.69358844 0.8485179
 0.9816594  0.9823182 ], shape=(20,), dtype=float32)
rounded label:tf.Tensor([1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(20,), dtype=float32)
predicted label rank:[2 1 2 1 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2]
mse:tf.Tensor(0.31809855, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0028_000.smt2
true label:[1, 0, 0, 1, 1]
true label rank:[2 1 1 2 2]
predicted label:tf.Tensor([0.9986656  0.81314236 0.90089166 0.9915141  0.91924137], shape=(5,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1.], shape=(5,), dtype=float32)
predicted label rank:[1 1 1 1 1]
mse:tf.Tensor(0.2958804, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/SYNAPSE_2_e8_1118_e7_1043_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2
 2 1 2 2 1 1 1 1 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2
 2 2 2 2 2 1 1 1 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 2 2 2 1 2 2 2 2 2 2
 2 1 1 1 1 1 1 1 1 1 1 2]
predicted label:tf.Tensor(
[2.7251244e-04 1.7186842e-06 1.3075581e-01 3.2829791e-02 1.9578665e-02
 8.7173581e-03 6.9489306e-01 4.6646792e-01 2.4071857e-01 2.9997823e-01
 1.6563976e-01 1.9996390e-01 1.1530802e-01 4.6588665e-01 5.6192279e-04
 3.0711782e-01 2.5246143e-02 1.5819460e-02 1.9264200e-01 1.0830605e-01
 3.4814209e-02 4.6686882e-06 2.2015840e-02 8.1295639e-02 7.1991022e-09
 4.2110413e-01 1.7845631e-04 3.3047795e-04 5.0954014e-02 5.2542013e-01
 8.9342308e-01 1.5454203e-02 1.7094731e-02 5.5779219e-03 1.7276108e-03
 1.0646820e-02 1.5316039e-02 2.8244972e-02 1.4430195e-02 3.0972570e-02
 3.6277741e-02 1.3831228e-02 1.8637121e-02 3.8922131e-02 2.8048009e-02
 1.5047789e-03 3.4287632e-02 1.2497246e-02 1.3347149e-02 1.3423085e-02
 2.3667365e-02 1.5397936e-02 1.8087089e-02 2.2443354e-02 1.9142359e-02
 3.2914668e-02 3.5027474e-02 2.6338369e-02 6.4681977e-02 8.3949596e-02
 1.4587700e-02 2.7918220e-03 8.2578063e-03 9.6154392e-02 6.9225252e-02
 1.2531370e-01 2.8790563e-02 1.0044485e-02 1.3847768e-02 8.3766878e-03
 3.2399595e-03 4.8708081e-02 1.0000000e+00 9.9998641e-01 9.9999070e-01
 4.1531274e-01 9.9966437e-01 9.9977100e-01 4.1805655e-02 3.2252133e-02
 1.3622522e-02 3.2733589e-02 9.9930912e-01 9.9996269e-01 9.9981201e-01
 3.4123129e-01 9.9058712e-01 9.9962729e-01 9.9994600e-01 9.9842292e-01
 9.9949682e-01 9.9998516e-01 6.5588951e-04 8.7526679e-01 9.9997997e-01
 9.3335932e-01 9.9921250e-01 9.9707890e-01 9.5331526e-01 9.4493449e-01
 9.4352132e-01 9.5949876e-01 9.9265558e-01 9.9625933e-01 9.9975848e-01
 3.9249703e-01 8.8188052e-04 9.9433994e-01 9.8193049e-01 9.9785835e-01
 9.9209499e-01 8.8796455e-01 9.9776495e-01 5.1171511e-01 7.5444937e-01
 9.3874079e-01 6.7433917e-05 1.5866357e-05 8.1849098e-04 1.1908531e-02
 9.7188640e-01 4.1979575e-01 9.7296381e-01 9.7313643e-01 9.8886395e-01
 4.5924699e-01 8.5160220e-01 9.3903428e-01 9.9371588e-01 4.0344211e-01
 4.4426930e-01 4.2103902e-01 3.8390800e-01 3.9702395e-01 3.1845653e-01
 5.1844323e-01 3.0971017e-01 9.3939608e-01 5.8312500e-01 9.9999976e-01
 9.9964237e-01 7.7354419e-01 9.9999225e-01 8.5522628e-01 8.2505715e-01
 5.5121797e-01 1.0000000e+00 9.8665476e-01 6.0314530e-01 3.7038380e-01
 1.8041620e-01 2.2614506e-01 1.2278438e-02 1.3855100e-04 1.5701836e-01
 2.2541285e-01 1.4201164e-02 4.1623437e-01 3.6307189e-01 4.8591349e-01], shape=(160,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.
 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(160,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2
 2 1 2 2 1 1 1 1 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2
 2 2 2 2 2 1 1 1 1 2 1 2 2 2 1 2 2 2 1 1 1 1 1 1 2 1 2 2 2 2 2 2 2 2 2 2 2
 2 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.0654562, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/break_safe.c-1_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.9162098  0.72991747 0.9996184  0.9645792  0.9984025  0.99233615
 0.9470173 ], shape=(7,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1.], shape=(7,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1]
mse:tf.Tensor(0.012012658, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0303_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 ... 1 1 1]
predicted label:tf.Tensor(
[1.3416111e-03 4.2477015e-07 5.7947636e-04 ... 1.4025569e-03 8.0567168e-07
 3.8428457e-06], shape=(1688,), dtype=float32)
rounded label:tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(1688,), dtype=float32)
predicted label rank:[1 1 1 ... 1 1 1]
mse:tf.Tensor(0.023104997, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/id_build.i.p+sep-reducer.c-1_000.smt2
true label:[1, 1, 0]
true label rank:[2 2 1]
predicted label:tf.Tensor([0.9545733 0.9942732 0.9436887], shape=(3,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)
predicted label rank:[1 1 1]
mse:tf.Tensor(0.29754823, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/MOESI_2_e8_926_e8_2138_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1
 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 2 2 2 2 1 2 2 1 1 1
 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2
 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 2 2 2 2
 2 1 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 1 1
 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2
 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2
 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1]
predicted label:tf.Tensor(
[4.30971384e-04 9.35008728e-08 1.61931813e-02 3.93807888e-03
 5.26440447e-09 8.52525234e-04 1.12828612e-03 3.07757042e-10
 2.52807252e-20 1.34456158e-03 6.28810928e-24 1.83281302e-03
 5.23071587e-02 2.34248340e-02 6.03295863e-02 2.26923823e-03
 3.25945766e-05 2.03802884e-02 1.37656927e-04 7.02830890e-25
 2.14178044e-06 9.26918996e-15 2.23417580e-02 8.75654817e-03
 1.05588938e-09 4.51242328e-01 2.13047533e-05 4.39530611e-03
 2.84299850e-01 5.92359543e-01 6.96579278e-01 3.62558663e-01
 6.49620891e-02 1.16232840e-07 2.75334477e-01 8.66311789e-03
 6.24176860e-03 3.09706748e-01 6.52775168e-03 2.35344082e-01
 4.47908044e-03 5.74379265e-02 2.87544727e-03 1.06175230e-05
 2.51760852e-11 9.38421488e-03 3.24752378e-11 4.66928780e-02
 4.67772126e-01 3.96990776e-03 0.00000000e+00 3.18581164e-02
 8.02304149e-02 1.12177179e-09 3.08504701e-03 1.79053311e-12
 6.73621893e-04 8.93473625e-04 1.67450309e-03 1.76781416e-03
 9.53555107e-04 3.11791897e-04 2.74956226e-04 7.43299723e-04
 5.84930182e-04 6.31690025e-04 1.20693445e-03 5.05089760e-04
 9.43124294e-04 6.89148903e-04 2.84403563e-04 1.11197543e-04
 8.97973776e-04 1.28465891e-03 9.01311636e-04 6.81072474e-04
 7.19308853e-04 3.74883413e-04 7.65740871e-04 5.75870275e-04
 2.41667032e-04 6.55651093e-04 1.23918056e-03 5.61773777e-04
 4.68831513e-06 4.62591648e-04 3.38017941e-04 4.08530235e-04
 2.05293298e-03 3.03685665e-04 3.62336636e-04 1.64297223e-03
 8.78638762e-09 3.05273175e-01 1.86941385e-01 2.13806629e-02
 1.71866834e-01 3.67515683e-02 7.50955343e-02 1.60516858e-01
 1.30876184e-01 6.58716261e-02 9.65188742e-02 7.26319849e-02
 4.81599867e-02 5.08273244e-02 3.81839573e-02 1.25803918e-01
 1.61286265e-01 7.35998154e-03 1.85054213e-01 2.98011303e-03
 3.33666801e-04 4.11867877e-05 9.13706026e-05 1.02649450e-04
 2.11924314e-04 2.04265118e-04 1.53720379e-04 1.07452353e-04
 1.11522306e-04 6.07406400e-05 1.77472830e-04 1.95294619e-04
 3.55243683e-04 1.28805637e-04 2.38209963e-04 1.50084496e-04
 1.09500106e-04 1.54701123e-08 2.68790126e-03 9.96759534e-03
 4.63426113e-04 4.70751524e-03 1.42508745e-03 1.26868486e-04
 6.99690372e-06 6.73800707e-04 1.38920546e-03 4.11123037e-04
 7.15523958e-04 9.36682522e-01 9.54176843e-01 1.42371505e-01
 1.51642352e-01 2.32334912e-01 2.57626355e-01 1.20777309e-01
 1.76957250e-03 4.00614738e-03 2.96637416e-03 2.26271152e-03
 6.31153584e-03 3.14542651e-03 2.34931707e-03 9.16313529e-01
 8.19830835e-01 4.36395407e-02 7.12320209e-03 1.45559609e-02
 2.85775065e-02 1.56121254e-02 1.01655722e-03 1.79407001e-03
 1.34909153e-03 2.55459547e-03 6.33537769e-04 3.74999642e-03
 1.24785304e-03 3.00854445e-03 9.99993324e-01 9.99924421e-01
 9.99947667e-01 9.99700665e-01 7.84000754e-03 9.99766767e-01
 9.98373032e-01 9.83200967e-01 9.99822497e-01 1.40991807e-03
 9.76636767e-01 9.99524951e-01 2.34514475e-03 1.18720531e-03
 1.20666623e-03 8.46091032e-01 9.80497003e-01 9.63072538e-01
 9.99999583e-01 1.00000000e+00 1.00000000e+00 9.99081194e-01
 9.99952435e-01 9.99806046e-01 7.24067569e-01 8.12315464e-01
 7.47245431e-01 9.99996126e-01 9.99405026e-01 9.81816649e-01
 9.52278614e-01 9.98414099e-01 9.99990821e-01 9.99979436e-01
 9.99992013e-01 9.78518367e-01 9.61200118e-01 9.69464302e-01
 9.58103895e-01 9.71048355e-01 9.93171930e-01 9.94753063e-01
 9.99972582e-01 9.99998093e-01 8.93236995e-01 9.99999404e-01
 9.99999285e-01 9.99998927e-01 9.99978304e-01 9.99998093e-01
 1.00000000e+00 1.00000000e+00 9.99997497e-01 9.71241117e-01
 9.63128209e-01 8.99583936e-01 9.06034708e-01 9.48656321e-01
 9.05625343e-01 9.38539565e-01 1.00000000e+00 9.99997377e-01
 8.78989339e-01 9.99982357e-01 9.99996305e-01 9.99994993e-01
 9.99991417e-01 1.00000000e+00 8.23379874e-01 6.97942376e-01
 9.43178535e-01 9.49430823e-01 9.34254527e-01 9.47930992e-01
 9.11167145e-01 9.51242268e-01 9.55109715e-01 9.93937433e-01
 9.38530803e-01 9.78688776e-01 9.89071965e-01 9.78203773e-01
 9.09013510e-01 9.57222939e-01 9.10969615e-01 9.73089099e-01
 8.99579287e-01 9.40696597e-01 9.81454194e-01 9.85927224e-01
 9.85956669e-01 9.72819686e-01 9.82684016e-01 8.01607966e-01
 8.98895383e-01 8.05299819e-01 8.82716238e-01 8.23973298e-01
 8.34025979e-01 7.98558235e-01 8.88731599e-01 9.99399185e-01
 9.96121407e-01 9.99360323e-01 9.99152064e-01 9.98686016e-01
 8.16307664e-01 8.90280306e-01 8.20126414e-01 8.71129513e-01
 8.56696606e-01 7.73324013e-01 9.67556596e-01 9.75794077e-01
 9.95337844e-01 9.96154845e-01 9.89881217e-01 3.08529437e-01
 4.88881469e-02 9.42566395e-02 2.43831694e-01 6.13333881e-02
 9.95205760e-01 9.91985977e-01 9.20615494e-01 9.89881158e-01
 9.45655644e-01 2.49865353e-02 2.50398934e-01 3.92274737e-01
 5.32525420e-01 5.89153290e-01 4.70716834e-01 4.78990018e-01
 3.76025140e-01 5.09026170e-01 4.90868479e-01 4.71645564e-01
 4.31236863e-01 8.93980265e-03 7.65681267e-04 1.29261613e-02
 3.13976467e-01 3.98331225e-01 3.05255055e-01 4.02020216e-02
 9.22600865e-01 7.75313258e-01 7.51403093e-01 9.17305350e-01
 9.50226665e-01 9.81526613e-01 9.33296323e-01 9.85213280e-01
 9.78338659e-01 9.89014030e-01 2.11197734e-02 6.23619556e-03
 3.00066769e-02 1.30017519e-01 4.23869193e-02 2.87154019e-02
 9.01170075e-02 4.46006656e-03 1.60954595e-02 1.48862302e-02
 8.14193487e-03 1.37587786e-02 1.57690048e-03 1.95121765e-03
 5.86330891e-04 2.21042037e-02 1.68659717e-01 1.57514513e-02
 1.88398063e-02 2.02744901e-02 1.80983841e-02 1.59746706e-02
 4.52184677e-02 9.58696008e-03 9.28800225e-01 9.82048988e-01
 9.78424788e-01 6.88417554e-02 6.44004345e-03 6.44764304e-03
 1.77053869e-01 2.25278735e-02 1.89212263e-02 5.17765880e-02
 1.73898339e-02 1.11988783e-02 2.10650563e-02 2.03678012e-02
 3.18079889e-02 8.08358192e-04 7.25358725e-04 2.74939139e-05
 1.23142898e-02 3.19406390e-03 6.80458546e-03 1.07288659e-02
 3.36268544e-03 1.46266818e-03 4.11599278e-02 1.49222910e-02
 8.93759727e-03 3.83978784e-02 1.00926459e-02 6.31421804e-04
 4.05657265e-05 3.61850858e-03 4.37527895e-04 2.23779678e-03
 3.31580639e-03 5.39124012e-04 3.72946262e-03 4.15542722e-03
 5.06290793e-03 1.43805146e-03 4.42999601e-03 2.09015608e-03
 2.51030922e-03 4.18503914e-05 4.90769962e-05 2.03599188e-06
 1.45386755e-02 9.99906659e-01 9.99999166e-01 1.00000000e+00
 3.93774748e-01 9.16634798e-01 3.55149806e-01 6.22747898e-01
 7.70621538e-01 8.00716996e-01 1.00000000e+00 1.00000000e+00
 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00
 1.00000000e+00 1.00000000e+00 9.99993324e-01 8.01919818e-01
 9.46386456e-01 5.70487082e-01 7.98009157e-01 4.75046843e-01
 4.93658990e-01 3.83914596e-21 3.40291897e-35 4.16778892e-01
 2.44955689e-01 3.74129295e-01 1.94229938e-06 3.35215932e-14
 3.10323298e-01 1.80702051e-36 6.21741686e-11 7.84792283e-12
 3.57852684e-07 2.16396131e-07 1.57537524e-17 9.11437750e-01
 9.87468243e-01 1.27720505e-01 4.45882678e-02 9.75504756e-01
 9.10925746e-01 1.67438954e-01 9.95523691e-01 1.42737017e-10
 7.84704983e-02 9.46608067e-01 9.08340096e-01 7.66408265e-01
 8.82816672e-01 9.45848346e-01 9.55435634e-01 9.33142602e-01
 9.67797995e-01 9.99976754e-01 9.99948025e-01 1.88373029e-02
 6.74182653e-01 6.78337932e-01 6.36816025e-04 1.80482864e-04
 5.66422939e-04 5.31592965e-03 8.88973475e-03 6.59902990e-02
 7.92695846e-06 5.97966300e-06 7.30133688e-05 6.29257602e-06
 1.62432492e-02 1.55588984e-02 5.00575006e-02 1.08709306e-01
 1.49176419e-02 1.82543695e-02 2.68939137e-02 2.76326537e-02
 1.51693821e-01 7.90496826e-01 1.48691565e-01 3.25669587e-01
 3.29653025e-01 9.16845679e-01 9.28597331e-01 3.29539180e-01
 8.98171365e-01 4.68637347e-01 4.30611700e-01 4.25992519e-01
 9.13926959e-02 3.36221099e-01 8.76069129e-01 8.63595307e-02
 1.51861370e-01 2.49890387e-01 1.06403798e-01 1.45831674e-01
 3.84220481e-02 6.25391986e-05 2.69019008e-02 6.41415715e-02
 5.77509403e-04 1.24243498e-02 1.34575069e-02 5.69483340e-02
 6.35114312e-02 5.52690029e-02 7.83796608e-02 1.34192556e-01
 5.37520051e-02 3.97734344e-02 1.00733519e-01 1.27161682e-01
 6.04056120e-02 1.02049112e-03 7.05689192e-04 2.04116106e-04
 2.11995840e-03 1.42723322e-04 5.89179993e-03 2.87328959e-02
 1.59293413e-03 2.19905376e-03 6.73383474e-04 8.00997019e-04
 2.18561292e-03 8.16583633e-04 3.75777483e-04 1.78605318e-04
 1.01129699e-05 1.51985884e-03 7.27385283e-04 1.71899796e-04
 1.11496571e-04 2.91109085e-04 8.57857962e-09 1.06570423e-02
 3.67790461e-04 6.71898842e-01 4.15581596e-08 9.44763422e-04
 5.22971153e-04 6.56366348e-04 1.92880630e-04 1.43909454e-03
 9.94533300e-04 3.52877378e-03 4.66674566e-04 1.59502029e-04
 2.88182497e-03 1.07407570e-03 6.78829383e-05 7.21645355e-03
 2.11911756e-05 6.30140305e-04 4.69267368e-04 4.50529842e-05
 5.55127859e-04 3.55064869e-04 4.35517495e-06 6.48349524e-04
 1.72704458e-04 1.18745447e-04 2.62230635e-04 1.90579891e-03
 2.33965511e-05 1.13710390e-04 3.86267900e-04 2.23350042e-07
 1.87039375e-04 9.98246687e-05 7.31468201e-04 5.47283774e-10
 1.01450086e-03 5.00559836e-05 2.58798979e-16 8.14288796e-06
 3.04660061e-05 6.33427089e-06 1.23848095e-05 2.40713358e-04
 5.95134497e-03 9.83448117e-05 5.35842591e-05 1.95115805e-04
 6.61522150e-04 1.02341175e-03 2.18494733e-05 2.58435309e-01
 2.04391330e-01 9.93267715e-01 3.35752189e-01 4.29916799e-01
 2.86700189e-01 3.80671501e-01 2.57882833e-01 2.09745467e-01
 2.08791852e-01 2.97260940e-01 3.96772087e-01 3.42220068e-04
 2.45109200e-03 8.38424265e-02 2.79359818e-02 1.00816933e-05
 8.30707550e-02 1.30470991e-02 3.11273336e-03 3.42300236e-02
 1.51008368e-04 7.97336102e-02 8.10833275e-02 1.23828143e-01
 1.40503049e-03 9.55555141e-02 4.43741679e-02 1.05912089e-02
 1.49503887e-01 4.11501825e-02 2.43925452e-02 6.70701265e-04
 1.75035596e-02 5.28634787e-02 3.40124071e-02 3.92540693e-02
 1.11055732e-01 2.32976675e-03 9.61933434e-02 2.26067573e-01
 9.99635875e-01 9.98553216e-01 9.97023821e-01 9.94546235e-01
 5.93547761e-01 1.00000000e+00 9.85269725e-01 6.84429348e-01
 6.69360220e-01 9.69945669e-01 7.01439321e-01 9.40147579e-01
 4.84644175e-01 1.06249267e-07 3.39197603e-30 2.76975509e-11
 2.83626216e-32 6.09139204e-02 7.84529857e-06 2.47909388e-17
 1.85358697e-15 0.00000000e+00 4.23350275e-01 2.22652036e-11
 2.01007947e-06 1.50122537e-09 9.01396449e-25 0.00000000e+00
 2.42409110e-03 5.52623461e-38 2.02325664e-05 1.09904426e-29
 6.44581905e-06 4.72901440e-11 1.31731405e-11 1.62800521e-01
 1.94817781e-04 6.16073608e-04 5.41388988e-04 6.21843338e-03
 1.68441236e-02], shape=(669,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.
 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(669,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1
 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 2 2 2 2 1 2 2 1 1 1
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 2 2 2 2
 2 1 1 1 2 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 2 1 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 2 1 2 1
 1 2 2 2 2 2 2 2 2 2 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1
 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1]
mse:tf.Tensor(0.06385048, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0065_000.smt2
true label:[0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0]
true label rank:[1 1 1 1 1 2 2 1 2 1 1 2 1 1]
predicted label:tf.Tensor(
[1.9630319e-01 5.1822239e-01 6.3529611e-04 2.0951033e-02 7.6235539e-01
 6.5481043e-01 5.8014393e-01 4.0020049e-02 6.5827829e-01 3.3372152e-01
 2.9215693e-02 6.6196442e-02 4.6249032e-03 5.3326279e-02], shape=(14,), dtype=float32)
rounded label:tf.Tensor([0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0.], shape=(14,), dtype=float32)
predicted label rank:[1 2 1 1 2 2 2 1 2 1 1 1 1 1]
mse:tf.Tensor(0.16354303, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/minepump_spec5_product59_true-unreach-call.cil.c.flat_000.smt2
true label:[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]
true label rank:[1 1 1 2 1 1 1 1 2 1 2 1 1 1 2 1 1 2 1 2 2 2 2 2 1 2 1 1 1 1 1 2 1 2 2 1 1
 1 1 1 1 2 2 2 2 2 1 1 2 2 1 1 1 1 1 2 2 2 2 1 2 1 1 2 2 1 2 2 2 2 1 1 2 1
 2 1 1 2 1 2 2 2 2 2 1 2 2 2 2 1 1 2 1 2 1 1 2 1 2 2 2 2 2 1 1 2 1 1 2 2 1
 1 2 1 1 1 2 2 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1 2 2 1 2 2 2 1 2 2 2 2 2 1 1 1
 1 1 2 2 1 2 2 2 2 2 2 2 1 1 1 2 2 1 1 2 1 2 2 1 2 2 1 1 1 2 1 1 1 1 1 1 1
 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2]
predicted label:tf.Tensor(
[2.70286202e-03 1.26708090e-01 7.11246248e-05 5.87023139e-01
 1.22431219e-02 2.81929135e-01 9.04216766e-02 3.85107994e-02
 8.38332415e-01 1.07465476e-01 3.21240723e-02 2.26706266e-04
 1.33572429e-01 5.29401243e-01 4.90430295e-02 3.63411248e-01
 4.54185307e-01 3.34371984e-01 3.98220003e-01 1.96605027e-02
 1.88879192e-01 3.27825546e-04 1.13629162e-01 5.09213567e-01
 9.67919827e-03 1.18326634e-01 3.72917652e-01 5.25822043e-02
 3.52901280e-01 1.80714607e-01 3.56211483e-01 2.76107669e-01
 2.92456269e-01 1.99127704e-01 1.43402815e-03 3.20944399e-01
 2.25095659e-01 1.79118574e-01 2.21919835e-01 2.60391414e-01
 3.17352742e-01 7.72791505e-02 2.20693767e-01 9.39833283e-01
 1.44287050e-02 2.15130776e-01 1.43886805e-02 2.39243150e-01
 2.00960606e-01 3.13597918e-03 5.77419996e-04 2.46386826e-02
 2.75901258e-02 2.59799063e-02 2.94737816e-02 3.78282368e-02
 5.09599447e-02 3.53488922e-02 1.82602912e-01 1.28444195e-01
 3.73897552e-02 9.72196460e-03 6.60189986e-03 3.32479477e-02
 9.12699461e-01 8.18998873e-01 5.11344552e-01 5.00479102e-01
 5.06738722e-01 4.40513730e-01 3.97341996e-01 4.29581523e-01
 5.18063247e-01 8.02212477e-01 6.92738891e-01 4.76956844e-01
 4.44905907e-01 3.72243464e-01 3.18679512e-01 5.14086008e-01
 6.86033249e-01 9.79032159e-01 5.47116637e-01 9.35856283e-01
 7.53753304e-01 4.71701860e-01 4.83346552e-01 4.39503223e-01
 4.65902805e-01 4.42421943e-01 4.50176716e-01 4.81806964e-01
 4.67842072e-01 4.82958525e-01 4.78182435e-01 4.74170595e-01
 5.90150595e-01 4.86377388e-01 4.48530912e-03 1.25320494e-01
 1.36816531e-01 9.97315049e-02 7.29672611e-02 1.86830759e-04
 5.56052029e-02 9.80560184e-02 6.75201416e-04 9.90724564e-02
 6.08469427e-01 1.35655105e-02 1.33492112e-01 7.31903315e-03
 3.91151698e-05 3.25682759e-03 3.08960855e-01 2.48476135e-05
 2.78638422e-01 1.95299071e-06 7.90706277e-03 9.78043079e-01
 2.38808423e-01 1.11453056e-01 7.89434910e-02 2.93343782e-01
 5.02493501e-01 3.22145075e-01 4.48597968e-01 2.83135772e-01
 2.27670163e-01 3.66955698e-01 4.56138551e-01 5.48969626e-01
 1.45282805e-01 4.45915937e-01 3.14445645e-01 5.62124074e-01
 3.48363072e-01 3.56310487e-01 8.66359472e-01 4.75146025e-01
 3.12863946e-01 3.21002156e-01 3.63264829e-01 3.44506800e-01
 3.52802515e-01 3.95396352e-02 1.91221416e-01 1.11764193e-01
 3.60411704e-01 3.84240776e-01 3.74467373e-01 2.25802213e-01
 2.58752286e-01 9.91742849e-01 1.00693107e-03 2.95809507e-02
 6.86877966e-03 9.71704721e-04 8.27097297e-02 6.33220732e-01
 1.06461495e-01 2.00510025e-04 6.24150038e-04 8.90023708e-01
 1.34671688e-01 5.15285134e-02 5.20705581e-01 6.94081426e-01
 5.69084287e-03 4.23146417e-07 4.15470481e-01 9.12443995e-02
 2.59900361e-01 2.32186168e-01 3.23066592e-01 2.64556825e-01
 6.71578164e-05 1.40630484e-01 3.82559299e-02 4.33012337e-06
 2.69946456e-03 4.34557885e-01 3.64590317e-01 1.54719830e-01
 2.76069462e-01 3.46877098e-01 6.71739617e-05 1.48352027e-01
 2.18215585e-02 2.74938822e-01 9.52256620e-02 1.04251057e-01
 9.76605117e-02 4.92856055e-01 7.47791873e-09 8.38532925e-01
 1.63400173e-03 1.25358994e-11 3.98121992e-05 6.73401473e-07
 1.04914579e-06], shape=(201,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0.
 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0.], shape=(201,), dtype=float32)
predicted label rank:[1 1 1 2 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 2 2
 2 1 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1]
mse:tf.Tensor(0.3060194, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/metros_4_e3_1091_e3_522_000.smt2
true label:[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 2 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1
 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1
 1 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 1 2 2 1 1 1 1 1 2 1 1 1 1 1 1 2 2 2 2 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1
 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1
 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 2 2 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 2
 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 2 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 2 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[3.80816460e-01 1.36734843e-01 6.57468140e-02 1.06028110e-01
 3.81530881e-01 3.75099480e-01 3.90731514e-01 1.86697215e-01
 2.50677168e-01 1.35633737e-01 4.70434785e-01 1.57931238e-01
 5.12678298e-06 1.15564466e-03 5.27263582e-02 2.36680806e-02
 1.57884657e-02 1.89347267e-02 6.73619215e-05 1.54937006e-05
 1.29368901e-03 8.00826529e-05 1.47044659e-04 1.07148290e-03
 2.86706388e-02 1.15160674e-01 9.81656909e-02 5.45092821e-02
 1.20999813e-02 1.62683725e-02 5.68440855e-02 3.14977884e-01
 1.34379316e-05 2.24782825e-02 6.48262203e-02 6.36920035e-02
 2.70208031e-01 1.09138700e-05 5.74527085e-02 4.43992227e-01
 4.71729338e-02 1.86676681e-02 3.26072295e-05 2.48364508e-02
 9.18652677e-06 1.47998333e-04 5.22575901e-05 1.95148587e-03
 1.00731850e-03 1.20618939e-03 1.20982528e-03 5.56081533e-04
 1.07902288e-03 5.16927242e-03 4.96026278e-02 6.77472353e-02
 6.33068681e-02 1.52111053e-04 7.74639249e-02 9.70870256e-04
 4.63536680e-02 4.24682200e-02 3.75071168e-02 7.16457665e-02
 5.49038947e-02 4.02707458e-02 5.90571165e-02 3.32899392e-02
 8.10290873e-02 9.33599234e-01 9.92143631e-01 6.91180825e-02
 5.04727662e-02 3.04609537e-04 9.98715520e-01 2.13889416e-06
 1.76485883e-05 8.49590151e-07 6.20706487e-06 2.27063894e-04
 5.19770692e-05 2.34736012e-06 1.23882890e-02 8.54864717e-03
 5.46595454e-03 3.21627740e-05 2.67145038e-03 4.84190859e-05
 2.22642124e-02 5.27739525e-03 6.10718131e-03 2.60970294e-02
 3.16837430e-03 5.47050834e-02 1.67106092e-02 4.52616811e-03
 7.11449981e-03 9.29191232e-01 9.93644893e-01 1.59427226e-02
 2.07332671e-02 3.71543429e-05 9.99741673e-01 1.75595284e-03
 1.30093396e-02 2.69015729e-02 1.03009152e-04 2.12629110e-01
 3.41683924e-02 5.05236983e-02 4.11197543e-03 7.89435804e-02
 8.34035873e-03 8.17736089e-02 9.37178731e-03 2.55688041e-01
 1.82321668e-03 3.33112866e-01 2.77694881e-01 2.39020586e-01
 2.35694230e-01 1.86057985e-01 3.16735178e-01 2.50513554e-01
 3.63698542e-01 7.30606914e-03 3.45708549e-01 1.30057335e-04
 5.71805239e-03 2.95769840e-01 4.64707613e-04 7.84149766e-03
 1.85402930e-02 6.18025959e-01 9.80940461e-02 1.43921316e-01
 1.31220222e-01 1.47835314e-02 2.53134370e-01 1.91420913e-01
 2.29017586e-01 2.16597885e-01 2.58851081e-01 2.32475221e-01
 2.49343276e-01 3.30793679e-01 3.18152398e-01 2.61293411e-01
 2.26512522e-01 8.15147796e-05 4.00899116e-05 1.16890669e-03
 1.06966496e-03 2.42424640e-08 2.14302540e-03 1.40696884e-05
 9.05577617e-05 3.36845070e-01 8.24630857e-02 2.21213132e-01
 3.25578153e-01 5.44803739e-02 9.11959410e-02 8.50561857e-02
 1.04783297e-01 2.36040294e-01 5.91366589e-02 2.62432039e-01
 2.89514264e-05 3.86688498e-06 7.36581278e-05 1.88648701e-04
 3.18658749e-06 2.07692385e-04 1.80989504e-04 3.66492714e-05
 2.90139943e-01 1.97290152e-01 3.19094896e-01 2.83766866e-01
 3.17372441e-01 2.92395920e-01 2.78603971e-01 2.60501921e-01
 2.68781483e-01 2.61898220e-01 3.04922163e-01 8.03989172e-03
 9.30064917e-03 4.82220709e-01 5.05983829e-04 1.10268593e-03
 4.16195571e-01 1.15308166e-02 1.70931220e-03 4.79814231e-01
 4.77599144e-01 5.13040721e-01 4.50193107e-01 4.83513653e-01
 5.01623988e-01 4.91679013e-01 4.73801762e-01 4.88101453e-01
 4.60221350e-01 4.74049747e-01 5.60364127e-03 3.93162054e-06
 6.28966212e-01 5.17474174e-01 6.93860650e-03 2.01166421e-01
 1.22225165e-01 2.32533455e-01 1.96197718e-01 1.52324557e-01
 1.75740868e-01 3.90556753e-02 1.19891763e-02 3.30654532e-01
 1.71610134e-06 6.13217831e-01 1.34665370e-02 5.01632690e-03
 1.90153837e-01 7.54684508e-02 3.49788964e-01 3.67216527e-01
 2.51264453e-01 3.74018013e-01 3.48964036e-01 3.72177362e-01
 3.86090934e-01 8.14200044e-02 3.66519600e-01 2.65365243e-01
 2.89967626e-01 2.80539870e-01 7.42107630e-04 7.47984529e-01
 1.39327586e-01 6.87005043e-01 7.14679241e-01 3.25509906e-03
 6.31266534e-02 2.34257877e-01 8.28095675e-02 5.37067652e-04
 1.07934624e-01 1.12086058e-01 5.34261465e-02 1.01393789e-01
 6.59616351e-01 2.32719958e-01 9.83394086e-02 1.66370481e-01
 4.74723577e-02 1.04032516e-01 1.36991948e-01 2.02864558e-01
 1.67221636e-01 1.10673904e-02 2.25479305e-02 1.31485164e-01
 6.90688491e-02 1.07602835e-01 1.28282130e-01 1.05582625e-01
 2.07228333e-01 1.84861094e-01 1.97435051e-01 8.10631812e-02
 2.40405917e-01 1.10207886e-01 1.01188362e-01 4.37752008e-02
 2.29407519e-01 9.15687382e-02 6.05284870e-02 9.73650694e-01
 2.37355024e-01 1.23145640e-01 4.57668304e-03 1.20863497e-01
 1.10989928e-01 1.99319452e-01 1.20404959e-01 1.25911832e-03
 1.70500100e-01 8.60163569e-03 2.06157833e-01 8.43707621e-02
 1.53144181e-01 1.06477052e-01 1.48049802e-01 1.51509792e-01
 1.65951312e-01 2.02521682e-03 1.49179995e-02 2.06826201e-07
 7.82343579e-10 1.89409141e-10 1.20102209e-06 3.48047683e-06
 9.94136453e-01 1.54673427e-01 2.02586919e-01 1.24514997e-01
 1.84436858e-01 3.69237155e-01 3.13773602e-01 1.64118528e-01
 1.83550894e-01 6.40487552e-01 1.88350081e-01 1.65299505e-01
 1.97888196e-01 2.98560053e-01 1.97829127e-01 2.58855224e-02
 9.40498650e-01 2.30602980e-01 1.49986356e-01 2.74590373e-01
 1.69106930e-01 1.80707693e-01 1.23429239e-01 5.36732674e-02
 1.83699936e-01 3.23042572e-01 1.80038512e-01 1.84916079e-01
 3.30303162e-01 1.07935667e-02 1.16428107e-01 1.37032658e-01
 3.10781598e-03 1.00380540e-01 8.27735662e-03 4.11421061e-04
 1.76638365e-04 1.72954798e-03 5.91802597e-03 2.15363503e-03
 1.63432956e-03 2.38540769e-03 1.87236071e-03 1.55749917e-03
 9.23961401e-03 2.54878402e-03 2.72861123e-03 4.42945957e-03
 1.50948658e-08 5.64861402e-09 5.26659640e-08 1.75505877e-04
 1.12814307e-02 4.05782231e-07 2.73454189e-03 9.71816348e-07
 1.25526149e-05 9.45766399e-09 2.09175706e-01 2.74529099e-01
 2.83061624e-01 3.12143117e-01 1.64075047e-01 5.57498038e-02
 2.56462336e-01 1.01590484e-01 2.63770401e-01 3.12968135e-01
 2.09787935e-01 1.25685347e-05 1.99213624e-03 8.47941637e-03
 4.54157591e-04 3.29778075e-01 3.23265791e-04 2.41950244e-01
 2.40696522e-07 1.06328691e-04 4.75370996e-08 1.15760177e-01
 1.33603364e-01 8.05741549e-03 9.97373044e-01 1.55106246e-01
 1.87011063e-01 7.13894665e-02 1.67255580e-01 3.37153673e-04
 1.00218087e-01 6.26255274e-02 1.62924379e-01 3.00787747e-07
 4.72915490e-05 1.39103502e-01 2.62032181e-01 2.00986207e-01
 1.56512529e-01 4.80175018e-04 9.02820826e-02 1.52593732e-01
 1.22277200e-01 3.44441235e-01 1.08967884e-04 1.00295842e-01
 3.25385273e-01 9.99495029e-01 9.97934580e-01 2.09478736e-02
 1.80951327e-01 9.06071067e-03 1.61480814e-01 6.53110147e-02
 1.41755641e-02 6.11885965e-01 2.36980140e-01 2.99425364e-01
 1.17353290e-01 1.24214113e-01 7.01250136e-02 5.35708070e-02
 1.44538283e-03 1.87416375e-02 4.53732610e-02 5.78451157e-03
 4.75052297e-02 1.32152438e-03 7.85488188e-02 2.47220993e-02
 1.18520260e-02 3.81036878e-01 9.99922335e-01 9.99664009e-01
 4.25577164e-04 1.36512130e-01 7.00754821e-02 1.56759113e-01
 1.73220217e-01 1.52368426e-01 1.65072262e-01 1.86211854e-01
 2.46098876e-01 3.27854872e-01 2.93705821e-01 2.53201902e-01
 1.85026586e-01 2.19448239e-01 3.10995400e-01 1.39415383e-01
 2.44772315e-01 1.93827212e-01 1.90808684e-01 2.44469911e-01
 2.51235127e-01 1.10139728e-01 1.66451395e-01 7.60709668e-07
 7.57192969e-02 2.56618857e-03 9.82499301e-01 1.01622850e-01
 2.15819478e-03 3.78259391e-01 3.58156562e-02 7.13574886e-02
 4.05540168e-02 5.97551167e-02 4.38365638e-02 4.81476784e-02
 2.02402472e-03 7.25433230e-03 5.52746058e-02 2.67895460e-02
 2.89696455e-02 2.58913934e-02 6.87494278e-02 3.91035684e-07
 2.00136602e-02 1.45016611e-02 3.98239195e-02 9.71518159e-02
 2.49188244e-02 7.40739405e-02 1.52263165e-01 1.92326874e-01
 9.68353570e-01 1.68749839e-01 3.45587730e-03 9.31099772e-01
 2.87766397e-01 1.96352780e-01 9.74117219e-02 1.25040948e-01
 4.56556082e-02 8.73962641e-02 3.66836786e-04 4.32193279e-03
 5.22864759e-02 6.93057775e-02 2.13319957e-02 4.50882018e-02
 9.13342237e-02 1.14873648e-02 1.12068444e-01 1.30043179e-01
 6.28568828e-02 4.78618145e-02 9.97747481e-02 1.36488616e-01
 1.02445066e-01 1.05948402e-06 1.71884094e-05 9.92638946e-01
 1.54814234e-11 4.24856017e-09 3.20846354e-08 3.50872142e-06
 1.63382865e-05 9.84455824e-01 1.43183127e-06 9.96301532e-01
 2.34037638e-04 3.23742628e-04 7.67184927e-11 2.51482277e-07
 3.15709764e-10 1.06072053e-04 2.69204378e-04 1.14815603e-05
 6.47510916e-08 4.69669703e-06 3.34024429e-04 2.10817205e-07
 2.88464071e-06 1.56509876e-03 1.22162655e-05 1.29145692e-05
 1.92572297e-05 1.19463773e-04 6.76156060e-06 2.78711319e-04
 1.37209892e-04], shape=(545,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(545,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.083609216, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0000_000.smt2
true label:[1, 1]
true label rank:[1 1]
predicted label:tf.Tensor([0.93332326 0.37123302], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 0.], shape=(2,), dtype=float32)
predicted label rank:[2 1]
mse:tf.Tensor(0.19989687, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0276_000.smt2
true label:[1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 2 2 2 2 1 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 1 1 2 2 2 2 2 1 1 2 2 2 2 2 2 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2
 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[9.99955475e-01 9.99977350e-01 1.00000000e+00 1.00000000e+00
 1.00000000e+00 9.85548854e-01 8.35357785e-01 8.32128346e-01
 9.97209072e-01 9.99391079e-01 9.99993622e-01 9.85297680e-01
 9.98922110e-01 1.00000000e+00 7.85833597e-03 5.62652946e-03
 8.44815552e-01 9.62080061e-02 2.15368271e-02 1.38220072e-01
 1.45100713e-01 4.56207097e-02 7.58247375e-02 1.23136610e-01
 6.99375153e-01 6.30602837e-01 8.15940857e-01 9.28951144e-01
 9.43678617e-03 9.77012813e-02 8.83787692e-01 9.79214609e-01
 9.87785101e-01 3.21338356e-01 9.48543787e-01 9.81747150e-01
 4.70666081e-01 9.93339539e-01 5.79565763e-04 1.11192465e-03
 1.07416511e-03 6.38097788e-07 1.04661203e-05 3.03715467e-03
 5.64537804e-05 1.23065383e-05 4.38984353e-06 5.34634892e-05
 2.92420387e-04 1.78927294e-05 5.06326556e-03 1.57076265e-05
 7.00619817e-03 1.41921341e-02 6.07708097e-03 7.86542892e-03
 2.10487843e-03 4.85497415e-02 1.62456632e-02 6.71061873e-03
 3.09407711e-04 1.26752257e-03 1.06719136e-03 6.92218542e-04
 3.10662985e-02 2.30354071e-03 2.05045938e-03 8.08775425e-04
 9.51442122e-03 3.51905823e-04 1.51908398e-03 9.37929749e-03
 6.26653433e-04 5.06141782e-03 7.75909430e-05 4.77105379e-04
 8.06897879e-04 2.15476648e-05 1.59724951e-02 2.27168202e-03
 4.48793173e-04 9.81723933e-05 1.41814351e-03 2.49624252e-04
 1.85558200e-03 2.28640437e-03 2.55485684e-05 9.85825062e-01
 1.00000000e+00 9.21839595e-01 9.30208206e-01 8.82982612e-01
 2.64529586e-02 9.37994719e-01 9.63500440e-01 9.78289962e-01
 9.73916471e-01 9.57646608e-01 9.61786807e-01 5.02191424e-01
 9.73323286e-01 9.81886983e-01 9.77220297e-01 9.91553247e-01
 8.63776147e-01 9.89030480e-01 1.39055997e-01 9.67571437e-01
 9.91162419e-01 9.95421171e-01 9.97787774e-01 9.73881125e-01
 9.96779919e-01 1.39025688e-01 9.81907904e-01 9.80689883e-01
 7.45085239e-01 9.45418119e-01 8.94708276e-01 9.75878954e-01
 3.23527873e-01 9.87048626e-01 9.98355269e-01 9.94984150e-01
 9.94120598e-01 9.94646847e-01 9.86826658e-01 6.15133762e-01
 9.93477821e-01 9.96860683e-01 9.95511889e-01 9.91829395e-01
 9.92408931e-01 9.97161150e-01 5.34618497e-01 9.95058775e-01
 1.44100368e-01 4.97492641e-01 2.03222364e-01 4.73396182e-02
 1.93472534e-01 2.07793176e-01 5.73458970e-02 9.94543135e-02
 2.05193222e-01 2.22411454e-02 3.12488377e-02 2.98082829e-03
 9.60648656e-02 5.09154797e-03 4.51281369e-02 1.54849678e-01
 4.98435259e-01 1.66640580e-02 9.79129374e-02 5.94860315e-02
 2.67371535e-03 1.44703031e-01 1.11811757e-02 5.83734989e-01
 1.92301422e-01 2.57063538e-01 2.27036268e-01 2.00548768e-03
 6.64472580e-04 2.83032656e-04 3.56614590e-04 1.44889951e-03
 2.30890512e-03 2.82827020e-03 3.32634481e-05 2.85304278e-01
 7.11504340e-01 8.00937653e-01 7.12381959e-01 5.76791823e-01
 3.05709213e-01 3.41832638e-04 2.67747045e-03 1.68710947e-04
 6.88225031e-04 6.33358955e-04 8.95947218e-04 2.84537673e-03
 2.33909488e-03 9.10456777e-02 1.54267251e-02 5.37098467e-01
 1.67853832e-02 2.28404403e-02 6.34185672e-02 4.75960970e-02
 1.86115503e-04 1.01415189e-05 3.45001245e-05 1.59591436e-04
 1.42991543e-04 7.34388828e-04 6.57320023e-04 1.51917338e-03
 3.15904617e-04 2.98053026e-04 4.75376844e-04 8.44299793e-04
 3.93676758e-03 6.24477863e-04 4.49806452e-04 9.35265125e-05
 1.15912553e-04 4.10902358e-05 1.71899796e-04 1.78945065e-03
 8.54462385e-04 8.86211216e-01 8.21163177e-01 8.52908373e-01
 7.45999098e-01 2.57916749e-02 9.63343978e-02 8.39731157e-01
 4.45637107e-03 3.63090336e-02 1.27601624e-03 1.93139911e-03
 2.33176351e-03 4.11161780e-03 8.70943069e-04 3.36644053e-03
 9.97364521e-04 5.58140874e-03 2.20805407e-04 2.55078077e-03
 3.62636745e-02 4.63812721e-05 2.78532505e-04 1.72576308e-03
 2.72005796e-04 8.63164663e-04 5.17964363e-04 7.59074092e-03
 1.56372786e-04 1.32071972e-03 8.47992301e-03 6.73171878e-03
 1.56199932e-03 1.40607357e-03 8.69101286e-03 4.80392575e-03
 1.25560164e-03 5.95581532e-03 8.14706087e-04 1.43527985e-03
 5.54621220e-04 2.75962353e-02 4.53859568e-04 2.77638435e-04
 7.43413257e-05 5.32627106e-04 8.73416662e-04 1.99398398e-03
 5.53742051e-03 8.50230455e-04 1.32402611e-05 2.98650884e-05
 1.13242881e-04 1.11601621e-05 2.34906329e-05 4.16904688e-04
 5.73992729e-04 1.25142932e-03 1.60050392e-03 2.86659598e-03
 3.66187096e-03 5.30898571e-04 2.09316611e-03 5.50508499e-04
 2.86733812e-05 7.19528316e-06 3.56850433e-05 1.72479486e-05
 4.22943485e-05 5.12946572e-05 1.74014713e-05 1.24424696e-04
 2.78383493e-04 2.05188990e-04 1.60753727e-04 2.70605087e-04
 1.19122863e-03 1.84714794e-04 3.75688076e-04 9.26571956e-05
 1.04448199e-03 6.40894650e-05 2.43544579e-04 8.08727741e-03
 2.10136175e-04 2.21621449e-05 1.01491773e-04 2.01255083e-04
 1.25885010e-04 3.48806381e-04 1.97574496e-03 1.08679833e-05
 1.71465290e-05 1.31253205e-06 1.97274039e-05 3.87464970e-05
 3.52554252e-06 3.83591652e-03 6.34702701e-07 3.22515116e-05
 7.48462253e-06 1.13965732e-04 3.26280715e-05 1.21175981e-04
 4.19884920e-04 2.87628845e-05 6.50998118e-06 3.25785254e-06
 3.96745554e-06 4.67230939e-06 1.23473478e-06 3.42726707e-04
 9.27042583e-06 2.45120355e-05 3.76055527e-06 1.04283790e-05
 1.88363047e-05 7.30093961e-05 3.04192305e-04 2.31172157e-06
 6.54569376e-05 2.93308108e-06 3.10147175e-06 2.24152172e-05
 4.53728990e-06 9.88374013e-05 3.29703093e-04 5.14385556e-06
 1.01227874e-06 1.13926553e-05 1.70435906e-05 6.79435880e-06
 2.74218764e-05 3.78680743e-05 2.83794088e-05 9.15319106e-06
 7.40725445e-05 3.17767008e-05 2.53766775e-04 6.34074211e-04
 2.79895648e-05 4.52141558e-06 1.07080086e-06 3.77568249e-05
 2.83181667e-04 2.12462164e-05 2.92718410e-04 3.51698109e-05
 1.83804405e-05 5.43368571e-07 1.87636988e-06 6.39102973e-06
 2.98173054e-05 8.52421799e-05 2.28881836e-04 6.91445757e-06
 3.77207252e-05 1.32518071e-05 1.16138166e-04 1.34766102e-04
 2.30193138e-04 3.02181943e-05 1.98811293e-04 5.38021377e-05
 2.66566312e-05 1.19734432e-04 7.33784100e-06 1.59502029e-04
 2.80084407e-07 1.10456108e-06 9.25946892e-08 1.25202623e-05
 1.78784262e-06 3.99885295e-07 3.22380438e-05 1.34825706e-04
 1.13902115e-05 2.99142721e-06 5.02236026e-06 8.79533331e-07
 7.25021209e-07 2.67922187e-05 1.62701735e-06 4.03391539e-07
 5.84615736e-05 9.27461369e-05 2.09748745e-04 1.04905077e-04
 4.85509634e-04 8.33421946e-04 2.87628845e-05 6.16835750e-05
 7.99241097e-05 5.78119470e-05 3.55601311e-04 4.70012426e-04
 4.43293829e-05 1.31177694e-05 2.43277168e-06 3.19884130e-05
 9.22163338e-07 3.83017914e-06 5.42049820e-05 6.69918222e-07
 1.44359883e-05 2.96294689e-04 3.19157989e-05 1.41510367e-03
 3.43248103e-05 7.27713108e-04 1.86055899e-04 1.20526878e-04
 9.53808012e-07 2.60431043e-05 1.58911007e-05 1.04752771e-05
 3.52382660e-04 2.84390408e-05 9.11775805e-06 6.77169237e-06
 1.25869947e-05 6.80388112e-05 7.78949252e-05 1.36882067e-04
 3.84133934e-08 1.23177988e-05 1.23207656e-06 1.39760759e-05
 4.47056154e-05 7.29682233e-06 2.18480825e-04 2.21644470e-07
 4.27489522e-06 1.21348003e-05 4.15071241e-07 8.28420070e-06
 2.94672100e-06 9.39606471e-05 2.85160446e-08 1.43035804e-05
 6.53615571e-05 1.33667390e-05 7.06344217e-05 2.25514174e-04
 1.50781870e-03 2.19273955e-09 5.48116222e-05 1.02479889e-05
 7.78044923e-05 4.48780020e-06 3.60572540e-06 1.16926432e-03
 1.74578217e-05 3.29198400e-07 1.44494315e-05 2.85029411e-04
 2.87530384e-05 8.15585918e-06 3.80992889e-04 1.71691179e-04
 3.58274083e-05 5.10926802e-05 1.09630302e-04 2.31363701e-05
 4.60242809e-05 1.12683119e-04 9.37934092e-05 1.83198026e-05
 2.08374240e-05 5.66509043e-05 1.73555636e-05 2.04443932e-04
 9.80600162e-05 1.18764699e-04 4.12838417e-05 5.86325405e-05
 7.73697175e-05 7.45711004e-05 6.91175461e-04 3.04520130e-04
 1.21938247e-05 2.29435827e-05 5.44688737e-06 2.72631787e-05
 1.63229306e-05 3.07482624e-05 2.22055987e-05 1.92314386e-04
 8.92797179e-05 7.69966300e-06 1.05422132e-05 4.19468488e-05
 1.34252241e-05 1.21501842e-04 2.05904245e-04 7.05870248e-16
 1.93160281e-26 6.57233379e-09 6.06143475e-03 3.66283182e-08
 1.63412094e-03 6.44898591e-06], shape=(514,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.
 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.
 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(514,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 1 1 1 1 1 1 1 2 2 2 2 1 1 2 2 2 1 2 2 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2
 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1
 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.028103182, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0018_000.smt2
true label:[1, 1]
true label rank:[1 1]
predicted label:tf.Tensor([0.74196875 0.9424299 ], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.03494722, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/nested6.c_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.9863095  0.9831115  0.9772196  1.         0.97229147 0.9968791
 0.9998993  0.97657514 0.9618592 ], shape=(9,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(9,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.00041917263, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/gulwani_fig1a.c_000.smt2
true label:[1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1]
predicted label:tf.Tensor([0.97179395 0.81559676 0.99928594 0.99261343 0.94890845 0.9475553 ], shape=(6,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1.], shape=(6,), dtype=float32)
predicted label rank:[1 1 1 1 1 1]
mse:tf.Tensor(0.0067026666, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/traverse3_unsafe.c_000.smt2
true label:[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[3.60141397e-02 4.01920080e-03 1.50680542e-04 9.99940276e-01
 2.04415846e-05 8.25852156e-04 1.35022402e-03 7.85350800e-04
 8.78956020e-02 2.26327777e-03 2.40057707e-03 9.30696726e-04
 9.73194838e-04 2.29579210e-03 2.17920542e-03 2.08012480e-05
 5.42056550e-05 7.56693989e-05 8.56624774e-06 1.48201752e-05
 9.54417701e-05 2.18659639e-03 4.20560991e-06 2.94297934e-04
 8.80044718e-06 1.09038310e-05 3.41439247e-02 1.07307732e-02
 5.29319048e-04 1.94674358e-05 8.70307213e-06 1.10528927e-04
 1.18500189e-04 5.51101120e-09 7.33947161e-08 6.16418123e-02
 6.64422203e-07 4.69058752e-04 1.21898947e-05 4.91982698e-03
 4.75117446e-07 1.81867222e-07 2.51995317e-07 1.30629396e-05
 3.43044235e-07 1.11775400e-04 6.93023205e-04 5.14268875e-04
 3.49372625e-04 7.05079001e-05 9.85145569e-04 9.76816227e-05
 6.94423914e-04 1.44386292e-03 1.92791224e-04 2.59190798e-04
 3.50028276e-04 2.55495310e-04 1.26904249e-03 1.04999542e-03
 4.56303358e-04 7.49006358e-06 6.32161914e-07 6.48402010e-06
 9.15694045e-07 9.99993205e-01 2.27119297e-01 9.69456673e-01
 9.99987483e-01 7.41571188e-04 3.29632894e-05 2.59090364e-02
 1.76462327e-05 1.75410211e-02 1.32378936e-03 3.63090634e-03
 1.26597881e-02 5.21451235e-04 2.40628719e-02 6.39808178e-03
 1.14017725e-02 4.57353271e-05 1.73419714e-04 3.11765075e-03
 3.14146280e-04 1.83373690e-04 6.13341672e-06 6.36547804e-04
 7.48966336e-02 8.16936904e-07 8.89116526e-03 9.39914584e-03
 4.92423773e-04 1.62523985e-03 3.32230330e-03 2.53677368e-04
 4.78112698e-03 8.48688185e-02 4.63864207e-03 3.49115431e-02
 2.10897624e-02 1.65048242e-03 8.50528479e-04 4.49615717e-03
 1.44845247e-03 1.20105684e-01 1.69282782e-06 9.68581140e-02
 7.22292066e-03 3.26197951e-05 4.44978476e-04 1.92552805e-04
 3.43013489e-05 2.00164318e-03 5.30317426e-03 1.80519564e-05
 8.02622111e-08 3.91701320e-08 1.47226453e-03 1.29448163e-05
 6.71405942e-05 1.48891297e-06 4.25487757e-04 1.30736325e-07
 3.83646693e-06 1.05821171e-04 3.59544647e-05 1.45712545e-06
 3.55988741e-04 3.83580846e-06 8.23430582e-07 2.46666764e-06
 5.75840473e-04 7.78181553e-02 1.95125937e-02 5.91132939e-01
 9.47518051e-02 7.54367709e-02 1.79827213e-04 4.83651757e-01
 1.40236020e-02 8.77839327e-03 2.02009082e-03 2.94923782e-04
 6.48412108e-03 8.16971064e-04 5.16355038e-04 1.93119049e-04
 1.18169188e-03 6.13987446e-04 1.72871351e-03 1.27935410e-03
 1.15230680e-03 1.25900179e-09 1.38047338e-03 3.03335582e-06
 3.18786260e-05 2.91831566e-06 3.95536423e-04 6.00779057e-03
 1.48147345e-03 2.75570154e-03 1.03387237e-03 2.46644020e-03
 1.17604434e-02 2.99379230e-03 7.38382339e-04 6.31443620e-01
 2.91705132e-04 4.22577614e-06 1.21867657e-03 1.27455592e-03
 1.81511678e-05 4.61876392e-04 2.55495310e-04 1.55776739e-04
 1.23935938e-03 8.06927681e-04 7.95125961e-04 8.36885301e-05
 5.94407320e-04 6.07788563e-04 5.95637066e-05 9.80168581e-04
 2.01135874e-04 4.96655703e-04 2.21848488e-04 2.17238069e-03
 2.45500742e-05 3.99918863e-05 5.85565158e-06 4.17083502e-04
 1.47831440e-02 7.01218843e-04 8.31397920e-05 5.17916679e-03
 1.49935484e-04 7.39732385e-03 6.75916672e-04 2.03564763e-03
 8.93026590e-04 1.29938126e-04 2.08958983e-03 5.07285404e-05
 1.36908889e-03 9.30964947e-04 1.38517618e-02 8.67534909e-05
 2.52078358e-08 4.11863721e-06 5.48683090e-07 4.92851466e-01
 7.97643588e-05 8.94531131e-01 2.60233879e-04 1.20627970e-01
 2.90006399e-04 5.53503036e-01 1.38998032e-04 1.93208456e-03
 8.25465406e-07 4.98459876e-01 6.41452289e-07 1.63346529e-03
 2.87443399e-04 9.16622885e-05 4.60177660e-04 9.86551214e-08
 8.01288770e-05 1.88634193e-08 2.34477047e-05 2.20892935e-06
 4.62128537e-06 5.04279107e-08 1.97247579e-10 2.32776383e-05
 5.59497379e-11 3.81335106e-08 4.07036669e-06 1.05955601e-02
 4.64865525e-06 1.58581727e-07 3.86422130e-07 1.27051408e-06
 2.15233165e-08 4.29165902e-06 3.99291515e-04 4.39316034e-04
 2.06658244e-03 9.18928683e-02 2.26724148e-03 1.48624182e-04
 3.08632851e-04 1.35825176e-05 3.23107839e-03 5.05572557e-03
 3.32759498e-07 7.07976938e-07 7.69972801e-04 2.02819705e-03
 3.98191810e-03 7.46369362e-04 1.15647912e-03 1.58101320e-04
 1.18924081e-02 2.24322081e-04 3.41531634e-03 1.58607960e-04
 1.16907656e-01 7.83752876e-06 9.27531719e-02 4.37350318e-05
 1.02960765e-02 2.32175417e-08 1.80009057e-08 1.21849494e-04
 1.54167414e-04 2.19604373e-03 3.27020884e-04 1.24413127e-05
 1.10498360e-04 1.14720766e-04 1.08269611e-04 1.60497427e-03
 1.05017126e-02 2.14496255e-03 1.45199895e-03 4.52426076e-03
 4.36693430e-04 8.34391713e-01 9.44787085e-01 1.05857247e-07
 1.66306218e-05 5.98157931e-06 4.71369913e-06 8.36099446e-07
 3.35765253e-05 3.62336636e-04 2.37737000e-02 6.33448362e-03
 1.96180627e-05 1.15414796e-05 1.53243542e-04 1.51518225e-06
 5.71491761e-08 5.00332824e-08 1.27553940e-04 2.69234180e-04
 4.45128971e-05 1.03259817e-05 9.56208224e-10 1.42635713e-07
 7.01836962e-06 2.43848126e-06 3.39169401e-06 4.03046608e-04
 7.55959354e-06 1.31192382e-06 6.15472454e-05 2.36788392e-03
 6.81549311e-04 3.64089012e-03 6.48051500e-04 1.93341672e-02
 1.49029493e-03 2.57632136e-03 4.83304262e-04 1.17573974e-04
 5.70061803e-03 2.88677216e-03 1.83579326e-03 3.89467750e-05
 1.24156475e-04 4.95430650e-05 5.82941902e-06 8.25895768e-06
 1.36241233e-05 5.68540827e-07 6.64279938e-08 7.33284253e-07
 6.01236794e-09 7.46185151e-06 3.92348738e-05 1.04372994e-04
 1.76403930e-07 7.22039040e-05 4.27359055e-06 5.46923280e-03
 1.91707468e-08 4.21108603e-01 2.09655715e-09 5.04052043e-01
 6.63979982e-11 9.99703098e-11 1.24272115e-09 1.01530552e-02
 4.86817953e-07 2.80686829e-09 5.96650170e-05 6.27696517e-09
 1.21539852e-04 6.49495513e-10 6.36818065e-09 1.70260668e-04
 1.24608869e-06 1.21952553e-05 2.79188156e-03 2.58717353e-10
 1.30304694e-03 1.94399220e-07 3.40332444e-05 1.67387249e-09
 4.85440614e-05 2.78655676e-08 2.92832124e-06 1.68650549e-05
 2.09157647e-09 1.97582402e-13 2.03883133e-09 6.91488533e-10
 7.00846282e-12 1.07271330e-06 1.26082209e-11 2.71774479e-06
 5.86232818e-06 8.75817022e-07 5.83551753e-07 1.32176280e-03
 8.73018871e-06 1.05029345e-03 2.59393454e-03 3.73883495e-06
 3.47443252e-09 2.71692304e-08 6.94761297e-08 2.74662231e-08
 2.93357459e-07 3.32002237e-05 6.06285084e-06 1.41412020e-04
 3.32343220e-08 5.28935061e-07 1.25506995e-05 2.93850899e-04
 2.34552954e-06 6.89387321e-04 1.84983015e-04 4.14512533e-06
 4.78199945e-05 5.89162111e-04 3.87951732e-03 1.45310163e-03
 1.09594284e-05 1.16773430e-04 1.24454498e-04 2.73764499e-06
 1.38934104e-06 1.17488996e-08 9.08094222e-09 3.26270163e-01
 1.20393597e-08 2.83096015e-01 4.39473595e-08 6.55432642e-02
 2.55192390e-06 2.89887190e-04 5.27157397e-07 2.35632062e-03
 4.49925661e-04 4.07698750e-03 3.94673225e-05 5.40573137e-06
 9.33703359e-06 9.22590494e-04 9.89915490e-01 3.03777218e-01
 1.87819004e-02 1.00000000e+00 1.39144213e-05 1.05316969e-04
 5.69943622e-05 1.17969328e-04 7.26014376e-04 3.24097914e-06
 1.72152519e-02 1.09528720e-01 1.49659514e-02 3.48117948e-03
 3.51697206e-04 1.42037868e-04 6.98127678e-07 4.08722508e-06
 8.72957207e-06 2.62695750e-07 1.55955553e-04 8.72969627e-04
 5.04718628e-07 5.05880147e-12 2.08893340e-07 1.81426606e-06
 5.61556518e-02 3.96566465e-05 1.10590585e-10 7.16160784e-08
 3.77266260e-05 2.82893833e-08 1.49329305e-02 1.77577138e-03
 3.18524241e-03 1.41739845e-04 1.21256671e-04 4.92200255e-03
 5.97625971e-04 1.06634965e-04 6.24746084e-04 8.48978758e-04
 2.74178386e-03 9.62495804e-04 6.24507666e-03 9.09658847e-05
 1.04996562e-03 6.24001026e-04 4.19169664e-04 3.00088704e-01
 1.66567006e-07 1.77034326e-06 4.36728669e-06 1.33246183e-04
 4.27365303e-04 1.51089819e-06 1.41620636e-04 1.85865164e-03
 6.66572686e-10 1.02541333e-06 3.89233215e-08 4.69678253e-06
 4.21213444e-05 2.15258524e-07 7.10535062e-07 7.17561245e-02
 7.35070425e-05 7.59452581e-04 6.85133182e-06 3.87880623e-01
 1.92493200e-04 7.31788814e-01 1.52947666e-06 3.60181808e-01
 8.41894746e-07 7.20704913e-01 3.96807025e-07 1.35784830e-06
 1.52798195e-12 3.89339812e-06 5.15779819e-09 2.50843328e-08
 8.42103454e-09 3.14352988e-10 1.37645211e-08 1.55409361e-05
 1.21533540e-05 1.19024115e-08 6.09113471e-09 5.56273001e-08
 2.11640909e-07 2.90695743e-06 4.81520368e-13 5.96121152e-09
 4.09639662e-13 9.32663679e-04 1.12604379e-04 3.29376276e-10
 6.55004783e-12 4.25242761e-05 5.52287133e-07 7.08313964e-05
 5.06402209e-09 2.04806588e-06 9.20757637e-10 8.56522311e-05
 7.65887125e-06 4.42810858e-07 9.46707175e-08 1.70003833e-08
 2.52219277e-08 4.24708724e-02 8.86159887e-06 1.88768712e-09
 4.93894614e-09 2.77532536e-06 2.38507986e-04 3.31610499e-05
 6.65754080e-04 3.37615035e-07 4.17262316e-04 1.31398439e-04
 2.14308500e-04 6.04499073e-05 5.94019890e-03 6.25247912e-06
 8.72142948e-07 1.31934881e-04 3.52928042e-03 1.45334005e-03
 1.11894201e-06 1.21999488e-04 7.39828101e-05 5.92584797e-07
 4.79907882e-08 9.24728283e-06 1.42600015e-06 3.09076905e-03
 1.20018626e-06 2.88661386e-06 1.98005819e-06 9.40084457e-04
 1.85423001e-08 1.85088481e-07 1.80426240e-03 1.24546885e-02
 5.87165356e-04 4.28144119e-07 5.20245962e-08 1.37812197e-02
 9.43917075e-06 9.67364940e-07 4.04553102e-09 1.27592403e-09
 4.25027849e-07 4.57487622e-05 5.19841560e-05 5.11842408e-08
 1.10995752e-05 3.26950249e-06 5.13820014e-05 1.31232309e-06
 2.34246254e-04 4.20493557e-10 1.13946199e-03 1.81607334e-06
 1.68770552e-04 4.09990664e-09 1.21978769e-06 3.04214787e-08
 4.91014421e-02 4.10194079e-05 2.48551369e-04 1.00000000e+00
 9.76592302e-04 2.34335661e-03 2.32772152e-07 4.97063994e-03
 6.02169894e-05 4.24604696e-06 2.51530856e-01 6.58262372e-02
 3.91915441e-03 8.16643454e-12 6.42409325e-02 1.97203087e-11
 1.09698325e-01 2.14647116e-06 1.54860020e-01 8.54324117e-06
 2.89218277e-01 4.08656398e-09 4.97263074e-02 2.02108920e-02
 1.10675097e-02 1.81019306e-03 4.80592251e-04 2.94685364e-03
 4.95702028e-04 2.12608920e-05 3.84002924e-04 4.19786572e-03
 5.20315766e-03 2.96476483e-03 2.39640474e-04 2.69818306e-03
 7.69968174e-05 3.38290920e-05 1.46955252e-04 5.15261199e-05
 3.03823272e-05 4.43837145e-08 1.83710654e-05 1.23673942e-08
 1.24514103e-04 3.65601118e-05 1.13336013e-04 2.00897455e-04
 3.59326601e-04 2.15321779e-04 3.12447548e-04 1.78635120e-04
 1.55687332e-04 6.50079016e-07 5.22467508e-06 1.27703079e-05
 1.13816659e-05 4.12884355e-03 2.52998369e-08 1.26549446e-06
 1.62839890e-04 6.09259887e-09 1.43711168e-10 3.02927483e-09
 1.49446450e-07 1.48748147e-09 4.38291764e-11 1.20569110e-09
 1.20278443e-07 4.49881043e-07 1.48858419e-07 9.79259494e-06
 5.29027147e-06 5.69736528e-07 8.86265017e-09 3.24998291e-06
 2.52681971e-03 2.26373886e-05 2.17513320e-06 4.12779536e-06
 3.74165829e-05 3.24712098e-02 3.33736539e-02 1.78799033e-03
 7.11977482e-04 3.43388319e-03 4.86668978e-05 2.26973571e-05
 1.02115460e-04 1.29269411e-05 7.33181834e-03 4.26530838e-04
 3.35319470e-07 2.18003988e-03 2.71067023e-03 3.53366137e-04
 1.39144957e-02 2.34615803e-03 1.51306391e-04 5.14460844e-05
 5.42087530e-09 2.11674617e-07 1.54227018e-03 8.94899726e-01
 1.41322613e-03 8.80463233e-07 3.12474327e-07 8.36906038e-05
 9.22722791e-07 1.51341601e-06 2.63550159e-09 1.14191811e-04
 2.89369200e-06 2.17775853e-10 8.23668142e-06 9.39364054e-06
 1.43148577e-08 8.03112101e-08 2.15312099e-07 2.01587227e-07
 3.37290444e-08 6.89826791e-08 1.14614238e-08 8.40318870e-10
 5.80214191e-06 7.49245288e-09 6.97049327e-05 3.26306395e-06
 1.83352802e-06 9.81335830e-08 3.33289368e-10 1.70385761e-06
 2.57966661e-08 4.95110896e-07 2.83878251e-07 7.04314800e-07
 1.84738518e-08 2.98389202e-09 7.20516002e-09 4.37744329e-12
 5.38615325e-07 2.50418980e-05 3.05964001e-08 1.20884636e-08
 3.73816249e-07 2.88137556e-07 9.95087134e-07 9.62058266e-07
 1.44125954e-06 3.23497602e-06 2.82862533e-08 8.44291606e-07
 4.17445563e-07 4.18726245e-07 1.04772994e-06 3.86059855e-06
 5.11416204e-07 1.41577212e-08 3.25021183e-08 6.14582996e-06
 3.55495968e-06 7.11135328e-08 3.29603665e-07 1.42321221e-08
 4.54522166e-07 1.41917201e-06 3.24519744e-10 6.15609242e-05
 1.95614732e-07 9.02841930e-06 4.77303729e-07 1.25176712e-07
 7.65560628e-08 7.01549243e-06 7.67458346e-08 1.97738409e-04
 1.88320875e-04 1.49130821e-04 5.60104847e-04 7.36773014e-04
 7.50273466e-04 5.55694103e-04 2.15775435e-05 2.50399113e-04
 3.51697206e-04 1.60948202e-05 6.43042677e-06 5.88920273e-08
 8.25619372e-06 4.09319728e-06 8.13629299e-07 1.35093285e-06
 2.11276285e-09 3.03387060e-06 1.82100994e-05 5.86505166e-06
 2.31473168e-05 3.36854725e-07 1.00443840e-08 8.28427983e-06
 1.15140546e-08 7.81050622e-02 7.70943952e-05 3.25709581e-04
 4.95702028e-04 6.60453588e-05 1.77955627e-03 8.19214256e-05
 3.20763753e-08 3.59733434e-08 1.93864107e-04 1.88457268e-08
 4.56517935e-03 1.36387348e-03 1.46925449e-04 3.44604254e-03
 3.04259956e-02 1.50710344e-03 3.10420990e-04 5.70684671e-04
 8.23919981e-05 8.35895538e-04], shape=(826,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(826,), dtype=float32)
predicted label rank:[1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.034854442, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/diamond_1-1.c-1_000.smt2
true label:[1, 1]
true label rank:[1 1]
predicted label:tf.Tensor([0.99998546 0.97851324], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.00023084051, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/car_all_e2_108_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1
 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 1 1 1 2 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 1
 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 2 2 2 2 1 1 2 2 1 1 1 2 2 2
 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2]
predicted label:tf.Tensor(
[4.30139303e-02 2.06300914e-02 8.95750642e-01 9.20589209e-01
 4.92011428e-01 1.04110539e-02 4.62323427e-03 1.33907795e-03
 2.46682763e-03 1.24555856e-01 7.10889399e-02 6.19989638e-28
 2.35736370e-03 1.00777864e-01 1.50442421e-01 2.12168485e-01
 4.45156355e-23 7.31899977e-01 6.59208059e-01 1.49892151e-06
 3.50568034e-12 3.47476409e-20 1.37446523e-01 7.14027882e-03
 1.69232488e-03 2.02079415e-02 1.68958187e-01 6.48096204e-03
 4.17741179e-01 2.32040882e-04 8.43494927e-05 1.17993355e-03
 8.50371003e-01 1.19854958e-04 5.05720382e-05 2.17974186e-04
 5.69267322e-05 4.72068787e-04 9.99718904e-04 2.86537409e-03
 1.53347850e-03 8.25571769e-05 2.00228393e-02 2.41216123e-02
 8.01493883e-01 2.15745568e-02 1.17558539e-02 1.37231052e-02
 6.67147279e-01 7.14227557e-03 1.96607113e-02 1.39166117e-02
 4.68630046e-01 6.86374009e-01 1.99764371e-02 2.00569639e-06
 8.12220871e-02 1.64628029e-04 3.33130360e-03 1.96546316e-04
 1.05494261e-03 7.41763142e-05 8.05056095e-03 1.02111697e-03
 2.41278708e-02 2.11309195e-02 2.60961652e-02 1.94924474e-02
 1.16489020e-04 1.95073783e-02 3.16690739e-06 3.52153480e-02
 2.78317928e-02 3.06849182e-02 5.48225105e-01 2.77076066e-02
 3.12534273e-02 5.71916826e-05 1.23872433e-05 2.77251005e-02
 6.40690327e-04 6.68239090e-06 1.19251013e-03 5.90041280e-03
 7.54970312e-03 1.00082099e-01 1.25154257e-02 9.99568105e-02
 4.06298459e-01 1.36263281e-01 1.67077780e-03 4.02374864e-02
 8.83540511e-03 9.97573137e-04 1.90228224e-03 6.12699986e-03
 5.71846962e-04 3.33119035e-02 1.51729643e-01 5.74679375e-02
 2.12467045e-01 1.81146413e-01 1.60518557e-01 7.64406213e-05
 1.02585554e-03 2.38092840e-02 2.79535925e-06 8.23804736e-03
 1.43188238e-03 2.06916928e-02 1.48445368e-04 8.07455778e-02
 2.94956863e-01 2.51194835e-03 1.99406058e-01 2.06800491e-01
 2.90996611e-01 1.34303591e-05 8.52376223e-04 9.79989767e-04
 1.63859129e-03 7.30621250e-05 4.31701541e-03 1.10260607e-05
 2.24757195e-03 2.19172299e-01 2.79331803e-02 2.49256641e-01
 1.28785849e-01 2.46612430e-01 8.46580583e-09 1.43647194e-04
 1.09649900e-05 2.19546646e-01 1.34339482e-01 1.41989470e-01
 1.99493200e-01 1.77182347e-01 2.03752160e-01 5.11127710e-03
 1.42081320e-01 1.65681422e-01 1.87210441e-01 1.81755215e-01
 4.70321536e-01 3.28419626e-01 2.02978820e-01 1.99203044e-01
 1.65460259e-01 2.03307092e-01 3.21120024e-04 1.64635181e-02
 2.75766551e-02 1.48487840e-14 5.25020242e-01 2.28100568e-01
 9.98730421e-01 4.07889485e-03 5.37591040e-01 2.08749563e-01
 2.86187947e-01 2.33449936e-02 2.55911827e-01 1.29232407e-02
 2.91953623e-01 2.78224945e-01 8.34912062e-03 2.73930609e-01
 2.57315040e-01 8.87703717e-01 1.82262361e-01 9.43407416e-03
 8.06433818e-08 4.91036445e-01 9.98314857e-01 1.04737759e-01
 8.29156339e-02 3.91009450e-03 1.02445483e-03 7.26023136e-05
 9.94467735e-02 1.14947885e-01 9.92359519e-02 6.42800927e-02
 5.17159700e-04 7.03250468e-02 7.15272725e-02 7.35547841e-02
 5.68598509e-04 7.43190348e-01 9.98528838e-01 5.21004200e-04
 5.04964390e-08 3.29135776e-01 4.28677311e-07 6.12720549e-01
 1.42175466e-01 4.22668159e-02 5.66744804e-03 2.46882439e-04
 2.75760889e-04 3.92984033e-01 4.85465527e-02 5.63637614e-02
 5.36527259e-05 1.67712569e-03 7.56414533e-02 2.96950340e-03
 5.37899137e-03 8.10067892e-01], shape=(210,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.], shape=(210,), dtype=float32)
predicted label rank:[1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1
 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2]
mse:tf.Tensor(0.1406412, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/four1.smt2-0044_000.smt2
true label:[0, 1, 1, 0, 0, 0]
true label rank:[1 2 2 1 1 1]
predicted label:tf.Tensor([0.5282146  0.46907592 0.7475045  0.9169959  0.4814742  0.06133047], shape=(6,), dtype=float32)
rounded label:tf.Tensor([1. 0. 1. 1. 0. 0.], shape=(6,), dtype=float32)
predicted label rank:[2 1 2 2 1 1]
mse:tf.Tensor(0.28351754, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/metros_3_e3_1275_e2_454_000.smt2
true label:[0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1
 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 2 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1
 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1
 1 1 1 2 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1
 1 2 2 1 2 1 1 1 2 1 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2
 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1]
predicted label:tf.Tensor(
[1.61249489e-01 1.53133869e-02 8.15055013e-01 8.96220207e-01
 2.35790908e-01 2.82329500e-01 9.24820304e-01 6.45068586e-02
 3.08999896e-01 4.13961470e-01 1.32066011e-03 5.54801218e-08
 1.13179386e-02 3.44864726e-02 4.46057022e-02 1.62564218e-02
 1.61081553e-04 6.76631927e-04 1.07620390e-05 2.20266475e-06
 1.83790922e-04 8.08841287e-05 9.46631134e-02 9.95442271e-03
 1.48969740e-01 6.94725215e-02 4.29654717e-02 3.01313698e-02
 5.14281511e-01 2.58207321e-04 1.05617762e-01 6.13055825e-02
 5.81753552e-02 5.74954808e-01 4.91505861e-03 4.49821949e-02
 4.32271391e-01 2.33600767e-05 2.27649808e-02 2.34841853e-01
 1.43947303e-02 2.38318571e-05 5.51471317e-07 4.58674585e-05
 3.05110216e-03 6.92963600e-04 1.55240297e-04 3.61621380e-04
 8.41379166e-04 1.07008219e-03 1.45801902e-03 4.47967947e-02
 4.82815206e-02 4.72258925e-02 2.73048878e-04 6.19341433e-02
 4.87029552e-04 5.29070795e-02 7.04752207e-02 8.01738501e-02
 4.24025953e-02 3.70544493e-02 3.28241587e-02 6.42204285e-02
 4.95847464e-02 3.66192460e-02 9.23710704e-01 2.84776390e-02
 7.45188892e-02 5.04881144e-04 9.96435285e-01 1.37802958e-03
 1.94430351e-04 1.84941292e-03 1.15293264e-03 7.84326694e-05
 3.30537558e-04 2.14036445e-05 1.02010131e-01 1.16682917e-01
 6.18351698e-02 1.01258829e-05 1.21672630e-01 8.62330198e-04
 7.54822791e-02 5.99194169e-02 4.13214862e-02 5.27446270e-02
 1.82831854e-01 6.83592260e-02 7.50169754e-02 2.05923885e-01
 4.15693223e-02 9.91011262e-01 1.56157225e-01 6.01322949e-02
 2.85387039e-04 9.64926958e-01 9.83417034e-04 2.31178701e-02
 2.25991011e-04 6.88007474e-03 4.05108929e-03 2.90307403e-03
 1.60728097e-02 2.74897218e-02 2.97709554e-01 2.62907863e-01
 3.74343783e-01 4.64534760e-03 3.58219147e-01 7.96553493e-03
 3.78526121e-01 8.70657265e-02 2.44978070e-01 2.85768092e-01
 3.19254041e-01 3.65405738e-01 3.21424425e-01 3.03679109e-02
 2.64174312e-01 8.68735369e-05 5.84562421e-02 2.91027099e-01
 3.13405991e-02 5.98141551e-03 3.15406919e-03 3.09646130e-04
 1.72576308e-03 8.48025084e-04 1.30170584e-03 3.50567698e-03
 2.64689803e-01 3.32613707e-01 2.98271924e-01 3.10482055e-01
 2.77027845e-01 2.89484978e-01 3.05319756e-01 2.67787218e-01
 2.93485880e-01 2.91495800e-01 3.37392092e-04 9.60705438e-06
 1.93092227e-03 1.55419111e-04 9.40086029e-05 1.87262663e-06
 1.73082822e-06 2.26966422e-05 1.14639193e-01 9.77097154e-02
 2.94396162e-01 1.15533143e-01 1.22475833e-01 5.44857085e-02
 1.55087113e-01 2.93712467e-01 6.25156760e-02 1.69326216e-01
 2.28017569e-04 2.72929668e-04 5.58559441e-06 3.94013186e-05
 1.25825405e-04 9.18895006e-04 5.42789698e-04 7.87501631e-05
 2.31334686e-01 1.41638786e-01 1.26040310e-01 2.71267593e-01
 3.22580218e-01 2.23595828e-01 2.86798298e-01 2.63369441e-01
 2.63614655e-01 1.79976702e-01 1.56581402e-04 2.49847653e-05
 8.56947899e-03 7.45028257e-04 1.97553635e-03 5.33550978e-03
 3.32033634e-03 5.22375107e-04 5.00765085e-01 5.01509726e-01
 5.01934052e-01 4.95432794e-01 5.05341351e-01 4.96656805e-01
 5.02452433e-01 4.93677825e-01 5.01423597e-01 4.96268958e-01
 7.62837648e-01 2.16662884e-04 6.61749661e-01 4.28061187e-02
 1.69616282e-01 1.22517169e-01 1.54839158e-01 1.92774355e-01
 1.48694634e-01 1.55119628e-01 2.61074305e-03 2.78973994e-06
 6.99748739e-07 1.30140781e-03 5.46158141e-08 9.68658447e-01
 1.30885839e-03 4.36323225e-01 3.95257831e-01 3.83780837e-01
 9.83458519e-01 4.63008583e-02 2.32532501e-01 1.05656445e-01
 2.26293713e-01 5.37129641e-01 2.03125775e-01 1.89511329e-01
 1.57203674e-01 7.03600049e-02 3.54600012e-01 1.42480433e-02
 4.80276555e-01 7.95831501e-01 6.96734369e-01 4.65878844e-03
 4.45539892e-01 2.87836015e-01 4.14282084e-04 3.51255208e-01
 3.70561481e-01 3.87122631e-01 3.93663585e-01 7.45230615e-01
 3.64261329e-01 4.69261676e-01 4.05016035e-01 4.48857903e-01
 3.35562527e-01 4.62943703e-01 3.56159508e-01 4.32596892e-01
 9.30448890e-01 6.07172430e-01 4.65951383e-01 4.86332595e-01
 4.93474066e-01 5.18159091e-01 4.84068871e-01 4.90366310e-01
 4.77933615e-01 4.87164855e-01 4.95599866e-01 4.88955140e-01
 4.75729614e-01 4.85832185e-01 4.73834157e-01 4.78089988e-01
 4.86880064e-01 1.69350088e-01 1.97102547e-01 1.28463924e-01
 2.75469601e-01 2.16263384e-01 2.73718983e-01 1.46089286e-01
 1.64093941e-01 1.77376717e-01 3.38052511e-02 1.36456668e-01
 2.70409018e-01 1.96782947e-01 1.34742260e-01 1.64003491e-01
 2.51785845e-01 1.54152691e-01 3.26608419e-02 6.94150031e-02
 5.04327227e-06 6.86381327e-07 1.77818183e-05 7.93444997e-05
 3.30602393e-06 1.38953567e-01 2.29202986e-01 1.36991590e-01
 1.77068174e-01 9.07978117e-02 1.33311152e-01 2.39426553e-01
 1.60894543e-01 1.57946199e-01 5.67187667e-01 3.46490800e-01
 3.53813678e-01 3.57605278e-01 3.18875909e-01 7.62876868e-03
 9.82229531e-01 2.88397491e-01 3.66352051e-01 3.30268800e-01
 3.43760669e-01 3.89146805e-01 3.65587026e-01 3.06249559e-01
 2.89397985e-01 2.95632184e-01 3.19453359e-01 3.11303198e-01
 3.35409045e-02 3.80032718e-01 3.36350799e-01 8.14797282e-02
 2.64846683e-01 1.86704040e-01 1.82837248e-04 1.39430165e-03
 2.39798427e-03 3.32078338e-03 1.48889422e-03 3.87519598e-04
 2.82859802e-03 1.26225948e-02 5.28955460e-03 2.38019228e-03
 1.19865239e-02 5.09053469e-04 1.06431253e-06 4.60173214e-06
 1.02959020e-05 3.49423754e-05 3.08257341e-03 8.59933643e-05
 1.16622448e-03 1.10005552e-04 5.28557621e-06 6.88195229e-04
 2.16638625e-01 2.17994571e-01 2.37360746e-01 1.94164604e-01
 3.73251319e-01 2.66870677e-01 2.48911828e-01 3.23061198e-01
 2.57227808e-01 2.84816682e-01 2.72943037e-08 1.62053108e-02
 8.56516563e-05 2.50410631e-05 2.91990310e-01 1.98204671e-05
 3.04726958e-01 1.95162670e-07 1.72571868e-06 8.15868378e-04
 2.72387087e-01 3.46831322e-01 4.00867790e-01 9.91475582e-01
 2.78045237e-01 1.27584934e-01 3.26006293e-01 3.61555517e-01
 2.17830241e-02 2.14031309e-01 2.50536203e-01 2.41897404e-02
 3.11362743e-03 3.68435562e-01 2.16682374e-01 2.28949457e-01
 5.09081781e-02 2.76982784e-04 5.25805652e-02 1.80977285e-01
 2.14550674e-01 6.17408156e-02 1.13281608e-03 2.14226693e-01
 2.50035048e-01 8.49851251e-01 9.61917281e-01 3.17126513e-04
 1.06565058e-02 5.31789660e-03 1.42067373e-02 2.01845169e-03
 1.54984057e-01 1.03632808e-02 1.83514595e-01 3.71891856e-02
 5.17675877e-02 6.33491755e-01 4.09293175e-03 5.20983040e-02
 1.80911720e-02 1.70793027e-01 4.41553891e-01 1.78158283e-02
 2.29428232e-01 1.43469095e-01 9.74480808e-02 5.08041680e-01
 1.71820104e-01 9.99933004e-01 9.99933362e-01 1.38342381e-03
 1.35816664e-01 4.33729172e-01 2.72669196e-01 3.11385155e-01
 2.89160639e-01 2.28994936e-01 2.36176461e-01 2.72892922e-01
 7.56990314e-02 1.22357696e-01 1.69026673e-01 1.27202004e-01
 1.80745125e-01 5.54186404e-02 2.46790439e-01 1.98259622e-01
 1.75206035e-01 3.28358650e-01 3.76306385e-01 2.49705017e-01
 2.55966574e-01 1.90147758e-03 2.63394117e-02 2.61932611e-04
 9.55746114e-01 3.55481803e-02 6.28849685e-01 7.45505691e-01
 9.44431722e-02 1.43840671e-01 1.31340146e-01 1.22118443e-01
 7.36546218e-02 4.71297790e-05 1.37060815e-05 3.35133374e-02
 1.03262126e-01 6.83624446e-02 5.95668852e-02 9.41896439e-02
 1.10624624e-05 2.64483094e-02 4.46387529e-02 3.23266089e-02
 4.81790900e-02 1.56977773e-02 1.58413351e-02 6.73970282e-02
 2.50163674e-03 8.68903816e-01 3.21087241e-03 8.35506678e-01
 9.17194605e-01 1.22545063e-02 9.95284319e-03 8.20690393e-03
 3.34307551e-03 1.49372816e-02 7.83324242e-04 8.74689358e-05
 3.36784124e-03 3.71265411e-03 1.27950013e-02 1.59145296e-02
 9.10288095e-03 6.78578019e-03 5.69301844e-03 2.66494453e-02
 9.00015235e-03 1.66179836e-02 4.43070531e-02 2.79780328e-02
 5.77914715e-03 4.04848576e-01 1.57058239e-04 9.99422789e-01
 1.54005454e-06 8.53764561e-08 4.31812452e-09 8.09139132e-01
 7.80072689e-01 3.20543414e-09 9.99936581e-01 2.59170406e-07
 1.99673400e-06 2.79264532e-05 1.67227477e-01 6.04212880e-02
 4.68766520e-05 3.62575054e-04 1.82718039e-04 1.33082667e-05
 5.18766392e-05 3.45751905e-05 4.28360408e-06 2.86479899e-05
 4.80426752e-06 3.31073999e-04 3.07258529e-06 1.26549512e-01
 2.34812498e-04 6.51797560e-10 2.82138586e-04 7.77199864e-03], shape=(520,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0.
 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(520,), dtype=float32)
predicted label rank:[1 1 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 2 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 2
 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1]
mse:tf.Tensor(0.095035344, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/bandec.smt2-0033_000.smt2
true label:[0, 1, 0]
true label rank:[1 2 1]
predicted label:tf.Tensor([0.58780384 0.01889735 0.61718637], shape=(3,), dtype=float32)
rounded label:tf.Tensor([1. 0. 1.], shape=(3,), dtype=float32)
predicted label rank:[2 1 2]
mse:tf.Tensor(0.56299824, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/test_locks_8.c-1_000.smt2
true label:[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]
true label rank:[1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2
 2 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 2 2 2
 2 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1]
predicted label:tf.Tensor(
[4.1545114e-01 1.0098219e-03 9.8758101e-02 1.8750367e-01 1.9259056e-01
 2.8145540e-01 2.2346097e-01 1.6979674e-01 2.5752878e-01 2.9701561e-01
 3.0242914e-01 1.7498264e-01 2.0392627e-01 2.2728896e-01 2.9640925e-01
 9.6699595e-01 9.9452329e-01 5.6384885e-01 4.4469413e-01 6.1347735e-01
 6.1695439e-01 4.3433350e-01 2.9649484e-01 5.1931375e-01 4.9857712e-01
 4.2014569e-01 5.0571132e-01 2.5312585e-01 9.9610591e-01 7.3811960e-01
 9.9198031e-01 1.1756569e-02 4.2902529e-03 2.8514487e-01 2.9679745e-01
 2.8833574e-01 3.3862144e-01 3.4179616e-01 4.1678977e-01 4.4038337e-01
 4.0646952e-01 2.6765972e-01 3.5222396e-01 4.0141872e-01 3.3191699e-01
 1.9028491e-01 1.0522261e-01 7.6112747e-01 5.7564008e-01 4.1850621e-01
 9.8194075e-01 8.2873309e-01 9.9809647e-01 5.4394346e-01 6.1391747e-01
 6.4559078e-01 7.2883362e-01 7.2790200e-01 7.8680754e-01 6.9824648e-01
 9.2954570e-01 1.2821266e-01 5.8100224e-03 8.0797374e-02 2.2163603e-01
 3.7971404e-01 4.6873659e-01 3.2553333e-01 3.9459789e-01 2.2013715e-01
 1.6122553e-01 4.7349763e-01 3.3848268e-01 5.1028687e-01 7.8643429e-01
 3.8691109e-01 3.3653280e-01 2.7854484e-01 3.4296042e-01 4.7056967e-01
 2.1335649e-01 8.5929632e-03 9.7821987e-01 4.5018250e-01 6.3655174e-01
 4.4934142e-01 4.6445420e-01 3.7940830e-01 4.3821555e-01 5.0016880e-01
 1.7456543e-01 9.8443252e-01 4.2422548e-01 4.3941712e-01 4.7481191e-01
 4.3890765e-01 1.7229807e-01 7.7544689e-02 1.4357415e-01 1.7666784e-01
 5.6003034e-03 5.2428246e-03 9.1986954e-03 7.6225400e-04 1.3844550e-02
 3.4257382e-01 9.3537599e-02 1.5419826e-01 1.4681330e-01 3.0663365e-01
 1.6639701e-01 4.0704319e-01 3.3891201e-04 3.9848685e-04 2.8689867e-01
 3.2231581e-01 3.4140718e-01 3.7509468e-01 4.2052108e-01 3.5142738e-01
 3.7918311e-01 1.0180169e-01 8.5622120e-01 7.6020253e-01 4.7060022e-01
 4.1688597e-01 4.6417779e-01 3.9900905e-01 3.8314635e-01 4.4301170e-01
 6.0545647e-01 7.0681864e-01 9.6583188e-01 8.1082201e-01 9.4743061e-01
 5.3253883e-01 9.8910397e-01 1.5970191e-01 5.8324659e-01 7.4570990e-01
 9.6388680e-01 9.8604238e-01 2.8644443e-02 1.1549592e-03], shape=(144,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1.
 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0.], shape=(144,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 2 2 1 1 2 1 1 2 1 2 2 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2
 2 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 2 2 2 2 2 2 2 1 2 2 2 2 1 1]
mse:tf.Tensor(0.28484425, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/amebsa.smt2-0078_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
true label rank:[1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2]
predicted label:tf.Tensor(
[1.48751378e-01 2.93526947e-02 3.91162038e-02 9.98701215e-01
 7.05378056e-02 7.44749546e-01 9.93726850e-02 2.77664661e-02
 3.82925570e-02 5.39239764e-01 1.33740902e-03 1.19319397e-04
 1.17692893e-04 2.36362219e-04 7.34210014e-04 2.27451324e-04
 2.48854160e-02 1.01864338e-03 7.39634037e-04 9.45653737e-05
 1.96188688e-03 1.36801600e-03 4.94871565e-05 2.91889906e-02
 1.86607242e-03 3.90142202e-04 9.06646252e-04 1.40032172e-03
 1.27199292e-03 1.27106905e-04 1.12710099e-04 9.27209854e-04
 1.32530928e-04 1.32137537e-03 1.18186921e-01 1.51183307e-02
 7.10234046e-03 4.16726768e-02 4.67486292e-01 3.40955168e-01
 4.18575108e-02 6.71383739e-03 2.31809616e-02 4.61953878e-03
 2.69182324e-02 1.81981534e-01 6.32442534e-02 8.78416300e-02
 3.55275869e-02 5.13431430e-02 4.59095240e-02 6.16548955e-02
 2.72842348e-02 4.80013788e-02 4.25178409e-02 2.00773478e-02
 2.49245465e-02 2.12748945e-02 2.03775525e-01 7.76077509e-02
 7.89770484e-03 9.48178768e-03 2.95198560e-02 6.00548685e-02
 5.15532494e-03 7.36382604e-02 8.95508647e-01 8.20289195e-01
 1.98184371e-01 1.41284913e-01 1.26529932e-02 8.93737674e-02
 4.82590199e-02 9.27805305e-02 1.05504096e-02 4.24996018e-03
 8.35099816e-03 1.61123872e-02 1.79448724e-03 8.82499814e-02
 1.93012655e-02 1.51550770e-03 1.16649270e-02 1.36667043e-01
 3.42214108e-02 3.77637148e-03 9.66140628e-03 1.71774030e-02
 3.89966369e-03 3.35496664e-03 7.41711259e-03 3.86992097e-02
 6.13969564e-03 4.94764447e-02 9.93809342e-01 2.85649002e-02
 1.05648100e-01 1.03876650e-01 2.62576342e-02 1.01035833e-03
 1.19050696e-04 3.05503607e-04 3.65823507e-04 1.28895044e-04
 1.24448538e-03 3.97682190e-04 9.95208684e-05 1.31314993e-03
 1.39617920e-03 1.10670473e-04 1.71631575e-04 1.67250633e-04
 9.97479796e-01 2.10518865e-05 1.94483995e-03 6.05318237e-05
 2.87204981e-04 1.95980072e-04 1.75714493e-04 1.33126974e-03
 3.81141901e-04 9.03900764e-06 1.56554580e-03 5.74698679e-05
 1.86376005e-01 9.41276550e-03 2.17558742e-02 3.73107791e-02
 5.64929843e-03 1.04666471e-01 3.31418096e-06 5.63321555e-06
 7.39963934e-06 5.66271782e-01 3.04152445e-06 2.57369876e-03
 4.97237625e-06 3.26693058e-04 3.57551144e-05 3.15508246e-03
 1.81146279e-05 1.97234167e-05 4.08976921e-05 1.02198319e-05
 1.22520214e-04 1.13959641e-06 6.14252785e-05 1.33650947e-05
 8.32601199e-06 1.15020373e-06 1.10935125e-05 1.01831203e-04
 1.84267759e-04 8.63498997e-08 3.60617087e-05 5.65211773e-02
 2.35793104e-05 5.09187566e-06 1.18455291e-03], shape=(159,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(159,), dtype=float32)
predicted label rank:[1 1 1 2 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.066750124, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/nest-if.c_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.99015015 0.9090188  0.973516   0.99999875 0.7295997  0.6086265
 0.9994166  0.6786485 ], shape=(8,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1.], shape=(8,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.042329088, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/bandec.smt2-0181_000.smt2
true label:[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]
true label rank:[1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1]
predicted label:tf.Tensor(
[4.9302694e-01 1.6111967e-01 9.0212762e-02 7.5078380e-01 1.9463092e-02
 2.2093356e-03 6.4139793e-05 9.4550729e-01 1.5304089e-03 9.4482303e-03
 1.7508268e-03 8.9794397e-03 2.4320483e-03 6.5425336e-03 4.3037236e-02
 9.2003340e-01 8.1348419e-03 4.0361285e-04 7.6551660e-05 5.5489838e-03
 3.4823033e-01 2.7522820e-01 6.6774398e-02 1.0468274e-02 5.6728423e-03
 8.9433789e-04 3.3047795e-03 1.5810311e-02 4.5110700e-01 1.4624792e-01], shape=(30,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.], shape=(30,), dtype=float32)
predicted label rank:[1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.11968548, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/tridag.smt2-0024_000.smt2
true label:[1, 0, 0, 0]
true label rank:[2 1 1 1]
predicted label:tf.Tensor([0.83235985 0.8927396  0.4313134  0.61885643], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1.], shape=(4,), dtype=float32)
predicted label rank:[2 2 1 2]
mse:tf.Tensor(0.3485254, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/bound.c_000.smt2
true label:[1, 1, 1, 1, 1, 1, 0, 0, 0, 1]
true label rank:[2 2 2 2 2 2 1 1 1 2]
predicted label:tf.Tensor(
[0.96524644 0.9676653  0.94049823 0.99999857 0.948696   0.95988595
 0.6861673  0.65892196 0.7940747  0.6731879 ], shape=(10,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(10,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.16523996, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/underapprox_2-2.c-1_000.smt2
true label:[1, 0]
true label rank:[2 1]
predicted label:tf.Tensor([0.9921975 0.900386 ], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.4053779, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/loop__while_after_while_if_000.smt2
true label:[0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 2 2 2 1 2 2 2 2 2 2 2 2]
predicted label:tf.Tensor(
[0.62534153 0.87737393 0.30046743 0.80816954 0.65197855 0.42235845
 0.6321686  0.7090546  0.9877422  0.68787897 0.78854287 0.51780754
 0.58744925 0.72116536], shape=(14,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(14,), dtype=float32)
predicted label rank:[2 2 1 2 2 1 2 2 2 2 2 2 2 2]
mse:tf.Tensor(0.20208406, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/minepump_spec1_product58_true-unreach-call.cil.c.flat_000.smt2
true label:[1, 0, 1]
true label rank:[2 1 2]
predicted label:tf.Tensor([0.9992533 0.999855  1.       ], shape=(3,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)
predicted label rank:[1 1 1]
mse:tf.Tensor(0.33323684, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/MOESI_2_e3_1523_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1
 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2
 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2
 2 2 2 1 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2
 2 1 1 1 1 1 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 2 2 2 2 2 2 2
 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[1.21298079e-04 3.90719615e-05 3.02657827e-05 1.19362077e-04
 3.56925993e-05 4.32014465e-04 2.49984860e-03 5.33514321e-05
 1.60333514e-03 4.33729219e-05 1.62634254e-03 1.20618939e-03
 1.44097209e-03 3.99738550e-04 1.65688992e-03 8.51519508e-06
 2.11328268e-04 8.40347493e-05 1.28674507e-03 1.92391872e-03
 1.54146552e-03 1.06158853e-03 1.18284252e-05 5.46544790e-04
 1.33484602e-03 4.91827726e-04 1.56340003e-03 2.30461359e-04
 7.44938850e-04 1.29044056e-04 8.48144293e-04 7.28577375e-04
 6.23911619e-04 1.42812729e-04 3.11025977e-03 1.06407715e-04
 5.18199801e-03 7.73978233e-03 5.72344661e-03 9.76505876e-03
 1.28307045e-02 4.52101231e-03 4.26894426e-03 6.32423162e-03
 4.36544418e-03 4.69505787e-03 6.48406148e-03 1.79201365e-04
 1.70358726e-18 6.02062643e-02 1.07674327e-06 3.98417105e-05
 1.62294718e-18 9.58963469e-08 9.01943800e-24 1.64860097e-31
 4.78679836e-02 4.47110534e-02 5.76173425e-01 3.63056388e-05
 5.13535888e-05 3.23474407e-04 3.15288684e-09 7.19141543e-13
 5.05837733e-12 5.46978522e-12 6.70036027e-10 3.09747458e-03
 1.18873417e-02 2.66760588e-04 1.83004141e-03 9.17866230e-01
 1.44163400e-01 1.08140707e-02 2.10583210e-03 1.15448236e-03
 3.18971336e-01 4.51374054e-03 7.63216615e-03 5.13222814e-03
 1.62640214e-03 4.42934036e-03 7.96532631e-03 5.11157513e-03
 4.44287062e-03 3.31643224e-03 2.11897492e-03 2.27898359e-04
 1.21341944e-02 2.93532014e-03 2.49114633e-03 1.53028965e-02
 2.77668238e-03 2.34012306e-02 8.27926051e-05 1.80682540e-03
 1.16647531e-25 2.19279438e-01 5.36280870e-03 1.41491319e-05
 8.08732875e-06 1.66724294e-01 3.56885791e-03 3.54173779e-03
 2.38978863e-03 2.55075097e-03 4.49973345e-03 7.52696395e-03
 4.58154082e-03 8.76635313e-04 1.34247541e-02 4.44859266e-04
 8.59522820e-03 9.47713852e-04 1.53669715e-03 3.62271607e-01
 5.19425392e-01 8.85413704e-16 1.41745895e-01 2.30811068e-08
 4.89462455e-17 4.90123383e-19 1.41265988e-03 2.47629503e-18
 1.72057439e-33 9.96434532e-11 5.01396535e-10 4.96080769e-18
 6.31568923e-07 1.68983383e-10 6.56335175e-01 1.29237771e-03
 1.95032792e-11 3.44872475e-03 3.06963921e-04 1.70532788e-09
 3.19561821e-09 2.06297636e-03 5.46511079e-13 6.34668350e-01
 7.12117553e-01 2.59918254e-10 2.12135911e-03 7.06127882e-02
 0.00000000e+00 1.07521802e-01 9.66479778e-02 3.87071630e-22
 8.81016254e-04 9.59982276e-02 7.99354666e-07 6.39381707e-02
 1.34128064e-01 1.64875686e-02 9.31501389e-02 4.99267280e-02
 1.58995390e-04 4.93071093e-35 1.45336098e-05 3.78384067e-27
 0.00000000e+00 2.22006150e-15 1.31653534e-11 1.16032362e-03
 1.46824121e-02 0.00000000e+00 1.20634109e-01 0.00000000e+00
 3.14205885e-04 3.00520658e-03 3.86196166e-01 1.13114119e-02
 1.35944784e-02 9.59789753e-03 1.52225196e-02 1.02837384e-02
 1.03331506e-02 7.56376982e-03 1.07163489e-02 1.07668340e-02
 1.16365254e-02 1.10774040e-02 1.20702684e-02 1.06420815e-02
 1.00546479e-02 1.04720891e-02 1.18757280e-05 1.12836063e-02
 8.43480229e-03 9.91061330e-03 1.19826198e-02 1.22646093e-02
 1.07091665e-02 7.88384676e-03 1.29290819e-02 1.26435459e-02
 1.22321248e-02 1.80249214e-02 9.24146175e-03 2.99349427e-03
 1.12606585e-02 8.29386711e-03 1.05546713e-02 1.45064592e-02
 1.14396811e-02 1.03726983e-02 1.28470361e-02 1.92822569e-07
 9.91046429e-03 4.86767292e-03 7.52532482e-03 3.72460485e-02
 6.27556443e-03 1.90515220e-02 1.32612288e-02 9.11083817e-03
 6.46975636e-03 1.36628747e-03 5.29217720e-03 2.70602107e-03
 4.54634428e-03 2.37716138e-02 5.59762120e-03 7.13250041e-03
 5.63916564e-03 1.38965249e-03 7.66205788e-03 8.52230430e-01
 7.80102611e-01 8.40194046e-01 8.89640331e-01 9.43048596e-01
 8.05195212e-01 8.20944071e-01 6.28311217e-01 7.30376363e-01
 9.02668595e-01 8.78570735e-01 8.30491185e-01 8.23371768e-01
 8.19302440e-01 8.94552469e-01 7.92881489e-01 8.35775495e-01
 2.55835673e-08 1.88276172e-03 2.75224447e-04 5.98162413e-04
 3.33279371e-04 9.29504633e-04 5.94691634e-02 2.09679008e-01
 4.27976072e-01 5.10948956e-01 9.09864902e-04 9.49442387e-04
 8.71256709e-01 7.15411782e-01 3.09664756e-01 3.87779295e-01
 3.01462382e-01 2.89777100e-01 1.01357251e-01 3.68397415e-01
 9.30070758e-01 8.12802911e-01 1.37447357e-01 9.17498767e-02
 1.88649863e-01 1.18957102e-01 2.37560868e-02 8.16591084e-02
 1.29705876e-01 6.22772872e-02 6.64612353e-02 3.77858877e-02
 1.09806359e-01 5.94982803e-02 1.80929899e-04 6.55617416e-02
 2.21653134e-01 1.16947055e-01 8.39110613e-02 1.40580833e-01
 9.33521092e-02 1.72763854e-01 4.63342667e-03 1.93975031e-01
 9.96299267e-01 4.43863869e-01 7.42506623e-01 1.91507220e-01
 8.44726324e-01 9.99823689e-01 7.65894055e-01 9.98628855e-01
 9.86776233e-01 1.00000000e+00 9.99997854e-01 9.99975562e-01
 3.67638469e-01 9.99971271e-01 9.99876499e-01 4.06287134e-01
 9.87098813e-01 9.93309379e-01 9.90052521e-01 9.99935269e-01
 1.00000000e+00 9.99995708e-01 1.00000000e+00 9.99996066e-01
 9.99995112e-01 9.99923646e-01 4.13766086e-01 3.97033453e-01
 4.15971309e-01 9.99983907e-01 1.00000000e+00 1.00000000e+00
 9.99989212e-01 9.99997973e-01 9.99855518e-01 1.00000000e+00
 1.00000000e+00 8.79120231e-01 7.56255865e-01 9.99999523e-01
 9.99999404e-01 9.99993443e-01 1.00000000e+00 7.35794842e-01
 9.99942660e-01 9.99970853e-01 9.99802351e-01 9.99753833e-01
 9.99986291e-01 7.63748229e-01 7.78494477e-01 7.21198559e-01
 7.21727431e-01 7.43070722e-01 9.99979436e-01 9.95753050e-01
 9.99809384e-01 3.59171897e-01 5.03677666e-01 9.50867891e-01
 9.99799490e-01 5.64216435e-01 9.99792218e-01 9.99992609e-01
 9.99965072e-01 9.99756932e-01 9.94180858e-01 3.15865219e-01
 9.16118979e-01 4.36254501e-01 7.86665201e-01 6.68356717e-01
 9.63260949e-01 9.63078499e-01 9.94994581e-01 7.86489010e-01
 3.17125559e-01 9.95435715e-01 9.87925947e-01 9.45955157e-01
 9.91671205e-01 9.12066460e-01 9.93976116e-01 9.96192694e-01
 9.84901130e-01 2.70993173e-01 4.07017410e-01 3.02479774e-01
 6.19862795e-01 7.13885069e-01 2.84187764e-01 5.34034431e-01
 5.86454272e-02 2.96406567e-01 7.83590078e-02 8.71439695e-01
 8.91878247e-01 9.99903858e-01 9.99953806e-01 7.25555241e-01
 8.23129773e-01 9.99986649e-01 9.99987602e-01 9.99776185e-01
 9.95413005e-01 9.98814106e-01 9.99822736e-01 9.99565363e-01
 9.99031842e-01 6.12338006e-01 8.91145527e-01 8.61527681e-01
 6.37525022e-01 9.64275301e-01 7.05007076e-01 8.65448833e-01
 9.34635758e-01 8.99691224e-01 6.85113549e-01 8.76705825e-01
 5.23024797e-01 6.38893723e-01 5.15302181e-01 5.16918004e-01
 4.98954266e-01 9.11970794e-01 6.65004373e-01 7.05103993e-01
 8.58894110e-01 8.45645308e-01 6.94848537e-01 5.06890416e-01
 5.16408622e-01 4.99739915e-01 4.95973498e-01 4.85596538e-01
 2.85192788e-01 4.47608292e-01 4.25562531e-01 3.53714049e-01
 4.58823353e-01 2.86966622e-01 4.54483837e-01 6.44613147e-01
 3.48224521e-01 5.12654722e-01 5.06932855e-01 4.98871326e-01
 7.20603168e-02 1.34549767e-01 2.97764540e-02 9.30927992e-01
 4.20053720e-01 6.62890315e-01 9.55243111e-01 8.86835933e-01
 8.63414407e-01 9.65116739e-01 5.50130665e-01 1.46508932e-01
 1.19063735e-01 1.79550499e-01 2.50444949e-01 4.84020710e-02
 1.80563569e-01 9.16885436e-02 1.43958896e-01 1.92835271e-01
 1.49021983e-01 4.05001044e-02 7.72029757e-02 5.90568781e-03
 4.12291259e-01 4.52452898e-03 3.49920690e-02 8.88699293e-02
 3.56812179e-02 8.11907649e-03 1.77203715e-02 3.12400758e-02
 1.11798704e-01 2.73188949e-02 2.21273303e-02 6.75436199e-01
 1.86739266e-01 3.33587289e-01 3.99017036e-02 1.76401734e-02
 1.34088993e-02 1.34172440e-02 3.51152420e-02 2.80359089e-02
 1.54210329e-02 2.46925652e-02 2.99882293e-02 6.89711869e-02
 2.30449438e-02 4.49611545e-02 3.13976407e-02 6.19573593e-02
 1.71701014e-02 4.40548062e-02 1.25363529e-01 3.15151066e-01
 9.36031580e-01 5.90737581e-01 9.12852407e-01 9.69614387e-01
 9.70591009e-01 9.90008473e-01 9.32524204e-01 9.67949867e-01
 9.83433604e-01 9.36057866e-01 1.83277726e-02 5.80302775e-02
 5.73201776e-02 7.11278021e-02 7.96199143e-02 2.62901872e-01
 2.99542159e-01 4.35576439e-02 1.24397278e-01 7.94121623e-02
 7.98497200e-02 1.44437224e-01 2.43765116e-03 4.56091762e-03
 3.58106554e-01 3.75742614e-02 9.98465538e-01 9.99969721e-01
 9.99134660e-01 5.08098960e-01 3.85300785e-01 4.49383736e-01
 4.76977408e-01 5.05785465e-01 4.29589987e-01 1.00000000e+00
 9.99991655e-01 1.00000000e+00 1.00000000e+00 9.99998927e-01
 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00
 5.07516265e-01 9.94382262e-01 3.32633793e-01 5.61069727e-01
 4.17875469e-01 3.54191810e-01 2.49542555e-15 0.00000000e+00
 4.16458249e-01 4.54948574e-01 3.11609030e-01 9.28386044e-07
 1.57593340e-01 1.28358603e-04 8.35569790e-06 1.61826611e-04
 7.62295821e-18 1.84778669e-27 3.52573920e-07 1.24254452e-26
 9.99600410e-01 3.55921388e-01 6.11216545e-01 8.95362735e-01
 1.81856006e-01 8.03505182e-02 9.99796391e-01 4.73770499e-03
 1.22474303e-04 9.88143265e-01 4.20744300e-01 2.29453772e-01
 1.44957095e-01 1.12679392e-01 3.58780444e-01 1.11893445e-01
 3.79388690e-01 1.69744998e-01 9.72488880e-01 4.45636958e-01
 7.23866224e-01 1.30222738e-02 1.74280107e-02 3.46186757e-03
 5.16125560e-03 2.88724899e-04 5.27709424e-02 1.43340319e-01
 3.03315639e-01 1.10384822e-03 5.65707684e-04 1.22465491e-02
 1.59786940e-02 7.17882514e-02 4.17765528e-01 4.48836535e-01
 3.73369098e-01 2.68989950e-01 2.53910601e-01 4.63761300e-01
 2.06595063e-01 4.20048382e-15 9.97293591e-01 2.92524427e-01
 2.27880955e-01 2.82400548e-01 1.80651665e-01 9.63309884e-01
 2.54914105e-01 9.72014964e-02 4.78287637e-01 1.98596954e-01
 2.25713283e-01 2.44707614e-01 2.61497796e-01 2.38165081e-01
 1.80259347e-02 8.35511088e-03 3.97077203e-02 9.40779150e-02
 9.75308120e-02 1.58894777e-01 1.27714756e-07 1.30664408e-02
 1.06782705e-01 3.19183499e-01 4.03167605e-02 1.09467179e-01
 2.48114169e-01 3.22854519e-02 2.23861307e-01 3.36338639e-01
 2.66323000e-01 2.24129409e-01 2.76772887e-01 2.24150270e-01
 1.76928908e-01 1.97378010e-01 1.27870739e-02 3.29980254e-03
 1.11638606e-02 4.10827994e-03 1.24852657e-02 3.33341956e-03
 2.21070647e-03 1.12223625e-02 1.80970164e-16 2.78937817e-03
 2.38070488e-02 1.39223337e-02 9.70530510e-03 1.31404400e-03
 5.11926413e-03 1.11220026e-04 2.11507082e-04 2.19464302e-04
 5.40353656e-02 2.90644169e-03 2.70350873e-02 6.00390536e-07
 1.15927458e-02 5.49763441e-04 9.25456285e-02 7.01190004e-08
 4.47428226e-03 3.51051986e-02 6.95077106e-05 2.85363197e-03
 1.14328563e-02 1.72266066e-02 2.12153792e-03 2.41916180e-02
 2.50535488e-01 9.01442766e-03 1.35802925e-02 3.82291943e-01
 4.00334597e-04 2.58213282e-03 1.02718771e-02 4.64856625e-04
 1.49101019e-04 3.75658274e-04 4.76568937e-04 1.46860975e-06
 1.58939391e-01 7.48544931e-04 8.48963857e-03 1.01861358e-01
 1.30331218e-02 7.51907825e-02 8.35600495e-03 2.34812498e-04
 2.62740105e-05 1.99426293e-01 3.77753377e-03 1.23566389e-03
 8.00786875e-05 6.22987747e-04 4.39577699e-02 5.37065773e-07
 7.92936589e-07 3.90547574e-01 3.06843996e-01 2.11089849e-03
 8.71419907e-04 1.09980404e-02 3.58045101e-04 3.95476818e-04
 2.27808952e-04 8.17278578e-06 2.94274092e-03 1.60725117e-01
 1.43501759e-02 2.30744779e-02 9.99476194e-01 6.78488612e-03
 1.25372112e-02 4.56704497e-02 6.64964318e-03 2.66782045e-02
 1.54720724e-01 3.15194920e-05 1.08982265e-01 3.79914105e-01
 6.43103647e-07 4.07886660e-07 1.85005009e-01 5.64903021e-04
 8.54348116e-07 2.60117650e-03 6.89786673e-03 1.38622336e-09
 4.12106514e-04 2.03601612e-05 9.99505281e-01 2.02929974e-03
 5.25712967e-03 1.16798161e-04 9.72332236e-06 7.06714392e-03
 8.74826219e-05 5.55770008e-09 4.36574221e-04 4.03589002e-05
 1.16058894e-04 8.41887595e-05 8.19475244e-05 7.57391763e-06
 6.63560629e-03 1.24103367e-01 2.83539295e-04 9.41559672e-03
 6.77841902e-03 9.77044702e-01 1.00000000e+00 1.00000000e+00
 9.34865773e-01 9.73914087e-01 9.91776943e-01 9.96796727e-01
 1.72394514e-03 1.65879726e-04 5.92397464e-10 1.23955279e-18
 8.67627501e-01 1.59926711e-26 2.03068566e-16 1.28373504e-03
 8.03565493e-31 2.09962622e-13 3.66346459e-21 1.15096951e-25
 7.80324578e-01 5.88473678e-03 0.00000000e+00 2.37319529e-01
 1.79230398e-11 8.48845679e-13 6.30437432e-15 9.76232588e-01
 2.89704382e-01 1.20551362e-04 1.57639384e-03 7.74745512e-09
 1.44449658e-07 9.46124104e-08 2.40176916e-04 2.16062029e-11
 1.98102502e-27 5.81964199e-10 1.71179602e-06 1.05229368e-07
 2.53885304e-07 4.48868915e-14], shape=(790,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1.
 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(790,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 2 1 1 2 2 1
 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 2 2 2
 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 2 1 2 2 2 2 2
 2 2 2 1 1 1 2 2 1 2 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 2 1 2 2 2
 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 2 2 2 1 1 1 2 1 2 2 2 2 2 2 2 2 2 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1
 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.10009055, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/loop__upcount_000.smt2
true label:[1, 1, 1, 1]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([0.98759407 0.99991655 0.9910134  0.9998611 ], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)
predicted label rank:[1 1 1 1]
mse:tf.Tensor(5.8673064e-05, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/apache-get-tag.i.v+nlh-reducer.c-1_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.8020743  0.97075105 0.9310507  0.9891045  0.9491462  0.96118295
 0.18165737 0.75783664], shape=(8,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 0. 1.], shape=(8,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 1 2]
mse:tf.Tensor(0.09716543, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/nest-if3_true-unreach-call.c.flat_000.smt2
true label:[1, 0, 0, 1, 0, 0, 1]
true label rank:[2 1 1 2 1 1 2]
predicted label:tf.Tensor(
[0.8119581  0.901953   0.45067915 0.75715345 0.5384619  0.97585624
 0.98999953], shape=(7,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 1. 1. 1. 1.], shape=(7,), dtype=float32)
predicted label rank:[2 2 1 2 2 2 2]
mse:tf.Tensor(0.33618596, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/xy10.c_000.smt2
true label:[1, 1, 1, 1, 1, 1, 0]
true label rank:[2 2 2 2 2 2 1]
predicted label:tf.Tensor(
[0.9216844  0.8205855  0.99874127 0.9834896  0.829249   0.84983474
 0.674414  ], shape=(7,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1.], shape=(7,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1]
mse:tf.Tensor(0.07787669, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/nested4.c_000.smt2
true label:[1, 1, 1, 1, 0, 1, 0, 1]
true label rank:[2 2 2 2 1 2 1 2]
predicted label:tf.Tensor(
[0.9549761  0.8975959  0.9970145  0.99996936 0.55525035 0.7101545
 0.65434515 0.7896463 ], shape=(8,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1.], shape=(8,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.10965653, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/count_by_1_variant_true-unreach-call.c.flat_000.smt2
true label:[1]
true label rank:[1]
predicted label:tf.Tensor([0.9062016], shape=(1,), dtype=float32)
rounded label:tf.Tensor([1.], shape=(1,), dtype=float32)
predicted label rank:[1]
mse:tf.Tensor(0.00879814, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0259_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1
 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 1 1
 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1
 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1
 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1
 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1
 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1
 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1
 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1
 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1
 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1
 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2
 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1
 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2]
predicted label:tf.Tensor(
[6.42883182e-02 1.38463676e-02 3.34501863e-02 2.63475686e-01
 2.85983026e-01 5.96576035e-01 3.52778494e-01 4.34734732e-01
 3.26250523e-01 3.63809556e-01 6.81881607e-02 2.37657130e-02
 1.74130797e-02 2.39092112e-02 7.96972513e-02 4.94617522e-02
 4.36342061e-02 4.38661575e-02 3.38464975e-04 4.40382779e-01
 7.02707887e-01 4.29899305e-01 2.51284659e-01 4.85582948e-02
 1.18432432e-01 2.54440606e-02 1.22711957e-01 9.96114612e-02
 2.82965213e-01 4.85179722e-02 3.29095811e-01 9.05877054e-02
 9.80404019e-02 3.30951512e-02 6.37333393e-02 2.53760815e-03
 6.08165562e-01 6.10641658e-01 4.96543169e-01 6.42530918e-01
 1.84877515e-02 9.53122377e-02 1.24409139e-01 2.85062492e-02
 2.83734500e-02 5.12534380e-03 6.43979013e-02 2.55421698e-02
 2.22018898e-01 2.68553883e-01 3.06694835e-01 1.85667038e-01
 6.10031486e-01 5.90062201e-01 5.63610196e-01 3.38523477e-01
 2.53503442e-01 3.32830012e-01 4.86434400e-01 8.86642754e-01
 1.78838760e-01 1.63002491e-01 1.46718293e-01 2.99794286e-01
 3.26156616e-04 4.61078584e-02 8.23088586e-02 4.64284122e-02
 7.76499510e-04 1.05046034e-02 1.52443647e-02 1.24074399e-01
 5.51240742e-02 8.72644782e-02 1.29397511e-02 3.84011865e-02
 2.14059651e-02 1.06137991e-02 2.33644247e-02 4.46677506e-02
 8.14923644e-03 3.21074426e-02 8.18759203e-04 5.88051140e-01
 6.78162873e-01 3.84329915e-01 3.30796629e-01 3.31745207e-01
 6.12312615e-01 4.12521660e-01 9.97178793e-01 6.72905445e-01
 2.86261290e-01 5.15499771e-01 9.36450601e-01 4.17387038e-01
 9.11070466e-01 5.57368457e-01 9.81916726e-01 9.16895032e-01
 5.33559203e-01 6.18192673e-01 8.25576544e-01 8.27728212e-01
 7.24710763e-01 6.96099639e-01 3.60531271e-01 9.49847102e-01
 7.73956537e-01 2.39672542e-01 8.59048009e-01 1.04597002e-01
 8.17979097e-01 3.51907313e-02 4.14487511e-01 9.98228192e-01
 1.08141869e-01 1.12156868e-01 1.02871358e-01 4.41262126e-03
 7.03361034e-02 4.21594977e-02 1.03225052e-01 8.75254869e-02
 1.53643280e-01 3.88657749e-01 1.35520488e-01 1.59133077e-01
 2.30084956e-01 1.03754520e-01 9.00897086e-02 1.96605921e-04
 4.03561890e-02 9.37000215e-02 1.18281245e-02 4.18185741e-01
 4.75577503e-01 4.17110354e-01 4.53621477e-01 3.95663500e-01
 4.33310330e-01 4.68973786e-01 4.26882207e-01 4.25612569e-01
 4.18577522e-01 9.86104846e-01 4.41780001e-01 4.25363839e-01
 4.23024118e-01 9.96706128e-01 4.11481231e-01 3.63388002e-01
 4.73497212e-01 3.93210799e-01 4.13056552e-01 3.45198691e-01
 4.21737313e-01 4.75148976e-01 3.47494483e-01 3.99847209e-01
 9.09049630e-01 3.05603862e-01 4.07431722e-01 3.39593530e-01
 9.50822949e-01 3.84397358e-01 1.66516542e-01 5.89258194e-01
 2.34527051e-01 1.52158439e-01 1.03341401e-01 2.88456172e-01
 4.63003397e-01 4.19977605e-02 3.41331750e-01 2.63466060e-01
 7.24444985e-01 1.64347649e-01 9.79896903e-01 3.18035156e-01
 4.55553234e-02 9.28985119e-01 9.78394330e-01 8.19512010e-01
 8.39289784e-01 8.90246034e-01 8.06292593e-01 8.21804285e-01
 8.11833322e-01 9.83958483e-01 8.91443253e-01 8.83779407e-01
 9.20436800e-01 9.76592541e-01 7.71425188e-01 8.65302861e-01
 9.50942874e-01 4.19762731e-03 3.43874097e-03 3.47700715e-03
 1.47587061e-03 3.76026630e-02 3.60530615e-03 3.97548079e-03
 5.38030267e-03 5.96976280e-03 7.99339473e-01 1.85534358e-03
 8.43822956e-04 2.50048935e-02 4.44763899e-03 1.73567533e-02
 4.04562779e-05 1.93372369e-02 1.55182928e-01 2.80467272e-01
 2.65056759e-01 9.42871571e-02 2.39416629e-01 1.11333102e-01
 2.12696463e-01 3.50017190e-01 2.03010648e-01 2.38345951e-01
 2.22680241e-01 9.48496759e-02 2.58619696e-01 9.95578408e-01
 9.03524399e-01 2.22678781e-01 9.18441219e-05 1.28141552e-01
 1.23298168e-02 3.48022580e-03 2.47097015e-02 1.94214284e-02
 1.53852999e-02 3.03041935e-02 1.89032555e-02 2.17911601e-02
 1.12966001e-02 1.52802169e-01 2.92822123e-02 4.41005141e-01
 2.13465095e-03 4.19191420e-02 3.03024054e-03 4.73231077e-04
 2.84152925e-02 3.12578082e-02 1.18173361e-02 2.19117105e-02
 4.19609845e-02 7.58954585e-02 2.74693668e-02 4.68070805e-02
 1.18377507e-02 2.62505114e-02 4.38593328e-02 4.79815006e-02
 1.72183305e-01 2.20139325e-02 1.54499412e-02 5.18232584e-04
 3.17968965e-01 1.42226517e-02 4.74630296e-02 1.43494010e-02
 3.57711017e-02 1.94033384e-02 6.64259553e-01 3.63460183e-03
 6.64379597e-02 1.39972568e-03 1.21036470e-02 7.00265169e-03
 2.38661468e-02 7.33200312e-02 1.25186741e-02 1.84626579e-02
 4.29787338e-02 5.47558069e-04 5.29965520e-01 3.16933692e-02
 1.87634528e-02 2.86148489e-02 2.70821631e-01 3.86123121e-01
 2.83545673e-01 1.13511086e-03 9.68054533e-02 2.18428969e-02
 4.83646035e-01 6.94540143e-03 5.00179231e-02 4.67191041e-02
 4.93146181e-02 2.09296644e-02 1.11647576e-01 1.32134557e-03
 4.95061994e-01 5.11915088e-01 4.25568163e-01 2.35616744e-01
 2.12953389e-01 5.46612501e-01 1.98374599e-01 3.58978271e-01
 8.46320212e-01 7.29133427e-01 1.83370799e-01 3.76126170e-03
 9.03287232e-02 1.23236030e-01 3.60798538e-02 1.53857112e-01
 2.02746332e-01 1.16989464e-01 2.14186966e-01 7.58192062e-01
 9.15895402e-02 2.30206251e-01 9.94247794e-02 3.33326250e-01
 1.53440237e-01 2.45169342e-01 7.52749443e-02 1.58928037e-02
 1.38955146e-01 4.19513881e-01 9.94940042e-01 3.37306559e-01
 5.00333250e-01 7.34807551e-02 2.32788980e-01 9.91313815e-01
 7.74031878e-02 2.81387478e-01 5.09167969e-01 9.94183064e-01
 1.60616487e-01 3.83514941e-01 5.36222458e-01 3.22516739e-01
 2.29674220e-01 3.13441396e-01 9.99530435e-01 1.60702169e-02
 1.75566614e-01 1.70117617e-03 5.71609139e-02 7.86798477e-01
 2.38546431e-02 3.09104919e-02 5.25873899e-03 3.75524163e-03
 2.21792996e-01 2.09927261e-02 1.98174417e-02 4.48262691e-02
 1.71854794e-02 4.16970253e-03 3.61472368e-04 3.75980735e-02
 5.79680204e-01 6.38746023e-01 7.35582709e-01 1.93132997e-01
 9.11271811e-01 3.76594394e-01 7.39522338e-01 6.24365211e-01
 5.49574077e-01 6.15067899e-01 5.99663198e-01 7.17040002e-01
 7.02344477e-01 6.62530124e-01 5.92825651e-01 5.99973977e-01
 1.78481936e-02 1.31937861e-01 2.54471302e-02 8.03157687e-03
 1.62930697e-01 3.17950547e-02 2.23512530e-01 2.09005088e-01
 2.26126313e-01 7.25641251e-02 1.55536413e-01 1.12856269e-01
 1.72587305e-01 5.95724583e-03 2.29655594e-01 7.01249860e-07
 5.45687079e-02 5.70869446e-03 5.39641082e-02 1.07115209e-02
 2.37743855e-02 1.55539304e-01 2.06202269e-03 2.15659440e-02
 2.50104070e-03 4.83093560e-02 2.20685571e-01 4.46805358e-03
 6.72126114e-02 1.35350138e-01 3.46259475e-02 6.02906942e-03
 3.73102129e-02 1.63802505e-03 3.12576890e-02 3.80307436e-04
 4.38952446e-03 1.46778107e-01 1.51437223e-02 6.68955445e-02
 8.09328258e-02 1.04086548e-01 1.12038255e-02 1.53825581e-02
 6.85751438e-04 5.42631745e-03 3.01581621e-03 2.16885507e-02
 1.56617165e-03 5.39509892e-05 1.71327591e-03 5.20616770e-04
 3.68088484e-04 2.54103243e-02 1.40263736e-02 2.09546089e-03
 2.58269906e-03 2.07839906e-02 6.21378422e-04 1.48161948e-02
 1.57174170e-02 5.05489111e-03 1.55833364e-03 1.43119507e-06
 5.41901886e-01 2.65664756e-02 1.32073462e-02 1.49812102e-02
 9.00298357e-04 4.56982851e-03 2.82055736e-02 9.68873501e-04
 1.14325583e-02 3.39779258e-03 1.88156962e-03 1.20139122e-02
 7.12612271e-03 7.36713409e-04 1.93658471e-03 1.75911188e-03
 2.58900404e-01 2.79304750e-05 1.16370753e-08 8.80311272e-05
 1.42902136e-04 1.73436165e-05 5.26621297e-05 1.91211700e-04
 5.02259281e-05 1.26302242e-04 1.21050660e-04 1.48147345e-04
 2.74336999e-05 1.88780882e-06 2.06559896e-04 7.23623161e-05
 3.89910747e-05 1.72635913e-03 4.01857495e-03 2.80794501e-03
 9.84400511e-04 2.93669105e-03 4.39515710e-03 8.07699561e-03
 2.66683102e-03 4.80577350e-03 9.43195820e-03 5.99813461e-03
 2.41881609e-03 5.33062220e-03 4.24611866e-02 5.87415695e-03
 8.92744367e-07 3.06904316e-04 2.13779211e-02 1.72463953e-02
 5.94165921e-03 1.98194683e-02 2.96831131e-03 4.71892953e-03
 1.34806931e-02 6.21980429e-03 1.33770704e-03 4.06998396e-03
 8.88773799e-03 6.56247139e-03 5.57392538e-02 9.08818841e-03
 2.07801759e-02 8.56654660e-05 1.23342872e-03 1.23649836e-04
 3.87638807e-04 1.18380785e-03 5.61833382e-04 1.77532434e-04
 1.39766932e-03 1.15175921e-04 3.51491570e-03 9.53688323e-02
 2.02497840e-03 5.90455532e-03 2.08735466e-04 3.60816717e-04
 3.24380398e-03 1.53273344e-04 7.65378161e-08 5.25266826e-02
 2.50738621e-01 2.47268409e-01 3.70943606e-01 6.14672005e-02
 4.58078682e-02 7.53933787e-02 4.53704983e-01 6.18512690e-01
 1.13641500e-01 5.78876317e-01 6.60703182e-02 8.68155479e-01
 1.67072296e-01 1.64061964e-01 8.46650720e-01 2.76882648e-02
 1.41268373e-02 5.56372404e-02 4.69651818e-03 3.49870324e-03
 7.06319213e-02 4.17391062e-02 5.60665131e-03 1.52171791e-01
 2.05144286e-03 3.64061594e-02 2.11472809e-02 1.05301142e-02
 1.39464736e-02 1.67824328e-02 7.97721624e-01 1.29291415e-03
 1.24186277e-04 5.58103893e-05 4.00866993e-05 8.62568617e-04
 9.48002707e-08 2.10753497e-05 2.11924314e-04 1.75029039e-04
 1.04975334e-04 1.31110655e-05 5.26934862e-04 9.26651483e-05
 6.14076853e-04 3.47183268e-05 1.33961439e-04 2.02667713e-03
 2.89329886e-03 7.78943300e-04 1.67453289e-03 1.53596401e-02
 9.61325943e-01 8.53729248e-03 9.80493426e-03 1.55289471e-02
 1.28390402e-01 7.00277686e-02 2.76491046e-03 6.16742671e-02
 5.31494915e-02 7.48595595e-03 8.87152851e-02 4.30916488e-01
 3.52828801e-02 1.97382569e-02 9.32604074e-04 5.76429665e-02
 1.61026716e-02 1.33750737e-02 1.39552563e-01 2.00308561e-02
 1.09100342e-03 6.37373328e-03 2.72709131e-03 2.57197022e-03
 1.89130902e-02 6.80744648e-04 5.08416593e-02 5.19818229e-07
 9.46351290e-01 2.21677423e-02 4.15918529e-02 6.67236745e-02
 7.79300928e-04 4.61819768e-02 1.44768953e-02 6.64019585e-03
 9.94313955e-02 1.81501806e-02 1.77572906e-01 4.36723232e-04
 9.24068689e-03 2.82031000e-02 1.89704299e-02 4.90056574e-02
 1.13146126e-01 6.63310289e-04 7.82904029e-03 6.37277961e-02
 1.27838850e-02 1.93503201e-02 3.83625031e-02 2.98465490e-02
 1.39939487e-02 1.30052269e-02 3.09313536e-02 2.14059651e-02
 4.20449674e-02 1.56464875e-02 4.02763784e-02 5.22847772e-02
 1.78435445e-02 9.03150558e-01 8.60087633e-01 8.17415357e-01
 5.32542229e-01 6.84497237e-01 7.88083792e-01 7.25901842e-01
 2.18681037e-01 3.53582764e-05 6.57587171e-01 8.26488853e-01
 1.29014254e-04 4.55898963e-08 4.86945271e-01 4.11332965e-01
 7.45767057e-02], shape=(657,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.
 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.
 0. 0. 1. 1. 0. 0. 0. 0. 0.], shape=(657,), dtype=float32)
predicted label rank:[1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 2 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 1 2 2 1 2
 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 2 1 2 1 1 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2
 1 1 2 1 1 2 2 1 1 2 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 2 1
 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 1 1 2 2 1 1 1 1 1]
mse:tf.Tensor(0.16726248, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/reverse_ret_unsafe.c_000.smt2
true label:[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[7.07678497e-02 9.99421597e-01 3.65197659e-04 7.80662417e-01
 1.07074678e-02 3.89964581e-02 2.59277821e-02 2.46664882e-03
 1.08385980e-02 2.49624252e-04 6.78449869e-04 3.00650669e-07
 8.26524501e-06 3.04057300e-02 5.12689352e-04 6.66406559e-05
 3.16488743e-03 4.82064486e-03 5.45156002e-03 1.22740269e-02
 5.52734733e-03 2.92620063e-03 1.59144402e-04 2.52434611e-03
 1.70637486e-06 1.26957893e-04 1.42982602e-03 4.24385071e-04
 1.92403793e-04 6.40003564e-05 3.62810679e-05 8.06540251e-04
 4.62979078e-04 1.07906708e-05 3.01480293e-04 5.04577160e-03
 5.75244427e-04 6.06966019e-03 7.12692738e-04 1.13429517e-01
 6.23285770e-04 1.18702766e-04 3.25709581e-04 1.82509422e-04
 4.47306520e-05 2.10136175e-04 1.75237656e-04 7.70332481e-05
 1.90615654e-04 3.24666500e-04 1.80258430e-05 3.40849161e-04
 3.66747379e-04 6.12920523e-03 8.02645087e-03 1.79031413e-05
 1.05413795e-03 7.29173422e-04 1.71889961e-02 4.18096781e-04
 2.39640474e-04 6.03377819e-04 3.43471766e-04 4.59134579e-04
 7.41705153e-05 2.80097395e-01 9.99389648e-01 2.02029943e-04
 2.77787447e-04 2.97337770e-04 6.99222088e-04 8.62547636e-01
 2.32113666e-06 1.25917792e-03 1.18574500e-03 2.49835625e-06
 4.19357275e-05 4.66094498e-05 2.68296890e-06 1.06781721e-03
 3.88464332e-03 4.56995531e-06 3.00017418e-05 2.97665596e-04
 8.47655101e-05 1.56015158e-04 1.33193181e-08 1.71899796e-04
 1.13862127e-01 2.84701586e-04 1.35425806e-01 2.45204568e-02
 2.16126442e-04 2.48908997e-04 8.87230453e-06 5.84298868e-06
 9.78020509e-09 1.21511976e-05 1.15487232e-07 2.34732752e-07
 2.82140661e-07 6.12764052e-06 1.30334611e-05 2.12997198e-04
 7.76467568e-05 2.15679407e-04 1.91859275e-08 4.19411063e-03
 1.31368637e-04 1.12521766e-05 3.68209330e-05 4.48198080e-07
 6.49569287e-08 1.26985096e-05 5.25469159e-06 1.55597925e-04
 9.21720186e-07 2.74420586e-06 5.75859303e-06 1.61277167e-05
 7.49817488e-08 4.14950314e-08 2.81405719e-05 5.22170573e-08
 7.55984900e-07 6.09985227e-06 1.13641113e-06 8.44826388e-07
 8.50023298e-06 1.35481358e-04 4.76807400e-05 1.39771964e-05
 3.12978500e-06 8.94649274e-05 1.14743743e-04 2.86221504e-04
 3.56434612e-06 5.85049391e-04 3.90520108e-06 1.68195367e-03
 5.26636839e-04 1.72749162e-03 1.31493807e-03 7.30514526e-04
 5.55220246e-03 8.89021794e-06 3.47188115e-02 9.78359938e-01
 2.70341225e-05 4.36278284e-02 1.51285529e-03 4.82704639e-02
 2.11857557e-02 1.24010775e-08 9.43611562e-02 2.27868557e-04
 1.49160624e-04 5.01060094e-06 1.83132291e-03 3.05689394e-01
 1.44868493e-02 2.34067440e-04 1.13895535e-03 5.72144854e-05
 1.57760978e-02 8.32513273e-02 3.17353904e-02 2.22393870e-03
 4.62800264e-04 1.45894289e-03 9.88240572e-06 6.98207659e-05
 9.08454149e-06 1.10451794e-04 7.37917480e-06 2.70730816e-05
 9.39649472e-05 2.56232917e-02 2.36276388e-02 8.24310519e-07
 3.00738215e-03 1.10091865e-02 7.18304515e-03 8.43048096e-04
 1.81155428e-05 1.68371201e-03 1.38193369e-04 2.46793032e-04
 8.80423340e-06 1.11292809e-06 6.08103861e-08 5.12017687e-06
 2.77656317e-03 1.15564555e-01 3.49884708e-08 2.58349180e-01
 2.70071626e-03 3.72233987e-03 1.21886134e-02 6.87954605e-01
 4.83742356e-03 8.37796926e-03 7.54585862e-03 4.27424908e-04
 1.24597549e-03 3.13878059e-04 7.75092840e-03 1.71065331e-04
 9.28104964e-06 4.54843044e-04 1.72939035e-05 6.01768970e-01
 4.70325351e-03 5.75107157e-01 1.00887716e-02 4.56056893e-02
 7.29644299e-03 4.01083618e-01 1.82762742e-03 3.09115648e-03
 7.21603632e-04 3.98676187e-01 2.17556953e-04 1.33002400e-02
 1.67952776e-02 1.85210109e-02 2.37854421e-02 4.42951918e-04
 9.65040028e-02 7.87537720e-05 4.44322824e-04 2.76863575e-04
 1.66153908e-03 6.79947043e-05 1.39430340e-05 1.93601847e-02
 1.09465858e-04 1.11263990e-03 1.12033347e-04 8.15063715e-04
 3.41206789e-04 4.38362360e-04 4.99963760e-04 7.56551027e-02
 2.03163922e-01 6.27801046e-06 3.94317508e-02 5.74862815e-06
 1.11187696e-02 6.37823343e-03 1.86033547e-02 4.64690447e-01
 3.73700261e-03 4.25555408e-02 6.96265042e-01 8.10601413e-02
 6.36309385e-04 7.31641054e-03 1.65394247e-01 7.48113280e-06
 4.46784437e-01 1.18593460e-04 4.74308878e-01 1.88054144e-02
 1.37769759e-01 1.73282623e-03 2.62320042e-04 1.53913390e-06
 4.97609377e-04 9.27149131e-07 7.63833523e-04 4.53550965e-05
 3.49373221e-02 1.35859636e-07 1.29481805e-06 2.43932009e-04
 9.18602309e-05 2.09219525e-05 5.69362310e-05 4.83619760e-06
 4.82236686e-08 7.34241621e-05 8.16403408e-05 1.20649411e-05
 1.81943178e-04 2.94971414e-05 1.50948763e-04 1.04895234e-03
 1.54005602e-06 4.48107719e-04 2.79873610e-04 6.78271055e-04
 9.08011198e-03 6.66604042e-01 1.23540860e-06 4.03684080e-02
 2.77996628e-06 9.84738108e-06 4.42042947e-03 2.71568251e-06
 2.34417212e-06 1.13139413e-05 2.85891474e-05 8.11323844e-06
 3.84062529e-04 3.04222107e-04 3.57404351e-03 1.45540237e-02
 1.13534927e-03 1.50293112e-04 2.16086377e-07 2.19478170e-05
 1.46097243e-02 7.32153654e-04 4.78307426e-01 9.64490771e-01
 1.06841326e-03 4.78396541e-05 3.94761562e-04 3.88723612e-03
 1.27241015e-03 7.57798553e-03 4.48903520e-05 1.85579062e-04
 1.45375729e-03 9.31690010e-05 3.16161215e-02 6.51149750e-02
 2.29252785e-01 2.76755571e-01 1.28374457e-01 3.49529073e-05
 1.10535324e-02 7.36044526e-01 3.44756554e-05 9.92738605e-01
 6.68674707e-04 1.37507915e-04 5.15222549e-04 7.33208656e-03
 2.38705707e-05 5.30302525e-04 5.44071198e-04 1.47259235e-03
 5.48280877e-05 1.87480450e-03 6.42389059e-04 5.58410406e-01
 3.37371239e-06 1.44924611e-01 1.40452385e-03 8.99662971e-01
 2.68369913e-04 1.93155620e-06 1.24095368e-06 2.72534996e-01
 1.52377155e-22 9.99954700e-01 6.57519698e-03 5.12647629e-02
 2.28440762e-03 7.89926635e-05 3.84062529e-04 5.84245205e-01
 2.70703465e-01 8.23794901e-01 5.02564311e-02 5.42490397e-07
 2.76695162e-01 5.75669050e-01 7.23158717e-02 2.41897283e-07
 2.03779340e-03 1.86383724e-04 1.50859356e-04 9.34070528e-01
 3.13073397e-03 2.96473503e-04 4.49350476e-03 5.00386953e-03
 1.06474246e-07 5.06087235e-06 1.70372587e-08 3.09135648e-05
 1.72734261e-04 1.99863825e-05 3.42052444e-05 6.88135624e-04
 1.66601637e-07 2.60323286e-04 5.78680634e-01 2.34961510e-04
 1.44778312e-07 2.65488680e-08 7.27156021e-07 1.30247491e-09
 5.59150976e-06 7.55816698e-04 1.15870162e-05 1.35117769e-03
 7.57201487e-05 1.12664700e-03 8.19653273e-04 4.44686413e-03
 9.03600454e-03 9.53929007e-01 1.14591074e-08 1.98188105e-10
 1.54331305e-11 8.16162064e-05 5.94989479e-01 2.64614820e-04
 5.51302810e-06 9.98912692e-01 5.27083874e-04 5.11201677e-07
 4.22504187e-01 7.98401237e-03 4.76053137e-05 7.31483102e-03
 1.87632520e-06 3.07083130e-04 1.44267082e-03 9.59520400e-01
 3.81469727e-04 7.11500645e-03 2.14815140e-03 1.60057545e-02
 2.68806636e-01 6.51681423e-03 1.75880194e-02 9.63791013e-02
 2.24269331e-02 5.20952472e-06 1.25241314e-07 2.48114079e-01
 1.33119654e-10 2.98402041e-01 1.79737806e-04 1.44034624e-04
 1.02454424e-03 6.28620386e-04 2.48424411e-02 1.57879740e-07
 1.39370561e-03 1.25661492e-03 2.96101607e-05 6.92912579e-01
 3.79765034e-03 1.43545866e-03 4.66211418e-07 1.47312880e-04
 2.40266323e-04 1.14116073e-03 9.55563784e-03 6.02194905e-01
 1.49291754e-03 1.51555049e-12 3.75449538e-08 2.13970225e-06
 9.84161735e-01 9.97437894e-01 1.07725988e-08 1.53864603e-05
 4.58168983e-03 1.70915496e-06 4.11224365e-03 2.85870135e-02
 8.27383995e-03 8.84254114e-05 1.59501633e-05 5.56087315e-01
 4.21762168e-02 8.59394670e-03 8.29006076e-01 2.63403654e-02
 4.04180497e-01 1.59653723e-02 1.58224195e-01 1.64114008e-05
 4.98618722e-01 2.68016458e-01 3.17215919e-04 7.76146173e-01
 3.66784820e-06 2.06073111e-07 2.40049280e-06 1.79929339e-05
 1.45029553e-05 1.42205977e-07 3.57484314e-05 4.29036008e-05
 3.65878208e-08 3.20357941e-07 6.34252501e-07 1.89095936e-05
 1.20659306e-05 4.98444524e-06 1.47874562e-06 1.23858452e-04
 2.07906178e-05 2.69583543e-05 2.61304399e-06 1.35958195e-04
 4.66278789e-06 1.68991228e-05 9.56210170e-06 1.23398277e-04
 4.90344246e-05 4.86671925e-04 3.49236666e-06 4.63674733e-05
 5.54116184e-07 8.42046738e-03 1.51975172e-07 6.44460499e-07
 5.38343465e-06 4.52071902e-07 4.57852511e-05 6.32965565e-03
 2.48968601e-04 5.32375852e-05 5.44242175e-06 1.84416771e-04
 1.69903040e-04 8.48442316e-04 6.07212883e-07 3.93138635e-07
 7.36622994e-08 2.17556953e-04 4.08172607e-04 2.28303989e-08
 1.34312357e-08 3.68790934e-05 1.74801789e-05 9.58495021e-01
 1.10594247e-05 5.26726246e-04 7.60924422e-07 4.41443920e-03
 1.02902326e-04 1.79304116e-05 7.20118669e-06 6.86027925e-05
 1.97904174e-05 1.53277218e-02 6.67303801e-04 7.72876319e-07
 5.90689297e-06 1.09199082e-05 3.66061649e-05 4.16427851e-04
 1.24847547e-05 2.21156006e-06 2.90399421e-05 3.21567059e-04
 1.15551637e-04 1.43706799e-04 7.09167123e-03 4.34253161e-05
 2.47691114e-05 4.42870441e-05 2.55018473e-04 3.82274389e-04
 9.06278274e-07 1.46644688e-05 1.60854142e-05 2.31021409e-06
 7.43534088e-08 3.15562306e-06 8.07844117e-06 1.18759948e-04
 7.05217144e-06 3.24625626e-06 1.88810864e-05 6.52492046e-04
 5.85979052e-08 1.78916707e-07 8.59987736e-03 4.85415995e-01
 1.42425299e-03 3.07462687e-05 2.06982495e-05 1.20379925e-02
 2.22268701e-03 1.20637276e-04 5.16700027e-07 1.06259859e-06
 3.85850668e-04 6.40273094e-04 7.45335221e-03 2.96083093e-03
 1.85826421e-03 4.68552113e-04 8.20815563e-04 3.47077847e-04
 1.60589218e-02 4.37266062e-05 6.85158193e-01 9.71406698e-04
 5.91108203e-03 6.72208043e-05 1.10483170e-03 6.73979521e-04
 3.75096142e-01 1.36260724e-05 1.25809014e-02 9.14517732e-05
 6.27666712e-04 8.78900290e-04 1.76219970e-07 1.93715096e-03
 1.68988645e-05 7.07125719e-06 7.39179254e-02 8.33365321e-03
 3.64334881e-02 6.52173185e-06 3.51938874e-01 1.77374943e-07
 5.48727810e-02 1.73985958e-03 6.43832982e-02 1.18756294e-03
 3.91712785e-02], shape=(625,), dtype=float32)
rounded label:tf.Tensor(
[0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0.], shape=(625,), dtype=float32)
predicted label rank:[1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2
 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1
 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1
 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.036233775, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/count_by_2_m_nest_000.smt2
true label:[1, 1, 1]
true label rank:[1 1 1]
predicted label:tf.Tensor([7.8406425e-05 9.9956536e-01 9.9910665e-01], shape=(3,), dtype=float32)
rounded label:tf.Tensor([0. 1. 1.], shape=(3,), dtype=float32)
predicted label rank:[1 2 2]
mse:tf.Tensor(0.3332814, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/jm2006_true-unreach-call.c.flat_000.smt2
true label:[1, 1, 1, 1]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([0.21920377 0.21028596 0.9696033  0.995614  ], shape=(4,), dtype=float32)
rounded label:tf.Tensor([0. 0. 1. 1.], shape=(4,), dtype=float32)
predicted label rank:[1 1 2 2]
mse:tf.Tensor(0.30855855, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0016_000.smt2
true label:[1, 1, 1, 1]
true label rank:[1 1 1 1]
predicted label:tf.Tensor([0.99949914 0.9291593  0.93459654 1.        ], shape=(4,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)
predicted label rank:[1 1 1 1]
mse:tf.Tensor(0.0023240675, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0002_000.smt2
true label:[1, 1]
true label rank:[1 1]
predicted label:tf.Tensor([0.76184684 0.99172753], shape=(2,), dtype=float32)
rounded label:tf.Tensor([1. 1.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.02839268, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/minepump_spec2_product58_true-unreach-call.cil.c.flat_000.smt2
true label:[0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1]
true label rank:[1 2 1 2 2 2 1 1 2 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1 2 1 1 2 2 2 2 1 1 1 2 1 2
 2 1 2 2 2 2 2 1 1 2 2 1 1 1 2 2 2 1 1 1 2 2 1 2 2 2 1 1 2 2 1 2 1 2 2 1 2
 1 2 2 2 2 1 1 1 2 2 2 1 2 1 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 2 2 2 1 1 2 1 2
 1 2 1 2 2 2 1 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1
 1 1 2 1 2 1 1 1 2 1 2]
predicted label:tf.Tensor(
[1.61316991e-03 3.03451884e-06 5.80312690e-06 3.27333570e-01
 8.66310418e-01 1.67429477e-01 4.77007031e-03 1.23329937e-01
 1.23595536e-01 6.46446049e-02 9.98646021e-03 1.80213124e-01
 6.55882835e-01 2.82299817e-01 3.12656343e-01 1.94345266e-01
 6.79545403e-01 1.65347338e-01 7.16295838e-03 7.75275648e-01
 6.81872070e-01 5.13774157e-01 4.47702557e-01 5.73703647e-01
 5.58653355e-01 5.28683543e-01 5.60090184e-01 5.47012746e-01
 6.13052428e-01 4.22508001e-01 9.80553031e-03 1.83338821e-01
 4.30398703e-01 3.42623442e-01 4.01156604e-01 3.84636194e-01
 2.34852046e-01 4.96693283e-01 4.33400869e-01 4.59851921e-01
 5.03177583e-01 2.11598277e-02 3.44066650e-01 5.92611611e-01
 3.42141449e-01 1.79110467e-02 4.47912008e-01 5.88398337e-01
 1.48270041e-01 1.69489324e-01 3.85579407e-01 2.20453948e-01
 3.86721313e-01 6.87954485e-01 2.22125709e-01 7.35098302e-01
 9.91355419e-01 8.77405643e-01 8.93068016e-01 8.21056843e-01
 8.84615779e-01 5.22123873e-01 6.07211113e-01 7.57550955e-01
 3.30683589e-03 3.36656570e-02 3.97661328e-03 7.82420516e-01
 4.95440900e-01 4.38986361e-01 4.11738008e-01 4.76150662e-01
 4.32234377e-01 5.01417935e-01 5.42706847e-01 1.10245526e-01
 3.74383807e-01 7.83182383e-01 7.82354355e-01 9.99268234e-01
 4.24751610e-01 6.80603853e-06 9.45668697e-01 5.16757488e-01
 5.24132311e-01 4.84446049e-01 4.44989800e-01 5.14412880e-01
 3.40224683e-01 3.41841578e-03 3.94135714e-03 3.99667203e-01
 4.48569655e-01 4.31089997e-01 3.61539066e-01 1.50605142e-01
 3.13605785e-01 1.68488473e-01 3.03663552e-01 3.63465905e-01
 8.38065753e-05 5.31982780e-02 3.13796997e-02 3.62476468e-01
 8.11555982e-03 3.10024679e-01 2.94795215e-01 3.47723424e-01
 2.55309522e-01 1.92638606e-01 4.03385222e-01 9.88844752e-01
 6.41494989e-04 1.13794208e-03 1.13687515e-02 4.93708376e-06
 5.90932667e-02 3.45087618e-01 3.05078864e-01 1.85626805e-01
 2.62481719e-01 2.26839185e-01 3.12484145e-01 2.09982488e-07
 2.15412945e-01 3.58879566e-04 6.68713450e-03 5.35375705e-07
 1.35633200e-01 1.61183119e-01 1.94315761e-01 2.42835939e-01
 8.82101655e-02 9.37238634e-02 1.74618065e-02 6.22094214e-01
 2.97486782e-04 2.79724598e-04 5.05799055e-02 2.87932158e-02
 3.80969644e-02 6.81220233e-01 4.13154393e-01 1.36494637e-04
 9.34682250e-01 4.73899841e-02 9.82099295e-01 4.10504639e-01
 5.98033130e-01 8.01819801e-01 1.55480236e-01 8.03485751e-01
 3.08826923e-01 1.06987357e-03 9.96296763e-01 5.20160198e-02
 6.97878003e-03 4.03349400e-02 3.13979387e-03], shape=(159,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1.
 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.
 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0.], shape=(159,), dtype=float32)
predicted label rank:[1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 2 1 1 2 2 2 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1
 1 1 1 2 1 1 2 1 1 1 2 1 1 1 1 1 2 1 2 2 2 2 2 2 2 2 2 1 1 1 2 1 1 1 1 1 2
 2 1 1 2 2 2 1 1 2 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 2 1 2 1
 2 2 1 2 1 1 2 1 1 1 1]
mse:tf.Tensor(0.36440685, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/s3_srvr_1a.cil.c-1_000.smt2
true label:[0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1]
true label rank:[1 2 2 1 1 1 2 1 1 1 1 2]
predicted label:tf.Tensor(
[7.3828840e-01 9.7766393e-01 8.5875332e-02 1.3139069e-02 1.8037856e-03
 1.8421459e-01 6.5687895e-01 2.0025751e-01 5.1597953e-03 1.2501711e-01
 9.7391009e-04 3.9744660e-01], shape=(12,), dtype=float32)
rounded label:tf.Tensor([1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], shape=(12,), dtype=float32)
predicted label rank:[2 2 1 1 1 1 2 1 1 1 1 1]
mse:tf.Tensor(0.16265552, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/chc-lia-lin-0125_000.smt2
true label:[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1
 1 1 1 1]
predicted label:tf.Tensor(
[9.99999166e-01 8.96254778e-01 9.96898651e-01 8.48264933e-01
 1.00000000e+00 1.37498975e-02 1.00000000e+00 9.99550641e-01
 9.96883810e-01 9.99416113e-01 2.44394243e-02 9.99458790e-01
 9.99965191e-01 9.91751909e-01 9.99997377e-01 9.98889923e-01
 1.24371767e-01 9.99990106e-01 1.26242638e-04 9.82570350e-01
 9.99984026e-01 9.65009689e-01 8.38343084e-01 9.99132097e-01
 9.61631775e-01 9.99923110e-01 9.99998927e-01 2.63416767e-03
 9.99664307e-01 9.89442766e-01 1.57250639e-08 3.11940908e-04
 9.96821284e-01 1.00000000e+00 1.00841202e-23 9.99320030e-01
 1.00000000e+00 8.34193170e-01 9.64951992e-01 1.80764200e-05
 9.99626875e-01], shape=(41,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1.
 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1.], shape=(41,), dtype=float32)
predicted label rank:[2 2 2 2 2 1 2 2 2 2 1 2 2 2 2 2 1 2 1 2 2 2 2 2 2 2 2 1 2 2 1 1 2 2 1 2 2
 2 2 1 2]
mse:tf.Tensor(0.7464108, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/apache-get-tag.i.v+lhb-reducer.c-1_000.smt2
true label:[1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1]
predicted label:tf.Tensor([0.26976526 0.48537803 0.9313654  0.99777293 0.8703295  0.6679275 ], shape=(6,), dtype=float32)
rounded label:tf.Tensor([0. 0. 1. 1. 1. 1.], shape=(6,), dtype=float32)
predicted label rank:[1 1 2 2 2 2]
mse:tf.Tensor(0.15498012, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/12.c_000.smt2
true label:[1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0]
true label rank:[2 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1
 2 2 1 1 2 2 1]
predicted label:tf.Tensor(
[5.8437300e-01 6.3036501e-02 1.9899815e-01 6.0051680e-04 2.8857797e-01
 4.0578097e-01 4.8240688e-01 6.0961102e-05 5.6338310e-04 6.0017705e-03
 4.5382977e-04 1.4414161e-02 5.7509542e-04 2.3984909e-04 6.8724394e-02
 4.3029621e-01 5.5526268e-01 4.9110258e-01 2.2737846e-01 2.9939663e-01
 5.5985749e-02 7.9102516e-03 1.5668196e-06 4.0254664e-01 1.4023569e-01
 8.9153647e-04 5.8388072e-01 1.3958574e-05 1.5174714e-01 2.8385052e-01
 8.7022579e-01 9.2630404e-01 7.6651913e-01 5.4910630e-01 4.3782994e-01
 7.7794284e-02 8.9485377e-01 1.1853278e-02 9.2795062e-01 8.1479955e-01
 6.4596534e-04 6.1459172e-01 8.1526792e-01 3.1346393e-01], shape=(44,), dtype=float32)
rounded label:tf.Tensor(
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0.], shape=(44,), dtype=float32)
predicted label rank:[2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 1 2
 1 2 2 1 2 2 1]
mse:tf.Tensor(0.24705167, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/25.c_000.smt2
true label:[0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 2 2 2 2 1 1 2 2 2 2 1 1 2 2 2 2 1 1 2 2 2 2 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.82871234 0.50404906 0.62428343 0.5161379  0.17601338 0.00514701
 0.7861041  0.6546502  0.70874536 0.71371734 0.7259387  0.68853843
 0.91153586 0.5545574  0.35479206 0.6391529  0.5638164  0.33341527
 0.13248312 0.93924654 0.9454284  0.60072756 0.331138   0.69916505
 0.01424921 0.04897764 0.03170085 0.00100157 0.32041743 0.01796919], shape=(30,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1.
 0. 0. 0. 0. 0. 0.], shape=(30,), dtype=float32)
predicted label rank:[2 2 2 2 1 1 2 2 2 2 2 2 2 2 1 2 2 1 1 2 2 2 1 2 1 1 1 1 1 1]
mse:tf.Tensor(0.21812978, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/SpamAssassin-loop.i.v+cfa-reducer.c-1_000.smt2
true label:[0, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 2 2 2 2 2 2 2 2 2]
predicted label:tf.Tensor(
[0.6485532  0.77781934 0.9942026  0.9273846  0.6009423  0.7973002
 0.10918573 0.94765264 0.9819455  0.4938237 ], shape=(10,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 0. 1. 1. 0.], shape=(10,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 1 2 2 1]
mse:tf.Tensor(0.17284572, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/tridag.smt2-0014_000.smt2
true label:[1]
true label rank:[1]
predicted label:tf.Tensor([0.60718644], shape=(1,), dtype=float32)
rounded label:tf.Tensor([1.], shape=(1,), dtype=float32)
predicted label rank:[1]
mse:tf.Tensor(0.1543025, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/SYNAPSE_123_e8_953_e7_1465_000.smt2
true label:[1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]
true label rank:[2 1 1 2 1 1 1 2 1 2 1 2 2 1 1 1 1 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 1 1 2 2 2
 1 1 1 2 1 1 2 1 2 2 2 1 2 1 2 2 2 2 1 2 2 2 2 2 2 1 1 1 1 1 2 2 2 2 1 2 2
 1 2 2 1 2 2 1 2 1 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2
 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2
 2 2 2 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2
 2 1 2 1 1 1 1 1 1 1 2 2 2 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 2 2 1 1 1
 1 1 1 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 2 2 1 2 2 2
 2 2 2 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2]
predicted label:tf.Tensor(
[9.9522662e-01 9.6863824e-01 3.0747539e-01 9.9964178e-01 4.3172503e-01
 7.1477592e-03 4.8285210e-01 9.5174348e-01 7.6583469e-01 9.9153841e-01
 5.7515274e-16 9.9896699e-01 8.1176535e-05 3.4405988e-01 8.1823123e-01
 7.0080578e-02 1.3069776e-01 1.5134019e-01 1.2716752e-01 2.4417689e-01
 3.3602971e-01 6.6267252e-02 5.8708072e-02 6.9369608e-01 2.8690797e-01
 4.5462433e-01 6.0940522e-01 4.9766898e-04 9.4059408e-02 7.1996909e-01
 9.6555650e-01 3.9370140e-01 6.0973865e-01 1.3309717e-04 7.0156753e-01
 0.0000000e+00 1.3727813e-12 0.0000000e+00 9.8651004e-01 9.9999654e-01
 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.1402215e-06 6.9313060e-08
 0.0000000e+00 1.0000000e+00 5.1903069e-02 0.0000000e+00 1.0000000e+00
 1.4483940e-10 1.0000000e+00 9.9997854e-01 2.7197599e-04 7.3496481e-10
 4.2271584e-01 7.3065436e-01 7.8100663e-01 9.0359080e-01 8.9313310e-01
 2.6279104e-01 2.8655899e-01 3.2987154e-01 1.8834084e-02 9.8244250e-03
 7.8704059e-03 6.8679452e-03 6.6551744e-05 1.2158355e-01 1.1782140e-02
 3.9724410e-03 3.0101001e-02 9.3857527e-01 9.3081331e-01 3.3765346e-02
 9.9931085e-01 9.9982780e-01 9.6550596e-01 9.9998546e-01 3.1945109e-04
 3.1331867e-02 6.4242089e-01 4.0429592e-02 6.2044752e-01 6.8013489e-01
 5.3725487e-01 1.3062358e-04 3.1047302e-01 2.8626770e-02 3.3542467e-09
 1.6555190e-04 1.6169146e-01 3.6473006e-02 1.0664884e-05 1.6646385e-03
 7.3985904e-02 2.0900369e-04 1.7344952e-04 3.8938373e-02 6.2690234e-01
 4.7563314e-03 1.1679199e-01 5.4161787e-02 1.0695520e-01 3.4716725e-04
 1.6500503e-01 2.7053952e-02 9.9679601e-01 3.5641789e-03 9.9834400e-01
 3.4747857e-01 6.8664551e-04 1.6775727e-04 6.0486794e-03 9.1844995e-05
 8.2125664e-03 3.7211429e-09 3.1661028e-05 1.9216478e-02 1.4334155e-05
 1.5038252e-04 9.8135847e-01 9.9984896e-01 9.9763095e-01 5.3910530e-01
 4.2442244e-01 9.3891412e-02 6.1657000e-01 4.4734040e-01 1.0552263e-01
 5.2422708e-01 6.0289538e-01 5.7002866e-01 5.2692729e-01 7.1402687e-01
 6.6289037e-01 3.5262945e-01 2.2392541e-02 4.8254684e-01 9.9393606e-01
 1.5708783e-01 4.5248380e-01 2.7083245e-01 1.2600205e-07 1.2546778e-04
 1.6889215e-02 1.9097328e-04 1.8366665e-02 2.9528332e-01 2.4213278e-01
 1.8598962e-01 1.1884779e-01 1.8308282e-02 3.7318768e-12 1.1597818e-01
 3.1324005e-01 6.0042202e-02 1.9798455e-01 3.1995773e-04 9.7894669e-04
 1.5434116e-02 9.6090138e-03 1.3653921e-07 2.4210478e-05 2.3969714e-16
 2.6922095e-01 1.3494333e-07 4.8157142e-07 2.2630394e-03 5.9113701e-09
 5.2267611e-03 4.3340167e-01 3.7132588e-01 1.2420061e-01 9.9282348e-01
 9.9985319e-01 9.9038780e-01 9.9998635e-01 9.9993527e-01 1.0589659e-03
 7.0085078e-01 4.1503906e-03 1.2174845e-03 1.6257763e-02 8.2172751e-02
 3.0549081e-36 4.2219204e-01 5.7604313e-01 9.5239282e-04 0.0000000e+00
 3.2174587e-04 1.2689534e-01 3.5284287e-01 5.4633182e-01 1.1954665e-01
 6.9679511e-01 8.0434531e-01 4.0345451e-01 2.6900196e-21 6.4774563e-06
 6.8804529e-22 1.4493610e-18 5.6194622e-27 3.3554226e-02 1.2214064e-18
 1.3239545e-25 2.0672540e-11 1.4351588e-06 4.6550930e-03 1.4453185e-08
 1.1730503e-14 1.5842143e-34 2.2129090e-07 3.4566353e-22 4.6604972e-14
 1.1572081e-17 6.7736645e-26 3.0230915e-25 1.2705994e-26 1.5801913e-01
 2.8948250e-05 5.9266476e-08 1.7381752e-05 1.6228613e-32 5.3316732e-28
 7.6202199e-27 1.8661214e-17 2.2477892e-01 2.7397883e-01 1.5845230e-01
 1.0186921e-09 8.0117643e-05 3.0763882e-01 2.1451712e-04 1.5920073e-02
 2.2519270e-01 4.3751204e-01 3.1175405e-01 2.1388330e-06 9.8583239e-01
 3.1499428e-01 2.0489171e-01 3.5708454e-01 1.8976992e-01 1.4299843e-01
 6.3328880e-06 2.9379535e-01 3.0514896e-03 8.9723931e-12 1.7534308e-05
 1.0087827e-01 1.1899793e-01 5.3379864e-02 2.4254319e-01 9.9997067e-01
 6.5739952e-22 9.9999964e-01 9.9997485e-01 9.9994302e-01 9.9998182e-01
 5.5133045e-01 7.5530005e-01 5.9169823e-01 4.9348500e-01 2.7107259e-09
 2.8107899e-01 9.5496241e-12 4.4888258e-04 5.2947026e-01 5.9397091e-11
 9.6978039e-01 2.3779768e-13 2.0810962e-04 6.8650872e-01 1.9356608e-04
 2.0302948e-12 8.4108114e-02 1.2524722e-06 1.7115699e-05 3.7567845e-06
 2.1246037e-01], shape=(281,), dtype=float32)
rounded label:tf.Tensor(
[1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0.
 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0.
 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.], shape=(281,), dtype=float32)
predicted label rank:[2 2 1 2 1 1 1 2 2 2 1 2 1 1 2 1 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1
 1 2 2 2 1 1 1 1 1 2 1 1 2 1 2 2 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2
 1 2 2 2 2 1 1 2 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 2 1
 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1 2 1 1 2 2 2 2 2 2 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 2 1 1 1 1
 1 1 2 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2
 2 2 2 2 1 1 1 1 1 2 1 2 1 1 2 1 1 1 1 1 1 1]
mse:tf.Tensor(0.4289937, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/gj2007_m_3_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.9976481  0.9936074  0.99420464 0.96284485 0.8937502  0.9092423
 0.92747295 0.98717725 0.9976096  0.99372923 0.9938655  0.99992955
 0.9786147  0.9115921  0.92791533 0.9956742  1.         1.
 0.98780406 0.9990085 ], shape=(20,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(20,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.0020065831, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/apache-get-tag.i.p+nlh-reducer.c-1_000.smt2
true label:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
true label rank:[1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[0.9822967  0.99031496 0.8763675  0.9977205  0.5886116  0.97784805
 0.02086282 0.4716652  0.9829136  0.9967629 ], shape=(10,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 0. 0. 1. 1.], shape=(10,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 1 1 2 2]
mse:tf.Tensor(0.14235783, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/durationThm_2_e1_118_000.smt2
true label:[1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[2 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[6.4926505e-01 9.9973321e-01 8.4029067e-01 9.6662152e-01 9.7261399e-01
 1.0000000e+00 7.2231829e-01 1.0000000e+00 1.1664918e-01 3.3706546e-01
 1.7898589e-02 5.8609211e-01 9.2719793e-02 6.1988568e-01 3.0423579e-01
 1.0000000e+00 5.4466188e-02 4.1891778e-01 4.8457620e-01 2.1851669e-08
 6.5007473e-05 7.1778774e-09 9.0025067e-03], shape=(23,), dtype=float32)
rounded label:tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.], shape=(23,), dtype=float32)
predicted label rank:[2 2 2 2 2 2 2 2 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1]
mse:tf.Tensor(0.31350422, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/minepump_spec5_product55_true-unreach-call.cil.c.flat_000.smt2
true label:[1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1]
true label rank:[2 1 1 2 1 1 1 2 1 2 1 2 1 1 2 1 1 2 2 1 2 2 1 1 2 1 1 1 2 1 2 1 2 2 1 1 1
 2 2 1 1 1 2 2 2 2 1 2 2 2 1 2 1 1 1 2 1 2 2 2 2 2 1 2 2 1 1 1 2 1 2 2 2 2
 2 2 1 2 1 1 2 2 2 2 2 2 2 2 1 1 2 1 1 2 1 1 2 2 2 2 2 2 2 2 1 1 2 1 1 2 2
 1 1 2 2 2 2 2 2 2 1 1 1 1 2 1 2 2 2 2 2 2 2 1 1 2 2 1 1 1 1 2 1 2 2 2 2 2
 2 2 1 1 1 2 2 2 1 2 2 2 2 2 2 2 2 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 1 1 1 2 1
 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 2 1 2 1 1 1 1 1 2 1 2]
predicted label:tf.Tensor(
[3.29661369e-03 1.16062403e-01 1.46597624e-04 5.85313678e-01
 6.22058451e-01 2.46163189e-01 1.23313069e-03 1.09069169e-01
 5.45990586e-01 7.96315372e-01 1.25503868e-01 5.31388521e-02
 1.36884242e-01 6.78746164e-01 5.41172922e-01 3.71144801e-01
 4.29016650e-02 3.22028399e-01 4.08817381e-01 4.29049939e-01
 4.86579895e-01 9.04350281e-01 1.09896958e-01 9.39182699e-01
 9.05540586e-02 8.43292594e-01 5.66195667e-01 4.95698839e-01
 5.86401939e-01 3.45799744e-01 5.60517311e-01 5.21714211e-01
 5.59480488e-01 4.30187285e-02 3.63615155e-03 6.21367931e-01
 2.94557929e-01 3.85571480e-01 4.99664485e-01 5.53167939e-01
 9.98689711e-01 4.58172053e-01 5.24544885e-06 9.94074702e-01
 9.81899083e-01 5.49844742e-01 4.97475326e-01 7.28145480e-01
 2.50675559e-01 5.99609256e-01 2.35154629e-01 2.01523304e-04
 9.02485847e-03 8.74842525e-01 1.62215501e-01 2.51481384e-01
 3.33285481e-01 2.35719413e-01 7.50859320e-01 5.08835554e-01
 3.82660598e-01 2.88438201e-02 1.44883990e-02 2.12007254e-01
 4.70409840e-01 1.52230561e-01 1.05984110e-11 4.32696581e-01
 4.29808766e-01 3.50495428e-01 1.55898035e-02 4.56498086e-01
 4.56463277e-01 5.10744870e-01 6.94401324e-01 3.78022909e-01
 7.27744460e-01 2.48059154e-01 2.94638574e-02 4.27604049e-01
 2.36297816e-01 9.86913860e-01 8.60360920e-01 8.18964720e-01
 9.16201591e-01 7.87024379e-01 8.41225147e-01 5.71787179e-01
 7.63892293e-01 9.03525710e-01 7.77745426e-01 7.84083128e-01
 9.40945625e-01 6.64400101e-01 8.22035432e-01 7.79568434e-01
 9.61276293e-01 8.66873801e-01 3.39414150e-01 3.66178155e-01
 3.55989575e-01 3.31403941e-01 3.28535199e-01 3.46744835e-01
 6.81060553e-03 3.45916271e-01 2.57915854e-01 9.06105340e-02
 3.48807961e-01 3.67896348e-01 3.95630777e-01 1.16666704e-01
 3.96195978e-01 2.85142660e-03 2.50359476e-02 4.16463196e-01
 3.47972661e-01 3.61052513e-01 3.72403920e-01 5.31929433e-02
 1.26997292e-01 1.78320229e-01 9.54299748e-01 3.30328435e-01
 5.51545441e-01 6.40776277e-01 4.99965280e-01 3.22463751e-01
 2.68312037e-01 4.14200306e-01 5.09949684e-01 5.69117725e-01
 2.07668066e-01 4.80493844e-01 4.02008832e-01 5.99962533e-01
 5.95600426e-01 8.29430938e-01 6.58152699e-02 2.60164857e-01
 1.15612775e-01 3.61386865e-01 3.54686618e-01 3.88212204e-01
 3.80026728e-01 4.79969293e-01 4.55575794e-01 4.02332783e-01
 3.74629855e-01 4.60641086e-01 2.64192820e-02 3.38508397e-01
 4.98586982e-01 3.78598452e-01 7.11220622e-01 3.22635353e-01
 2.44081020e-04 7.09747110e-06 1.03601247e-01 8.48592281e-01
 8.80949616e-01 4.23422456e-02 2.34188735e-01 3.46681476e-03
 3.18523645e-02 3.69065940e-01 1.84729338e-01 5.34251392e-01
 2.07641721e-03 8.42559338e-01 2.11483836e-02 8.48286748e-01
 2.49478221e-03 2.75283754e-01 8.21799040e-03 1.08385682e-02
 9.05209780e-03 5.59783280e-02 8.72713149e-01 9.80797410e-01
 1.44142985e-01 1.47046715e-01 2.36896992e-01 3.22082639e-03
 2.16873595e-05 8.79708296e-06 1.23875707e-01 1.24844670e-01
 1.41835213e-03 1.61220819e-01 1.62318408e-01 1.17609501e-02
 1.30624294e-01 4.94494766e-01 3.91169477e-17 8.49111259e-01
 6.82143450e-01 9.71282589e-07 6.04663193e-02 9.28372145e-04
 4.31798935e-01 3.37066770e-01 7.63207197e-01 3.02332920e-13
 2.44757533e-03 3.49165819e-13 9.08151269e-03 1.24287605e-03
 1.00631337e-09 3.95192832e-01 1.15163927e-10], shape=(211,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1.
 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(211,), dtype=float32)
predicted label rank:[1 1 1 2 2 1 1 1 2 2 1 1 1 2 2 1 1 1 1 1 1 2 1 2 1 2 2 1 2 1 2 2 2 1 1 2 1
 1 1 2 2 1 1 2 2 2 1 2 1 2 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2
 2 1 2 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 2 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1 1 1 2 2 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1]
mse:tf.Tensor(0.31374732, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/MOESI_1_e3_1884_e7_1875_000.smt2
true label:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
true label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1
 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1
 1 1 2 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 2 1 2 1 1 1 1
 1 1 1 2 1 2 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 2 1 1 1 2 1 1 1 1 2 1 1
 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 1 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 1 1 1 1 1 1 2 1 2 1 1 1
 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1
 1 1 1 2 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 2 1 1 1 2 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1
 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1
 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
predicted label:tf.Tensor(
[1.36085153e-02 5.95653057e-03 5.63497524e-05 3.26068699e-02
 1.21972735e-04 2.75492668e-03 8.71038437e-02 9.16622885e-05
 5.14525175e-03 4.32103872e-03 1.34824514e-02 2.46852636e-04
 1.77621841e-04 5.49488068e-02 8.79302621e-03 4.27356362e-03
 2.25711763e-02 6.78676367e-03 4.70870733e-03 7.43323565e-03
 6.46942854e-03 8.37923435e-05 2.78380513e-03 6.93757247e-05
 2.20537186e-04 8.24750168e-05 3.16628814e-03 4.86841798e-03
 3.77402284e-05 1.43080950e-03 1.41032338e-02 9.40465927e-03
 2.57792664e-07 1.29243993e-09 8.97794962e-03 7.37836957e-03
 1.70054436e-02 2.15330124e-02 1.50737464e-02 2.86984742e-02
 2.46066153e-02 1.25457942e-02 1.50668025e-02 2.40876079e-02
 1.73167586e-02 1.29615664e-02 2.98540890e-02 1.17577612e-02
 1.05603039e-02 2.71409750e-04 2.95490026e-04 2.67520845e-02
 4.44723368e-02 2.96808183e-02 2.89275944e-02 6.24743402e-02
 4.58919108e-02 3.88863683e-02 7.84041286e-02 8.24857354e-02
 3.39699984e-02 1.99423432e-02 1.50448680e-02 4.88987565e-02
 3.29748690e-02 3.35441232e-02 1.33284620e-05 5.81218740e-10
 1.73711777e-02 3.34980032e-05 9.62782718e-12 4.92921174e-02
 1.66938007e-02 1.44729018e-03 2.61249461e-05 1.36509538e-02
 7.96687603e-03 4.41876054e-03 8.38807225e-03 1.34170949e-02
 3.64169478e-03 9.48971510e-03 2.73825300e-08 3.94812238e-10
 1.04294717e-02 8.29130411e-04 2.27445364e-03 8.68293047e-02
 1.28740072e-03 5.45009607e-05 2.11088061e-02 1.58777833e-02
 1.76769495e-03 2.33876407e-02 1.20932758e-02 2.36204267e-03
 1.70556605e-02 3.81410122e-03 7.39198923e-03 5.38915396e-04
 1.08798444e-02 9.71502066e-03 5.71045876e-01 6.39754534e-03
 6.51800632e-03 7.58269429e-03 3.87981534e-03 1.36236409e-07
 8.40884447e-03 1.35171413e-03 1.22188628e-02 8.93831253e-03
 3.13712881e-05 7.19766831e-05 1.05902553e-03 4.04196978e-03
 8.29347968e-03 1.21413469e-02 7.14629889e-03 3.30784917e-03
 3.85141373e-03 1.45435333e-03 7.05757737e-03 1.73777342e-03
 2.00490057e-02 4.98530269e-03 3.48672271e-03 6.09818101e-03
 3.36804986e-03 7.36030936e-03 1.08155608e-02 4.65661883e-02
 2.68959641e-01 1.06559396e-02 4.24408913e-03 2.79805064e-03
 1.17877782e-04 6.78777695e-03 5.32669128e-06 7.48431921e-01
 7.49737918e-01 4.01445866e-01 6.49522722e-01 4.95934486e-03
 5.48222363e-02 2.49212056e-01 2.82454789e-02 2.90746613e-07
 9.96183634e-01 8.63615274e-01 1.96382403e-03 3.98792195e-30
 0.00000000e+00 9.99997973e-01 7.59679870e-06 9.98199761e-01
 5.19990921e-04 6.21242791e-18 2.08777189e-03 0.00000000e+00
 6.04852300e-19 9.32034671e-01 0.00000000e+00 1.51364438e-15
 1.65315192e-11 3.49451602e-02 0.00000000e+00 5.25152683e-03
 3.56436790e-11 7.15436637e-02 1.95916616e-09 2.13912040e-01
 1.77789175e-07 4.16736186e-01 6.31777630e-10 7.50943601e-01
 3.06953490e-02 2.13377643e-06 6.77695870e-03 1.19479413e-24
 2.11876631e-03 0.00000000e+00 3.17096710e-03 1.00000000e+00
 9.70244288e-01 1.85582638e-01 7.53920758e-05 1.01888984e-01
 3.12969983e-02 1.32024884e-02 2.73176730e-02 1.49373651e-01
 1.35481060e-01 5.68275154e-02 1.97131902e-01 2.24607140e-01
 1.83010578e-01 3.91326904e-01 7.37467110e-02 8.84666145e-02
 1.00746751e-03 2.05168664e-01 1.27148092e-01 3.42067540e-01
 1.26115650e-01 6.66900158e-01 1.80272609e-01 9.37472761e-01
 1.88057184e-01 1.22918397e-01 7.23327787e-07 2.33061761e-01
 8.63188207e-02 4.91946340e-02 3.30945611e-01 1.28502935e-01
 1.89532638e-02 4.14372981e-01 2.58549511e-01 4.65186149e-01
 6.72388077e-03 3.18619370e-01 1.78518891e-03 1.04093552e-03
 2.18844343e-06 2.96106700e-05 8.04337859e-03 9.56265751e-08
 1.05394993e-05 1.92910433e-04 1.07219275e-04 2.23129988e-04
 1.77621841e-04 2.99969925e-05 2.54907775e-08 1.85466695e-06
 9.84703802e-05 1.36840331e-22 2.84105323e-10 9.28882073e-05
 6.02902546e-05 1.70707703e-04 2.18093395e-04 1.92314386e-04
 8.25872557e-05 1.44839287e-04 5.74991427e-05 7.08041116e-05
 6.32875526e-05 1.10615394e-04 4.72265128e-05 7.18654992e-05
 1.68561935e-04 1.58637762e-04 1.39117241e-04 1.20434270e-04
 6.98242948e-05 1.49041414e-04 4.18921411e-02 5.60318828e-02
 5.19859195e-02 2.94410586e-02 1.82687044e-02 2.91212201e-02
 4.42168117e-02 2.44121552e-02 5.35128117e-02 2.48034596e-02
 3.61056805e-01 4.55418229e-02 9.41301882e-02 8.44877757e-15
 9.46103334e-02 9.87495303e-01 2.98319757e-02 9.97607350e-01
 6.49073720e-02 5.31356037e-02 4.55387478e-10 4.27136719e-02
 6.80501461e-02 3.45362812e-01 1.22613907e-02 3.17370296e-02
 4.86992724e-10 9.46494401e-01 1.00203481e-16 8.39644670e-03
 3.36793065e-03 5.80400229e-04 2.30905205e-01 9.38020647e-02
 2.05355734e-01 1.49699450e-01 6.49061799e-03 1.73696607e-01
 1.79970086e-01 1.26298279e-01 2.49870777e-01 2.73473501e-01
 3.09246421e-01 3.32161844e-01 2.61822224e-01 2.98839629e-01
 2.32188612e-01 4.36900198e-01 5.03211915e-01 4.51299191e-01
 4.76719499e-01 5.24204016e-01 4.74624246e-01 4.46877331e-01
 3.64309549e-01 1.17291063e-01 4.26332265e-01 4.28279608e-01
 5.12936890e-01 5.11419713e-01 4.95570153e-01 4.28673387e-01
 4.08506155e-01 4.20602471e-01 3.91605794e-01 4.72196758e-01
 1.04265183e-01 1.64762557e-01 2.19248891e-01 9.99648690e-01
 7.88364232e-01 6.70868814e-01 1.64767236e-01 1.22619092e-01
 4.97028530e-02 1.31860375e-03 3.64044309e-03 9.84721541e-01
 9.34541225e-04 6.17155731e-02 1.85524523e-02 4.31326032e-03
 9.39890146e-01 9.00176406e-01 2.56719887e-01 5.14917970e-02
 5.85433543e-02 5.03153205e-02 6.48467839e-02 4.04146016e-02
 5.50098121e-02 2.27371454e-02 1.82313025e-02 2.77874768e-02
 1.70654655e-02 1.81060731e-02 8.78483388e-06 8.51088762e-03
 9.08958852e-01 9.45214689e-01 1.66769981e-01 2.03963161e-01
 1.68341041e-01 4.25511599e-02 8.23175433e-05 1.65318727e-01
 2.30069041e-01 2.54423440e-01 1.94560736e-01 3.49013805e-02
 1.86602682e-01 7.50606060e-02 9.83091712e-01 2.28844792e-01
 9.99739289e-01 9.34191704e-01 8.73728335e-01 9.73826826e-01
 9.58251894e-01 9.93540287e-01 7.86212742e-01 9.94596601e-01
 8.97861362e-01 9.99992192e-01 9.61522043e-01 9.99331951e-01
 4.18216586e-02 9.98197794e-01 9.97036934e-01 2.19349593e-01
 5.93558609e-01 8.87124419e-01 9.26666498e-01 9.91523921e-01
 9.99993682e-01 9.99787569e-01 9.99969482e-01 9.89521623e-01
 1.96044445e-02 6.83028996e-01 1.78537220e-01 9.81341839e-01
 5.97639740e-01 9.92766500e-01 9.88976598e-01 2.28092074e-03
 7.71066368e-01 1.55316085e-01 6.81563914e-01 2.46711910e-01
 4.62644398e-01 8.35180283e-04 8.55063362e-08 5.66738784e-01
 5.13553321e-01 9.99998987e-01 7.22152352e-01 4.70983982e-03
 1.00406505e-04 9.92625117e-01 8.17849874e-01 9.65624809e-01
 9.82434750e-01 5.54083943e-01 5.69773793e-01 4.53309715e-01
 1.64191246e-01 4.10836816e-01 9.27502394e-01 4.47890729e-01
 9.99613464e-01 5.92028499e-01 9.34962153e-01 5.55627108e-01
 5.40787578e-01 7.80200958e-03 6.20853186e-01 3.30600768e-01
 7.54897058e-01 9.42878783e-01 3.36120248e-01 2.06570625e-02
 6.92319512e-01 6.36283398e-01 6.92725122e-01 6.27081037e-01
 5.83839417e-01 9.99933004e-01 8.68658364e-01 3.50266099e-01
 2.95242965e-01 1.53466552e-01 8.93099904e-01 4.05429304e-02
 3.45916241e-01 2.48766631e-01 2.48509496e-01 3.47623736e-01
 3.62903535e-01 1.84949011e-01 2.25400567e-01 1.68146998e-01
 4.24919128e-02 5.30607700e-02 9.16849673e-02 2.82745153e-01
 1.67194605e-01 1.03712410e-01 1.19659483e-01 2.08443850e-01
 1.65277719e-02 3.20902467e-02 7.35995173e-03 7.03417063e-02
 1.14128292e-02 3.39896977e-02 3.49341333e-02 1.37002766e-02
 1.12878382e-02 1.51087940e-02 5.86729050e-02 4.65424061e-02
 1.36311650e-02 2.33352780e-02 4.05521393e-02 1.20028019e-01
 2.31481194e-02 8.89517963e-02 2.42179841e-01 1.50887609e-01
 2.31985748e-02 6.64352477e-02 2.48880833e-01 2.05872059e-02
 8.64627957e-03 1.29549980e-01 6.05048537e-02 1.99038833e-01
 4.72787023e-02 3.83035392e-01 3.10291350e-02 7.18437731e-02
 8.56125057e-02 8.16225708e-02 2.56911218e-02 5.30394018e-02
 7.20167458e-02 9.55922306e-02 1.03711277e-01 1.27927870e-01
 1.80759668e-01 4.63331938e-02 1.43699229e-01 9.00030732e-02
 9.82401967e-02 1.82881296e-01 1.31879896e-01 3.66192460e-02
 2.79452622e-01 3.28404605e-02 1.83810234e-01 5.81210315e-01
 2.51747549e-01 3.10788095e-01 1.36958718e-01 8.36193562e-04
 6.09597564e-03 1.58587098e-03 3.52054834e-04 1.64598227e-04
 6.62267208e-04 1.32948309e-01 2.13688612e-03 1.64508820e-04
 9.55816795e-05 1.96695328e-04 1.78298354e-03 2.63049603e-02
 5.10811806e-04 1.24123394e-02 2.01016665e-04 2.02625990e-03
 4.82797623e-04 4.95284796e-04 2.54601240e-04 3.25682759e-03
 1.32369995e-03 8.48034024e-03 3.28779221e-04 1.44332647e-04
 2.23739892e-01 1.94509327e-02 3.44657898e-03 1.18495107e-01
 1.83597207e-03 1.94754004e-02 1.47446692e-02 1.65778697e-02
 1.31230354e-02 1.32171512e-02 2.36024082e-01 3.01824212e-02
 1.71116292e-02 6.81558251e-03 2.18497217e-02 8.14346075e-02
 2.31328607e-03 4.58109379e-03 4.16997075e-02 1.77973807e-02
 1.27002597e-02 1.10766888e-02 3.67026627e-02 1.52423084e-02
 3.32769752e-02 5.63263893e-04 2.26011872e-03 2.51858562e-01
 1.98365331e-01 9.99277890e-01 9.99988794e-01 4.74394888e-01
 5.31806529e-01 3.26801538e-01 2.71990716e-01 3.79684865e-01
 4.77329582e-01 4.71879750e-01 2.09114164e-01 4.56825107e-01
 5.13507366e-01 3.03670019e-01 8.34232867e-02 9.94152308e-01
 8.98083091e-01 4.65695679e-01 1.00000000e+00 9.99997616e-01
 4.31628108e-01 4.50598866e-01 5.11887431e-01 4.99336600e-01
 2.30020881e-02 1.00000000e+00 2.42997915e-01 2.62679279e-01
 7.76877403e-02 4.81963664e-01 1.91420317e-03 9.98887777e-01
 2.81716129e-05 1.85813755e-01 9.73079681e-01 6.90096617e-03
 1.12204209e-04 8.57046323e-10 3.33410442e-01 3.30133140e-02
 8.05540204e-01 9.39487815e-02 5.84393501e-01 3.25217843e-03
 4.28405702e-02 3.30762923e-01 9.92815733e-01 1.20878547e-01
 1.72811091e-01 8.65876675e-03 1.58585697e-01 2.56981134e-01
 2.46520519e-01 1.32453144e-01 2.14138389e-01 1.05034024e-01
 9.51136351e-02 8.59135151e-01 5.69918513e-01 1.29456133e-01
 2.01470733e-01 3.97893786e-03 2.45170891e-02 1.99472696e-01
 8.90249610e-02 1.77474976e-01 1.55976415e-03 6.82108700e-02
 5.15590310e-02 2.42657453e-01 2.50130177e-01 6.68785870e-02
 1.20082885e-01 1.46372557e-01 1.21359974e-01 8.86481575e-05
 5.45129061e-01 1.71062052e-02 4.09234732e-01 2.26832122e-01
 1.28615111e-01 9.51012969e-02 4.44165945e-01 1.99365139e-01
 2.24416941e-01 6.99488282e-01 1.99760497e-02 6.23815894e-01
 9.79678512e-01 3.42920899e-01 1.68216199e-01 3.89348954e-01
 4.56009388e-01 2.59442836e-01 3.32988888e-01 3.85032356e-01
 2.10705400e-03 2.08186716e-01 2.80458897e-01 9.30600643e-01
 3.56534928e-01 4.36135232e-02 9.98523831e-01 1.05297565e-03
 4.47112322e-01 7.26891458e-02 2.40870774e-01 4.51688528e-01
 2.78910637e-01 3.77586424e-01 3.39189440e-01 1.73653245e-01
 2.04265922e-01 5.16602576e-01 1.84408814e-01 6.73055649e-04
 1.37227774e-02 2.37645395e-07 1.21213496e-02 1.22657418e-03
 5.64783812e-04 1.80804223e-01 1.45310998e-01 5.52944839e-05
 8.83311033e-04 5.58039546e-03 1.24221742e-02 2.59041786e-04
 2.84790993e-04 1.14339518e-05 1.55827403e-03 3.06603312e-02
 5.23337722e-03 2.58594751e-04 2.02477968e-05 6.34989142e-03
 7.36406446e-03 5.09309769e-03 5.79559803e-03 1.07743144e-02
 3.24745178e-02 1.10742815e-13 3.18238735e-02 2.40029693e-01
 3.69668007e-04 5.22160828e-02 7.10121691e-02 6.92158937e-04
 9.30890441e-02 3.18562984e-03 5.72386384e-03 5.20166755e-03
 1.97869539e-03 2.23994255e-04 7.68987417e-01 9.35277820e-01
 8.84047449e-02 8.16853344e-01 2.53736973e-04 1.05888873e-01
 2.79918313e-03 1.19619668e-02 1.04976892e-02 1.11248195e-02
 2.86823511e-03 2.31236219e-03 1.87703967e-03 2.53140926e-04
 1.32424086e-01 3.67051244e-01 6.46740198e-03 1.46512628e-01
 2.67771482e-02 4.18329537e-02 3.29604149e-02 6.78905249e-02
 3.70083153e-02 2.72845626e-02 2.72035599e-02 6.16836846e-02
 4.16027904e-02 8.19340944e-02 1.14014208e-01 1.68840319e-01
 1.08016580e-01 8.35144520e-03 1.74928010e-02 2.37937510e-01
 1.15812391e-01 1.02012753e-02 8.05247282e-08 1.85230565e-32
 7.84948051e-01 1.45751238e-03 1.02009025e-35 3.74033809e-01
 4.18034196e-03 7.78774458e-15 4.26682954e-14 4.47011961e-27
 2.97914539e-06 1.93268061e-04 2.66750225e-14 3.77466596e-15
 1.35454351e-27 1.14059237e-19 1.89129726e-10 3.20030356e-16
 8.28057920e-18 7.59014842e-16 1.38731958e-15 1.11249361e-18
 9.58025865e-30 2.72073641e-33 3.09722918e-16 1.43830840e-16
 2.66287394e-27 5.75918602e-06 2.09637915e-11 2.67326832e-04
 1.57192926e-06 8.07942629e-01 8.56737852e-01 6.50843680e-01
 7.14367628e-01 2.65137166e-01 4.26948369e-02], shape=(803,), dtype=float32)
rounded label:tf.Tensor(
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0.
 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0.
 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1.
 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0.
 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0.], shape=(803,), dtype=float32)
predicted label rank:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1
 2 2 1 1 1 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1
 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1
 2 1 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2 1 2 1 2 2 2 2 1 2 1 2
 1 1 1 1 2 2 2 2 1 1 2 2 2 2 2 2 1 1 1 2 1 2 2 2 2 2 1 2 1 2 2 1 1 2 2 2 2
 2 2 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 2 1 1 2
 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 1 1 1 1 1 1
 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 2 2 1
 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 1]
mse:tf.Tensor(0.14782688, shape=(), dtype=float32)
-------
../benchmarks/LIA-lin-noInterval-trainData-datafold-templates/test_data/spline-fixed.smt2-0001_000.smt2
true label:[0, 1]
true label rank:[1 2]
predicted label:tf.Tensor([0.06148112 0.04796207], shape=(2,), dtype=float32)
rounded label:tf.Tensor([0. 0.], shape=(2,), dtype=float32)
predicted label rank:[1 1]
mse:tf.Tensor(0.4550781, shape=(), dtype=float32)
-------
mean(mse_list):0.18356556
